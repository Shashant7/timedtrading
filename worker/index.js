// Timed Trading Worker — KV latest + trail + rank + top lists + Discord alerts (CORRIDOR-ONLY)
import { DASHBOARD_HTML } from "./dashboard-html.js";
import {
  kvGetJSON,
  kvPutJSON,
  kvPutText,
  kvPutJSONWithRetry,
  stableHash,
  d1InsertTrailPoint,
  d1InsertIngestReceipt,
  slimPayloadForD1,
  minimalPayloadForD1,
} from "./storage.js";
import {
  normTicker,
  isNum,
  normalizeTfKey,
  validateTimedPayload,
  validateCapturePayload,
  validateCandlesPayload,
} from "./ingest.js";
import {
  KANBAN_STAGE_ORDER,
  LEGACY_STAGE_MAP,
  normalizeStage,
  enforceStageMonotonicity,
  getTradeDirection,
} from "./trading.js";
import {
  sendJSON,
  corsHeaders,
  ackJSON,
  readBodyAsJSON,
  requireKeyOr401,
  checkRateLimit,
  checkRateLimitFixedWindow,
} from "./api.js";
import {
  notifyDiscord,
  shouldSendDiscordAlert,
  generateProactiveAlerts,
} from "./alerts.js";
import {
  alpacaCronFetchLatest,
  alpacaBackfill,
  computeServerSideScores,
  computeTfBundle,
  assembleTickerData,
  getSessionType,
  signalFreshness,
  computeOvernightSignals,
  computeTDSequential,
  computeTDSequentialMultiTF,
} from "./indicators.js";
import { createExecutionAdapter } from "./execution.js";
import {
  shouldLogPrediction,
  logPrediction,
  matchPatterns,
  getActivePatterns,
  resolveExpiredPredictions,
  getModelHealth,
  runWeeklyRetrospective,
  computeMultiLevelPredictions,
  extractTDSeqFeatures,
} from "./model.js";

// ─── Pattern Library Cache (for Kanban integration) ────────────────────────
// Avoids hitting D1 on every ingest. Refreshes every 5 minutes.
let _patternCache = { patterns: [], ts: 0 };
const PATTERN_CACHE_TTL_MS = 5 * 60 * 1000; // 5 minutes

async function getCachedPatterns(DB) {
  if (!DB) return [];
  const now = Date.now();
  if (_patternCache.patterns.length > 0 && now - _patternCache.ts < PATTERN_CACHE_TTL_MS) {
    return _patternCache.patterns;
  }
  try {
    const patterns = await getActivePatterns(DB);
    // Pre-parse definition_json for fast matching
    const parsed = patterns.map(p => {
      try {
        return {
          ...p,
          definition_json: typeof p.definition_json === "string" ? JSON.parse(p.definition_json) : p.definition_json,
        };
      } catch { return null; }
    }).filter(Boolean);
    _patternCache = { patterns: parsed, ts: now };
    return parsed;
  } catch (e) {
    console.warn("[PATTERN CACHE] Failed to refresh:", String(e?.message || e).slice(0, 100));
    return _patternCache.patterns; // return stale cache on error
  }
}

/**
 * Match a payload against cached patterns and return enrichment data.
 * Designed to be called in the ingest hot path (synchronous matching, async cache refresh).
 */
function matchPatternsForPayload(payload, cachedPatterns) {
  if (!cachedPatterns || cachedPatterns.length === 0) return null;
  const matched = matchPatterns(payload, cachedPatterns);
  if (matched.length === 0) return null;

  const bullMatches = matched.filter(m => m.expected_direction === "UP");
  const bearMatches = matched.filter(m => m.expected_direction === "DOWN");
  const bestBull = bullMatches.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];
  const bestBear = bearMatches.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];

  const bullConf = bestBull?.confidence || 0;
  const bearConf = bestBear?.confidence || 0;
  const netSignal = bullConf - bearConf;

  return {
    matched: matched.map(m => ({ id: m.pattern_id, name: m.name, dir: m.expected_direction, conf: m.confidence, ev: m.expected_value })),
    bullCount: bullMatches.length,
    bearCount: bearMatches.length,
    bestBull: bestBull ? { id: bestBull.pattern_id, name: bestBull.name, conf: bestBull.confidence, ev: bestBull.expected_value } : null,
    bestBear: bestBear ? { id: bestBear.pattern_id, name: bestBear.name, conf: bestBear.confidence, ev: bestBear.expected_value } : null,
    netSignal: Math.round(netSignal * 1000) / 1000,
    direction: netSignal > 0.1 ? "BULLISH" : netSignal < -0.1 ? "BEARISH" : "NEUTRAL",
  };
}

// Routes:
// POST /timed/ingest?key=...
// GET  /timed/all
// GET  /timed/latest?ticker=XYZ
// GET  /timed/tickers
// GET  /timed/trail?ticker=XYZ
// GET  /timed/top?bucket=long|short|setup&n=10
// GET  /timed/momentum?ticker=XYZ
// GET  /timed/momentum/history?ticker=XYZ
// GET  /timed/momentum/all
// GET  /timed/sectors - Get all sectors and ratings
// GET  /timed/sectors/:sector/tickers?limit=10 - Get top tickers in sector
// GET  /timed/sectors/recommendations?limit=10&totalLimit=50 - Get top tickers across overweight sectors
// POST /timed/ingest-candles?key=... (multi-timeframe OHLCV capture)
// GET  /timed/candles?ticker=XYZ&tf=30&limit=200 (multi-timeframe OHLCV series)
// POST /timed/watchlist/add?key=... - Add tickers to watchlist
// POST /timed/cleanup-no-scores?key=... - Remove tickers without score data from index
// GET  /timed/health
// GET  /timed/version
// POST /timed/purge?key=... (manual purge)
// POST /timed/clear-rate-limit?key=...&ip=...&endpoint=... (clear rate limit)
// GET  /timed/trades?version=2.1.0 (get trades, optional version filter)
// POST /timed/trades?key=... (create/update trade)
// DELETE /timed/trades/:id?key=... (delete trade)
// GET  /timed/alert-debug?ticker=XYZ (debug why alerts aren't firing)
// GET  /timed/debug/trades (get all trades with details)
// GET  /timed/debug/tickers (get all tickers with latest data)
// GET  /timed/debug/config (check Discord and other config)
// POST /timed/debug/simulate-trades?key=... (manually simulate trades for all tickers)

/** Route table: [method, pathOrPredicate, key]. pathOrPredicate is exact path string or (pathname) => bool for param routes. */
const ROUTES = [
  ["POST", "/timed/ingest", "POST /timed/ingest"],
  ["POST", "/timed/ingest-capture", "POST /timed/ingest-capture"],
  ["POST", "/timed/ingest-candles", "POST /timed/ingest-candles"],
  ["POST", "/timed/heartbeat", "POST /timed/heartbeat"],
  ["GET", "/timed/latest", "GET /timed/latest"],
  ["GET", "/timed/tickers", "GET /timed/tickers"],
  ["GET", "/timed/all", "GET /timed/all"],
  ["GET", "/timed/candles", "GET /timed/candles"],
  ["GET", "/timed/trail/performance", "GET /timed/trail/performance"],
  ["GET", "/timed/trail", "GET /timed/trail"],
  ["GET", "/timed/top", "GET /timed/top"],
  ["GET", "/timed/momentum", "GET /timed/momentum"],
  ["GET", "/timed/momentum/history", "GET /timed/momentum/history"],
  ["GET", "/timed/momentum/all", "GET /timed/momentum/all"],
  ["GET", "/timed/sectors", "GET /timed/sectors"],
  ["GET", "/timed/sectors/recommendations", "GET /timed/sectors/recommendations"],
  ["GET", (p) => p.startsWith("/timed/sectors/") && p.endsWith("/tickers"), "GET /timed/sectors/:sector/tickers"],
  ["POST", "/timed/debug/fix-index", "POST /timed/debug/fix-index"],
  ["POST", "/timed/watchlist/add", "POST /timed/watchlist/add"],
  ["GET", "/timed/activity", "GET /timed/activity"],
  ["GET", "/timed/check-ticker", "GET /timed/check-ticker"],
  ["GET", "/timed/ingest-status", "GET /timed/ingest-status"],
  ["GET", "/timed/ingestion/stats", "GET /timed/ingestion/stats"],
  ["GET", "/timed/ingest-audit", "GET /timed/ingest-audit"],
  ["GET", "/timed/health", "GET /timed/health"],
  ["POST", "/timed/purge", "POST /timed/purge"],
  ["POST", "/timed/rebuild-index", "POST /timed/rebuild-index"],
  ["POST", "/timed/clear-rate-limit", "POST /timed/clear-rate-limit"],
  ["POST", "/timed/cleanup-tickers", "POST /timed/cleanup-tickers"],
  ["GET", "/timed/social-additions", "GET /timed/social-additions"],
  ["GET", "/timed/cors-debug", "GET /timed/cors-debug"],
  ["GET", "/timed/version", "GET /timed/version"],
  ["GET", "/timed/alert-debug", "GET /timed/alert-debug"],
  ["GET", "/timed/alert-replay", "GET /timed/alert-replay"],
  ["GET", (p) => p.startsWith("/timed/ledger/trades/") && p.endsWith("/decision-card"), "GET /timed/ledger/trades/:id/decision-card"],
  ["GET", (p) => p.startsWith("/timed/ledger/trades/"), "GET /timed/ledger/trades/:id"],
  ["GET", "/timed/ledger/trades", "GET /timed/ledger/trades"],
  ["GET", "/timed/ledger/alerts", "GET /timed/ledger/alerts"],
  ["GET", "/timed/ledger/summary", "GET /timed/ledger/summary"],
  ["GET", "/timed/trades", "GET /timed/trades"],
  ["GET", "/timed/portfolio", "GET /timed/portfolio"],
  ["POST", "/timed/trades", "POST /timed/trades"],
  ["DELETE", (p) => p.startsWith("/timed/trades/"), "DELETE /timed/trades/:id"],
  ["OPTIONS", "/timed/ai/chat", "OPTIONS /timed/ai/chat"],
  ["POST", "/timed/ai/chat", "POST /timed/ai/chat"],
  ["GET", "/timed/ai/updates", "GET /timed/ai/updates"],
  ["GET", "/timed/ai/daily-summary", "GET /timed/ai/daily-summary"],
  ["GET", "/timed/ai/monitor", "GET /timed/ai/monitor"],
  ["GET", "/timed/debug/trades", "GET /timed/debug/trades"],
  ["GET", "/timed/debug/tickers", "GET /timed/debug/tickers"],
  ["GET", "/timed/debug/config", "GET /timed/debug/config"],
  ["GET", "/timed/debug/daily", "GET /timed/debug/daily"],
  ["POST", "/timed/ml/train", "POST /timed/ml/train"],
  ["POST", "/timed/ml/backfill-queue", "POST /timed/ml/backfill-queue"],
  ["POST", "/timed/admin/replay-ticker", "POST /timed/admin/replay-ticker"],
  ["POST", "/timed/admin/replay-ticker-d1", "POST /timed/admin/replay-ticker-d1"],
  ["GET", "/timed/admin/replay-data-stats", "GET /timed/admin/replay-data-stats"],
  ["GET", "/timed/admin/data-range", "GET /timed/admin/data-range"],
  ["GET", "/timed/admin/history", "GET /timed/admin/history"],
  ["POST", "/timed/admin/replay-ingest", "POST /timed/admin/replay-ingest"],
  ["POST", "/timed/admin/replay-day", "POST /timed/admin/replay-day"],
  ["POST", "/timed/admin/dedupe-trades", "POST /timed/admin/dedupe-trades"],
  ["POST", "/timed/admin/refresh-latest-from-ingest", "POST /timed/admin/refresh-latest-from-ingest"],
  ["POST", "/timed/admin/force-sync", "POST /timed/admin/force-sync"],
  ["POST", "/timed/admin/fix-zero-ts-events", "POST /timed/admin/fix-zero-ts-events"],
  ["POST", "/timed/admin/reset", "POST /timed/admin/reset"],
  ["GET", "/timed/watchlist/coverage", "GET /timed/watchlist/coverage"],
  ["POST", "/timed/cleanup-no-scores", "POST /timed/cleanup-no-scores"],
  ["POST", "/timed/purge-trades-by-version", "POST /timed/purge-trades-by-version"],
  ["POST", "/timed/debug/migrate-brk", "POST /timed/debug/migrate-brk"],
  ["POST", "/timed/debug/cleanup-duplicates", "POST /timed/debug/cleanup-duplicates"],
  ["GET", "/timed/debug/score-analysis", "GET /timed/debug/score-analysis"],
  ["POST", "/timed/debug/purge-ticker", "POST /timed/debug/purge-ticker"],
  ["POST", "/timed/debug/cleanup-all-duplicates", "POST /timed/debug/cleanup-all-duplicates"],
  ["POST", "/timed/debug/recalculate-ranks", "POST /timed/debug/recalculate-ranks"],
  ["POST", "/timed/debug/fix-entry-prices", "POST /timed/debug/fix-entry-prices"],
  ["POST", "/timed/debug/fix-backfill-trades", "POST /timed/debug/fix-backfill-trades"],
  ["POST", "/timed/debug/clear-all-trades", "POST /timed/debug/clear-all-trades"],
  ["POST", "/timed/debug/simulate-trades", "POST /timed/debug/simulate-trades"],
  ["POST", "/timed/admin/reprocess-kanban", "POST /timed/admin/reprocess-kanban"],
  ["POST", "/timed/admin/backfill-trades", "POST /timed/admin/backfill-trades"],
  ["POST", "/timed/admin/backfill-positions", "POST /timed/admin/backfill-positions"],
  ["POST", "/timed/admin/backfill-alerts", "POST /timed/admin/backfill-alerts"],
  ["POST", "/timed/admin/backfill-derived", "POST /timed/admin/backfill-derived"],
  ["POST", "/timed/admin/alpaca-backfill", "POST /timed/admin/alpaca-backfill"],
  ["POST", "/timed/admin/alpaca-compute", "POST /timed/admin/alpaca-compute"],
  ["GET", "/timed/admin/alpaca-status", "GET /timed/admin/alpaca-status"],
  ["POST", "/timed/admin/candle-replay", "POST /timed/admin/candle-replay"],
  ["POST", "/timed/admin/run-lifecycle", "POST /timed/admin/run-lifecycle"],
  ["POST", "/timed/admin/model-resolve", "POST /timed/admin/model-resolve"],
  ["POST", "/timed/admin/model-retro", "POST /timed/admin/model-retro"],
  ["POST", "/timed/admin/model-approve", "POST /timed/admin/model-approve"],
  ["GET", "/timed/model/health", "GET /timed/model/health"],
  ["GET", "/timed/model/predictions", "GET /timed/model/predictions"],
  ["GET", "/timed/model/patterns", "GET /timed/model/patterns"],
  ["GET", "/timed/model/changelog", "GET /timed/model/changelog"],
  ["GET", "/timed/model/signals", "GET /timed/model/signals"],
];

function getRouteKey(method, pathname) {
  for (const [m, p, key] of ROUTES) {
    if (m !== method) continue;
    if (typeof p === "function") {
      if (p(pathname)) return key;
      continue;
    }
    if (p === pathname) return key;
  }
  return null;
}

// Trading day key in US/Eastern (for daily change vs yesterday close)
const NY_DAY_FMT = new Intl.DateTimeFormat("en-CA", {
  timeZone: "America/New_York",
  year: "numeric",
  month: "2-digit",
  day: "2-digit",
});
const NY_WD_FMT = new Intl.DateTimeFormat("en-US", {
  timeZone: "America/New_York",
  weekday: "short",
});
function nyTradingDayKey(tsMs) {
  const ms = Number(tsMs);
  if (!Number.isFinite(ms)) return null;
  try {
    return NY_DAY_FMT.format(new Date(ms)); // YYYY-MM-DD
  } catch {
    return null;
  }
}
function isNyWeekend(tsMs) {
  const ms = Number(tsMs);
  if (!Number.isFinite(ms)) return false;
  try {
    const wd = String(NY_WD_FMT.format(new Date(ms))).toLowerCase();
    return wd.startsWith("sat") || wd.startsWith("sun");
  } catch {
    return false;
  }
}

// Convert a wall-clock time in a TZ (YYYY-MM-DD at 00:00:00) to a UTC ms timestamp.
// We use a small fixed-point iteration to handle DST correctly.
const NY_TS_PARTS_FMT = new Intl.DateTimeFormat("en-US", {
  timeZone: "America/New_York",
  hour12: false,
  year: "numeric",
  month: "2-digit",
  day: "2-digit",
  hour: "2-digit",
  minute: "2-digit",
  second: "2-digit",
});
function tzOffsetMs(ts, timeZone) {
  const d = new Date(Number(ts));
  const parts = new Intl.DateTimeFormat("en-US", {
    timeZone,
    hour12: false,
    year: "numeric",
    month: "2-digit",
    day: "2-digit",
    hour: "2-digit",
    minute: "2-digit",
    second: "2-digit",
  }).formatToParts(d);
  const map = {};
  for (const p of parts) if (p.type !== "literal") map[p.type] = p.value;
  const asIso = `${map.year}-${map.month}-${map.day}T${map.hour}:${map.minute}:${map.second}Z`;
  const wallAsUtc = Date.parse(asIso);
  return wallAsUtc - Number(ts);
}
function nyWallMidnightToUtcMs(dayKey) {
  if (!dayKey) return null;
  const t0 = Date.parse(`${dayKey}T00:00:00Z`); // wall time interpreted as UTC
  if (!Number.isFinite(t0)) return null;
  let ts = t0;
  for (let i = 0; i < 3; i++) {
    const off = tzOffsetMs(ts, "America/New_York");
    const next = t0 - off;
    if (!Number.isFinite(next)) break;
    if (Math.abs(next - ts) < 1000) {
      ts = next;
      break;
    }
    ts = next;
  }
  return ts;
}

// Convert a NY wall-clock time (YYYY-MM-DD at HH:MM:SS) to a UTC ms timestamp.
// Uses the same fixed-point iteration as nyWallMidnightToUtcMs for DST correctness.
function nyWallTimeToUtcMs(dayKey, hh = 0, mm = 0, ss = 0) {
  if (!dayKey) return null;
  const H = String(Math.max(0, Math.min(23, Number(hh) || 0))).padStart(2, "0");
  const M = String(Math.max(0, Math.min(59, Number(mm) || 0))).padStart(2, "0");
  const S = String(Math.max(0, Math.min(59, Number(ss) || 0))).padStart(2, "0");
  const t0 = Date.parse(`${dayKey}T${H}:${M}:${S}Z`); // wall time interpreted as UTC
  if (!Number.isFinite(t0)) return null;
  let ts = t0;
  for (let i = 0; i < 3; i++) {
    const off = tzOffsetMs(ts, "America/New_York");
    const next = t0 - off;
    if (!Number.isFinite(next)) break;
    if (Math.abs(next - ts) < 1000) {
      ts = next;
      break;
    }
    ts = next;
  }
  return ts;
}

function prevTradingDayKey(dayKey) {
  if (!dayKey) return null;
  // Work with a stable noon UTC anchor so DST shifts don’t jump dates.
  let ms = Date.parse(`${dayKey}T12:00:00Z`);
  if (!Number.isFinite(ms)) return null;
  for (let i = 0; i < 10; i++) {
    ms -= 24 * 60 * 60 * 1000;
    const k = nyTradingDayKey(ms);
    if (!k) continue;
    if (!isNyWeekend(ms)) return k;
  }
  return null;
}

// True when previous state is from before today's market open and current bar is at/after open (AH/PM gap bridge).
function isFirstBarOfDayAfterGap(existingTs, currentTs, marketOpenTs) {
  if (!Number.isFinite(marketOpenTs)) return false;
  const cur = Number(currentTs);
  if (!Number.isFinite(cur) || cur < marketOpenTs) return false;
  const prev = Number(existingTs);
  return !Number.isFinite(prev) || prev < marketOpenTs;
}

async function computePrevCloseFromTrail(db, ticker, asOfTs) {
  if (!db || !ticker) return null;
  const dayKey = nyTradingDayKey(asOfTs);
  const prevKey = prevTradingDayKey(dayKey);
  if (!prevKey) return null;
  // Watchlist semantics: previous close = prior trading day regular session close (4pm ET).
  const closeCutoff = nyWallTimeToUtcMs(prevKey, 16, 0, 0);
  if (!Number.isFinite(closeCutoff)) return null;
  const lookbackStart = closeCutoff - 14 * 24 * 60 * 60 * 1000;
  try {
    const row = await db
      .prepare(
        `SELECT price AS price, ts AS ts
         FROM timed_trail
         WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3 AND price IS NOT NULL
         ORDER BY ts DESC
         LIMIT 1`,
      )
      .bind(String(ticker).toUpperCase(), lookbackStart, closeCutoff + 1000)
      .first();
    const p = Number(row?.price);
    const ts = Number(row?.ts);
    if (!Number.isFinite(p) || p <= 0) return null;
    return { close: p, ts: Number.isFinite(ts) ? ts : null, dayKey: prevKey };
  } catch {
    return null;
  }
}

// Derive a minimal ticker context from common payload fields.
// This is a fallback for when Pine capture throttles `payload.context`.
function deriveTickerContext(obj) {
  const pickStr = (...vals) => {
    for (const v of vals) {
      if (typeof v === "string") {
        const s = v.trim();
        if (s) return s;
      }
    }
    return "";
  };

  const fundamentals = obj?.fundamentals && typeof obj.fundamentals === "object"
    ? obj.fundamentals
    : {};
  const profile =
    obj?.profile && typeof obj.profile === "object"
      ? obj.profile
      : obj?.company_profile && typeof obj.company_profile === "object"
        ? obj.company_profile
        : {};
  const meta = obj?.meta && typeof obj.meta === "object" ? obj.meta : {};

  const name = pickStr(
    obj?.name,
    obj?.company_name,
    fundamentals?.name,
    fundamentals?.longName,
    fundamentals?.shortName,
    profile?.name,
    meta?.name,
  );
  const description = pickStr(
    obj?.description,
    fundamentals?.description,
    fundamentals?.business_summary,
    fundamentals?.longBusinessSummary,
    profile?.description,
    profile?.summary,
  );
  const sector = pickStr(obj?.sector, fundamentals?.sector, profile?.sector);
  const industry = pickStr(
    obj?.industry,
    fundamentals?.industry,
    profile?.industry,
  );
  const website = pickStr(obj?.website, fundamentals?.website, profile?.website);

  const out = {};
  if (name) out.name = name;
  if (description) out.description = description;
  if (sector) out.sector = sector;
  if (industry) out.industry = industry;
  if (website) out.website = website;

  return Object.keys(out).length > 0 ? out : null;
}

function mergeTickerContext(existing, incoming) {
  const a =
    existing && typeof existing === "object" && !Array.isArray(existing)
      ? existing
      : null;
  const b =
    incoming && typeof incoming === "object" && !Array.isArray(incoming)
      ? incoming
      : null;
  if (!a && !b) return null;
  if (!a) return b;
  if (!b) return a;

  const out = { ...a };
  for (const [k, v] of Object.entries(b)) {
    if (v == null) continue;
    if (typeof v === "string") {
      const s = v.trim();
      if (!s) continue;
      out[k] = s;
      continue;
    }
    out[k] = v;
  }
  return out;
}

function sanitizeTickerContext(ctx, hostObj = null) {
  if (!ctx || typeof ctx !== "object" || Array.isArray(ctx)) return null;
  const host = hostObj && typeof hostObj === "object" ? hostObj : null;

  const cleanStr = (s, fallback = "") => {
    if (s == null) return fallback;
    let v = String(s);
    // If something double-escaped upstream, normalize literal "\\r" sequences too.
    if (v.includes("\\r")) v = v.replace(/\\r/g, "r");
    // Some upstream strings contain a literal carriage return (\r) where "r" should be (seen in sector/name).
    // Prefer a known-good fallback when available; otherwise treat it as "r".
    if (v.includes("\r")) {
      if (fallback) return String(fallback);
      v = v.replace(/\r/g, "r");
    }
    return v.trim();
  };

  const out = { ...ctx };
  if (typeof out.name === "string") out.name = cleanStr(out.name, host?.name);
  if (typeof out.description === "string")
    out.description = cleanStr(out.description, host?.description);
  if (typeof out.sector === "string")
    out.sector = cleanStr(out.sector, host?.sector);
  if (typeof out.industry === "string")
    out.industry = cleanStr(out.industry, host?.industry);
  if (typeof out.country === "string")
    out.country = cleanStr(out.country, host?.country);

  // Nested string fields (keep objects but clean known strings).
  if (
    out.technical_rating &&
    typeof out.technical_rating === "object" &&
    !Array.isArray(out.technical_rating) &&
    typeof out.technical_rating.status === "string"
  ) {
    out.technical_rating = { ...out.technical_rating };
    out.technical_rating.status = cleanStr(out.technical_rating.status);
  }

  return out;
}

function numParam(url, key, fallback) {
  const v = url?.searchParams?.get(key);
  if (v == null || v === "") return fallback;
  const n = Number(v);
  return Number.isFinite(n) ? n : fallback;
}

async function ensureTickerIndex(KV, ticker) {
  try {
    const key = "timed:tickers";

    // Use retry logic to handle race conditions
    let retries = 3;
    let success = false;

    while (retries > 0 && !success) {
      const cur = (await kvGetJSON(KV, key)) || [];

      // Debug: Always log for BMNR/BABA/ETHT
      if (ticker === "BMNR" || ticker === "BABA" || ticker === "ETHT") {
        console.log(
          `[TICKER INDEX] ensureTickerIndex called for ${ticker} (retries: ${retries}):`,
          {
            alreadyInIndex: cur.includes(ticker),
            currentIndexSize: cur.length,
            indexSample: cur.slice(0, 10),
          },
        );
      }

      if (!cur.includes(ticker)) {
        cur.push(ticker);
        cur.sort();
        await kvPutJSON(KV, key, cur);

        // Verify it was added (with small delay to ensure KV consistency)
        await new Promise((resolve) => setTimeout(resolve, 50));
        const verify = (await kvGetJSON(KV, key)) || [];
        const wasAdded = verify.includes(ticker);

        if (wasAdded) {
          console.log(
            `[TICKER INDEX] Added ${ticker} to index. New count: ${cur.length}, Verified: ${wasAdded}`,
          );
          success = true;
        } else {
          // Retry if verification failed (possible race condition)
          console.warn(
            `[TICKER INDEX] ${ticker} verification failed, retrying... (retries left: ${
              retries - 1
            })`,
          );
          retries--;
          if (retries > 0) {
            await new Promise((resolve) => setTimeout(resolve, 100));
          }
        }

        if (
          !wasAdded &&
          retries === 0 &&
          (ticker === "BMNR" || ticker === "BABA" || ticker === "ETHT")
        ) {
          console.error(
            `[TICKER INDEX ERROR] ${ticker} was NOT added to index after ${3} retries!`,
            {
              beforeAdd: cur.length,
              afterAdd: verify.length,
              tickerInVerify: verify.includes(ticker),
              verifySample: verify.slice(0, 10),
            },
          );
        }
      } else {
        // Already in index - success
        if (ticker === "BMNR" || ticker === "BABA" || ticker === "ETHT") {
          console.log(
            `[TICKER INDEX DEBUG] ${ticker} already in index (count: ${cur.length})`,
          );
        }
        success = true;
      }
    }
  } catch (err) {
    console.error(`[TICKER INDEX ERROR] Failed to ensure ${ticker} in index:`, {
      error: String(err),
      message: err.message,
      stack: err.stack,
    });
    // Don't throw - we don't want index failures to break ingestion
  }
}

function marketType(ticker) {
  const t = String(ticker || "").toUpperCase();
  if (t.endsWith("USDT") || t.endsWith("USD")) return "CRYPTO_24_7";
  if (t.endsWith("1!")) return "FUTURES_24_5";
  if (["DXY", "US500", "USOIL", "GOLD", "SILVER"].includes(t)) return "MACRO";
  return "EQUITY_RTH";
}

function getEasternParts(date = new Date()) {
  const fmt = new Intl.DateTimeFormat("en-US", {
    timeZone: "America/New_York",
    weekday: "short",
    hour: "2-digit",
    minute: "2-digit",
    hour12: false,
  });
  const parts = fmt.formatToParts(date);
  const obj = {};
  for (const p of parts) obj[p.type] = p.value;
  return {
    weekday: obj.weekday || "",
    hour: Number(obj.hour || 0),
    minute: Number(obj.minute || 0),
  };
}

function isMarketHoursET(date = new Date()) {
  const { weekday, hour, minute } = getEasternParts(date);
  if (["Sat", "Sun"].includes(weekday)) return false;
  const mins = hour * 60 + minute;
  return mins >= 9 * 60 + 30 && mins <= 16 * 60;
}

function minutesSince(ts) {
  if (!ts || typeof ts !== "number") return null;
  return (Date.now() - ts) / 60000;
}

function formatUtcHourBucket(ts) {
  if (!Number.isFinite(ts)) return null;
  return new Date(ts).toISOString().slice(0, 13); // YYYY-MM-DDTHH (UTC)
}

function buildAlertDedupeKey({ ticker, action, side, ts }) {
  const t = String(ticker || "").toUpperCase();
  const act = String(action || "").toUpperCase();
  const dir = String(side || "").toUpperCase();
  const bucket = formatUtcHourBucket(ts);
  const day = bucket ? bucket.slice(0, 10) : null;
  if (!t || !act || !bucket) {
    return { key: null, bucket: null, day };
  }
  return {
    key: `timed:alerted:${t}:${act}:${dir || "UNKNOWN"}:${bucket}`,
    bucket,
    day,
  };
}

async function shouldSendTradeDiscordEvent(
  KV,
  { tradeId, type, ts },
  ttlSec = 48 * 60 * 60,
) {
  try {
    const id = String(tradeId || "").trim();
    const t = String(type || "")
      .trim()
      .toUpperCase();
    const ms = Number(ts);
    if (!id || !t || !Number.isFinite(ms)) {
      return { ok: true, key: null, deduped: false };
    }
    // Minute-bucketed idempotency. Prevents duplicate Discord posts caused by concurrent ingests/races.
    const bucket = Math.floor(ms / 60000);
    const key = `timed:dedupe:trade_event:${id}:${t}:${bucket}`;
    const already = await KV.get(key);
    if (already) return { ok: true, key, deduped: true };
    await kvPutText(KV, key, "1", ttlSec);
    return { ok: true, key, deduped: false };
  } catch (e) {
    // Fail open: better to alert than silently drop.
    return {
      ok: false,
      key: null,
      deduped: false,
      error: String(e?.message || e),
    };
  }
}

function stalenessBucket(ticker, ts) {
  const mt = marketType(ticker);
  const age = minutesSince(ts);
  if (age == null) return { mt, bucket: "UNKNOWN", ageMin: null };

  const warn = mt === "EQUITY_RTH" ? 120 : mt === "FUTURES_24_5" ? 60 : 30;
  const stale = mt === "EQUITY_RTH" ? 480 : mt === "FUTURES_24_5" ? 180 : 120;

  if (age <= warn) return { mt, bucket: "FRESH", ageMin: age };
  if (age <= stale) return { mt, bucket: "AGING", ageMin: age };
  return { mt, bucket: "STALE", ageMin: age };
}

/**
 * Check if a payload has changed meaningfully from the existing KV state.
 * Returns true if the write should proceed, false if it can be skipped.
 * Always writes if: kanban_stage changed, scores changed by >0.5, price changed by >0.1%, or no existing data.
 */
function hasPayloadChangedMeaningfully(existing, newPayload) {
  if (!existing || typeof existing !== "object") return true;
  if (!newPayload || typeof newPayload !== "object") return true;

  // Schema migration: force write if new payload has ema_map but existing doesn't
  if (newPayload.ema_map && !existing.ema_map) return true;

  // Always write if kanban stage changed
  const oldStage = String(existing?.kanban_stage || "");
  const newStage = String(newPayload?.kanban_stage || "");
  if (oldStage !== newStage) return true;

  // Always write if state changed
  const oldState = String(existing?.state || "");
  const newState = String(newPayload?.state || "");
  if (oldState !== newState) return true;

  // Always write if there's a trade event (entry_ts changed)
  const oldEntry = Number(existing?.entry_ts);
  const newEntry = Number(newPayload?.entry_ts);
  if (Number.isFinite(newEntry) && newEntry !== oldEntry) return true;

  // Score delta check (skip if HTF and LTF both moved < 0.5)
  const htfDelta = Math.abs((Number(newPayload?.htf_score) || 0) - (Number(existing?.htf_score) || 0));
  const ltfDelta = Math.abs((Number(newPayload?.ltf_score) || 0) - (Number(existing?.ltf_score) || 0));
  if (htfDelta >= 0.5 || ltfDelta >= 0.5) return true;

  // Price delta check (skip if price moved < 0.1%)
  const oldPrice = Number(existing?.price);
  const newPrice = Number(newPayload?.price);
  if (Number.isFinite(oldPrice) && Number.isFinite(newPrice) && oldPrice > 0) {
    const priceDelta = Math.abs(newPrice - oldPrice) / oldPrice;
    if (priceDelta >= 0.001) return true;
  } else if (Number.isFinite(newPrice)) {
    return true; // no old price, new one exists
  }

  // Flags change (any new flags that weren't there before)
  const oldFlags = existing?.flags || {};
  const newFlags = newPayload?.flags || {};
  for (const key of Object.keys(newFlags)) {
    if (newFlags[key] && !oldFlags[key]) return true;
  }

  // Time gate: always write at least once per 5 minutes
  const oldTs = Number(existing?.ts || existing?.ingest_ts);
  const newTs = Number(newPayload?.ts || newPayload?.ingest_ts);
  if (Number.isFinite(oldTs) && Number.isFinite(newTs) && (newTs - oldTs) > 5 * 60 * 1000) return true;

  return false;
}

function computeRR(d) {
  // RR should be based on the "entry reference" (trigger price when available),
  // otherwise it looks artificially better/worse after a move has already run.
  const price = Number(d.price);
  const entryRefRaw = Number(d.trigger_price);
  const entryRef =
    Number.isFinite(entryRefRaw) && entryRefRaw > 0 ? entryRefRaw : price;
  const sl = Number(d.sl);
  if (!Number.isFinite(entryRef) || !Number.isFinite(sl)) return null;

  // Use MAX TP from tp_levels if available, otherwise fall back to first TP
  let tp = Number(d.tp_max_price);
  if (!Number.isFinite(tp)) tp = Number(d.tp_target_price);
  if (!Number.isFinite(tp)) tp = Number(d.tp);
  if (d.tp_levels && Array.isArray(d.tp_levels) && d.tp_levels.length > 0) {
    // Extract prices from tp_levels (handle both object and number formats)
    const tpPrices = d.tp_levels
      .map((tpItem) => {
        if (
          typeof tpItem === "object" &&
          tpItem !== null &&
          tpItem.price != null
        ) {
          return Number(tpItem.price);
        }
        return typeof tpItem === "number" ? Number(tpItem) : Number(tpItem);
      })
      .filter((p) => Number.isFinite(p));

    if (tpPrices.length > 0) {
      // Use maximum TP for LONG, minimum for SHORT
      const state = String(d.state || "");
      const isLong = state.includes("BULL");
      const isShort = state.includes("BEAR");
      tp = isShort ? Math.min(...tpPrices) : Math.max(...tpPrices);
    }
  }

  if (!Number.isFinite(tp)) return null;

  // Determine direction from state to calculate risk/reward correctly
  const state = String(d.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");

  let risk, gain;

  if (isLong) {
    // For LONG: SL should be below entryRef, TP should be above entryRef
    risk = entryRef - sl;
    gain = tp - entryRef;
  } else if (isShort) {
    // For SHORT: SL should be above entryRef, TP should be below entryRef
    risk = sl - entryRef;
    gain = entryRef - tp;
  } else {
    // Fallback to absolute values if direction unclear
    risk = Math.abs(entryRef - sl);
    gain = Math.abs(tp - entryRef);
  }

  // Ensure both risk and gain are positive
  if (risk <= 0 || gain <= 0) return null;
  return gain / risk;
}

/**
 * RR WARNING SYSTEM: Data-driven warnings based on historical win rates.
 * 
 * From GOLD_PATTERNS_ANALYSIS.md:
 * - RR 0-2: 60.8% win rate (good)
 * - RR 2-5: 54.8% win rate (acceptable)
 * - RR 5-10: 16.4% win rate (AVOID!)
 * - RR 10-20: 29.4% win rate (medium)
 * - RR 20+: 85.9% win rate (excellent)
 * 
 * @param {number} rr - Risk/Reward ratio
 * @returns {object|null} - Warning info or null if no warning
 */
function computeRRWarning(rr) {
  if (!Number.isFinite(rr) || rr <= 0) return null;
  
  if (rr >= 5 && rr <= 10) {
    return {
      level: "WARNING",
      severity: "high",
      message: "RR 5-10 has historically low win rate (16.4%)",
      winRateEstimate: 0.164,
      recommendation: "Consider tighter stop or skip this trade",
      color: "orange",
    };
  }
  
  if (rr > 10 && rr < 20) {
    return {
      level: "CAUTION",
      severity: "medium",
      message: "RR 10-20 has moderate win rate (29.4%)",
      winRateEstimate: 0.294,
      recommendation: "Only if high conviction setup",
      color: "yellow",
    };
  }
  
  if (rr >= 20) {
    return {
      level: "FAVORABLE",
      severity: "none",
      message: "RR 20+ has excellent win rate (85.9%)",
      winRateEstimate: 0.859,
      recommendation: "Strong setup - favorable odds",
      color: "green",
    };
  }
  
  if (rr >= 2 && rr < 5) {
    return {
      level: "GOOD",
      severity: "none",
      message: "RR 2-5 has solid win rate (54.8%)",
      winRateEstimate: 0.548,
      recommendation: null,
      color: "blue",
    };
  }
  
  if (rr < 2) {
    return {
      level: "GOOD",
      severity: "none",
      message: "RR 0-2 has best win rate (60.8%)",
      winRateEstimate: 0.608,
      recommendation: null,
      color: "blue",
    };
  }
  
  return null;
}

// Helper function: completionForSize (normalize completion to 0-1)
// NOTE: Pine computes completion, but we keep a worker-side fallback for safety.
function completionForSize(ticker) {
  const c = Number(ticker?.completion);
  if (Number.isFinite(c)) return Math.max(0, Math.min(1, c));

  const price = Number(ticker?.price);
  const triggerPrice = Number(ticker?.trigger_price);
  const tp = Number(ticker?.tp);
  if (
    !Number.isFinite(price) ||
    !Number.isFinite(triggerPrice) ||
    !Number.isFinite(tp)
  )
    return 0;

  const denom = Math.abs(tp - triggerPrice);
  if (!(denom > 0)) return 0;

  const raw = Math.abs(price - triggerPrice) / denom;
  return Math.max(0, Math.min(1, raw));
}

function computeTpMaxFromLevels(ticker) {
  const tpMaxRaw = Number(ticker?.tp_max_price);
  if (Number.isFinite(tpMaxRaw) && tpMaxRaw > 0) return tpMaxRaw;
  const tpLevels = Array.isArray(ticker?.tp_levels) ? ticker.tp_levels : [];
  const tpPrices = tpLevels
    .map((tpItem) => {
      if (
        typeof tpItem === "object" &&
        tpItem !== null &&
        tpItem.price != null
      ) {
        return Number(tpItem.price);
      }
      return typeof tpItem === "number" ? Number(tpItem) : Number(tpItem);
    })
    .filter((p) => Number.isFinite(p));
  if (tpPrices.length === 0) return null;
  const state = String(ticker?.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");
  return isShort ? Math.min(...tpPrices) : Math.max(...tpPrices);
}

function computeCompletionToTpMax(ticker) {
  const price = Number(ticker?.price);
  const triggerPrice = Number(ticker?.trigger_price);
  const tpMax = computeTpMaxFromLevels(ticker);
  if (
    !Number.isFinite(price) ||
    !Number.isFinite(triggerPrice) ||
    !Number.isFinite(tpMax)
  )
    return null;
  const denom = Math.abs(tpMax - triggerPrice);
  if (!(denom > 0)) return null;
  const raw = Math.abs(price - triggerPrice) / denom;
  return Math.max(0, Math.min(1, raw));
}

function computeRRWith(entryRef, slRef, tpRef, state) {
  const e = Number(entryRef);
  const sl = Number(slRef);
  const tp = Number(tpRef);
  if (!Number.isFinite(e) || !Number.isFinite(sl) || !Number.isFinite(tp))
    return null;

  const s = String(state || "");
  const isLong = s.includes("BULL");
  const isShort = s.includes("BEAR");

  let risk, gain;
  if (isLong) {
    risk = e - sl;
    gain = tp - e;
  } else if (isShort) {
    risk = sl - e;
    gain = e - tp;
  } else {
    risk = Math.abs(e - sl);
    gain = Math.abs(tp - e);
  }
  if (!(risk > 0) || !(gain > 0)) return null;
  return gain / risk;
}

function computeDynamicStopBreakeven(ticker) {
  const state = String(ticker?.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");
  const sl = Number(ticker?.sl);
  const trig = Number(ticker?.trigger_price);
  if (!Number.isFinite(sl) || sl <= 0) return null;
  if (!Number.isFinite(trig) || trig <= 0) return sl;
  if (isShort) return Math.min(sl, trig);
  if (isLong) return Math.max(sl, trig);
  return sl;
}

function computeRRTargets(ticker) {
  const state = String(ticker?.state || "");
  const price = Number(ticker?.price);
  const triggerPrice = Number(ticker?.trigger_price);
  const sl = Number(ticker?.sl);
  const tpLikely =
    Number(ticker?.tp_target_price) ||
    Number(ticker?.tp_target) ||
    Number(ticker?.tp_target_price);
  const tpRef = Number.isFinite(tpLikely) && tpLikely > 0 ? tpLikely : null;
  if (!tpRef || !Number.isFinite(sl) || sl <= 0) return null;

  const entryRef =
    Number.isFinite(triggerPrice) && triggerPrice > 0 ? triggerPrice : null;
  const rrEntryLikely = entryRef
    ? computeRRWith(entryRef, sl, tpRef, state)
    : null;

  const dynStop = computeDynamicStopBreakeven(ticker);
  const rrNowLikely =
    Number.isFinite(price) && Number.isFinite(dynStop)
      ? computeRRWith(price, dynStop, tpRef, state)
      : null;

  return {
    tp_likely: tpRef,
    sl_dynamic: Number.isFinite(dynStop) ? dynStop : null,
    rr_entry_likely: Number.isFinite(rrEntryLikely) ? rrEntryLikely : null,
    rr_now_likely: Number.isFinite(rrNowLikely) ? rrNowLikely : null,
  };
}

function computeDataCompleteness(tickerData) {
  const hasTfTech = !!(
    tickerData?.tf_tech && typeof tickerData.tf_tech === "object"
  );
  const hasTriggersField = "triggers" in (tickerData || {});
  const triggersNonEmpty =
    Array.isArray(tickerData?.triggers) &&
    tickerData.triggers.some((t) => typeof t === "string" && t.trim());
  const hasTpLevels =
    Array.isArray(tickerData?.tp_levels) && tickerData.tp_levels.length > 0;
  const hasDailyEma = !!tickerData?.daily_ema_cloud;
  const hasIchD = !!tickerData?.ichimoku_d;
  const hasIchW = !!tickerData?.ichimoku_w;

  const missing = [];
  if (!hasTfTech) missing.push("tf_tech");
  if (!hasTriggersField) missing.push("triggers_field");
  if (!hasTpLevels) missing.push("tp_levels");
  if (!hasDailyEma) missing.push("daily_ema_cloud");
  if (!hasIchD) missing.push("ichimoku_d");
  if (!hasIchW) missing.push("ichimoku_w");

  // Score is intentionally simple + stable for UI filters.
  // 100 = fully instrumented, lower scores indicate missing context.
  let score = 100;
  if (!hasTfTech) score -= 35;
  if (!hasTriggersField) score -= 5;
  if (!hasTpLevels) score -= 10;
  if (!hasDailyEma) score -= 10;
  if (!hasIchD) score -= 15;
  if (!hasIchW) score -= 10;
  score = Math.max(0, Math.min(100, score));

  return {
    score,
    missing,
    has_tf_tech: hasTfTech,
    has_triggers_field: hasTriggersField,
    triggers_non_empty: triggersNonEmpty,
    has_tp_levels: hasTpLevels,
    has_daily_ema_cloud: hasDailyEma,
    has_ichimoku_d: hasIchD,
    has_ichimoku_w: hasIchW,
  };
}

function tfTechAlignmentSummary(tickerData) {
  const tfTech = tickerData?.tf_tech;
  if (!tfTech || typeof tfTech !== "object") return null;

  const side = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  if (!side) return null;

  const TF_ORDER = ["W", "D", "4H", "1H", "30", "10"];
  const WEIGHTS = { W: 2.0, D: 2.0, "4H": 1.5, "1H": 1.5, 30: 1.0, 10: 1.0 };

  let alignedW = 0;
  let opposedW = 0;
  let presentW = 0;
  const stacks = {};

  for (const k of TF_ORDER) {
    const row = tfTech[k];
    const stack = Number(row?.ema?.stack);
    if (!Number.isFinite(stack)) continue;
    presentW += WEIGHTS[k] || 1.0;
    stacks[k] = stack;
    const isAligned = side === "LONG" ? stack >= 4 : stack <= -4;
    const isOpposed = side === "LONG" ? stack <= -4 : stack >= 4;
    if (isAligned) alignedW += WEIGHTS[k] || 1.0;
    if (isOpposed) opposedW += WEIGHTS[k] || 1.0;
  }

  // Convert to a bounded score contribution:
  // - strong alignment across TFs => +0..+10
  // - strong opposition => down to -8
  const raw = alignedW - opposedW;
  const score = Math.max(-8, Math.min(10, raw * 2));

  const sq30 = tfTech["30"]?.sq;
  const sq10 = tfTech["10"]?.sq;
  const squeezeOn = !!(sq30?.s === 1 || sq10?.s === 1);
  const squeezeRel = !!(sq30?.r === 1 || sq10?.r === 1);

  return {
    score,
    side,
    aligned_weight: Math.round(alignedW * 10) / 10,
    opposed_weight: Math.round(opposedW * 10) / 10,
    present_weight: Math.round(presentW * 10) / 10,
    squeeze_on: squeezeOn,
    squeeze_release: squeezeRel,
    stacks,
  };
}

/**
 * GOLD STANDARD SCORING: Data-driven trigger scoring based on historical analysis.
 * 
 * Winner Correlation Data (from GOLD_PATTERNS_ANALYSIS.md):
 * - LTF Pullback (setup state): 84.3% of winners
 * - State Transition: 36.6% of winners
 * - HTF Improving: 34.1% of winners
 * - Squeeze ON (coiling): 21.8% of winners
 * - Squeeze Release: 8.8% of winners (WAS OVERWEIGHTED!)
 * - EMA Cross: 6.3% of winners (WAS OVERWEIGHTED!)
 * 
 * REDUCED WEIGHTS to match data:
 * - Squeeze Release 30M: +6 → +2
 * - EMA Cross 1H: +6 → +2
 * - Buyable Dip 1H: +7 → +3
 */
function triggerSummaryAndScore(tickerData) {
  const side = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  const list = Array.isArray(tickerData?.triggers)
    ? tickerData.triggers
        .filter((t) => typeof t === "string" && t.trim())
        .map((t) => t.trim())
    : [];

  const uniq = Array.from(new Set(list));
  let score = 0;

  const has = (s) => uniq.includes(s);
  const matchSide = (bull, bear) => {
    if (!side) return 0;
    if (side === "LONG" && has(bull)) return 1;
    if (side === "SHORT" && has(bear)) return 1;
    if (side === "LONG" && has(bear)) return -1;
    if (side === "SHORT" && has(bull)) return -1;
    return 0;
  };

  // REDUCED WEIGHTS based on Gold Standard analysis
  if (has("SQUEEZE_RELEASE_30M")) score += 2;  // Was +6, only 8.8% correlation
  score += 2 * matchSide("EMA_CROSS_1H_13_48_BULL", "EMA_CROSS_1H_13_48_BEAR");  // Was +6, only 6.3% correlation
  score += 1 * matchSide("EMA_CROSS_30M_13_48_BULL", "EMA_CROSS_30M_13_48_BEAR");  // Was +2
  if (has("ST_FLIP_1H")) score += 1;
  if (has("ST_FLIP_30M")) score += 1;
  score += 3 * matchSide("BUYABLE_DIP_1H_13_48_LONG", "BUYABLE_DIP_1H_13_48_SHORT");  // Was +7

  // LTF triggers (1m, 3m, 5m, 10m) — keep same weights (minor contributors)
  if (has("SQUEEZE_RELEASE_10M")) score += 1;  // Was +3
  if (has("SQUEEZE_RELEASE_5M")) score += 1;   // Was +2
  if (has("SQUEEZE_RELEASE_3M")) score += 0.5; // Was +1
  if (has("SQUEEZE_RELEASE_1M")) score += 0.5; // Was +1
  score += 1 * matchSide("EMA_CROSS_10M_13_48_BULL", "EMA_CROSS_10M_13_48_BEAR");  // Was +2
  score += 0.5 * matchSide("EMA_CROSS_5M_13_48_BULL", "EMA_CROSS_5M_13_48_BEAR");
  score += 0.5 * matchSide("EMA_CROSS_3M_13_48_BULL", "EMA_CROSS_3M_13_48_BEAR");
  score += 0.5 * matchSide("EMA_CROSS_1M_13_48_BULL", "EMA_CROSS_1M_13_48_BEAR");
  if (has("ST_FLIP_10M")) score += 0.5;
  if (has("ST_FLIP_5M")) score += 0.5;
  if (has("ST_FLIP_3M")) score += 0.5;
  if (has("ST_FLIP_1M")) score += 0.5;

  // Fallback for legacy payloads without triggers[] populated
  const flags = tickerData?.flags || {};
  if (uniq.length === 0) {
    if (flags.sq30_release) score += 2;           // Was +4
    if (flags.ema_cross_1h_13_48) score += 2;     // Was +5
    if (flags.buyable_dip_1h_13_48) score += 3;   // Was +7
    if (flags.sq10_release) score += 1;           // Was +3
    if (flags.sq5_release) score += 1;            // Was +2
    if (flags.sq3_release) score += 0.5;
    if (flags.sq1_release) score += 0.5;
    if (flags.ema_cross_10m_13_48) score += 1;
    if (flags.ema_cross_5m_13_48) score += 0.5;
    if (flags.ema_cross_3m_13_48) score += 0.5;
    if (flags.ema_cross_1m_13_48) score += 0.5;
    if (flags.st_flip_10m) score += 0.5;
    if (flags.st_flip_5m) score += 0.5;
    if (flags.st_flip_3m) score += 0.5;
    if (flags.st_flip_1m) score += 0.5;
  }

  score = Math.max(-6, Math.min(12, score));  // Reduced cap from 18 to 12

  return {
    score,
    side,
    count: uniq.length,
    top: uniq.slice(0, 5),
  };
}

/**
 * GOLD STANDARD SCORE: Data-driven scoring based on historical winner analysis.
 * 
 * This replaces complex scoring with signals that actually predict winners:
 * - LTF Pullback (setup state): 84.3% correlation
 * - State Transition: 36.6% correlation
 * - HTF Improving: 34.1% correlation
 * - Squeeze ON (coiling): 21.8% correlation
 * - Corridor alignment: High value (quality setups)
 * 
 * @param {object} d - Ticker data
 * @param {object} existing - Previous ticker state (for transition detection)
 * @returns {number} - Score 0-100
 */
function computeGoldScore(d, existing = null) {
  let score = 0;
  const state = String(d?.state || "");
  const htf = Number(d?.htf_score) || 0;
  const ltf = Number(d?.ltf_score) || 0;
  const flags = d?.flags || {};
  
  // ═══════════════════════════════════════════════════════════════════════
  // HIGHEST VALUE: LTF Pullback setup state (84.3% of winners)
  // ═══════════════════════════════════════════════════════════════════════
  const isSetup = state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";
  if (isSetup) score += 25;
  
  // LTF depth in pullback (deeper = better setup)
  const isBullSetup = state === "HTF_BULL_LTF_PULLBACK";
  const isBearSetup = state === "HTF_BEAR_LTF_PULLBACK";
  if (isBullSetup && ltf <= -5) score += 10;   // Deep pullback
  if (isBullSetup && ltf <= -10) score += 5;   // Very deep pullback
  if (isBearSetup && ltf >= 5) score += 10;    // Deep bear pullback
  if (isBearSetup && ltf >= 10) score += 5;    // Very deep
  
  // ═══════════════════════════════════════════════════════════════════════
  // HIGH VALUE: State transition & HTF improving (34-37% correlation)
  // ═══════════════════════════════════════════════════════════════════════
  if (existing && typeof existing === "object") {
    const prevState = existing.state;
    const prevHtf = Number(existing.htf_score) || 0;
    
    // State just changed
    if (prevState && prevState !== state) {
      score += 15;
      d.__state_just_changed = true;
    }
    
    // HTF improving (moving in favorable direction)
    const isBull = state.includes("BULL");
    const isBear = state.includes("BEAR");
    if ((isBull && htf > prevHtf) || (isBear && htf < prevHtf)) {
      score += 10;
      d.__htf_improving = true;
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════
  // MEDIUM VALUE: Squeeze ON - coiling (21.8% correlation)
  // Note: Squeeze ON is more predictive than Squeeze Release!
  // ═══════════════════════════════════════════════════════════════════════
  if (flags.sq30_on && !flags.sq30_release) score += 8;
  
  // ═══════════════════════════════════════════════════════════════════════
  // REDUCED VALUE: Squeeze release, EMA cross (was overweighted)
  // ═══════════════════════════════════════════════════════════════════════
  if (flags.sq30_release) score += 4;           // Was +12
  if (flags.ema_cross_1h_13_48) score += 2;     // Was +5-6
  
  // ═══════════════════════════════════════════════════════════════════════
  // CORRIDOR BONUS: Quality setup indicator
  // ═══════════════════════════════════════════════════════════════════════
  const inCorridor = corridorSide(d) != null;
  if (inCorridor) score += 12;
  if (inCorridor && isSetup) score += 8;  // Perfect setup: corridor + pullback
  
  // ═══════════════════════════════════════════════════════════════════════
  // MOMENTUM ALIGNMENT: Both TFs aligned
  // ═══════════════════════════════════════════════════════════════════════
  const isMomentum = state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  if (isMomentum && inCorridor) score += 5;
  
  return Math.max(0, Math.min(100, Math.round(score)));
}

function triggerReasonCorroboration(tickerData) {
  const rawReason =
    tickerData?.trigger_reason != null
      ? String(tickerData.trigger_reason).trim()
      : "";
  const rawDir =
    tickerData?.trigger_dir != null
      ? String(tickerData.trigger_dir).trim()
      : "";
  if (!rawReason) return { corroborated: true, note: "" };

  const triggers = Array.isArray(tickerData?.triggers)
    ? tickerData.triggers
        .filter((t) => typeof t === "string" && t.trim())
        .map((t) => t.trim())
    : [];
  const flags =
    tickerData?.flags && typeof tickerData.flags === "object"
      ? tickerData.flags
      : {};

  const hasAny = (...xs) => xs.some((x) => triggers.includes(x));

  // Only guard the noisy categories that can "stick" on HTF series.
  if (rawReason === "EMA_CROSS_1H_13_48") {
    const ok =
      hasAny("EMA_CROSS_1H_13_48_BULL", "EMA_CROSS_1H_13_48_BEAR") ||
      !!flags.ema_cross_1h_13_48;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }
  if (rawReason === "EMA_CROSS_30M_13_48") {
    const ok =
      hasAny("EMA_CROSS_30M_13_48_BULL", "EMA_CROSS_30M_13_48_BEAR") ||
      !!flags.ema_cross_30m_13_48;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }
  // LTF EMA cross (10m, 5m, 3m, 1m): corroborate if triggers[] or flags match
  if (
    /^EMA_CROSS_(10M|5M|3M|1M)_13_48$/i.test(rawReason) ||
    (rawReason.includes("EMA_CROSS") && /10M|5M|3M|1M/.test(rawReason))
  ) {
    const hasEmaTrigger =
      triggers.some(
        (t) =>
          /^EMA_CROSS_(10M|5M|3M|1M)_13_48_(BULL|BEAR)$/i.test(t),
      );
    const hasEmaFlag =
      !!(
        flags.ema_cross_10m_13_48 ||
        flags.ema_cross_5m_13_48 ||
        flags.ema_cross_3m_13_48 ||
        flags.ema_cross_1m_13_48
      );
    const ok = hasEmaTrigger || hasEmaFlag;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }
  // LTF squeeze release (10m, 5m, 3m, 1m)
  if (
    /^SQUEEZE_RELEASE_(10M|5M|3M|1M)$/i.test(rawReason) ||
    (rawReason.includes("SQUEEZE_RELEASE") && /10M|5M|3M|1M/.test(rawReason))
  ) {
    const hasSqTrigger = triggers.some((t) =>
      /^SQUEEZE_RELEASE_(10M|5M|3M|1M)$/i.test(t),
    );
    const hasSqFlag =
      !!(flags.sq10_release || flags.sq5_release || flags.sq3_release || flags.sq1_release);
    const ok = hasSqTrigger || hasSqFlag;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }

  return { corroborated: true, note: "" };
}

/**
 * Detect "Flip Watch" - tickers about to transition from PULLBACK to momentum
 * Based on analysis of top movers: 76% flipped from PULLBACK to momentum within 6h
 * Common traits: Low completion (<15%), Early phase (<35%), Strong HTF, In/near corridor
 */
function detectFlipWatch(tickerData, trail = []) {
  const state = String(tickerData?.state || "");
  const htfScore = Number(tickerData?.htf_score);
  const ltfScore = Number(tickerData?.ltf_score);
  const completion = Number(tickerData?.completion);
  const phase = Number(tickerData?.phase_pct);
  const flags = tickerData?.flags || {};

  // Must be in PULLBACK state (setup quadrant)
  const inPullback =
    state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";
  if (!inPullback) return null;

  const isBullSetup = state === "HTF_BULL_LTF_PULLBACK";
  const isBearSetup = state === "HTF_BEAR_LTF_PULLBACK";

  // Check corridor status
  const inCorridor = (() => {
    if (!Number.isFinite(htfScore) || !Number.isFinite(ltfScore)) return false;
    if (isBullSetup) {
      return htfScore > 0 && ltfScore >= -10 && ltfScore <= 0;
    } else if (isBearSetup) {
      return htfScore < 0 && ltfScore >= 0 && ltfScore <= 10;
    }
    return false;
  })();

  const nearCorridor = (() => {
    if (inCorridor) return false; // already in, not "near"
    if (!Number.isFinite(htfScore) || !Number.isFinite(ltfScore)) return false;
    if (isBullSetup) {
      // Near corridor: HTF positive, LTF slightly below corridor (-15 to -10)
      return htfScore > 0 && ltfScore >= -15 && ltfScore < -10;
    } else if (isBearSetup) {
      // Near corridor: HTF negative, LTF slightly above corridor (10 to 15)
      return htfScore < 0 && ltfScore > 10 && ltfScore <= 15;
    }
    return false;
  })();

  // Score components (0-100 scale)
  const reasons = [];
  let score = 0;

  // 1. Corridor status (30 points)
  if (inCorridor) {
    score += 30;
    reasons.push("In corridor");
  } else if (nearCorridor) {
    score += 20;
    reasons.push("Near corridor");
  }

  // 2. HTF strength (20 points) - Strong HTF indicates trend support
  const htfStrength = Math.abs(htfScore);
  if (htfStrength >= 20) {
    score += 20;
    reasons.push(`Strong HTF (${htfScore.toFixed(1)})`);
  } else if (htfStrength >= 15) {
    score += 15;
    reasons.push(`Moderate HTF (${htfScore.toFixed(1)})`);
  } else if (htfStrength >= 10) {
    score += 10;
    reasons.push(`Weak HTF (${htfScore.toFixed(1)})`);
  }

  // 3. Low completion (20 points) - 64% of winners had completion <15%
  if (Number.isFinite(completion)) {
    if (completion < 0.15) {
      score += 20;
      reasons.push(`Very low completion (${Math.round(completion * 100)}%)`);
    } else if (completion < 0.25) {
      score += 15;
      reasons.push(`Low completion (${Math.round(completion * 100)}%)`);
    } else if (completion < 0.35) {
      score += 10;
      reasons.push(`Moderate completion (${Math.round(completion * 100)}%)`);
    }
  }

  // 4. Early phase (15 points) - 52% of winners had phase <35%
  if (Number.isFinite(phase)) {
    if (phase < 0.35) {
      score += 15;
      reasons.push(`Early phase (${Math.round(phase * 100)}%)`);
    } else if (phase < 0.5) {
      score += 10;
      reasons.push(`Mid phase (${Math.round(phase * 100)}%)`);
    }
  }

  // 5. Squeeze signals (15 points) - 40% had sq30_on, 32% had sq30_release
  if (flags.sq30_release) {
    score += 15;
    reasons.push("Squeeze released");
  } else if (flags.sq30_on) {
    score += 10;
    reasons.push("Squeeze building");
  }

  // 6. HTF improving (bonus 10 points) - momentum building
  if (flags.htf_improving_4h) {
    score += 10;
    reasons.push("HTF improving");
  }

  // 7. LTF approaching flip zone (bonus) - LTF moving toward zero
  if (Number.isFinite(ltfScore)) {
    const ltfAbs = Math.abs(ltfScore);
    if (ltfAbs <= 5) {
      score += 5;
      reasons.push("LTF near flip zone");
    }
  }

  // 8. Check recent trail for momentum building (if available)
  if (Array.isArray(trail) && trail.length >= 2) {
    // Look at last 6 points (~30 minutes at 5m cadence)
    const recent = trail.slice(-6);
    const htfScores = recent
      .map((p) => Number(p?.htf_score))
      .filter(Number.isFinite);
    const ltfScores = recent
      .map((p) => Number(p?.ltf_score))
      .filter(Number.isFinite);

    if (htfScores.length >= 3) {
      // Check if HTF is strengthening
      const htfLast = htfScores[htfScores.length - 1];
      const htfFirst = htfScores[0];
      const htfImproving = isBullSetup
        ? htfLast > htfFirst
        : htfLast < htfFirst;
      if (htfImproving) {
        score += 5;
        reasons.push("HTF strengthening");
      }
    }

    if (ltfScores.length >= 3) {
      // Check if LTF is moving toward momentum zone
      const ltfLast = ltfScores[ltfScores.length - 1];
      const ltfFirst = ltfScores[0];
      const ltfMovingToMomentum = isBullSetup
        ? ltfLast > ltfFirst
        : ltfLast < ltfFirst;
      if (ltfMovingToMomentum) {
        score += 5;
        reasons.push("LTF moving to momentum");
      }
    }
  }

  // Require minimum score of 50 to flag as flip watch
  if (score < 50) return null;

  return {
    score,
    reasons,
    state,
    htf_score: htfScore,
    ltf_score: ltfScore,
    completion,
    phase,
    in_corridor: inCorridor,
    near_corridor: nearCorridor,
  };
}

/** 8 Kanban lanes (Worker = source of truth):
 *  watch, setup_watch | flip_watch, just_flipped | enter_now | just_entered | hold | trim | exit | archive
 *  UI maps: Watching | Almost Ready | Enter Now | Just Entered | Hold | Trim | Exit | Archived
 */

/**
 * Compute completion towards a specific TP tier (for 3-tier system).
 * Uses the TRIM TP (first tier) for trim lane decisions instead of generic completion.
 * @param {object} tickerData - Ticker payload
 * @param {string} tier - "TRIM", "EXIT", or "RUNNER"
 * @returns {number} - Completion percentage (0-1) towards the specified tier's TP
 */
function computeCompletionToTier(tickerData, tier = "TRIM") {
  const price = Number(tickerData?.price);
  const entryPrice = Number(tickerData?.entry_price);
  const direction = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  
  if (!Number.isFinite(price) || !Number.isFinite(entryPrice) || !direction) {
    return Number(tickerData?.completion) || 0; // Fallback to generic completion
  }
  
  // Build or get TP array
  const tpArray = tickerData?.tpArray || build3TierTPArray(tickerData, entryPrice, direction);
  if (!Array.isArray(tpArray) || tpArray.length === 0) {
    return Number(tickerData?.completion) || 0;
  }
  
  // Find the target tier's TP
  const targetTp = tpArray.find(tp => tp.tier === tier);
  if (!targetTp || !Number.isFinite(targetTp.price)) {
    return Number(tickerData?.completion) || 0;
  }
  
  const tpPrice = targetTp.price;
  const isLong = direction === "LONG";
  
  // Calculate completion: how much of the move from entry to TP has been achieved
  const totalMove = Math.abs(tpPrice - entryPrice);
  if (totalMove <= 0) return 0;
  
  const currentMove = isLong
    ? Math.max(0, price - entryPrice)
    : Math.max(0, entryPrice - price);
  
  return Math.min(1, currentMove / totalMove);
}

/**
 * Check if a ticker qualifies for ENTER stage based on consolidated criteria.
 * 4 data-driven paths derived from Gold Standard analysis:
 * - Path 1: Gold Standard LONG (67.7% of big UP moves)
 * - Path 2: Gold Standard SHORT (82.7% of big DOWN moves)
 * - Path 3: Momentum + High Score (balanced approach)
 * - Path 4: Setup + Squeeze Release (explosive move)
 * 
 * @param {object} d - Ticker data
 * @returns {object} - { qualifies, path, confidence, reason }
 */
function qualifiesForEnter(d, asOfTs = null) {
  const state = String(d?.state || "");
  const inCorridor = corridorSide(d) != null;
  const score = Number(d?.score ?? d?.rank) || 0;
  const flags = d?.flags || {};
  const htf = Number(d?.htf_score) || 0;
  const ltf = Number(d?.ltf_score) || 0;
  const completion = Number(d?.completion) || 0;
  const phase = Number(d?.phase_pct) || 0;
  const rr = Number(d?.rr) || 0;
  
  // ── PRECISION SCORING ENGINE v2 fields ──
  const stSupportScore = d?.st_support?.supportScore ?? 0.5; // 0.0–1.0, 0.5 = neutral
  const fuel30 = d?.fuel?.["30"]?.fuelPct ?? 50;
  const fuel10 = d?.fuel?.["10"]?.fuelPct ?? 50;
  const fuelD = d?.fuel?.D?.fuelPct ?? 50;
  const primaryFuel = Math.max(fuel30, fuel10); // best LTF fuel reading
  // EMA triplet: depth (0-10), structure (-1 to +1), momentum (-1 to +1)
  const emaDepth30 = d?.ema_map?.["30"]?.depth ?? 5;
  const emaDepthD = d?.ema_map?.D?.depth ?? 5;
  const emaStruct30 = d?.ema_map?.["30"]?.structure ?? 0;
  const emaStructD = d?.ema_map?.D?.structure ?? 0;
  const emaMom30 = d?.ema_map?.["30"]?.momentum ?? 0;
  const emaMomD = d?.ema_map?.D?.momentum ?? 0;
  const activeGates = d?.active_gates || [];
  const hasActiveGate = activeGates.length > 0;
  const hasActiveBullGate = activeGates.some(g => g.side === "bull" && !g.completed);
  const hasActiveBearGate = activeGates.some(g => g.side === "bear" && !g.completed);
  const multiHorizonGate = activeGates.filter(g => !g.completed).length >= 2; // Day + Week both active
  
  // ═══════════════════════════════════════════════════════════════════════════
  // UNIVERSAL HARD GATES: Apply to ALL entries
  // ═══════════════════════════════════════════════════════════════════════════
  
  // Trigger freshness: reject stale triggers (> 7 days old for replays, allows more historical data)
  // Use asOfTs for replays (historical data), otherwise current time
  const triggerTs = Number(d?.trigger_ts) || 0;
  const now = asOfTs > 0 ? asOfTs : Date.now();
  const triggerAgeDays = triggerTs > 0 ? (now - triggerTs) / (1000 * 60 * 60 * 24) : 999;
  if (triggerAgeDays > 7) {
    return { qualifies: false, reason: "trigger_stale" };
  }
  
  // Completion gate: must have room to run
  // JOURNEY DATA: Top sustained moves had median completion <30% at start.
  // Tighter than before: cap at 50% (momentum) / 70% (pullback)
  const isPullback = state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";
  const maxCompletion = isPullback ? 0.70 : 0.50;
  if (completion > maxCompletion) {
    return { qualifies: false, reason: "move_too_advanced" };
  }
  
  // Fuel gate (replaces binary phase gate): continuous 0-100% measure of move exhaustion
  // Combines phase oscillator (60%) + RSI distance from extremes (40%)
  // Minimum fuel required: 40% for momentum, 30% for pullback (pullbacks inherently show lower fuel)
  // Legacy fallback: if fuel data not available, use the old phase gate
  const hasFuelData = d?.fuel != null;
  if (hasFuelData) {
    const minFuel = isPullback ? 30 : 40;
    if (primaryFuel < minFuel) {
      return { qualifies: false, reason: "fuel_exhausted", fuelPct: primaryFuel };
    }
  } else {
    // Legacy phase gate (backward compat for data without fuel fields)
    const maxPhase = isPullback ? 0.60 : 0.45;
    if (Math.abs(phase) > maxPhase) {
      return { qualifies: false, reason: "phase_too_late" };
    }
  }
  
  // RR gate: must have favorable risk/reward
  // CANDLE BACKTEST DATA (Jan 13 - Feb 7, 2,257 closed trades):
  //   RR < 1.5: 22.8% WR (1,166 trades — too many bad entries)
  //   RR 1.5-3: 48.0% WR (546 trades — breakeven+)
  //   RR 3-5:   66.2% WR (296 trades — good edge)
  //   RR 5+:    87.1% WR (249 trades — strong edge)
  // TUNING v2: Pullback entries naturally have lower computed RR (tight ATR-based SL).
  //   Fully blocking RR < 1.5 killed 84% of trades including the 37.8% WR pullback longs.
  //   Graduated: RR >= 1.5 for momentum, RR >= 1.0 for pullbacks (prevents only truly terrible setups)
  // Skip R:R check when RR cannot be computed (missing SL/TP in stored data)
  // Skip R:R check for gold_short entries (TradingView sends LONG-oriented SL/TP)
  const isPotentialGoldShort = state === "HTF_BULL_LTF_BULL" && htf >= 25 && ltf >= 15;
  const rrKnown = Number.isFinite(rr) && rr > 0;
  const rrMin = isPullback ? 1.0 : 1.5;
  if (rrKnown && rr < rrMin && !isPotentialGoldShort) {
    return { qualifies: false, reason: "rr_too_low" };
  }
  
  // ─────────────────────────────────────────────────────────────────────────────
  // CRITICAL: Price vs SL validation - reject stale signals already past SL
  // VERSION: 2.6.4 - Direction-aware SL validation
  // ─────────────────────────────────────────────────────────────────────────────
  // A signal that has already breached its SL is INVALID for entry
  // BUT: TradingView sends SL assuming LONG direction. For SHORT entries,
  // the SL will be computed/flipped at trade creation time, so we only validate
  // if the raw SL is already on the correct side for the intended direction.
  //
  // For LONG: raw sl should be BELOW price (standard TradingView format)
  //           if price < sl, the LONG entry has already failed its stop
  // For SHORT: raw sl is typically BELOW price (TradingView LONG format)
  //            we'll compute a new SL above price at trade creation, so skip validation
  const currentPrice = Number(d?.price);
  const sl = Number(d?.sl);
  
  if (Number.isFinite(currentPrice) && currentPrice > 0 && Number.isFinite(sl) && sl > 0) {
    // Infer intended direction from state (used for general classification)
    // BUT: Entry paths like gold_short override this direction at trade creation
    // So we only apply strict SL validation for LONG entries from PULLBACK states
    const inferredDirection = sideFromStateOrScores(d);
    const isBullishPullback = state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_RALLY";
    
    // Only validate SL for LONG entries from pullback states (where SL is correctly below price)
    // SHORT entries (gold_short from HTF_BULL_LTF_BULL) will have SL computed above price later
    if (inferredDirection === "LONG" && isBullishPullback && currentPrice < sl) {
      // Price already below SL for a LONG pullback entry - signal has failed
      return { qualifies: false, reason: "price_below_sl_long" };
    }
    
    // For LONG entries: check minimum distance from SL (only if SL is below price)
    // JOURNEY DATA: Median pullback is 1.22%. If SL is < 0.8% away, there's no room
    // to survive even a small dip. Require at least 0.8% distance.
    if (inferredDirection === "LONG" && sl < currentPrice) {
      const distToSL = (currentPrice - sl) / currentPrice;
      if (distToSL < 0.008) {
        return { qualifies: false, reason: "price_too_close_to_sl" };
      }
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // SECTOR ALIGNMENT: Boost confidence when the sector is aligned
  // Real-world proof: NVDA, AVGO, TSM all LONG on 2/5/26, all ran because
  // the entire semiconductor sector (6+ tickers) had HTF > 15.
  // ═══════════════════════════════════════════════════════════════════════════
  const ticker = String(d?.ticker || "").toUpperCase();
  const sectorAlign = getSectorAlignmentCached(ticker);
  const sectorAligned = !!(sectorAlign?.aligned);
  const sectorBull = sectorAlign?.direction === "BULL";
  const sectorBear = sectorAlign?.direction === "BEAR";
  const sectorStrength = sectorAlign?.strength || 0;

  // ═══════════════════════════════════════════════════════════════════════════
  // ST SUPPORT MAP GATE: Multi-TF SuperTrend alignment check
  // supportScore: 0.0 = all bearish, 0.5 = neutral, 1.0 = all bullish
  // For LONG momentum entries: require >= 0.5 (majority of TFs bullish)
  // For pullback entries: require >= 0.3 (allow counter-LTF dips)
  // Golden Gate active = bypass support gate (probabilistic edge overrides)
  // ═══════════════════════════════════════════════════════════════════════════
  const hasSupportData = d?.st_support != null;
  if (hasSupportData) {
    const isBullEntry = state.includes("BULL_LTF_BULL") || state === "HTF_BULL_LTF_PULLBACK";
    const isBearEntry = state.includes("BEAR_LTF_BEAR") || state === "HTF_BEAR_LTF_PULLBACK";
    const minSupport = isPullback ? 0.3 : 0.5;
    
    if (isBullEntry && stSupportScore < minSupport && !hasActiveBullGate) {
      return { qualifies: false, reason: "st_support_weak_bull", supportScore: stSupportScore };
    }
    if (isBearEntry && (1 - stSupportScore) < minSupport && !hasActiveBearGate) {
      return { qualifies: false, reason: "st_support_weak_bear", supportScore: stSupportScore };
    }
  }

  // ═══════════════════════════════════════════════════════════════════════════
  // CONFIRMATION SIGNALS: Required for higher quality entries
  // Signals from server-side scoring (flags) now carry timestamps and are
  // subject to freshness decay. TradingView trigger-based signals are treated
  // as inherently fresh (they arrive in real-time).
  // ═══════════════════════════════════════════════════════════════════════════
  
  // Detect SuperTrend and EMA confirmation signals from triggers
  const triggers = d?.triggers || [];
  const triggerSet = new Set(triggers.map(t => String(t).toUpperCase()));
  
  // Freshness threshold: signals below this are considered stale
  const FRESHNESS_MIN = 0.3;
  
  // Helper: check flag + freshness in one step
  const flagFresh = (flag, flagTs, signalType) => {
    if (!flag) return false;
    if (!flagTs || flagTs <= 0) return true; // legacy data without timestamp — accept
    return signalFreshness(flagTs, now, signalType) >= FRESHNESS_MIN;
  };
  
  // SuperTrend flip (bullish or bearish) on any timeframe
  // Triggers from TradingView are always fresh; flag-based signals use decay
  const hasStFlipBull = triggerSet.has("ST_FLIP_30M") || triggerSet.has("ST_FLIP_1H") || 
                        triggerSet.has("ST_FLIP_10M") || triggerSet.has("ST_FLIP_3M") ||
                        flagFresh(flags.st_flip_30m, flags.st_flip_30m_ts, "momentum") ||
                        flagFresh(flags.st_flip_1h, flags.st_flip_1h_ts, "structural") ||
                        flagFresh(flags.st_flip_10m, flags.st_flip_10m_ts, "momentum") ||
                        flagFresh(flags.st_flip_3m, flags.st_flip_3m_ts, "momentum");
  
  // EMA cross signals (confirmation of momentum)
  const hasEmaCrossBull = triggerSet.has("EMA_CROSS_1H_13_48_BULL") || triggerSet.has("EMA_CROSS_30M_13_48_BULL") ||
                          triggerSet.has("EMA_CROSS_10M_13_48_BULL") ||
                          flagFresh(flags.ema_cross_1h_13_48, flags.ema_cross_1h_13_48_ts, "entry") ||
                          flagFresh(flags.ema_cross_30m_13_48, flags.ema_cross_30m_13_48_ts, "entry");
  const hasEmaCrossBear = triggerSet.has("EMA_CROSS_1H_13_48_BEAR") || triggerSet.has("EMA_CROSS_30M_13_48_BEAR") ||
                          triggerSet.has("EMA_CROSS_10M_13_48_BEAR");
  
  // Squeeze release (explosive potential)
  const hasSqRelease = triggerSet.has("SQUEEZE_RELEASE_30M") || triggerSet.has("SQUEEZE_RELEASE_1H") ||
                       flagFresh(flags.sq30_release, flags.sq30_release_ts, "momentum") ||
                       flagFresh(flags.sq1h_release, flags.sq1h_release_ts, "entry");
  
  // LTF momentum confirmation: LTF score should be turning (not deeply negative for LONG)
  // For pullback entries, we want to see LTF recovering (ltf > -10) or momentum signals
  const ltfRecovering = ltf > -10 || hasStFlipBull || hasEmaCrossBull || hasSqRelease;
  
  // ── PRECISION ENRICHMENT HELPER ──
  // Wraps entry path results with precision scoring context.
  // Golden Gate active → confidence upgrade. Multi-horizon gate → highest conviction.
  const enrichResult = (result) => {
    if (!result.qualifies) return result;
    // Golden Gate confidence boost
    const isLong = !result.path?.includes("short");
    const gateMatch = isLong ? hasActiveBullGate : hasActiveBearGate;
    if (gateMatch) {
      // Upgrade confidence: low → medium, medium → high
      if (result.confidence === "low") result.confidence = "medium";
      else if (result.confidence === "medium" && multiHorizonGate) result.confidence = "high";
      result.gate_boost = true;
    }
    if (multiHorizonGate) result.multi_horizon_gate = true;
    // Attach precision metrics for downstream logging/decisions
    result.precision = {
      fuelPct: primaryFuel,
      supportScore: stSupportScore,
      emaDepth30, emaDepthD,
      emaStruct30, emaStructD,
      emaMom30, emaMomD,
      activeGateCount: activeGates.length,
    };
    return result;
  };
  
  // ═══════════════════════════════════════════════════════════════════════════
  // ENTRY PATHS: Each path has its own corridor/setup requirements
  // ═══════════════════════════════════════════════════════════════════════════
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 1: GOLD LONG (67.7% of big UP moves start from HTF_BULL_LTF_PULLBACK)
  // Historical: median HTF=20, median LTF=-9 at move start
  // Strategy: Buy the pullback in a bullish trend when LTF starts recovering
  // SECTOR ALIGNMENT BOOST: When sector is bullish, relax thresholds and boost confidence
  // ═══════════════════════════════════════════════════════════════════════════
  if (state === "HTF_BULL_LTF_PULLBACK") {
    // DATA: gold_long had 82% loss rate (292 trades, -$20k). The pullbackCorridor
    // was too loose — any LTF -5 to -10 passed because ltfRecovering was trivially true.
    // Tighten: require HTF >= 10 (stronger trend), and require a REAL confirmation signal
    // (SuperTrend flip, EMA cross, or squeeze release), not just ltf > -10.
    const htfMin = (sectorBull && sectorStrength >= 50) ? 8 : 10;
    const pullbackCorridor = htf >= htfMin && ltf >= -25 && ltf <= 3;
    const hasRealConfirmation = hasStFlipBull || hasEmaCrossBull || hasSqRelease;
    if (pullbackCorridor) {
      // High confidence: deep pullback WITH real recovery confirmation signal
      if (ltf <= -5 && hasRealConfirmation) {
        const conf = (sectorBull && sectorStrength >= 60) ? "high_sector" : "high";
        return enrichResult({ qualifies: true, path: "gold_long", confidence: conf, reason: "pullback_with_confirmation", sectorStrength });
      }
      // Medium→High with sector: shallow pullback with SuperTrend or EMA confirmation
      if (ltf <= 0 && (hasStFlipBull || hasEmaCrossBull)) {
        const conf = (sectorBull && sectorStrength >= 60) ? "high" : "medium";
        return enrichResult({ qualifies: true, path: "gold_long_shallow", confidence: conf, reason: "shallow_with_signal", sectorStrength });
      }
      // Medium confidence: deep pullback with strong HTF structure
      // DATA: gold_long_deep had 81% loss rate (223 trades, -$16k). Tighten:
      //   HTF 10→15, LTF -8→-12, require real confirmation OR strong sector alignment
      if (ltf <= -12 && htf >= 15 && (hasRealConfirmation || (sectorBull && sectorStrength >= 60))) {
        return enrichResult({ qualifies: true, path: "gold_long_deep", confidence: "medium", reason: "deep_pullback_structure", sectorStrength });
      }
      // SECTOR UNLOCK: When sector is strongly aligned, allow entry with just HTF+pullback
      // This captures the NVDA/AVGO/TSM pattern — individual ticker may not have all signals
      // but the sector conviction is the confirmation
      if (sectorBull && sectorStrength >= 70 && htf >= 8 && ltf <= 0) {
        return enrichResult({ qualifies: true, path: "gold_long_sector", confidence: "medium", reason: "sector_aligned_pullback", sectorStrength });
      }
      // Low confidence: corridor pullback
      // DATA: gold_long_corridor had 73% loss rate (106 trades, -$4.1k).
      // Now requires real confirmation signal + strong HTF + sector alignment
      if (ltf <= -5 && htf >= 15 && inCorridor && hasRealConfirmation && sectorBull) {
        return enrichResult({ qualifies: true, path: "gold_long_corridor", confidence: "low", reason: "corridor_pullback_confirmed", sectorStrength });
      }
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 2: GOLD SHORT (82.7% of big DOWN moves start from HTF_BULL_LTF_BULL)
  // Historical: median HTF=28, median LTF=19 at move start
  // Strategy: Fade the blow-off top when BOTH HTF and LTF are overextended
  // This is a mean-reversion play, NOT a trend trade
  // ═══════════════════════════════════════════════════════════════════════════
  if (state === "HTF_BULL_LTF_BULL") {
    // High confidence: extreme overextension (clear blow-off top)
    if (htf >= 35 && ltf >= 25) {
      return enrichResult({ qualifies: true, path: "gold_short", confidence: "high", reason: "extreme_blowoff" });
    }
    // High confidence: moderate overextension WITH bearish signal confirmation
    if (htf >= 28 && ltf >= 18 && (hasEmaCrossBear || hasSqRelease)) {
      return enrichResult({ qualifies: true, path: "gold_short_confirmed", confidence: "high", reason: "blowoff_with_signal" });
    }
    // Medium confidence: at the blow-off level
    // DATA (candle replay Jan 13-Feb 7): HTF_BULL_LTF_BULL had 29.3% WR overall.
    // Tighten: require BOTH high thresholds AND signal confirmation (no "ltf >= 25" fallback)
    if (htf >= 30 && ltf >= 22 && (hasEmaCrossBear || hasSqRelease)) {
      return enrichResult({ qualifies: true, path: "gold_short_medium", confidence: "medium", reason: "near_blowoff" });
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 2B: GOLD SHORT (bear-side pullback - mirror of Gold LONG)
  // HTF_BEAR_LTF_PULLBACK: short the pullback in a bearish trend
  // SECTOR ALIGNMENT BOOST: When sector is bearish, relax thresholds
  // ═══════════════════════════════════════════════════════════════════════════
  if (state === "HTF_BEAR_LTF_PULLBACK") {
    const htfMin = (sectorBear && sectorStrength >= 50) ? -3 : -5;
    const bearPullbackCorridor = htf <= htfMin && ltf >= -5 && ltf <= 25;
    if (bearPullbackCorridor) {
      const ltfBearRecovering = ltf < 10 || flags.st_flip_bear || hasEmaCrossBear || hasSqRelease;
      if (ltf >= 5 && ltfBearRecovering) {
        const conf = (sectorBear && sectorStrength >= 60) ? "high_sector" : "high";
        return enrichResult({ qualifies: true, path: "gold_short_pullback", confidence: conf, reason: "bear_pullback_with_confirmation", sectorStrength });
      }
      if (ltf >= 0 && (flags.st_flip_bear || hasEmaCrossBear)) {
        const conf = (sectorBear && sectorStrength >= 60) ? "high" : "medium";
        return enrichResult({ qualifies: true, path: "gold_short_pullback_shallow", confidence: conf, reason: "bear_shallow_with_signal", sectorStrength });
      }
      if (ltf >= 8 && htf <= -10) {
        return enrichResult({ qualifies: true, path: "gold_short_pullback_deep", confidence: "medium", reason: "bear_deep_pullback", sectorStrength });
      }
      // SECTOR UNLOCK: Bear sector alignment
      if (sectorBear && sectorStrength >= 70 && htf <= -8 && ltf >= 0) {
        return enrichResult({ qualifies: true, path: "gold_short_sector", confidence: "medium", reason: "sector_aligned_bear_pullback", sectorStrength });
      }
      if (ltf >= 0 && htf <= -10 && inCorridor) {
        return enrichResult({ qualifies: true, path: "gold_short_corridor", confidence: "low", reason: "bear_corridor_pullback", sectorStrength });
      }
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 3: MOMENTUM (aligned HTF+LTF with confirmation signal)
  // Both HTF and LTF aligned + SuperTrend/EMA/Squeeze confirmation
  // ═══════════════════════════════════════════════════════════════════════════
  // DATA (candle replay Jan 13-Feb 7): HTF_BULL_LTF_BULL had 29.3% WR.
  // Tighten momentum: require RR >= 3.0 (RR 3-5 had 66.2% WR) and higher score
  const isMomentum = state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  if (isMomentum && score >= 85 && rr >= 3.0 && (hasStFlipBull || hasEmaCrossBull || hasSqRelease)) {
    return enrichResult({ qualifies: true, path: "momentum_score", confidence: "medium", reason: "momentum_with_signal" });
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 4: SQUEEZE RELEASE (explosive move from compression)
  // Pullback state + squeeze just released + decent score and RR
  // ═══════════════════════════════════════════════════════════════════════════
  const isSetup = state.includes("PULLBACK");
  if (isSetup && hasSqRelease && score >= 70 && rr >= 2.0) {
    return enrichResult({ qualifies: true, path: "squeeze_setup", confidence: "medium", reason: "squeeze_release" });
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 5: MOMENTUM ELITE (high-conviction flag from TradingView)
  // ═══════════════════════════════════════════════════════════════════════════
  if ((flags.thesis_match || flags.momentum_elite) && score >= 70 && rr >= 2.0) {
    return enrichResult({ qualifies: true, path: "elite", confidence: "medium", reason: "momentum_elite" });
  }
  
  return { qualifies: false, reason: "criteria_not_met" };
}

/**
 * Classify kanban stage for a ticker using 7-lane workflow system.
 * 
 * DISCOVERY MODE (no position): watch → setup → enter
 * MANAGEMENT MODE (has position): just_entered → defend → trim → exit
 * 
 * LANES:
 *   watch        - Valid data, monitoring pool
 *   setup        - Pullback forming, preparing for entry
 *   enter        - Entry criteria met, execute position
 *   just_entered - Position open < 15 min, initial hold
 *   defend       - Warning signals, tighten SL to protect gains
 *   trim         - At EXTREMES, take profit NOW (RSI >= 80, Phase >= 75)
 *   exit         - SL breach or critical, close position NOW
 * 
 * @param {object} tickerData - Ticker payload with scores, state, flags, etc.
 * @param {object|null} openPosition - Optional: open position from D1 (for position-aware classification)
 * @returns {string|null} - Kanban stage or null
 */
function classifyKanbanStage(tickerData, openPosition = null, asOfTs = null) {
  const state = String(tickerData?.state || "");
  const hasPosition = !!(openPosition && openPosition.status === "OPEN");
  
  // ═══════════════════════════════════════════════════════════════════════════
  // MANAGEMENT MODE: Open position drives stage
  // Position-based classification takes absolute priority
  // 7-Lane Flow: just_entered → defend → trim → exit
  // ═══════════════════════════════════════════════════════════════════════════
  if (hasPosition) {
    const completion = Number(tickerData?.completion) || 0;
    const phase = Number(tickerData?.phase_pct) || 0;
    const currentPrice = Number(tickerData?.price);
    const direction = String(openPosition.direction || "").toUpperCase();
    const entryPrice = Number(openPosition.entryPrice || openPosition.avgEntry);
    const entryTs = Number(openPosition.entry_ts || openPosition.created_at) || 0;
    const now = Date.now();
    const positionAgeMin = entryTs > 0 ? (now - entryTs) / (1000 * 60) : 999;
    
    // Calculate P&L
    let pnlPct = 0;
    if (Number.isFinite(entryPrice) && entryPrice > 0 && Number.isFinite(currentPrice)) {
      pnlPct = direction === "LONG"
        ? ((currentPrice - entryPrice) / entryPrice) * 100
        : ((entryPrice - currentPrice) / entryPrice) * 100;
    }
    
    // Get RSI and Phase from ticker data for extreme detection
    const rsi5_10m = Number(tickerData?.tf_tech?.["10"]?.rsi?.r5) || 50;
    const rsi5_30m = Number(tickerData?.tf_tech?.["30"]?.rsi?.r5) || 50;
    const phase_10m = Number(tickerData?.tf_tech?.["10"]?.ph?.v) || 0;
    const phase_30m = Number(tickerData?.tf_tech?.["30"]?.ph?.v) || 0;
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 1: EXIT - Immediate close conditions (highest priority)
    // ─────────────────────────────────────────────────────────────────────────
    
    // Check SL breach using position's trailing SL
    const positionSL = Number(openPosition.sl);
    if (Number.isFinite(positionSL) && positionSL > 0 && Number.isFinite(currentPrice)) {
      const slBreached = direction === "LONG" 
        ? currentPrice <= positionSL 
        : currentPrice >= positionSL;
      if (slBreached) {
        tickerData.__exit_reason = "sl_breached";
        return "exit";
      }
    }
    
    // Hard exit at -8% loss (capital protection)
    if (pnlPct <= -8) {
      tickerData.__exit_reason = "max_loss";
      return "exit";
    }
    
    // Check move status for critical issues
    const tickerDataWithPositionSL = Number.isFinite(positionSL) && positionSL > 0
      ? { ...tickerData, sl: positionSL }
      : tickerData;
    const moveStatus = computeMoveStatus(tickerDataWithPositionSL);
    const reasons = moveStatus?.reasons || [];
    const severity = String(moveStatus?.severity || "").toUpperCase();
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 1: EXIT - Only HARD invalidation signals (close position NOW)
    // SL breach, max loss, or truly critical regime break.
    // "below_trigger" alone is NOT an exit signal - it goes to DEFEND.
    // ─────────────────────────────────────────────────────────────────────────
    
    // Hard exit at -4% loss (capital protection)
    // DATA: Loser P10 is around -0.5%, but some outliers reach -4%.
    // -4% is catastrophic for a day/swing trade - exit immediately.
    if (pnlPct <= -4) {
      tickerData.__exit_reason = "max_loss";
      return "exit";
    }
    
    // SL breach: the position's trailing stop has been hit
    if (
      reasons.includes("sl_breached") ||
      severity === "CRITICAL" ||
      reasons.includes("trigger_breached_5pct")
    ) {
      tickerData.__exit_reason = reasons.join(",") || "critical";
      return "exit";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 2: TRIM - At extremes, take partial profit
    // JOURNEY DATA: TRIM before pullback signals: ST flip (21%), ATR spike (14%),
    //   RSI OB (4%). RSI extreme (>=80) catches most peaks (57% of exhaustion signals).
    // PRECISION ENGINE: Fuel gauge "critical" (<25%) is now the primary trim signal,
    //   replacing the binary phase >= 75 check. Also triggers on Golden Gate completion.
    // ─────────────────────────────────────────────────────────────────────────
    
    const isRsiExtreme = direction === "LONG"
      ? (rsi5_10m >= 80 || rsi5_30m >= 80)
      : (rsi5_10m <= 20 || rsi5_30m <= 20);
    
    // Fuel gauge: "critical" = move exhausted, take profit
    // Uses continuous phase+RSI measure instead of binary phase >= 75 check
    const fuel30 = tickerData?.fuel?.["30"];
    const fuel10 = tickerData?.fuel?.["10"];
    const isFuelCritical = (fuel30?.status === "critical") || (fuel10?.status === "critical");
    
    // Legacy phase extreme fallback (for data without fuel fields)
    const isPhaseExtreme = !fuel30 && (direction === "LONG"
      ? (phase_10m >= 75 || phase_30m >= 75)
      : (phase_10m <= -75 || phase_30m <= -75));
    
    const completionToTrimTp = computeCompletionToTier(tickerData, "TRIM");
    const isNearTp = completionToTrimTp >= 0.85 || completion >= 0.85;
    const isPnlExtreme = pnlPct >= 5;
    
    // SuperTrend flip against direction: preceded 21% of pullbacks in journey data
    // Only trigger TRIM if position is profitable (avoid trimming into a loss)
    const stFlipAgainst = pnlPct > 1.0 && (
      (direction === "LONG" && tickerData?.flags?.st_flip_bear) ||
      (direction === "SHORT" && tickerData?.flags?.st_flip_bull)
    );
    
    // Golden Gate completion: price reached 61.8% ATR level (the gate target)
    // This is a natural trim point — the probabilistic edge has been captured
    const gateCompleted = (tickerData?.active_gates || []).some(g => g.completed);
    
    if (isRsiExtreme || isFuelCritical || isPhaseExtreme || isNearTp || isPnlExtreme || stFlipAgainst || gateCompleted) {
      tickerData.__trim_reason = isRsiExtreme ? "rsi_extreme" : 
                                  isFuelCritical ? "fuel_critical" :
                                  isPhaseExtreme ? "phase_extreme" :
                                  gateCompleted ? "gate_completed" :
                                  isNearTp ? "near_tp" :
                                  isPnlExtreme ? "pnl_extreme" : "st_flip_against";
      return "trim";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 3: DEFEND - Warning signals (tighten SL, protect capital)
    // Includes: adverse P&L, below_trigger, RSI weakening, phase against
    // Key change: "below_trigger" and "left_entry_corridor" now route here,
    // NOT to EXIT. These are soft signals = defend the position, not panic sell.
    //
    // SECTOR ALIGNMENT PATIENCE: When the sector is aligned with our direction,
    // we widen the DEFEND threshold. Sector alignment means the dip is likely
    // temporary (see: NVDA/AVGO/TSM 2/5/26 — dipped at open, recovered strong
    // because sector was aligned). Conversely, if sector is AGAINST our direction,
    // be more defensive.
    // ─────────────────────────────────────────────────────────────────────────
    const sectorAlignForPosition = getSectorAlignmentCached(String(tickerData?.ticker || "").toUpperCase());
    const sectorWithUs = sectorAlignForPosition?.aligned &&
      ((direction === "LONG" && sectorAlignForPosition.direction === "BULL") ||
       (direction === "SHORT" && sectorAlignForPosition.direction === "BEAR"));
    const sectorAgainstUs = sectorAlignForPosition?.aligned &&
      ((direction === "LONG" && sectorAlignForPosition.direction === "BEAR") ||
       (direction === "SHORT" && sectorAlignForPosition.direction === "BULL"));

    // Adverse P&L threshold: wider when sector is with us (dips are buying opps)
    // Normal: -2%, Sector aligned: -3%, Sector against: -1.5%
    const adverseThreshold = sectorWithUs ? -3 : sectorAgainstUs ? -1.5 : -2;
    const isAdverseMove = pnlPct < adverseThreshold && pnlPct > -6;
    
    // Below trigger / left corridor - position is weakening but not dead
    const isBelowTrigger = reasons.includes("below_trigger") || reasons.includes("above_trigger");
    const isLeftCorridor = reasons.includes("left_entry_corridor");
    
    // RSI divergence (price up but RSI weakening)
    const isRsiWeakening = direction === "LONG"
      ? (rsi5_30m < 40 && pnlPct > 0)
      : (rsi5_30m > 60 && pnlPct > 0);
    
    // Phase against direction
    const isPhaseAgainst = direction === "LONG"
      ? (phase_30m < -25)
      : (phase_30m > 25);
    
    // Any warning signal with gains = defend
    const hasGains = pnlPct > 0.5;
    const needsDefense = (isRsiWeakening || isPhaseAgainst) && hasGains;
    
    // PRECISION ENGINE: Fuel "low" (25-50%) = move approaching exhaustion
    const isFuelLow = (fuel30?.status === "low") || (fuel10?.status === "low");
    const fuelDefend = isFuelLow && hasGains; // only defend on fuel if we have gains to protect
    
    // PRECISION ENGINE: ST support score dropping below 0.3 = multi-TF support collapsing
    const stSupportScore = tickerData?.st_support?.supportScore ?? 0.5;
    const supportCollapsing = (direction === "LONG" && stSupportScore < 0.3) ||
                              (direction === "SHORT" && stSupportScore > 0.7);
    
    if (isAdverseMove || isBelowTrigger || isLeftCorridor || needsDefense || fuelDefend || supportCollapsing) {
      tickerData.__defend_reason = isAdverseMove ? "adverse_move" :
                                    isBelowTrigger ? "below_trigger" :
                                    isLeftCorridor ? "left_corridor" :
                                    supportCollapsing ? "st_support_collapse" :
                                    fuelDefend ? "fuel_low" :
                                    isRsiWeakening ? "rsi_weakening" :
                                    isPhaseAgainst ? "phase_against" : "warning";
      return "defend";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 4: JUST_ENTERED - Position age < 15 minutes
    // Initial hold period, no action needed
    // ─────────────────────────────────────────────────────────────────────────
    
    if (positionAgeMin < 15) {
      return "just_entered";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // DEFAULT: HOLD - Healthy position, past initial period, no warning signals
    // This is the "all clear" state - position is working as expected
    // ─────────────────────────────────────────────────────────────────────────
    return "hold";
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // DISCOVERY MODE: No position, evaluate entry opportunity
  // 7-Lane Flow: watch → setup → enter
  // ═══════════════════════════════════════════════════════════════════════════
  
  // Check entry qualification using consolidated criteria
  // Pass asOfTs for replay support (historical trigger freshness check)
  const entry = qualifiesForEnter(tickerData, asOfTs);
  if (entry.qualifies) {
    // Store entry context for UI display
    tickerData.__entry_path = entry.path;
    tickerData.__entry_confidence = entry.confidence;
    tickerData.__entry_reason = entry.reason;
    // PATTERN BOOST: Upgrade entry confidence when patterns strongly match
    const pm = tickerData?.pattern_match;
    if (pm && pm.direction === "BULLISH" && pm.bestBull?.conf > 0.6) {
      tickerData.__entry_confidence = "high";
      tickerData.__entry_reason = (tickerData.__entry_reason || "") + ` +pattern:${pm.bestBull.name}`;
    }
    return "enter";
  }
  
  // Check if in SETUP zone (corridor + pullback state)
  const inCorridor = corridorSide(tickerData) != null;
  const isSetup = state.includes("PULLBACK");
  
  // SETUP: In corridor with setup state - preparing for entry
  if (inCorridor && isSetup) {
    return "setup";
  }
  
  // SETUP: Flip watch active (about to transition) - treat as setup
  const flags = tickerData?.flags || {};
  if (flags.flip_watch && inCorridor) {
    return "setup";
  }
  
  // ─────────────────────────────────────────────────────────────────────────
  // PATTERN-AWARE PROMOTION: Watch → Setup when patterns strongly match
  // If the model sees high-confidence bull patterns on a watch ticker that
  // is in or near a corridor, treat it as a setup (the model sees something
  // that the rule-based system doesn't yet classify as setup).
  // ─────────────────────────────────────────────────────────────────────────
  const pmDiscovery = tickerData?.pattern_match;
  if (pmDiscovery && pmDiscovery.direction === "BULLISH" && pmDiscovery.bullCount >= 2 && pmDiscovery.bestBull?.conf > 0.55) {
    const htfScore = Number(tickerData?.htf_score) || 0;
    const ltfScore = Number(tickerData?.ltf_score) || 0;
    // Only promote if scores are reasonably positive (model + scores agree)
    if (htfScore > 40 && ltfScore > 30) {
      tickerData.__setup_reason = `pattern_model:${pmDiscovery.bestBull.name}(${pmDiscovery.bullCount} bull patterns)`;
      return "setup";
    }
  }
  
  // WATCH: Valid data, monitoring pool
  const hasValidData =
    state &&
    Number.isFinite(Number(tickerData?.price)) &&
    String(tickerData?.ticker || "").trim();
  
  if (hasValidData) {
    return "watch";
  }
  
  // No stage - not in trading pipeline
  return null;
}

function deriveKanbanMeta(tickerData, stage) {
  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  const completion = Number(tickerData?.completion) || 0;
  const phase = Number(tickerData?.phase_pct) || 0;
  const phaseZone = String(tickerData?.phase_zone || "").toUpperCase();
  const severity = String(ms?.severity || "").toUpperCase();
  const reasons = Array.isArray(ms?.reasons) ? ms.reasons : [];

  // ENTER stage: show entry path and confidence
  if (stage === "enter" || stage === "enter_now") {
    const path = tickerData?.__entry_path || "unknown";
    const confidence = tickerData?.__entry_confidence || "medium";
    const reason = tickerData?.__entry_reason || "criteria_met";
    const emoji = confidence === "high" ? "🎯" : "✅";
    return {
      bucket: path,
      emoji,
      reason,
      confidence,
      reasons: [reason],
    };
  }

  // JUST_ENTERED stage: show initial hold status
  if (stage === "just_entered") {
    return {
      bucket: "holding",
      emoji: "🆕",
      reason: "just_opened",
      reasons: ["position_new"],
    };
  }

  // HOLD stage: healthy position, working as expected
  if (stage === "hold") {
    return {
      bucket: "holding",
      emoji: "💎",
      reason: "position_healthy",
      reasons: ["on_track"],
    };
  }

  // DEFEND stage: show why we're defending (tighten SL)
  if (stage === "defend") {
    const defendReason = tickerData?.__defend_reason || "warning";
    const emoji = "🛡";
    const reasonMap = {
      adverse_move: "Price moving against",
      below_trigger: "Below entry anchor",
      left_corridor: "Left entry corridor",
      rsi_weakening: "RSI divergence",
      phase_against: "Phase turning",
      warning: "Warning signals",
    };
    return {
      bucket: "tighten_sl",
      emoji,
      reason: reasonMap[defendReason] || "defending",
      reasons: [defendReason],
    };
  }

  // TRIM stage: show why we're trimming (EXTREMES only)
  if (stage === "trim") {
    const trimReason = tickerData?.__trim_reason || "extreme";
    const emoji = "✂️";
    const reasonMap = {
      rsi_extreme: "RSI at extreme",
      phase_extreme: "Phase at extreme",
      near_tp: "Near TP target",
      pnl_extreme: "P&L > 6%",
    };
    return {
      bucket: "take_profit",
      emoji,
      reason: reasonMap[trimReason] || `${Math.round(completion * 100)}% complete`,
      reasons: [trimReason],
    };
  }

  // EXIT stage: show urgency
  if (stage === "exit") {
    const exitReason = tickerData?.__exit_reason || reasons[0] || "exit_signal";
    const emoji = severity === "CRITICAL" ? "🚨" : "🚪";
    const reasonMap = {
      sl_breached: "SL hit",
      max_loss: "Max loss (-8%)",
      critical: "Critical issue",
      left_entry_corridor: "Left corridor",
      large_adverse_move: "Large adverse move",
    };
    return {
      bucket: "close_now",
      emoji,
      reason: reasonMap[exitReason] || exitReason,
      reasons: [exitReason],
    };
  }

  // SETUP stage: show readiness indicators
  if (stage === "setup") {
    const flags = tickerData?.flags || {};
    // PATTERN-PROMOTED setup: model identified high-confidence patterns
    if (tickerData?.__setup_reason?.startsWith("pattern_model:")) {
      const pm = tickerData?.pattern_match;
      return {
        bucket: "pattern_setup",
        emoji: "🧠",
        reason: `Model: ${pm?.bestBull?.name || "pattern match"}`,
        reasons: ["pattern_model", ...(pm?.matched?.map(m => m.id) || [])],
        patternMatch: pm,
      };
    }
    if (flags.flip_watch) {
      return { bucket: "flip_watch", emoji: "🔄", reason: "about_to_flip", reasons: ["flip_watch"] };
    }
    if (flags.sq30_on) {
      return { bucket: "squeeze_building", emoji: "🎯", reason: "squeeze_on", reasons: ["squeeze_on"] };
    }
    return { bucket: "preparing", emoji: "⏳", reason: "pullback_forming", reasons: ["setup"] };
  }

  // WATCH stage: show monitoring
  if (stage === "watch") {
    return null;  // No special meta for watch
  }

  return null;
}

function computeMoveStatus(tickerData) {
  const side = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  const flags = tickerData?.flags || {};
  const momentumElite = !!flags.momentum_elite;

  const price = Number(tickerData?.price);
  const sl = Number(tickerData?.sl);
  const tp = computeTpMaxFromLevels(tickerData) ?? Number(tickerData?.tp);
  const triggerTsRaw = Number(tickerData?.trigger_ts);
  const entryTsRaw = Number(
    tickerData?.entry_ts ?? tickerData?.kanban_cycle_enter_now_ts,
  );
  const entryPriceRaw = Number(tickerData?.entry_price);
  let triggerTs = triggerTsRaw;
  const curTs = Number(tickerData?.ts ?? tickerData?.ingest_ts ?? Date.now());

  const reasons = [];

  // If we can't infer direction, don't mark invalidated.
  if (!side) {
    return {
      status: "ACTIVE",
      side: null,
      severity: "NONE",
      reasons: [],
    };
  }

  // Only consider a "move" ACTIVE once we've actually entered the cycle.
  // ENTER_NOW stamps entry_ts/entry_price (or cycle enter ts), which is our proxy for “we took it”.
  // Without this, tickers can incorrectly show HOLD/DEFEND/TRIM/EXIT just because they have a trigger_ts.
  const hasEntered = Number.isFinite(entryTsRaw) && entryTsRaw > 0;
  if (!hasEntered) {
    return {
      status: "NONE",
      side,
      severity: "NONE",
      reasons: [],
    };
  }

  // If we don't have a trigger timestamp, this isn't an active "move" yet.
  // This prevents labeling the entire universe as ACTIVE/HOLD/TRIM/EXIT.
  if (!Number.isFinite(triggerTs) || triggerTs <= 0) {
    // Back-compat: if the user has acted (ENTER_NOW stamps entry_ts/entry_price),
    // we still need move-status logic even if trigger_ts is missing.
    if (Number.isFinite(entryTsRaw) && entryTsRaw > 0) {
      triggerTs = entryTsRaw;
    } else {
      return {
        status: "NONE",
        side,
        severity: "NONE",
        reasons: [],
      };
    }
  }

  // If the trigger is stale, don't keep the ticker stuck in "move" lanes forever.
  // This is especially important when the market is closed and many names won't ingest frequently.
  // Treat old triggers as no active move so opportunity lanes (Flip Watch / Enter Now) can surface.
  if (Number.isFinite(curTs) && curTs > 0) {
    const ageMs = curTs - triggerTs;
    const STALE_TRIGGER_MS = 14 * 24 * 60 * 60 * 1000; // 14 days
    if (Number.isFinite(ageMs) && ageMs > STALE_TRIGGER_MS) {
      const entryAgeMs =
        Number.isFinite(entryTsRaw) && entryTsRaw > 0 ? curTs - entryTsRaw : null;
      const entryFresh =
        entryAgeMs != null &&
        Number.isFinite(entryAgeMs) &&
        entryAgeMs >= 0 &&
        entryAgeMs <= STALE_TRIGGER_MS;
      if (entryFresh) {
        triggerTs = entryTsRaw;
      } else {
        return {
          status: "NONE",
          side,
          severity: "NONE",
          reasons: [],
        };
      }
    }
  }

  // Soft invalidation: breached trigger/entry anchor (clear “get out” signal even before SL).
  // This avoids cases like AGQ: ENTER_NOW → large adverse move → no EXIT lane until SL.
  const anchorPrice = (() => {
    const trigPx = Number(tickerData?.trigger_price);
    if (Number.isFinite(trigPx) && trigPx > 0) return trigPx;
    if (Number.isFinite(entryPriceRaw) && entryPriceRaw > 0) return entryPriceRaw;
    return null;
  })();
  if (Number.isFinite(price) && Number.isFinite(anchorPrice) && anchorPrice > 0) {
    const adversePct = Math.abs((price - anchorPrice) / anchorPrice);
    // DATA-DRIVEN: Require minimum 2.0% adverse move before flagging trigger invalidation.
    // Journey analysis (103 pullbacks): median pullback 1.22%, P75 = 2.20%.
    // Sub-2.0% dips are normal pullbacks during sustained moves. Flag only when
    // the adverse move exceeds the P75 pullback threshold.
    const MIN_ADVERSE_PCT = 0.020; // 2.0% (raised from 1.5%)
    if (side === "LONG" && price < anchorPrice && adversePct >= MIN_ADVERSE_PCT) reasons.push("below_trigger");
    if (side === "SHORT" && price > anchorPrice && adversePct >= MIN_ADVERSE_PCT) reasons.push("above_trigger");
    if (
      (reasons.includes("below_trigger") || reasons.includes("above_trigger")) &&
      Number.isFinite(adversePct) &&
      adversePct >= 0.05
    ) {
      reasons.push("trigger_breached_5pct");
    }
  }

  // Hard invalidation: SL breach
  if (Number.isFinite(price) && Number.isFinite(sl) && sl > 0) {
    if (side === "LONG" && price <= sl) reasons.push("sl_breached");
    if (side === "SHORT" && price >= sl) reasons.push("sl_breached");
  }

  // Completion: TP reached/exceeded (move is "done" from entry standpoint)
  if (Number.isFinite(price) && Number.isFinite(tp) && tp > 0) {
    if (side === "LONG" && price >= tp) reasons.push("tp_reached");
    if (side === "SHORT" && price <= tp) reasons.push("tp_reached");
  }

  // Regime breaks: HTF structure disagrees with direction
  // NOTE: These are useful for discovery (setup/enter) but too noisy for position management.
  // DATA: daily_ema_regime_break caused 19 exits (47% WR) - nearly coin flip.
  // Only include as informational; NOT used for exit decisions on open positions.
  // The Kanban stage classifier ignores WARNING-only severity for EXIT.
  if (!dailyEmaRegimeOk(tickerData, side))
    reasons.push("daily_ema_regime_break");
  if (!ichimokuRegimeOk(tickerData, side))
    reasons.push("ichimoku_regime_break");

  // Late-cycle: disqualifier unless Momentum Elite
  if (isLateCycle(tickerData) && !momentumElite) reasons.push("late_cycle");

  // Overextension: extremely high completion means little edge left (relative to MAX TP)
  const comp = (() => {
    const cMax = computeCompletionToTpMax(tickerData);
    return Number.isFinite(cMax) ? cMax : completionForSize(tickerData);
  })();
  if (Number.isFinite(comp) && comp >= 0.95) reasons.push("overextended");

  // If we have a trigger timestamp and we're not in the entry corridor anymore,
  // only flag as "left_entry_corridor" if price moved ADVERSELY (not in our favor).
  // A favorable move out of corridor is a good thing (price going our way).
  if (Number.isFinite(triggerTs) && triggerTs > 0) {
    const ent = entryType(tickerData);
    if (ent && ent.corridor === false) {
      // Only count as "left corridor" if the move was adverse
      // Check if price moved against our position
      const isAdverseCorridorExit = (() => {
        if (!Number.isFinite(price) || !Number.isFinite(anchorPrice) || anchorPrice <= 0) {
          return false; // Can't determine, don't trigger
        }
        const priceDelta = price - anchorPrice;
        // For LONG: adverse if price went DOWN
        // For SHORT: adverse if price went UP
        if (side === "LONG") return priceDelta < 0;
        if (side === "SHORT") return priceDelta > 0;
        return false;
      })();
      
      if (isAdverseCorridorExit) {
        reasons.push("left_entry_corridor");
      }
    }
  }

  // Adverse move detection (tightened from 15% to 10% for earlier exits)
  if (Number.isFinite(price) && Number.isFinite(anchorPrice) && anchorPrice > 0) {
    const adverseMove = (price - anchorPrice) / anchorPrice;
    const isAdverse = 
      (side === "LONG" && adverseMove < 0) ||
      (side === "SHORT" && adverseMove > 0);
    
    if (isAdverse) {
      const absMove = Math.abs(adverseMove);
      // Critical: >10% adverse move = hard exit (was 15%)
      if (absMove >= 0.10) {
        reasons.push("large_adverse_move");
      }
      // Warning: >5% adverse move = defensive signal
      else if (absMove >= 0.05) {
        reasons.push("adverse_move_warning");
      }
    }
  }

  // IMPORTANT: do NOT mark the entire universe invalidated for "soft" reasons.
  // Only hard-stop conditions should become INVALIDATED / COMPLETED.
  const isCompleted = reasons.includes("tp_reached");
  const isInvalidated = 
    reasons.includes("sl_breached") || 
    reasons.includes("large_adverse_move");

  const status = isCompleted
    ? "COMPLETED"
    : isInvalidated
      ? "INVALIDATED"
      : "ACTIVE";

  // Severity is used by Kanban stage logic and UI; keep it consistent:
  // NONE | WARNING | CRITICAL
  const severity = reasons.includes("sl_breached") || reasons.includes("trigger_breached_5pct")
    ? "CRITICAL"
    : reasons.length
      ? "WARNING"
      : "NONE";

  return {
    status,
    side,
    severity,
    reasons,
  };
}

function sideFromStateOrScores(tickerData) {
  const state = String(tickerData?.state || "");
  if (state.includes("BULL")) return "LONG";
  if (state.includes("BEAR")) return "SHORT";
  const h = Number(tickerData?.htf_score);
  const l = Number(tickerData?.ltf_score);
  if (Number.isFinite(h) && Number.isFinite(l)) {
    if (h > 0) return "LONG";
    if (h < 0) return "SHORT";
  }
  return null;
}

function dailyEmaRegimeOk(tickerData, side) {
  const cloud = tickerData?.daily_ema_cloud;
  const pos =
    cloud?.position != null ? String(cloud.position).toLowerCase() : "";
  if (!pos) return true;
  if (side === "LONG") return pos !== "below";
  if (side === "SHORT") return pos !== "above";
  return true;
}

function ichimokuRegimeOk(tickerData, side) {
  const dPos =
    tickerData?.ichimoku_d?.position != null
      ? String(tickerData.ichimoku_d.position).toLowerCase()
      : "";
  const wPos =
    tickerData?.ichimoku_w?.position != null
      ? String(tickerData.ichimoku_w.position).toLowerCase()
      : "";

  // If we don't have Ichimoku in the payload yet, don't block.
  if (!dPos && !wPos) return true;

  const dBadLong = dPos === "below";
  const wBadLong = wPos === "below";
  const dBadShort = dPos === "above";
  const wBadShort = wPos === "above";

  // Block only when BOTH HTFs disagree with the trade direction.
  if (side === "LONG") return !(dBadLong && wBadLong);
  if (side === "SHORT") return !(dBadShort && wBadShort);
  return true;
}

function isLateCycle(tickerData) {
  const z = String(tickerData?.phase_zone || "").toUpperCase();
  const phase = Number(tickerData?.phase_pct) || 0;
  // Zones are: LOW / MEDIUM / HIGH / EXTREME (from Pine).
  if (z === "EXTREME") return true;
  if (z === "HIGH") return true;
  // Additional safety for legacy payloads without zones.
  return phase >= 0.7;
}

// Helper function: entryType (check if ticker is in corridor)
function entryType(ticker) {
  // Corridor is defined in score-space (HTF/LTF bands), not by TP/SL price bounds.
  // This must match `corridorSide()` and the UI corridor filters.
  return { corridor: corridorSide(ticker) != null };
}

// Dynamic SCORE calculation that considers real-time conditions
// NOTE: This returns a SCORE (0-200+), not a RANK (position 1-135)
// RANK is determined by sorting all tickers by this score
function computeDynamicScore(ticker) {
  const baseScore = Number(ticker.rank) || 50; // Base score from worker (0-100)
  const htf = Number(ticker.htf_score) || 0;
  const ltf = Number(ticker.ltf_score) || 0;
  const comp = completionForSize(ticker);
  const phase = Number(ticker.phase_pct) || 0;
  const rr = Number(ticker.rr) || 0;
  const flags = ticker.flags || {};
  const state = String(ticker.state || "");
  const holdIntent = String(
    ticker.hold_intent || ticker.horizon_bucket || "",
  ).toUpperCase();

  const sqRel = !!flags.sq30_release;
  const sqOn = !!flags.sq30_on;
  const phaseZoneChange = !!flags.phase_zone_change;
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  const ent = entryType(ticker);
  const inCorridor = ent.corridor;

  let dynamicScore = baseScore;

  // Data completeness penalty: prefer fully-instrumented names.
  const completeness =
    ticker?.data_completeness || computeDataCompleteness(ticker);
  if (completeness && typeof completeness === "object") {
    if (completeness.score < 70) dynamicScore -= 6;
    else if (completeness.score < 85) dynamicScore -= 3;
  }

  // Per-TF technical structure: reward aligned multi-timeframe stacks.
  const tfAlign = ticker?.tf_summary || tfTechAlignmentSummary(ticker);
  if (
    tfAlign &&
    typeof tfAlign === "object" &&
    Number.isFinite(tfAlign.score)
  ) {
    dynamicScore += tfAlign.score;
    if (tfAlign.squeeze_on && !sqRel && inCorridor) dynamicScore += 1;
    if (tfAlign.squeeze_release && inCorridor) dynamicScore += 2;
  }

  // Explicit triggers[] “why now” boost (bounded).
  const trig = ticker?.trigger_summary || triggerSummaryAndScore(ticker);
  if (trig && typeof trig === "object" && Number.isFinite(trig.score)) {
    dynamicScore += trig.score;
  }

  // Move status: deprioritize invalidated/completed moves
  const ms = ticker?.move_status || computeMoveStatus(ticker);
  if (ms && typeof ms === "object") {
    if (ms.status === "INVALIDATED") dynamicScore -= 30;
    else if (ms.status === "COMPLETED") dynamicScore -= 20;
  }

  // Corridor bonus (high priority - active setups)
  if (inCorridor) {
    dynamicScore += 12; // Strong bonus for being in corridor

    // Extra bonus if aligned AND in corridor (perfect setup)
    if (aligned) {
      dynamicScore += 8;
    }
  }

  // Squeeze release in corridor = very strong signal
  if (sqRel && inCorridor) {
    dynamicScore += 10;
  }

  // Squeeze on in corridor = building pressure
  if (sqOn && inCorridor && !sqRel) {
    dynamicScore += 5;
  }

  // RR bonus (scaled - better RR = higher score)
  if (rr >= 2.0) {
    dynamicScore += 8; // Excellent RR
  } else if (rr >= 1.5) {
    dynamicScore += 5; // Good RR
  } else if (rr >= 1.0) {
    dynamicScore += 2; // Acceptable RR
  }

  // Phase bonus (early phase = better opportunity)
  if (phase < 0.3) {
    dynamicScore += 6; // Very early
  } else if (phase < 0.5) {
    dynamicScore += 3; // Early
  } else if (phase > 0.7) {
    dynamicScore -= 5; // Late phase penalty
  }

  // Completion bonus (low completion = more room to run)
  if (comp < 0.3) {
    dynamicScore += 5; // Early in move
  } else if (comp > 0.8) {
    dynamicScore -= 8; // Near completion penalty
  }

  // Phase 2: Hold-intent scoring (small nudge; only when HTF strength supports it)
  // Goal: favor longer-duration setups when HTF strength is high, without overpowering other gates.
  const htfAbs = Math.abs(htf);
  if (holdIntent === "POSITION" && htfAbs >= 15) {
    dynamicScore += 2;
  } else if (holdIntent === "SWING" && htfAbs >= 10) {
    dynamicScore += 1;
  }

  // Score strength bonus (strong HTF/LTF scores)
  const htfStrength = Math.min(8, Math.abs(htf) * 0.15);
  const ltfStrength = Math.min(6, Math.abs(ltf) * 0.12);
  dynamicScore += htfStrength + ltfStrength;

  // Phase zone change bonus
  if (phaseZoneChange) {
    dynamicScore += 4;
  }

  // NO CAP - let scores go above 100 to help tickers separate from one another
  // Minimum is 0, but no maximum cap
  dynamicScore = Math.max(0, dynamicScore);

  return Math.round(dynamicScore * 100) / 100; // Round to 2 decimals for precision
}

// Compute RR at trigger price (for alert evaluation)
// This evaluates RR at the entry point, not current price
// This is critical because price moves after trigger, which decreases RR
function computeRRAtTrigger(d) {
  // Use trigger_price if available, otherwise fall back to current price
  const triggerPrice =
    d.trigger_price != null ? Number(d.trigger_price) : Number(d.price);
  const sl = Number(d.sl);
  if (!Number.isFinite(triggerPrice) || !Number.isFinite(sl)) return null;

  // Use MAX TP from tp_levels if available, otherwise fall back to first TP
  let tp = Number(d.tp);
  if (d.tp_levels && Array.isArray(d.tp_levels) && d.tp_levels.length > 0) {
    // Extract prices from tp_levels (handle both object and number formats)
    const tpPrices = d.tp_levels
      .map((tpItem) => {
        if (
          typeof tpItem === "object" &&
          tpItem !== null &&
          tpItem.price != null
        ) {
          return Number(tpItem.price);
        }
        return typeof tpItem === "number" ? Number(tpItem) : Number(tpItem);
      })
      .filter((p) => Number.isFinite(p));

    if (tpPrices.length > 0) {
      // Use maximum TP (best-case scenario for RR calculation)
      tp = Math.max(...tpPrices);
    }
  }

  if (!Number.isFinite(tp)) return null;

  // Determine direction from state to calculate risk/reward correctly
  const state = String(d.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");

  let risk, gain;

  if (isLong) {
    // For LONG: SL should be below trigger price, TP should be above trigger price
    risk = triggerPrice - sl; // Risk is distance from trigger price to SL (down)
    gain = tp - triggerPrice; // Gain is distance from trigger price to TP (up)
  } else if (isShort) {
    // For SHORT: SL should be above trigger price, TP should be below trigger price
    risk = sl - triggerPrice; // Risk is distance from trigger price to SL (up)
    gain = triggerPrice - tp; // Gain is distance from trigger price to TP (down)
  } else {
    // Fallback to absolute values if direction unclear
    risk = Math.abs(triggerPrice - sl);
    gain = Math.abs(tp - triggerPrice);
  }

  // Ensure both risk and gain are positive
  if (risk <= 0 || gain <= 0) return null;
  return gain / risk;
}

// ─────────────────────────────────────────────────────────────
// Horizon + ETA v2 (Worker-derived, % based)
// ─────────────────────────────────────────────────────────────

function clampNum(x, lo, hi) {
  const n = Number(x);
  if (!Number.isFinite(n)) return lo;
  return Math.max(lo, Math.min(hi, n));
}

function median(values) {
  const arr = Array.isArray(values)
    ? values.filter((n) => Number.isFinite(Number(n))).map((n) => Number(n))
    : [];
  if (arr.length === 0) return null;
  arr.sort((a, b) => a - b);
  const mid = Math.floor(arr.length / 2);
  if (arr.length % 2 === 1) return arr[mid];
  return (arr[mid - 1] + arr[mid]) / 2;
}

// Infer ATR (absolute) from ATR_FIB tp_levels by solving:
// price_i - price_j = (mult_i - mult_j) * ATR
function inferAtrAbsFromTpLevels(tpLevels, timeframe) {
  if (!Array.isArray(tpLevels) || tpLevels.length < 2) return null;
  const tf = String(timeframe || "").toUpperCase();

  const atrFib = tpLevels
    .map((tp) => {
      const type = String(tp?.type || "").toUpperCase();
      const t = String(tp?.timeframe || "").toUpperCase();
      const price = Number(tp?.price);
      const mult = Number(tp?.multiplier);
      if (type !== "ATR_FIB") return null;
      if (t !== tf) return null;
      if (!Number.isFinite(price) || price <= 0) return null;
      if (!Number.isFinite(mult) || mult <= 0) return null;
      return { price, mult };
    })
    .filter(Boolean);

  if (atrFib.length < 2) return null;

  const ests = [];
  for (let i = 0; i < atrFib.length; i++) {
    for (let j = i + 1; j < atrFib.length; j++) {
      const dm = Math.abs(atrFib[i].mult - atrFib[j].mult);
      const dp = Math.abs(atrFib[i].price - atrFib[j].price);
      if (dm <= 1e-9) continue;
      if (!Number.isFinite(dp) || dp <= 0) continue;
      const atr = dp / dm;
      if (Number.isFinite(atr) && atr > 0) ests.push(atr);
    }
  }

  const atrMed = median(ests);
  if (!Number.isFinite(atrMed) || atrMed <= 0) return null;
  return atrMed;
}

function horizonBucketFromEtaDays(etaDays) {
  const eta = Number(etaDays);
  if (!Number.isFinite(eta) || eta <= 0) return "UNKNOWN";
  if (eta <= 7) return "SHORT_TERM";
  if (eta <= 30) return "SWING";
  return "POSITIONAL";
}

function deriveHorizonAndMetrics(payload) {
  if (!payload || typeof payload !== "object") return {};

  const state = String(payload.state || "");
  const direction = state.includes("BULL")
    ? "LONG"
    : state.includes("BEAR")
      ? "SHORT"
      : null;
  const isLong = direction === "LONG";

  const entryRef =
    payload.trigger_price != null && Number(payload.trigger_price) > 0
      ? Number(payload.trigger_price)
      : Number(payload.price);
  const sl = Number(payload.sl);

  const out = {
    entry_ref: Number.isFinite(entryRef) ? entryRef : null,
    risk_pct: null,
    tp_max_price: null,
    tp_max_pct: null,
    tp_target_price: null,
    tp_target_pct: null,
    expected_return_pct: null,
    eta_days_v2: null,
    eta_days_next: null,
    eta_days_max: null,
    eta_confidence: 0.4,
    horizon_bucket: "UNKNOWN",
    // Alias for downstream clarity (Phase 2: hold-intent scoring/labeling)
    hold_intent: "UNKNOWN",
  };

  if (!direction || !Number.isFinite(entryRef) || entryRef <= 0) {
    const etaFallback = Number(payload.eta_days);
    out.horizon_bucket = horizonBucketFromEtaDays(etaFallback);
    out.eta_days_v2 = Number.isFinite(etaFallback) ? etaFallback : null;
    out.eta_confidence = Number.isFinite(etaFallback) ? 0.35 : 0.2;
    out.hold_intent = out.horizon_bucket;
    return out;
  }

  if (Number.isFinite(sl) && sl > 0) {
    const riskAbs = Math.abs(entryRef - sl);
    const riskPct = riskAbs / entryRef;
    if (Number.isFinite(riskPct) && riskPct > 0) {
      out.risk_pct = Math.round(riskPct * 10000) / 100;
    }
  }

  const tpLevelsRaw = Array.isArray(payload.tp_levels) ? payload.tp_levels : [];
  const minDistPct = 0.01;

  const tpCandidates = tpLevelsRaw
    .map((tp) => {
      const price = Number(tp?.price);
      if (!Number.isFinite(price) || price <= 0) return null;
      const distancePct = Math.abs(price - entryRef) / entryRef;
      if (!Number.isFinite(distancePct) || distancePct < minDistPct)
        return null;
      if (isLong && price <= entryRef) return null;
      if (!isLong && price >= entryRef) return null;
      return {
        price,
        distancePct,
        timeframe: String(tp?.timeframe || "D").toUpperCase(),
        type: String(tp?.type || "ATR_FIB").toUpperCase(),
        source: String(tp?.source || "").trim(),
        confidence: Number(tp?.confidence),
        multiplier: tp?.multiplier == null ? null : Number(tp?.multiplier),
        _fused: tp?._fused || null,
      };
    })
    .filter(Boolean);

  if (tpCandidates.length > 0) {
    const tpMax = isLong
      ? Math.max(...tpCandidates.map((t) => t.price))
      : Math.min(...tpCandidates.map((t) => t.price));
    if (Number.isFinite(tpMax) && tpMax > 0) {
      out.tp_max_price = tpMax;
      const tpMaxPct = (Math.abs(tpMax - entryRef) / entryRef) * 100;
      if (Number.isFinite(tpMaxPct) && tpMaxPct > 0) {
        out.tp_max_pct = Math.round(tpMaxPct * 100) / 100;
      }
    }
  }

  const atrD = inferAtrAbsFromTpLevels(tpLevelsRaw, "D");
  const atrW = inferAtrAbsFromTpLevels(tpLevelsRaw, "W");
  const atr4 = inferAtrAbsFromTpLevels(tpLevelsRaw, "240");

  let dailyAtrPct = null;
  if (Number.isFinite(atrD) && atrD > 0) dailyAtrPct = atrD / entryRef;
  else if (Number.isFinite(atrW) && atrW > 0) dailyAtrPct = atrW / entryRef / 5;
  else if (Number.isFinite(atr4) && atr4 > 0)
    dailyAtrPct = (atr4 / entryRef) * 1.8;

  const htfAbs = Math.abs(Number(payload.htf_score) || 0);
  const ltfAbs = Math.abs(Number(payload.ltf_score) || 0);
  const momentumFactor = clampNum(
    0.85 + (htfAbs / 50) * 0.25 + (ltfAbs / 50) * 0.25,
    0.75,
    1.45,
  );

  let expectedDailyMovePct = null;
  if (Number.isFinite(dailyAtrPct) && dailyAtrPct > 0) {
    expectedDailyMovePct = clampNum(
      dailyAtrPct * 0.35 * momentumFactor,
      0.003,
      dailyAtrPct * 1.1,
    );
    out.eta_confidence += 0.25;
  } else if (Number.isFinite(out.risk_pct) && out.risk_pct > 0) {
    expectedDailyMovePct = clampNum(
      (out.risk_pct / 100) * 0.25 * momentumFactor,
      0.003,
      0.02,
    );
    out.eta_confidence += 0.1;
  } else {
    expectedDailyMovePct = 0.006;
    out.eta_confidence += 0.05;
  }

  // Intelligent target TP: use horizon-aware TP array to pick a realistic target
  const tpArray = buildIntelligentTPArray(payload, entryRef, direction);
  const targetTp =
    tpArray && tpArray.length > 1
      ? tpArray[1]
      : tpArray && tpArray.length > 0
        ? tpArray[0]
        : null;
  if (targetTp && Number.isFinite(targetTp.price) && targetTp.price > 0) {
    out.tp_target_price = Number(targetTp.price);
    const targetPct =
      (Math.abs(out.tp_target_price - entryRef) / entryRef) * 100;
    if (Number.isFinite(targetPct) && targetPct > 0) {
      out.tp_target_pct = Math.round(targetPct * 100) / 100;
      out.expected_return_pct = out.tp_target_pct;
    }
    if (Number.isFinite(expectedDailyMovePct) && expectedDailyMovePct > 0) {
      const etaTarget = targetPct / 100 / expectedDailyMovePct;
      if (Number.isFinite(etaTarget) && etaTarget > 0) {
        out.eta_days_v2 = Math.round(clampNum(etaTarget, 0.2, 180) * 100) / 100;
        out.eta_confidence += 0.15;
      }
    }
  }

  const qualityScore = (tp) => {
    const tf = String(tp?.timeframe || "D").toUpperCase();
    const type = String(tp?.type || "").toUpperCase();
    const conf = Number(tp?.confidence);
    const tfScore =
      tf === "W" ? 3 : tf === "D" ? 2 : tf === "240" || tf === "4H" ? 1 : 0;
    const typeScore = type.startsWith("FUSED")
      ? 3
      : type === "STRUCTURE"
        ? 3
        : type === "LIQUIDITY"
          ? 2
          : type === "FVG"
            ? 1.5
            : type === "GAP"
              ? 1
              : type === "ATR_FIB"
                ? 1
                : 0.5;
    const confScore = Number.isFinite(conf)
      ? clampNum((conf - 0.6) / 0.3, 0, 1)
      : 0.5;
    return tfScore + typeScore + confScore;
  };

  const scored = tpCandidates
    .map((tp) => ({
      ...tp,
      _q: qualityScore(tp),
      _eta: tp.distancePct / expectedDailyMovePct,
    }))
    .filter((tp) => Number.isFinite(tp._eta) && tp._eta > 0)
    .sort((a, b) => {
      const aScore = a._q / (1 + a.distancePct * 12);
      const bScore = b._q / (1 + b.distancePct * 12);
      return bScore - aScore;
    });

  const next = scored[0] || null;
  if (next) {
    out.eta_days_next = Math.round(clampNum(next._eta, 0.2, 180) * 100) / 100;
    if (!Number.isFinite(out.eta_days_v2)) {
      out.eta_days_v2 = out.eta_days_next;
      out.eta_confidence += 0.2;
    }
  }

  if (Number.isFinite(out.tp_max_price) && out.tp_max_price > 0) {
    const distMaxPct = Math.abs(out.tp_max_price - entryRef) / entryRef;
    const etaMax = distMaxPct / expectedDailyMovePct;
    if (Number.isFinite(etaMax) && etaMax > 0) {
      out.eta_days_max = Math.round(clampNum(etaMax, 0.5, 365) * 100) / 100;
    }
  }

  if (
    !Number.isFinite(out.expected_return_pct) &&
    Number.isFinite(out.tp_max_pct)
  ) {
    out.expected_return_pct = out.tp_max_pct;
  }

  out.eta_confidence =
    Math.round(clampNum(out.eta_confidence, 0.1, 0.95) * 100) / 100;
  const etaForBucket = Number.isFinite(out.eta_days_v2)
    ? out.eta_days_v2
    : Number(payload.eta_days);
  out.horizon_bucket = horizonBucketFromEtaDays(etaForBucket);
  out.hold_intent = out.horizon_bucket;

  return out;
}

function normalizeDay(ts) {
  const ms = Number(ts);
  if (!Number.isFinite(ms)) return null;
  return Math.floor(ms / 86400000);
}

function buildDailyCloseSeries(trail = [], maxDays = 20) {
  if (!Array.isArray(trail) || trail.length === 0) return [];
  const dayMap = new Map();
  for (const point of trail) {
    const day = normalizeDay(point.ts);
    const price = Number(point.price);
    if (!Number.isFinite(day) || !Number.isFinite(price)) continue;
    // Keep last price of the day
    dayMap.set(day, price);
  }
  const days = Array.from(dayMap.keys()).sort((a, b) => a - b);
  const clipped = days.slice(-1 * Math.max(1, maxDays + 1));
  return clipped.map((day) => ({ day, close: dayMap.get(day) }));
}

function buildReturnMap(series = []) {
  const map = new Map();
  for (let i = 1; i < series.length; i++) {
    const prev = series[i - 1];
    const cur = series[i];
    if (!prev || !cur) continue;
    const ret = (cur.close - prev.close) / Math.max(1e-9, prev.close);
    if (!Number.isFinite(ret)) continue;
    map.set(cur.day, ret);
  }
  return map;
}

function pearsonCorrelation(a = [], b = []) {
  if (!Array.isArray(a) || !Array.isArray(b)) return null;
  const n = Math.min(a.length, b.length);
  if (n < 5) return null;
  const x = a.slice(-n);
  const y = b.slice(-n);
  const mean = (arr) => arr.reduce((s, v) => s + v, 0) / arr.length;
  const meanX = mean(x);
  const meanY = mean(y);
  let num = 0;
  let denX = 0;
  let denY = 0;
  for (let i = 0; i < n; i++) {
    const dx = x[i] - meanX;
    const dy = y[i] - meanY;
    num += dx * dy;
    denX += dx * dx;
    denY += dy * dy;
  }
  const den = Math.sqrt(denX * denY);
  if (!Number.isFinite(den) || den <= 0) return null;
  return num / den;
}

async function computeOpenTradesCorrelation(env, KV, options = {}) {
  const cacheKey = "timed:corr:open_trades";
  const ttlSec = Number(options.ttlSec || 300);
  const now = Date.now();
  try {
    const cached = await kvGetJSON(KV, cacheKey);
    if (
      cached &&
      cached.computedAt &&
      now - cached.computedAt < ttlSec * 1000
    ) {
      return cached;
    }
  } catch {
    // ignore cache errors
  }

  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  const trades = (await kvGetJSON(KV, "timed:trades:all")) || [];
  const openTickers = Array.from(
    new Set(
      trades
        .filter((t) => {
          const status = String(t?.status || "").toUpperCase();
          return status === "OPEN" || status === "TP_HIT_TRIM" || !status;
        })
        .map((t) => String(t?.ticker || "").toUpperCase())
        .filter(Boolean),
    ),
  );

  if (openTickers.length < 2) {
    return {
      ok: true,
      computedAt: now,
      tickers: openTickers,
      avgCorrByTicker: {},
    };
  }

  const sinceTs = now - 35 * 24 * 60 * 60 * 1000;
  const seriesMap = new Map();

  await Promise.all(
    openTickers.map(async (ticker) => {
      const res = await d1GetTrailRange(env, ticker, sinceTs, 8000);
      const trail = res && Array.isArray(res.trail) ? res.trail : [];
      const dailySeries = buildDailyCloseSeries(trail, 20);
      seriesMap.set(ticker, dailySeries);
    }),
  );

  const returnMapByTicker = new Map();
  for (const ticker of openTickers) {
    const series = seriesMap.get(ticker) || [];
    returnMapByTicker.set(ticker, buildReturnMap(series));
  }

  const avgCorrByTicker = {};
  const sectorMap = new Map();
  const sectorCounts = {};
  for (const ticker of openTickers) {
    try {
      const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
      const sector =
        latest?.sector || latest?.fundamentals?.sector || "UNKNOWN";
      sectorMap.set(ticker, sector);
      sectorCounts[sector] = (sectorCounts[sector] || 0) + 1;
    } catch {
      sectorMap.set(ticker, "UNKNOWN");
      sectorCounts.UNKNOWN = (sectorCounts.UNKNOWN || 0) + 1;
    }
  }
  for (const ticker of openTickers) {
    const baseMap = returnMapByTicker.get(ticker);
    if (!baseMap || baseMap.size < 5) continue;
    const corrVals = [];
    for (const other of openTickers) {
      if (other === ticker) continue;
      const otherMap = returnMapByTicker.get(other);
      if (!otherMap || otherMap.size < 5) continue;
      const commonDays = [];
      for (const [day, ret] of baseMap.entries()) {
        if (otherMap.has(day)) {
          commonDays.push([ret, otherMap.get(day)]);
        }
      }
      if (commonDays.length < 5) continue;
      const a = commonDays.map((v) => v[0]);
      const b = commonDays.map((v) => v[1]);
      const corr = pearsonCorrelation(a, b);
      if (Number.isFinite(corr)) corrVals.push(Math.abs(corr));
    }
    if (corrVals.length > 0) {
      const avg =
        corrVals.reduce((sum, v) => sum + v, 0) / Math.max(1, corrVals.length);
      const diversity = Math.round(Math.max(0, 1 - avg) * 100);
      avgCorrByTicker[ticker] = {
        avg_corr: Math.round(avg * 1000) / 1000,
        diversity_score: diversity,
        corr_count: corrVals.length,
      };
    }
  }

  // Fallback proxy: sector concentration when return series is insufficient.
  for (const ticker of openTickers) {
    if (avgCorrByTicker[ticker]) continue;
    const sector = sectorMap.get(ticker) || "UNKNOWN";
    const sameSector = Math.max(1, sectorCounts[sector] || 1);
    const total = Math.max(1, openTickers.length);
    const share = sameSector / total;
    const avg = Math.min(0.95, 0.3 + 0.7 * share);
    const diversity = Math.round(Math.max(0, 1 - avg) * 100);
    avgCorrByTicker[ticker] = {
      avg_corr: Math.round(avg * 1000) / 1000,
      diversity_score: diversity,
      corr_count: 0,
      _proxy: "sector",
    };
  }

  const result = {
    ok: true,
    computedAt: now,
    tickers: openTickers,
    avgCorrByTicker,
  };

  try {
    await kvPutJSON(KV, cacheKey, result, ttlSec);
  } catch {
    // ignore cache set errors
  }

  return result;
}

// ── Corridor helpers (must match UI corridors)
// LONG ltf -10..22: wider upper bound so momentum entries (LTF 12-22) still qualify
// SHORT ltf -12..10. Accept htf_score/htfScore, ltf_score/ltfScore (ingest payloads may use either)
function inLongCorridor(d) {
  const h = Number(d?.htf_score ?? d?.htfScore);
  const l = Number(d?.ltf_score ?? d?.ltfScore);
  return (
    Number.isFinite(h) && Number.isFinite(l) && h > 0 && l >= -10 && l <= 22
  );
}
function inShortCorridor(d) {
  const h = Number(d?.htf_score ?? d?.htfScore);
  const l = Number(d?.ltf_score ?? d?.ltfScore);
  return (
    Number.isFinite(h) && Number.isFinite(l) && h < 0 && l >= -12 && l <= 10
  );
}
function corridorSide(d) {
  if (inLongCorridor(d)) return "LONG";
  if (inShortCorridor(d)) return "SHORT";
  return null;
}

function fmt2(x) {
  const n = Number(x);
  return Number.isFinite(n) ? n.toFixed(2) : "—";
}
function pct01(x) {
  const n = Number(x);
  return Number.isFinite(n) ? `${Math.round(n * 100)}%` : "—";
}

// ─────────────────────────────────────────────────────────────
// Trade Simulation Functions (Worker-Level)
// ─────────────────────────────────────────────────────────────

const TRADE_SIZE = 1000; // $1000 per trade
const PORTFOLIO_START_CASH = 100000;
const MIN_TRADE_NOTIONAL = 1000;
const MAX_TRADE_NOTIONAL = 5000;
const PORTFOLIO_KEY = "timed:portfolio:v1";

function clamp(x, lo, hi) {
  const n = Number(x);
  if (!Number.isFinite(n)) return lo;
  return Math.max(lo, Math.min(hi, n));
}

function computeTradeConfidence(tickerData) {
  const t = tickerData && typeof tickerData === "object" ? tickerData : {};
  const flags = t.flags && typeof t.flags === "object" ? t.flags : {};
  const rank = Number(t.rank) || 0;
  const rr =
    Number(t.rr_now_likely) || Number(t.rr_entry_likely) || Number(t.rr) || 0;
  const h = Math.abs(Number(t.htf_score) || 0);
  const l = Math.abs(Number(t.ltf_score) || 0);

  // Rank is the strongest driver: 60→0, 90→1
  const cRank = clamp((rank - 60) / 30, 0, 1);
  // RR: 1.0→0, 2.5→1
  const cRr = clamp((rr - 1.0) / 1.5, 0, 1);
  // Scores: soft contribution
  const cScore = clamp((h / 60) * 0.6 + (l / 35) * 0.4, 0, 1);
  const bonus =
    (flags.momentum_elite ? 0.08 : 0) +
    (flags.thesis_match ? 0.08 : 0) +
    (flags.sq30_release ? 0.04 : 0);

  const confidence = clamp(
    0.55 * cRank + 0.25 * cRr + 0.2 * cScore + bonus,
    0,
    1,
  );
  return confidence;
}

async function getPortfolioState(KV) {
  try {
    const p = await kvGetJSON(KV, PORTFOLIO_KEY);
    if (p && typeof p === "object" && Number.isFinite(Number(p.cash))) return p;
  } catch {
    // ignore
  }
  const now = Date.now();
  return {
    version: 1,
    startCash: PORTFOLIO_START_CASH,
    cash: PORTFOLIO_START_CASH,
    created_at: now,
    updated_at: now,
  };
}

async function putPortfolioState(KV, p) {
  try {
    const now = Date.now();
    const next = { ...(p || {}), updated_at: now };
    if (!Number.isFinite(Number(next.startCash)))
      next.startCash = PORTFOLIO_START_CASH;
    if (!Number.isFinite(Number(next.cash)))
      next.cash = Number(next.startCash) || PORTFOLIO_START_CASH;
    await kvPutJSON(KV, PORTFOLIO_KEY, next);
    return next;
  } catch {
    return p;
  }
}

function tradeNotionalFromConfidence(confidence, cashAvailable) {
  const base =
    MIN_TRADE_NOTIONAL +
    (MAX_TRADE_NOTIONAL - MIN_TRADE_NOTIONAL) * clamp(confidence, 0, 1);
  const maxByCash = Number.isFinite(Number(cashAvailable))
    ? Number(cashAvailable)
    : base;
  const capped = Math.min(base, maxByCash, MAX_TRADE_NOTIONAL);
  return clamp(capped, MIN_TRADE_NOTIONAL, MAX_TRADE_NOTIONAL);
}

function computeSharesForTrade(ticker, entryPrice, notional) {
  const sym = String(ticker || "").toUpperCase();
  const isFutures = FUTURES_SPECS[sym] || sym.endsWith("1!");
  if (isFutures && FUTURES_SPECS[sym]) {
    return { shares: 1, pointValue: FUTURES_SPECS[sym].pointValue };
  }
  const px = Number(entryPrice);
  const n = Number(notional);
  if (!Number.isFinite(px) || px <= 0 || !Number.isFinite(n) || n <= 0)
    return { shares: null, pointValue: 1 };
  return { shares: n / px, pointValue: 1 };
}

// Futures contract specifications (point value per contract)
const FUTURES_SPECS = {
  "ES1!": { pointValue: 50, name: "E-mini S&P 500" },
  "NQ1!": { pointValue: 20, name: "E-mini Nasdaq-100" },
  "MES1!": { pointValue: 5, name: "Micro E-mini S&P 500" },
  "MNQ1!": { pointValue: 2, name: "Micro E-mini Nasdaq-100" },
  "YM1!": { pointValue: 5, name: "E-mini Dow" },
  "RTY1!": { pointValue: 50, name: "E-mini Russell 2000" },
  ES: { pointValue: 50, name: "E-mini S&P 500" },
  NQ: { pointValue: 20, name: "E-mini Nasdaq-100" },
  YM: { pointValue: 5, name: "E-mini Dow" },
};

const FUTURES_TICKERS = new Set([
  // Base symbols
  "ES", "NQ", "YM", "RTY", "CL", "GC", "SI", "HG", "NG",
  // TradingView continuous contract symbols
  "ES1!", "NQ1!", "YM1!", "RTY1!", "CL1!", "GC1!", "SI1!", "HG1!", "NG1!",
  // Micro futures
  "MES", "MNQ", "MES1!", "MNQ1!",
]);

// Non-equity instruments that should NOT be traded with equity logic
// These need special handling (different market structure, sizing, SL logic)
const NON_EQUITY_BLOCKLIST = new Set([
  // Volatility indices
  "VIX", "UVXY", "SVXY", "VXX", "VIXY",
  // Commodities / Metals
  "SILVER", "GOLD", "COPPER", "PLATINUM", "PALLADIUM",
  // Crypto (if ever ingested)
  "BTC", "ETH", "BTCUSD", "ETHUSD",
  // Leveraged / Inverse ETFs (decay makes SL/TP unreliable)
  "SQQQ", "TQQQ", "SPXU", "SPXL", "UDOW", "SDOW",
  "LABU", "LABD", "SOXL", "SOXS", "FNGU", "FNGD",
  "TNA", "TZA", "NUGT", "DUST", "JNUG", "JDST",
]);

// Check if ticker should trigger a trade (matches UI logic)
function shouldTriggerTradeSimulation(ticker, tickerData, prevData) {
  const tickerUpper = String(ticker || "").toUpperCase();

  // Skip futures
  if (FUTURES_TICKERS.has(tickerUpper)) return false;

  // Must have valid entry/exit levels (support alternate field names)
  const slVal = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
  const tpVal = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
  if (!tickerData.price || !Number.isFinite(slVal) || slVal <= 0 || !Number.isFinite(tpVal) || tpVal <= 0) return false;

  const flags = tickerData.flags || {};
  const flipWatch = !!flags.flip_watch;
  const state = String(tickerData.state || "");
  const alignedLong = state === "HTF_BULL_LTF_BULL";
  const alignedShort = state === "HTF_BEAR_LTF_BEAR";
  const aligned = alignedLong || alignedShort;

  const h = Number(tickerData.htf_score);
  const l = Number(tickerData.ltf_score);

  // ─────────────────────────────────────────────────────────────────────────────
  // GOLD STANDARD ENTRY LOGIC (direction-specific based on historical analysis)
  // ─────────────────────────────────────────────────────────────────────────────
  
  // LONG: Traditional corridor + NEW pullback setup (HTF_BULL_LTF_PULLBACK)
  // 67.7% of big UP moves started from HTF_BULL_LTF_PULLBACK
  const longCorridorClassic = h > 0 && l >= -10 && l <= 22;  // Original
  const longPullbackSetup = state === "HTF_BULL_LTF_PULLBACK" && h >= 10 && l >= -15 && l <= 5;  // Gold standard
  const inLongCorridor = longCorridorClassic || longPullbackSetup;

  // SHORT: Traditional corridor + NEW blow-off top setup (HTF_BULL_LTF_BULL with high scores)
  // 82.7% of big DOWN moves started from HTF_BULL_LTF_BULL when BOTH scores overextended!
  const shortCorridorClassic = h < 0 && l >= -12 && l <= 10;  // Original (rarely works)
  const shortBlowOffTop = state === "HTF_BULL_LTF_BULL" && h >= 25 && l >= 15;  // Gold standard
  const inShortCorridor = shortCorridorClassic || shortBlowOffTop;

  const inCorridor = inLongCorridor || inShortCorridor;

  // Determine side based on which corridor we're in
  let side = null;
  if (inLongCorridor && (alignedLong || longPullbackSetup)) {
    side = "LONG";
  } else if (inShortCorridor) {
    side = "SHORT";
  }

  // For LONG: allow aligned OR pullback setup
  // For SHORT: allow aligned OR blow-off top setup
  const corridorAlignedOK = 
    (side === "LONG" && (alignedLong || longPullbackSetup)) || 
    (side === "SHORT" && (alignedShort || shortBlowOffTop));

  if (!inCorridor || !corridorAlignedOK) return false;
  
  // Log gold standard match for debugging
  const gsLong = matchesGoldStandardLong(tickerData);
  const gsShort = matchesGoldStandardShort(tickerData);
  if (gsLong.match || gsShort.match) {
    console.log(`[GOLD_STANDARD] ${tickerUpper} side=${side} gsLong=${gsLong.score} gsShort=${gsShort.score} state=${state} htf=${h} ltf=${l}`);
  }

  // Check for trigger conditions
  const enteredAligned = prevData && prevData.state !== state && aligned;
  const prevH = prevData ? Number(prevData.htf_score) : NaN;
  const prevL = prevData ? Number(prevData.ltf_score) : NaN;
  const prevInCorridor =
    Number.isFinite(prevH) &&
    Number.isFinite(prevL) &&
    ((prevH > 0 && prevL >= -10 && prevL <= 22) ||
      (prevH < 0 && prevL >= -12 && prevL <= 10));
  const justEnteredCorridor = !!prevData && !prevInCorridor && inCorridor;
  const trigReason = String(tickerData.trigger_reason || "");
  const trigOk = trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");
  const sqRelease = !!flags.sq30_release;

  const shouldConsiderAlert =
    inCorridor &&
    corridorAlignedOK &&
    (justEnteredCorridor || enteredAligned || trigOk || sqRelease || flipWatch);

  const momentumElite = !!flags.momentum_elite;
  // Relaxed thresholds for testing exit/trim system
  const baseMinRR = 0.3;  // Lowered from 1.2 to allow more entries for testing
  const baseMaxComp = 0.8;  // Raised from 0.5
  const baseMaxPhase = 0.85;  // Raised from 0.65
  const minRR = momentumElite ? Math.max(0.2, baseMinRR * 0.9) : baseMinRR;
  const maxComp = flipWatch || sqRelease
    ? Math.min(0.9, baseMaxComp * 1.2)
    : momentumElite
      ? Math.min(0.85, baseMaxComp * 1.1)
      : baseMaxComp;
  const maxPhase = momentumElite
    ? Math.min(0.9, baseMaxPhase * 1.15)
    : baseMaxPhase;

  // Relaxed rank threshold for testing (will tighten after validating exit system)
  const rank = Number(tickerData.rank ?? tickerData.rank_position ?? tickerData.position) || 0;
  const minRank = momentumElite ? 40 : 50;
  const rankOk = rank >= minRank;

  const rr = Number(tickerData.rr) || 0;
  const compRaw = completionForSize(tickerData);
  const compToMax = computeCompletionToTpMax(tickerData);
  const comp = Number.isFinite(compToMax) ? compToMax : compRaw;
  const phase = Number(tickerData.phase_pct) || 0;

  const rrOk = rr >= minRR;
  const compOk = comp <= maxComp;
  const phaseOk = phase <= maxPhase;

  const momentumEliteTrigger =
    momentumElite &&
    inCorridor &&
    corridorAlignedOK &&
    (trigOk || sqRelease || flipWatch || justEnteredCorridor);
  const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

  // Don't enter if the move has already invalidated/completed
  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  if (ms && (ms.status === "INVALIDATED" || ms.status === "COMPLETED"))
    return false;

  // Phase 1/3 gates applied to simulation entries too.
  const inferredSide = side || sideFromStateOrScores(tickerData);
  if (!dailyEmaRegimeOk(tickerData, inferredSide)) return false;
  if (!ichimokuRegimeOk(tickerData, inferredSide)) return false;
  if (isLateCycle(tickerData) && !momentumElite) return false;
  // Fresh trigger: pullback→re-align, squeeze release, flip_watch, or just entered corridor (market moved in).
  const prevStateStr = prevData ? String(prevData.state || "") : "";
  const enteredFromPullback =
    !!enteredAligned && prevStateStr.includes("PULLBACK");
  const freshPullbackOk =
    enteredFromPullback ||
    sqRelease ||
    (trigReason === "SQUEEZE_RELEASE" || trigReason.includes("SQUEEZE_RELEASE")) ||
    (trigReason.includes("EMA_CROSS")) ||
    flipWatch ||
    justEnteredCorridor;
  if (!freshPullbackOk) return false;

  return enhancedTrigger && rrOk && compOk && phaseOk && rankOk;
}

// Debug: return blockers for trade entry (same logic as shouldTriggerTradeSimulation)
function getEntryBlockers(ticker, tickerData, prevData) {
  const blockers = [];
  const tickerUpper = String(ticker || "").toUpperCase();
  if (FUTURES_TICKERS.has(tickerUpper)) return ["futures_disabled"];

  const slVal = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
  const tpVal = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
  if (!tickerData.price || !Number.isFinite(slVal) || slVal <= 0 || !Number.isFinite(tpVal) || tpVal <= 0) {
    blockers.push("missing_levels");
    return blockers;
  }

  const flags = tickerData.flags || {};
  const flipWatch = !!flags.flip_watch;
  const state = String(tickerData.state || "");
  const alignedLong = state === "HTF_BULL_LTF_BULL";
  const alignedShort = state === "HTF_BEAR_LTF_BEAR";
  const aligned = alignedLong || alignedShort;
  const h = Number(tickerData.htf_score);
  const l = Number(tickerData.ltf_score);

  // GOLD STANDARD: Direction-specific corridor logic
  const longCorridorClassic = h > 0 && l >= -10 && l <= 22;
  const longPullbackSetup = state === "HTF_BULL_LTF_PULLBACK" && h >= 10 && l >= -15 && l <= 5;
  const inLongCorridor = longCorridorClassic || longPullbackSetup;
  
  const shortCorridorClassic = h < 0 && l >= -12 && l <= 10;
  const shortBlowOffTop = state === "HTF_BULL_LTF_BULL" && h >= 25 && l >= 15;
  const inShortCorridor = shortCorridorClassic || shortBlowOffTop;
  
  const inCorridor = inLongCorridor || inShortCorridor;
  
  let side = null;
  if (inLongCorridor && (alignedLong || longPullbackSetup)) side = "LONG";
  else if (inShortCorridor) side = "SHORT";
  
  const corridorAlignedOK = 
    (side === "LONG" && (alignedLong || longPullbackSetup)) || 
    (side === "SHORT" && (alignedShort || shortBlowOffTop));

  if (!inCorridor) blockers.push("not_in_corridor");
  if (inCorridor && !corridorAlignedOK) blockers.push("corridor_misaligned");
  
  // Add gold standard info for debugging
  const gsLong = matchesGoldStandardLong(tickerData);
  const gsShort = matchesGoldStandardShort(tickerData);
  if (gsLong.match) blockers.push(`gs_long_match(${gsLong.score})`);
  if (gsShort.match) blockers.push(`gs_short_match(${gsShort.score})`);

  const prevH = prevData ? Number(prevData.htf_score) : NaN;
  const prevL = prevData ? Number(prevData.ltf_score) : NaN;
  const prevInCorridor = Number.isFinite(prevH) && Number.isFinite(prevL) &&
    ((prevH > 0 && prevL >= -10 && prevL <= 22) || (prevH < 0 && prevL >= -12 && prevL <= 10));
  const justEnteredCorridor = !!prevData && !prevInCorridor && inCorridor;
  const trigReason = String(tickerData.trigger_reason || "");
  const trigOk = trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");
  const sqRelease = !!flags.sq30_release;
  const enteredAligned = prevData && prevData.state !== state && aligned;

  const shouldConsiderAlert = inCorridor && corridorAlignedOK &&
    (justEnteredCorridor || enteredAligned || trigOk || sqRelease || flipWatch);
  const momentumElite = !!flags.momentum_elite;
  const momentumEliteTrigger = momentumElite && inCorridor && corridorAlignedOK &&
    (trigOk || sqRelease || flipWatch || justEnteredCorridor);
  const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

  // Relaxed thresholds for testing exit/trim system
  const rank = Number(tickerData.rank ?? tickerData.rank_position ?? tickerData.position) || 0;
  const minRank = momentumElite ? 40 : 50;  // Lowered for testing
  if (rank < minRank) blockers.push(`rank_below_min(${rank}<${minRank})`);

  const rr = Number(tickerData.rr) || 0;
  const minRR = momentumElite ? Math.max(0.2, 0.3 * 0.9) : 0.3;  // Lowered for testing
  if (rr < minRR) blockers.push(`rr_below_min(${rr?.toFixed(2)}<${minRR})`);

  const compRaw = completionForSize(tickerData);
  const compToMax = computeCompletionToTpMax(tickerData);
  const comp = Number.isFinite(compToMax) ? compToMax : compRaw;
  const maxComp = flipWatch || sqRelease ? 0.9 : momentumElite ? 0.85 : 0.8;  // Raised for testing
  if (comp > maxComp) blockers.push(`completion_high(${(comp*100).toFixed(0)}%>${(maxComp*100).toFixed(0)}%)`);

  const phase = Number(tickerData.phase_pct) || 0;
  const maxPhase = momentumElite ? 0.9 : 0.85;  // Raised for testing
  if (phase > maxPhase) blockers.push(`phase_high(${(phase*100).toFixed(0)}%>${(maxPhase*100).toFixed(0)}%)`);

  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  if (ms?.status === "INVALIDATED") blockers.push("move_invalidated");
  if (ms?.status === "COMPLETED") blockers.push("move_completed");

  const inferredSide = side || sideFromStateOrScores(tickerData);
  if (!dailyEmaRegimeOk(tickerData, inferredSide)) blockers.push("htf_regime_gate");
  if (!ichimokuRegimeOk(tickerData, inferredSide)) blockers.push("ichimoku_regime_gate");
  if (isLateCycle(tickerData) && !momentumElite) blockers.push("late_cycle");

  const prevStateStr = prevData ? String(prevData.state || "") : "";
  const enteredFromPullback = !!enteredAligned && prevStateStr.includes("PULLBACK");
  const freshPullbackOk = enteredFromPullback || sqRelease ||
    (trigReason === "SQUEEZE_RELEASE" || trigReason.includes("SQUEEZE_RELEASE")) ||
    trigReason.includes("EMA_CROSS") || flipWatch || justEnteredCorridor;
  if (!freshPullbackOk) blockers.push("no_fresh_pullback");

  if (!enhancedTrigger) blockers.push("no_enhanced_trigger");

  return blockers;
}

function isOpenTradeStatus(status) {
  const s = String(status || "").toUpperCase();
  return s === "OPEN" || s === "TP_HIT_TRIM" || !s;
}

async function findOpenTradeForTicker(KV, ticker, direction = null) {
  const trades = (await kvGetJSON(KV, "timed:trades:all")) || [];
  const t = String(ticker || "").toUpperCase();
  const dir = direction ? String(direction).toUpperCase() : null;
  return (
    trades.find((trade) => {
      if (!trade) return false;
      if (String(trade.ticker || "").toUpperCase() !== t) return false;
      if (dir && String(trade.direction || "").toUpperCase() !== dir)
        return false;
      return isOpenTradeStatus(trade.status);
    }) || null
  );
}

async function checkIngestCoverage(KV, now = new Date()) {
  if (!isMarketHoursET(now)) return { ok: true, skipped: true };
  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
  const missing = [];
  const maxAgeMin = 10;

  for (const ticker of tickers) {
    if (marketType(ticker) !== "EQUITY_RTH") continue;
    const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
    const lastTsRaw = latest?.ingest_ts ?? latest?.ts ?? null;
    const lastTs = Number(lastTsRaw);
    const ageMin = Number.isFinite(lastTs)
      ? (now.getTime() - lastTs) / 60000
      : null;

    if (!Number.isFinite(ageMin) || ageMin > maxAgeMin) {
      missing.push({
        ticker: String(ticker).toUpperCase(),
        ageMin,
        lastTs,
        state: latest?.state,
        rank: latest?.rank,
        price: latest?.price,
      });
      const missKey = `timed:ingest:missing:${String(ticker).toUpperCase()}`;
      const already = await KV.get(missKey);
      if (!already) {
        await kvPutText(KV, missKey, "1", 60 * 60);
        await appendActivity(KV, {
          type: "ingest_missing",
          ticker: String(ticker).toUpperCase(),
          action: "missing_ingest",
          age_min: Number.isFinite(ageMin) ? Math.round(ageMin) : null,
          last_ingest_ts: Number.isFinite(lastTs) ? lastTs : null,
          state: latest?.state,
          rank: latest?.rank,
          price: latest?.price,
        });
      }
    } else {
      const missKey = `timed:ingest:missing:${String(ticker).toUpperCase()}`;
      await KV.delete(missKey);
    }
  }

  return { ok: true, missing, checked: tickers.length };
}

function buildEntryDecision(ticker, tickerData, prevState) {
  const tickerUpper = String(ticker || "").toUpperCase();
  const blockers = [];
  const warnings = [];
  const flags = tickerData.flags || {};
  const flipWatch = !!flags.flip_watch;
  const state = String(tickerData.state || "");

  const alignedLong = state === "HTF_BULL_LTF_BULL";
  const alignedShort = state === "HTF_BEAR_LTF_BEAR";
  const aligned = alignedLong || alignedShort;

  const h = Number(tickerData.htf_score);
  const l = Number(tickerData.ltf_score);
  const inCorridor =
    Number.isFinite(h) &&
    Number.isFinite(l) &&
    ((h > 0 && l >= -10 && l <= 22) || (h < 0 && l >= -12 && l <= 10));
  const side =
    h > 0 && l >= -10 && l <= 22
      ? "LONG"
      : h < 0 && l >= -12 && l <= 10
        ? "SHORT"
        : null;
  const corridorAlignedOK =
    (side === "LONG" && alignedLong) || (side === "SHORT" && alignedShort);

  const enteredAligned = aligned && prevState && prevState !== state;
  const trigReason = String(tickerData.trigger_reason || "");
  const trigOk = trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");
  const sqRelease = !!flags.sq30_release;
  // Note: do NOT treat mere presence of trigger_price/trigger_ts as a trigger.
  // Many payloads include those fields continuously, causing over-trading.
  const hasTrigger = false;

  const shouldConsiderAlert =
    inCorridor &&
    corridorAlignedOK &&
    (enteredAligned || trigOk || sqRelease || hasTrigger);

  const momentumElite = !!flags.momentum_elite;
  const baseMinRR = 1.2;
  const baseMaxComp = 0.5;
  const baseMaxPhase = 0.65;
  const minRR = momentumElite ? Math.max(1.0, baseMinRR * 0.9) : baseMinRR;
  const maxComp = flipWatch || sqRelease
    ? Math.min(0.6, baseMaxComp * 1.2)
    : momentumElite
      ? Math.min(0.55, baseMaxComp * 1.1)
      : baseMaxComp;
  const maxPhase = momentumElite
    ? Math.min(0.75, baseMaxPhase * 1.15)
    : baseMaxPhase;

  const price = Number(tickerData.price);
  const triggerPrice = Number(tickerData.trigger_price);
  const entryPrice =
    Number.isFinite(price) && price > 0
      ? price
      : Number.isFinite(triggerPrice) && triggerPrice > 0
        ? triggerPrice
        : null;
  const entryPriceSource =
    Number.isFinite(price) && price > 0
      ? "price"
      : Number.isFinite(triggerPrice) && triggerPrice > 0
        ? "trigger_price"
        : null;

  // Normalize sl/tp from alternate field names (payloads may vary)
  const slVal = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
  const tpVal = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
  if (Number.isFinite(slVal) && tickerData.sl == null) tickerData.sl = slVal;
  if (Number.isFinite(tpVal) && tickerData.tp == null) tickerData.tp = tpVal;

  const hasLevels = Number.isFinite(slVal) && slVal > 0 && Number.isFinite(tpVal) && tpVal > 0;
  const rrAtEntry =
    entryPrice != null ? calculateRRAtEntry(tickerData, entryPrice) : null;
  const compRaw = completionForSize(tickerData);
  const compToMax = computeCompletionToTpMax(tickerData);
  const comp = Number.isFinite(compToMax) ? compToMax : compRaw;
  const phase = Number(tickerData.phase_pct) || 0;

  const rrOk =
    (rrAtEntry != null && Number.isFinite(rrAtEntry))
      ? rrAtEntry >= minRR
      : (hasLevels && entryPrice != null);
  const compOk = comp <= maxComp;
  const phaseOk = phase <= maxPhase;

  const rank = Number(tickerData.rank ?? tickerData.rank_position ?? tickerData.position) || 0;
  const minRank = momentumElite ? 60 : 70;
  const rankOk = rank >= minRank;

  if (FUTURES_TICKERS.has(tickerUpper)) blockers.push("futures_disabled");
  if (!Number.isFinite(entryPrice) || !hasLevels)
    blockers.push("missing_levels");
  if (!inCorridor) blockers.push("not_in_corridor");
  if (inCorridor && !corridorAlignedOK) blockers.push("corridor_misaligned");
  if (!shouldConsiderAlert) blockers.push("no_trigger");

  // Move invalidation/completion gate (don't suggest entries on broken/done moves)
  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  if (ms && ms.status === "INVALIDATED") blockers.push("move_invalidated");
  if (ms && ms.status === "COMPLETED") blockers.push("move_completed");

  // Phase 1: HTF regime gate + late-cycle disqualifier + pullback-only entry constraint
  const inferredSide = side || sideFromStateOrScores(tickerData);
  if (!dailyEmaRegimeOk(tickerData, inferredSide))
    blockers.push("htf_regime_gate");
  if (!ichimokuRegimeOk(tickerData, inferredSide))
    blockers.push("ichimoku_regime_gate");

  const lateCycle = isLateCycle(tickerData);
  if (lateCycle && !momentumElite) blockers.push("late_cycle");
  else if (lateCycle && momentumElite) warnings.push("late_cycle");

  // Pullback-only entry: require a pullback→re-alignment transition OR a squeeze release OR flip_watch.
  const enteredFromPullback =
    !!enteredAligned && String(prevState || "").includes("PULLBACK");
  const freshPullbackOk =
    enteredFromPullback || sqRelease || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("SQUEEZE_RELEASE") || trigReason.includes("EMA_CROSS") || flipWatch;
  if (!freshPullbackOk) blockers.push("no_fresh_pullback");

  if (!rankOk) blockers.push("rank_below_min");
  if (!rrOk) blockers.push("rr_below_min");
  if (!compOk) blockers.push("completion_high");
  if (!phaseOk) blockers.push("phase_high");

  const staleness = String(tickerData.staleness || "").toUpperCase();
  if (staleness && staleness !== "FRESH") warnings.push("stale_data");

  return {
    ok: blockers.length === 0,
    action: "ENTRY",
    side: side || (alignedLong ? "LONG" : alignedShort ? "SHORT" : null),
    blockers,
    warnings,
    entry_price: entryPrice,
    entry_price_source: entryPriceSource,
    checks: {
      aligned,
      in_corridor: inCorridor,
      corridor_aligned: corridorAlignedOK,
      entered_aligned: enteredAligned,
      trigger_ok: trigOk,
      squeeze_release: sqRelease,
      has_trigger: hasTrigger,
      rank,
      rank_min: minRank,
      rr_at_entry: rrAtEntry,
      rr_min: minRR,
      completion: comp,
      completion_max: maxComp,
      phase,
      phase_max: maxPhase,
    },
  };
}

function computeTradePnlComponents(trade, tickerData) {
  const direction = String(trade?.direction || "").toUpperCase();
  const isLong = direction === "LONG";
  const entryPrice = Number(trade?.entryPrice);
  const currentPrice = Number(tickerData?.price ?? trade?.currentPrice);
  const shares = Number(trade?.shares);
  const pointValue = Number(trade?.pointValue) || 1;
  const trimmedPct = clamp(Number(trade?.trimmedPct || 0), 0, 1);
  const remainingPct = Math.max(0, 1 - trimmedPct);
  if (
    !Number.isFinite(entryPrice) ||
    !Number.isFinite(currentPrice) ||
    !Number.isFinite(shares)
  ) {
    return {
      pnl: null,
      pnlPct: null,
      realized: Number(trade?.realizedPnl || 0) || 0,
      unrealized: null,
    };
  }
  const dirSign = isLong ? 1 : -1;
  const unrealized =
    (currentPrice - entryPrice) * shares * pointValue * remainingPct * dirSign;
  const realized = Number(trade?.realizedPnl || 0) || 0;
  const pnl = realized + unrealized;
  const notional =
    Number(trade?.notional) ||
    (Number.isFinite(entryPrice) ? entryPrice * shares : null);
  const pnlPct =
    Number.isFinite(notional) && notional !== 0 ? (pnl / notional) * 100 : null;
  return { pnl, pnlPct, realized, unrealized };
}

// Helper: Score TP level for intelligent selection
function scoreTPLevel(tpLevel, entryPrice, direction, allTPs, horizonConfig) {
  const isLong = direction === "LONG";
  const price = Number(tpLevel.price || tpLevel);

  // Base score from confidence (0.60-0.85, normalize to 0-1)
  const confidence = Number(tpLevel.confidence || 0.75);
  let score = (confidence - 0.6) / (0.85 - 0.6); // Normalize to 0-1

  // Timeframe priority: Weekly > Daily > 4H
  const tf = String(tpLevel.timeframe || "D").toUpperCase();
  if (tf === "W") score += 0.3;
  else if (tf === "D") score += 0.2;
  else if (tf === "240" || tf === "4H") score += 0.1;

  // Type priority: STRUCTURE > ATR_FIB > LIQUIDITY > FVG > GAP
  const type = String(tpLevel.type || "ATR_FIB").toUpperCase();
  if (type === "STRUCTURE") score += 0.25;
  else if (type === "ATR_FIB") {
    // Boost key Fibonacci levels (61.8%, 100%, 161.8%)
    const mult = Number(tpLevel.multiplier || 0);
    if (mult === 0.618 || mult === 1.0 || mult === 1.618) score += 0.2;
    else if (mult === 0.382 || mult === 0.786 || mult === 1.236) score += 0.15;
    else score += 0.1;
  } else if (type === "LIQUIDITY") score += 0.15;
  else if (type === "FVG") score += 0.1;
  else if (type === "GAP") score += 0.05;

  // Distance from entry (use horizon-aware bands)
  const distancePct = Math.abs(price - entryPrice) / entryPrice;
  const bands = horizonConfig || {};
  const sweetMin = Number(bands.sweetMin ?? 0.02);
  const sweetMax = Number(bands.sweetMax ?? 0.05);
  const okMin = Number(bands.okMin ?? 0.01);
  const okMax = Number(bands.okMax ?? 0.08);
  const minDist = Number(bands.minDistancePct ?? 0.01);
  const tooFar = Number(bands.tooFarPct ?? 0.15);

  if (distancePct >= sweetMin && distancePct <= sweetMax) {
    score += 0.2; // Sweet spot
  } else if (distancePct >= okMin && distancePct <= okMax) {
    score += 0.1; // Acceptable range
  } else if (distancePct < minDist) {
    score -= 0.2; // Too close - penalize
  } else if (distancePct > tooFar) {
    score -= 0.1; // Too far - slight penalty
  }

  // Clustering penalty: if many TPs are very close, prefer ones that stand out
  const clusteringThreshold = entryPrice * 0.005; // 0.5% clustering threshold
  const nearbyTPs = allTPs.filter((tp) => {
    const tpPrice = Number(tp.price || tp);
    return Math.abs(tpPrice - price) < clusteringThreshold;
  }).length;

  if (nearbyTPs > 3) {
    score -= 0.15; // Heavy clustering penalty
  } else if (nearbyTPs > 1) {
    score -= 0.05; // Light clustering penalty
  }

  return score;
}

// Helper: Fuse many TP candidates into a few "confluence" TP zones.
// We cluster nearby TPs and return weighted centroids (still direction-safe).
function fuseTPCandidates(
  tpCandidates,
  entryPrice,
  direction,
  risk,
  horizonConfig,
) {
  if (!Array.isArray(tpCandidates) || tpCandidates.length === 0) return [];
  const isLong = direction === "LONG";

  // Cluster distance: a blend of % of entry and fraction of risk.
  // This keeps clustering stable across different price ranges.
  const clusterAbs = Math.max(entryPrice * 0.003, (Number(risk) || 0) * 0.25); // ~0.3% or 0.25R

  const items = tpCandidates
    .map((tp) => {
      const price = Number(tp?.price);
      if (!Number.isFinite(price) || price <= 0) return null;
      return { ...tp, price };
    })
    .filter(Boolean)
    .sort((a, b) => a.price - b.price);

  const tfPriority = (tf) => {
    const t = String(tf || "D").toUpperCase();
    if (t === "W") return 3;
    if (t === "D") return 2;
    if (t === "240" || t === "4H") return 1;
    return 0;
  };

  const clusters = [];
  for (const tp of items) {
    const s = scoreTPLevel(tp, entryPrice, direction, items, horizonConfig);
    const w = Math.max(0.1, 1 + s); // keep weights positive
    const last = clusters[clusters.length - 1];
    if (!last) {
      clusters.push({
        items: [{ tp, s, w }],
        min: tp.price,
        max: tp.price,
        sumW: w,
        sumWP: w * tp.price,
      });
      continue;
    }

    // Add to cluster if close to its current centroid (or within min/max band)
    const centroid = last.sumWP / Math.max(1e-9, last.sumW);
    const closeToCentroid = Math.abs(tp.price - centroid) <= clusterAbs;
    const closeToBand =
      tp.price >= last.min - clusterAbs && tp.price <= last.max + clusterAbs;

    if (closeToCentroid || closeToBand) {
      last.items.push({ tp, s, w });
      last.min = Math.min(last.min, tp.price);
      last.max = Math.max(last.max, tp.price);
      last.sumW += w;
      last.sumWP += w * tp.price;
    } else {
      clusters.push({
        items: [{ tp, s, w }],
        min: tp.price,
        max: tp.price,
        sumW: w,
        sumWP: w * tp.price,
      });
    }
  }

  const fused = clusters
    .map((c, idx) => {
      const price = c.sumWP / Math.max(1e-9, c.sumW);
      // Direction safety: ignore clusters that ended up on wrong side (paranoia)
      if (isLong && price <= entryPrice) return null;
      if (!isLong && price >= entryPrice) return null;

      const bestTf = c.items
        .map((x) => x.tp?.timeframe)
        .sort((a, b) => tfPriority(b) - tfPriority(a))[0];

      const confidences = c.items
        .map((x) => Number(x.tp?.confidence))
        .filter((n) => Number.isFinite(n));
      const confidence =
        confidences.length > 0
          ? Math.max(...confidences) // prefer the strongest member
          : 0.75;

      const sources = Array.from(
        new Set(
          c.items.map((x) => String(x.tp?.source || "").trim()).filter(Boolean),
        ),
      );
      const types = Array.from(
        new Set(
          c.items.map((x) => String(x.tp?.type || "").trim()).filter(Boolean),
        ),
      );

      // Confluence score: sum of member scores + small boost for multiple confirmations,
      // and a light penalty for a very wide cluster.
      const sumScore = c.items.reduce((acc, x) => acc + (x.s || 0), 0);
      const confluenceBoost = 0.2 * Math.log(1 + c.items.length);
      const spreadPct = (c.max - c.min) / Math.max(1e-9, entryPrice);
      const spreadPenalty = Math.min(0.2, spreadPct * 2); // cap penalty
      const fusedScore = sumScore + confluenceBoost - spreadPenalty;

      return {
        price,
        source:
          sources.length > 0
            ? `FUSED(${c.items.length}): ${sources.slice(0, 2).join(", ")}`
            : `FUSED(${c.items.length})`,
        type:
          types.length > 0 ? `FUSED:${types.slice(0, 2).join(",")}` : "FUSED",
        timeframe: bestTf || "D",
        confidence,
        multiplier: null,
        label: `TP_FUSED_${idx + 1}`,
        _fused: {
          idx,
          count: c.items.length,
          min: c.min,
          max: c.max,
          score: fusedScore,
        },
      };
    })
    .filter(Boolean)
    .sort((a, b) => (b._fused?.score || 0) - (a._fused?.score || 0));

  return fused;
}

// ─────────────────────────────────────────────────────────────────────────────
// GOLD STANDARD PATTERNS (from historical movers analysis)
// ─────────────────────────────────────────────────────────────────────────────
// Derived from 637 significant moves (331 UP, 306 DOWN) across 160 tickers.
// These patterns identify the optimal entry conditions for LONG vs SHORT.
const GOLD_STANDARD_PATTERNS = {
  // LONG ENTRIES (from 331 UP moves, median +5.94%, P90 +15.19%)
  // Primary setup: HTF_BULL_LTF_PULLBACK (67.7% of big up moves started here)
  // Key insight: Buy the pullback when HTF is bullish but LTF has dipped
  LONG: {
    // Optimal state at entry (in order of preference)
    preferredStates: ["HTF_BULL_LTF_PULLBACK", "HTF_BEAR_LTF_BEAR", "HTF_BULL_LTF_BULL"],
    stateWeights: { HTF_BULL_LTF_PULLBACK: 1.0, HTF_BEAR_LTF_BEAR: 0.5, HTF_BULL_LTF_BULL: 0.4 },
    // Score thresholds at move start (from historical analysis)
    htf: { min: 10, optimal: 20, max: 50 },    // Median at start: +20, Avg: +16
    ltf: { min: -25, optimal: -9, max: 5 },    // Median at start: -9 (in pullback)
    // Corridor (LTF range for entry)
    corridor: { min: -15, max: 10 },           // Wider than SHORT; catch pullbacks
    // Pre-move signal frequency (for scoring)
    signals: {
      ltfPullback: 0.843,      // 84.3% of winners had LTF in pullback
      stateTransition: 0.366,  // 36.6% had state change before move
      htfImproving: 0.341,     // 34.1% had HTF momentum improving
      squeezeOn: 0.218,        // 21.8% had squeeze active (coiling)
      flipWatch: 0.163,        // 16.3% had flip watch
      stFlip: 0.118,           // 11.8% had ST flip
      squeezeRelease: 0.088,   // 8.8% had squeeze release
    },
    // Move statistics (for TP calibration)
    moveStats: { median: 5.94, p75: 9.5, p90: 15.19, avg: 8.17 },
    // TP multipliers (calibrated to median/P90 move)
    tpMultipliers: { trim: 0.6, exit: 1.0, runner: 1.5 },
  },

  // SHORT ENTRIES (from 306 DOWN moves, median -6.34%)
  // CRITICAL: 82.7% started from HTF_BULL_LTF_BULL (overextended momentum!)
  // Key insight: SHORT the blow-off top, NOT the bearish setup
  SHORT: {
    // Optimal state at entry - COUNTER-INTUITIVE!
    preferredStates: ["HTF_BULL_LTF_BULL", "HTF_BEAR_LTF_PULLBACK", "HTF_BULL_LTF_PULLBACK"],
    stateWeights: { HTF_BULL_LTF_BULL: 1.0, HTF_BEAR_LTF_PULLBACK: 0.3, HTF_BULL_LTF_PULLBACK: 0.2 },
    // Score thresholds at move start (BOTH positive = overextended)
    htf: { min: 20, optimal: 28, max: 50 },    // Median at start: +28 (strongly bullish!)
    ltf: { min: 10, optimal: 19, max: 35 },    // Median at start: +19 (also strong)
    // Corridor (LTF range for SHORT entry) - HIGH values indicate blow-off top
    corridor: { min: 12, max: 35 },            // Both HTF and LTF must be strong
    // Pre-move signal frequency
    signals: {
      ltfPullback: 0.905,      // 90.5% (note: "pullback" here means LTF was positive)
      stateTransition: 0.373,  // 37.3% had state change
      htfImproving: 0.359,     // 35.9% had HTF still improving (!)
      stFlip: 0.180,           // 18.0% had ST flip
      squeezeOn: 0.196,        // 19.6% had squeeze
      momentumElite: 0.144,    // 14.4% had momentum elite
    },
    // Move statistics (for TP calibration)
    moveStats: { median: 6.34, p75: 10.5, p90: 18.0, avg: 9.61 },
    // TP multipliers (calibrated to median/P90 move)
    tpMultipliers: { trim: 0.6, exit: 1.0, runner: 1.618 },
  },
};

// Helper: Check if ticker matches gold standard LONG pattern
function matchesGoldStandardLong(tickerData) {
  const state = String(tickerData?.state || "");
  const htf = Number(tickerData?.htf_score);
  const ltf = Number(tickerData?.ltf_score);
  const flags = tickerData?.flags || {};
  const gs = GOLD_STANDARD_PATTERNS.LONG;

  // Must have valid scores
  if (!Number.isFinite(htf) || !Number.isFinite(ltf)) return { match: false, score: 0 };

  let score = 0;
  const reasons = [];

  // State matching (primary criterion)
  if (gs.preferredStates.includes(state)) {
    score += gs.stateWeights[state] * 30;
    reasons.push(`state:${state}`);
  }

  // HTF in optimal range
  if (htf >= gs.htf.min && htf <= gs.htf.max) {
    const htfScore = htf >= gs.htf.optimal ? 25 : 15;
    score += htfScore;
    reasons.push(`htf:${htf.toFixed(1)}`);
  }

  // LTF in pullback (negative or low) - KEY for LONG
  if (ltf >= gs.ltf.min && ltf <= gs.ltf.max) {
    // Closer to optimal (-9) = higher score
    const ltfDist = Math.abs(ltf - gs.ltf.optimal);
    const ltfScore = Math.max(0, 25 - ltfDist);
    score += ltfScore;
    reasons.push(`ltf:${ltf.toFixed(1)}`);
  }

  // Signal bonuses
  if (flags.sq30_release) { score += 10; reasons.push("squeeze_release"); }
  if (flags.flip_watch) { score += 8; reasons.push("flip_watch"); }
  if (flags.momentum_elite && htf >= 15) { score += 5; reasons.push("momentum_elite"); }

  return { match: score >= 50, score, reasons };
}

// Helper: Check if ticker matches gold standard SHORT pattern (blow-off top)
function matchesGoldStandardShort(tickerData) {
  const state = String(tickerData?.state || "");
  const htf = Number(tickerData?.htf_score);
  const ltf = Number(tickerData?.ltf_score);
  const flags = tickerData?.flags || {};
  const gs = GOLD_STANDARD_PATTERNS.SHORT;

  // Must have valid scores
  if (!Number.isFinite(htf) || !Number.isFinite(ltf)) return { match: false, score: 0 };

  let score = 0;
  const reasons = [];

  // State matching - CRITICAL: look for HTF_BULL_LTF_BULL (blow-off top)
  if (gs.preferredStates.includes(state)) {
    score += gs.stateWeights[state] * 30;
    reasons.push(`state:${state}`);
  }

  // HTF must be STRONGLY POSITIVE for short (overextended)
  if (htf >= gs.htf.min && htf <= gs.htf.max) {
    // Higher HTF = stronger blow-off signal
    const htfScore = htf >= gs.htf.optimal ? 25 : 15;
    score += htfScore;
    reasons.push(`htf:${htf.toFixed(1)}`);
  }

  // LTF must also be POSITIVE (both overextended = blow-off top)
  if (ltf >= gs.ltf.min && ltf <= gs.ltf.max) {
    // Closer to optimal (+19) = higher score
    const ltfDist = Math.abs(ltf - gs.ltf.optimal);
    const ltfScore = Math.max(0, 25 - ltfDist);
    score += ltfScore;
    reasons.push(`ltf:${ltf.toFixed(1)}`);
  }

  // Additional blow-off indicators
  const completion = Number(tickerData?.completion) || 0;
  const phase = Number(tickerData?.phase_pct) || 0;
  if (completion >= 0.7) { score += 10; reasons.push("high_completion"); }
  if (phase >= 0.6) { score += 8; reasons.push("high_phase"); }
  if (flags.st_flip_bear) { score += 12; reasons.push("st_flip_bear"); }

  return { match: score >= 50, score, reasons };
}

// ─────────────────────────────────────────────────────────────────────────────
// Direction-specific SL Adjustment Logic
// ─────────────────────────────────────────────────────────────────────────────
// Based on historical analysis:
// - LONG entries from pullback: tighter initial SL (smaller risk, higher RR)
// - SHORT entries from blow-off top: wider initial SL (allow volatility)
// 
// This function suggests SL adjustments based on direction and pattern confidence.
function computeDirectionAwareSL(tickerData, baseSL, direction, entryPrice) {
  const isLong = direction === "LONG";
  const gsMatch = isLong ? matchesGoldStandardLong(tickerData) : matchesGoldStandardShort(tickerData);
  
  // If not a gold standard match, return base SL unchanged
  if (!gsMatch.match) return { sl: baseSL, adjusted: false, reason: null };
  
  // Get ATR for SL calculations
  let atr = Number(tickerData?.atr);
  if (!Number.isFinite(atr) || atr <= 0) {
    atr = Math.abs(entryPrice - baseSL);  // Infer from existing SL
  }
  
  let adjustedSL = baseSL;
  let reason = null;
  
  if (isLong) {
    // LONG from pullback: SL must survive typical pullbacks
    // JOURNEY DATA (28 detailed journeys, 103 pullbacks):
    //   Pullback depth: P25=0.60%, Median=1.22%, P75=2.20%, P90=3.29%
    //   In ATR:         P25=1.53,  Median=2.53,  P75=4.52,  P90=6.18
    // SL at 1.5x ATR survives ~40% of pullbacks; 2.5x survives ~50%.
    // We want to survive most normal pullbacks but cut losses on breakdowns.
    if (gsMatch.score >= 70) {
      const adjusted = entryPrice - atr * 1.5;  // 1.5x ATR (was 0.65x) — above median pullback
      if (adjusted > baseSL && adjusted < entryPrice) {
        adjustedSL = adjusted;
        reason = `GS_LONG_TIGHT_SL(score=${gsMatch.score},1.5ATR)`;
      }
    } else if (gsMatch.score >= 50) {
      // Medium confidence: wider buffer at 2.0x ATR
      const adjusted = entryPrice - atr * 2.0;  // 2.0x ATR (was 0.8x)
      if (adjusted > baseSL && adjusted < entryPrice) {
        adjustedSL = adjusted;
        reason = `GS_LONG_MED_SL(score=${gsMatch.score},2.0ATR)`;
      }
    }
  } else {
    // SHORT from blow-off top: wider SL to handle volatility at tops
    // JOURNEY DATA: Short candidate pullbacks (against-move) can spike 2-4 ATR
    // before reversing. Need room for the initial squeeze.
    if (gsMatch.score >= 70) {
      const wider = entryPrice + atr * 1.8;  // 1.8x ATR (was 1.0x) — room for squeeze
      if (wider > entryPrice && (wider > baseSL || baseSL < entryPrice)) {
        adjustedSL = wider;
        reason = `GS_SHORT_SL(score=${gsMatch.score},1.8ATR)`;
      }
    }
  }
  
  return { 
    sl: adjustedSL, 
    adjusted: adjustedSL !== baseSL, 
    reason,
    gsScore: gsMatch.score,
    gsReasons: gsMatch.reasons
  };
}

// ─────────────────────────────────────────────────────────────────────────────
// 3-TIER TP SYSTEM CONFIGURATION
// ─────────────────────────────────────────────────────────────────────────────
// Instead of variable 4-5 TP levels with 10-25-50-100% trims, we normalize to
// exactly 3 tiers with fixed quantities and progressive SL trailing.
// NOTE: These are now direction-aware via GOLD_STANDARD_PATTERNS.tpMultipliers
const THREE_TIER_CONFIG = {
  // ATR multiplier ranges for each tier (based on ATR-Fibonacci levels from Pine)
  // JOURNEY DATA (28 detailed journeys, 103 pullbacks):
  //   Median pullback depth: 1.22% / 2.53 ATR
  //   TRIM before pullback signals: ST flip (21%), ATR spike (14%), RSI OB (4%)
  //   Peak exhaustion signals: RSI OB (57%), price overextended (57%), RSI extreme (43%)
  //   Support during pullbacks: FVG (most), EMA8 (21%), EMA21 (9%), ST (6%)
  //
  // TRIM should fire BEFORE the typical pullback (1-2x ATR from entry).
  // EXIT should capture the bulk of the move (2-3x ATR).
  // RUNNER lets position ride for extended moves with trailing stop.
  TRIM: { minMult: 1.0, maxMult: 1.5, trimPct: 0.5, label: "TRIM TP" },    // 50% off at 1-1.5x ATR
  EXIT: { minMult: 1.5, maxMult: 2.5, trimPct: 0.75, label: "EXIT TP" },   // additional 25% at 1.5-2.5x ATR
  RUNNER: { minMult: 2.5, maxMult: 5.0, trimPct: 1.0, label: "RUNNER TP" }, // final 25% with trailing stop
};

// Helper: Infer ATR from TP levels when not directly available
function inferAtrFromTPLevels(tickerData, entryPrice) {
  const tpLevels = tickerData?.tp_levels;
  if (!Array.isArray(tpLevels) || tpLevels.length === 0) return null;
  
  // Find a TP with a known multiplier to back-calculate ATR
  for (const tp of tpLevels) {
    const price = Number(typeof tp === "object" ? tp.price : tp);
    const mult = Number(typeof tp === "object" ? tp.multiplier : null);
    if (Number.isFinite(price) && Number.isFinite(mult) && mult > 0 && Number.isFinite(entryPrice)) {
      const distance = Math.abs(price - entryPrice);
      return distance / mult;
    }
  }
  
  // Fallback: estimate ATR as ~2% of entry price (typical for stocks)
  return Number.isFinite(entryPrice) ? entryPrice * 0.02 : null;
}

// Helper: Build 3-tier TP array with ATR-based selection
// Normalizes variable TP levels to exactly 3 tiers: TRIM (60%), EXIT (80%), RUNNER (100%)
function build3TierTPArray(tickerData, entryPrice, direction) {
  const isLong = direction === "LONG";
  const sl = Number(tickerData.sl);

  if (!Number.isFinite(entryPrice) || !Number.isFinite(sl)) {
    return [];
  }

  // ── PRECISION ENGINE: Use ATR Fibonacci level-based TPs if available ──
  // These are computed from daily ATR levels: TRIM=61.8%, EXIT=100%, RUNNER=161.8%
  const pTrim = Number(tickerData.tp_trim);
  const pExit = Number(tickerData.tp_exit);
  const pRunner = Number(tickerData.tp_runner);
  const hasPrecisionTPs = Number.isFinite(pTrim) && pTrim > 0 &&
                          Number.isFinite(pExit) && pExit > 0 &&
                          Number.isFinite(pRunner) && pRunner > 0;

  if (hasPrecisionTPs) {
    // Validate TPs are in the correct direction
    const trimValid = isLong ? pTrim > entryPrice : pTrim < entryPrice;
    const exitValid = isLong ? pExit > entryPrice : pExit < entryPrice;
    const runnerValid = isLong ? pRunner > entryPrice : pRunner < entryPrice;

    if (trimValid && exitValid && runnerValid) {
      const result = [
        {
          price: pTrim,
          trimPct: THREE_TIER_CONFIG.TRIM.trimPct,
          tier: "TRIM",
          label: `TRIM TP (${Math.round(THREE_TIER_CONFIG.TRIM.trimPct * 100)}%) @ 61.8% ATR`,
          source: "ATR Fibonacci (Daily 61.8%)",
          timeframe: "D",
          multiplier: 0.618,
        },
        {
          price: pExit,
          trimPct: THREE_TIER_CONFIG.EXIT.trimPct,
          tier: "EXIT",
          label: `EXIT TP (${Math.round(THREE_TIER_CONFIG.EXIT.trimPct * 100)}%) @ 100% ATR`,
          source: "ATR Fibonacci (Daily 100%)",
          timeframe: "D",
          multiplier: 1.0,
        },
        {
          price: pRunner,
          trimPct: THREE_TIER_CONFIG.RUNNER.trimPct,
          tier: "RUNNER",
          label: `RUNNER TP (${Math.round(THREE_TIER_CONFIG.RUNNER.trimPct * 100)}%) @ 161.8% ATR`,
          source: "ATR Fibonacci (Daily 161.8%)",
          timeframe: "D",
          multiplier: 1.618,
        },
      ];
      // Sort by distance from entry (closest first)
      result.sort((a, b) => Math.abs(a.price - entryPrice) - Math.abs(b.price - entryPrice));
      return result;
    }
  }

  // ── FALLBACK: Legacy TP computation (tp_levels / ATR multipliers) ──

  // Get ATR from ticker data or infer from TP levels
  let atr = Number(tickerData.atr);
  if (!Number.isFinite(atr) || atr <= 0) {
    atr = inferAtrFromTPLevels(tickerData, entryPrice);
  }
  if (!Number.isFinite(atr) || atr <= 0) {
    // Last resort: use distance to SL as ATR proxy
    atr = Math.abs(entryPrice - sl);
  }

  // Extract all TP levels with metadata
  let tpLevels = [];
  if (
    tickerData.tp_levels &&
    Array.isArray(tickerData.tp_levels) &&
    tickerData.tp_levels.length > 0
  ) {
    tpLevels = tickerData.tp_levels
      .map((tpItem) => {
        if (typeof tpItem === "object" && tpItem !== null) {
          const price = Number(tpItem.price);
          const mult = tpItem.multiplier ? Number(tpItem.multiplier) : null;
          // If no multiplier, calculate it from ATR
          const calculatedMult = Number.isFinite(mult) ? mult :
            (Number.isFinite(price) && Number.isFinite(atr) && atr > 0
              ? Math.abs(price - entryPrice) / atr
              : null);
          return {
            price,
            source: tpItem.source || "ATR Level",
            type: tpItem.type || "ATR_FIB",
            timeframe: tpItem.timeframe || "D",
            confidence: Number(tpItem.confidence || 0.75),
            multiplier: calculatedMult,
            label: tpItem.label || "TP",
          };
        }
        const price = Number(tpItem);
        const calculatedMult = Number.isFinite(price) && Number.isFinite(atr) && atr > 0
          ? Math.abs(price - entryPrice) / atr
          : null;
        return {
          price,
          source: "ATR Level",
          type: "ATR_FIB",
          timeframe: "D",
          confidence: 0.75,
          multiplier: calculatedMult,
          label: "TP",
        };
      })
      .filter((item) => Number.isFinite(item.price) && item.price > 0);
  }

  // Add primary TP if valid
  const primaryTP = Number(tickerData.tp);
  if (Number.isFinite(primaryTP) && primaryTP > 0) {
    const calculatedMult = Number.isFinite(atr) && atr > 0
      ? Math.abs(primaryTP - entryPrice) / atr
      : null;
    tpLevels.push({
      price: primaryTP,
      source: "Primary TP",
      type: "ATR_FIB",
      timeframe: "D",
      confidence: 0.75,
      multiplier: calculatedMult,
      label: "TP",
    });
  }

  // Filter by direction (TP must be in profit direction)
  const validTPs = tpLevels.filter((item) => {
    const price = Number(item.price);
    if (!Number.isFinite(price) || price <= 0) return false;
    return isLong ? price > entryPrice : price < entryPrice;
  });

  // Group TPs by tier based on ATR multiplier
  const tiers = {
    TRIM: [],
    EXIT: [],
    RUNNER: [],
  };

  for (const tp of validTPs) {
    const mult = tp.multiplier;
    if (!Number.isFinite(mult)) continue;

    if (mult >= THREE_TIER_CONFIG.TRIM.minMult && mult < THREE_TIER_CONFIG.EXIT.minMult) {
      tiers.TRIM.push(tp);
    } else if (mult >= THREE_TIER_CONFIG.EXIT.minMult && mult < THREE_TIER_CONFIG.RUNNER.minMult) {
      tiers.EXIT.push(tp);
    } else if (mult >= THREE_TIER_CONFIG.RUNNER.minMult) {
      tiers.RUNNER.push(tp);
    }
  }

  // Select best TP from each tier (prefer HTF, then highest confidence)
  const selectBestFromTier = (tierTPs) => {
    if (tierTPs.length === 0) return null;
    
    // HTF priority: W > D > 4H > others
    const htfPriority = (tf) => {
      const t = String(tf || "D").toUpperCase();
      if (t === "W") return 3;
      if (t === "D") return 2;
      if (t === "240" || t === "4H") return 1;
      return 0;
    };
    
    tierTPs.sort((a, b) => {
      const htfDiff = htfPriority(b.timeframe) - htfPriority(a.timeframe);
      if (htfDiff !== 0) return htfDiff;
      return (b.confidence || 0) - (a.confidence || 0);
    });
    
    return tierTPs[0];
  };

  const trimTp = selectBestFromTier(tiers.TRIM);
  const exitTp = selectBestFromTier(tiers.EXIT);
  const runnerTp = selectBestFromTier(tiers.RUNNER);

  // ─────────────────────────────────────────────────────────────────────────────
  // GOLD STANDARD: Direction-specific TP multipliers
  // Based on historical analysis: LONG median +5.94%, SHORT median -6.34%
  // ─────────────────────────────────────────────────────────────────────────────
  const gsConfig = isLong ? GOLD_STANDARD_PATTERNS.LONG : GOLD_STANDARD_PATTERNS.SHORT;
  const gsTpMult = gsConfig.tpMultipliers;
  
  // Build the 3-tier array, interpolating missing tiers
  const result = [];

  // TRIM TP (0.618x - 1.0x ATR) - 60% off
  if (trimTp) {
    result.push({
      price: trimTp.price,
      trimPct: THREE_TIER_CONFIG.TRIM.trimPct,
      tier: "TRIM",
      label: `TRIM TP (${Math.round(THREE_TIER_CONFIG.TRIM.trimPct * 100)}%)`,
      source: trimTp.source,
      timeframe: trimTp.timeframe,
      multiplier: trimTp.multiplier,
    });
  } else {
    // Interpolate: use direction-specific multiplier from gold standard
    const trimMult = gsTpMult.trim || 0.75;
    const interpPrice = isLong
      ? entryPrice + atr * trimMult
      : entryPrice - atr * trimMult;
    result.push({
      price: interpPrice,
      trimPct: THREE_TIER_CONFIG.TRIM.trimPct,
      tier: "TRIM",
      label: `TRIM TP (${Math.round(THREE_TIER_CONFIG.TRIM.trimPct * 100)}%)`,
      source: `ATR Interpolated (GS ${direction})`,
      timeframe: "D",
      multiplier: trimMult,
    });
  }

  // EXIT TP (1.0x - 1.618x ATR) - 80% cumulative
  if (exitTp) {
    result.push({
      price: exitTp.price,
      trimPct: THREE_TIER_CONFIG.EXIT.trimPct,
      tier: "EXIT",
      label: `EXIT TP (${Math.round(THREE_TIER_CONFIG.EXIT.trimPct * 100)}%)`,
      source: exitTp.source,
      timeframe: exitTp.timeframe,
      multiplier: exitTp.multiplier,
    });
  } else {
    // Interpolate: use direction-specific multiplier from gold standard
    const exitMult = gsTpMult.exit || 1.272;
    const interpPrice = isLong
      ? entryPrice + atr * exitMult
      : entryPrice - atr * exitMult;
    result.push({
      price: interpPrice,
      trimPct: THREE_TIER_CONFIG.EXIT.trimPct,
      tier: "EXIT",
      label: `EXIT TP (${Math.round(THREE_TIER_CONFIG.EXIT.trimPct * 100)}%)`,
      source: `ATR Interpolated (GS ${direction})`,
      timeframe: "D",
      multiplier: exitMult,
    });
  }

  // RUNNER TP (1.618x+ ATR) - 100% cumulative
  if (runnerTp) {
    result.push({
      price: runnerTp.price,
      trimPct: THREE_TIER_CONFIG.RUNNER.trimPct,
      tier: "RUNNER",
      label: `RUNNER TP (${Math.round(THREE_TIER_CONFIG.RUNNER.trimPct * 100)}%)`,
      source: runnerTp.source,
      timeframe: runnerTp.timeframe,
      multiplier: runnerTp.multiplier,
    });
  } else {
    // Interpolate: use direction-specific multiplier from gold standard
    const runnerMult = gsTpMult.runner || 2.0;
    const interpPrice = isLong
      ? entryPrice + atr * runnerMult
      : entryPrice - atr * runnerMult;
    result.push({
      price: interpPrice,
      trimPct: THREE_TIER_CONFIG.RUNNER.trimPct,
      tier: "RUNNER",
      label: `RUNNER TP (${Math.round(THREE_TIER_CONFIG.RUNNER.trimPct * 100)}%)`,
      source: `ATR Interpolated (GS ${direction})`,
      timeframe: "D",
      multiplier: runnerMult,
    });
  }

  // Ensure TPs are sorted by distance from entry (closest first)
  result.sort((a, b) => {
    const distA = Math.abs(a.price - entryPrice);
    const distB = Math.abs(b.price - entryPrice);
    return distA - distB;
  });

  return result;
}

// Helper: Build intelligent TP array with progressive trim levels (25%, 50%, 75%)
// This creates a systematic TP array that allows holding winners longer
// DEPRECATED: Use build3TierTPArray instead - kept for backward compatibility
function buildIntelligentTPArray(tickerData, entryPrice, direction) {
  const isLong = direction === "LONG";
  const sl = Number(tickerData.sl);

  if (!Number.isFinite(entryPrice) || !Number.isFinite(sl)) {
    return [];
  }

  // Calculate risk (distance from entry to SL)
  const risk = Math.abs(entryPrice - sl);
  if (risk <= 0) return [];

  // Horizon-aware settings (short vs swing vs positional)
  const bucketRaw = String(
    tickerData.horizon_bucket ||
      horizonBucketFromEtaDays(tickerData.eta_days_v2 ?? tickerData.eta_days) ||
      "",
  )
    .trim()
    .toUpperCase();
  const bucket = bucketRaw || "SWING";

  const horizonConfigMap = {
    SHORT_TERM: {
      minDistancePct: 0.05, // 5% min run-up before first trim (was 3%)
      sweetMin: 0.05,
      sweetMax: 0.12,
      okMin: 0.03,
      okMax: 0.18,
      tooFarPct: 0.25,
      minDistanceBetweenTPs: 0.04,
      maxTPs: 3,
      trimLevels: [0.2, 0.5, 1.0],
      fallbackMultipliers: [0.7, 1.0, 1.4],
    },
    SWING: {
      minDistancePct: 0.06, // 6% min run-up before first trim (was 4%)
      sweetMin: 0.08,
      sweetMax: 0.2,
      okMin: 0.05,
      okMax: 0.3,
      tooFarPct: 0.45,
      minDistanceBetweenTPs: 0.06,
      maxTPs: 4,
      trimLevels: [0.1, 0.25, 0.5, 1.0],
      fallbackMultipliers: [0.6, 1.0, 1.6],
    },
    POSITIONAL: {
      minDistancePct: 0.08, // 8% min run-up before first trim (was 6%)
      sweetMin: 0.15,
      sweetMax: 0.4,
      okMin: 0.1,
      okMax: 0.6,
      tooFarPct: 0.8,
      minDistanceBetweenTPs: 0.1,
      maxTPs: 4,
      trimLevels: [0.1, 0.25, 0.5, 1.0],
      fallbackMultipliers: [0.5, 1.0, 1.8],
    },
  };
  const horizonConfig = horizonConfigMap[bucket] || horizonConfigMap.SWING;

  // Extract all TP levels with metadata
  let tpLevels = [];
  if (
    tickerData.tp_levels &&
    Array.isArray(tickerData.tp_levels) &&
    tickerData.tp_levels.length > 0
  ) {
    tpLevels = tickerData.tp_levels
      .map((tpItem) => {
        if (typeof tpItem === "object" && tpItem !== null) {
          return {
            price: Number(tpItem.price),
            source: tpItem.source || "ATR Level",
            type: tpItem.type || "ATR_FIB",
            timeframe: tpItem.timeframe || "D",
            confidence: Number(tpItem.confidence || 0.75),
            multiplier: tpItem.multiplier ? Number(tpItem.multiplier) : null,
            label: tpItem.label || "TP",
          };
        }
        return {
          price: Number(tpItem),
          source: "ATR Level",
          type: "ATR_FIB",
          timeframe: "D",
          confidence: 0.75,
          multiplier: null,
          label: "TP",
        };
      })
      .filter((item) => Number.isFinite(item.price) && item.price > 0);
  }

  // Add primary TP if valid
  const primaryTP = Number(tickerData.tp);
  if (Number.isFinite(primaryTP) && primaryTP > 0) {
    tpLevels.push({
      price: primaryTP,
      source: "Primary TP",
      type: "ATR_FIB",
      timeframe: "D",
      confidence: 0.75,
      multiplier: null,
      label: "TP",
    });
  }

  // Filter by direction and ensure they're beyond entry
  // Also filter out TPs that are too close - these are likely noise
  const minDistancePct = horizonConfig.minDistancePct;
  const validTPs = tpLevels
    .filter((item) => {
      const price = Number(item.price);
      if (!Number.isFinite(price) || price <= 0) return false;

      // Direction check
      const directionValid = isLong ? price > entryPrice : price < entryPrice;
      if (!directionValid) return false;

      // Distance check - filter out TPs too close to entry
      const distancePct = Math.abs(price - entryPrice) / entryPrice;
      if (distancePct < minDistancePct) return false;

      return true;
    })
    .sort((a, b) => {
      // Sort by distance from entry (closest first for LONG, furthest first for SHORT)
      const distA = Math.abs(a.price - entryPrice);
      const distB = Math.abs(b.price - entryPrice);
      return isLong ? distA - distB : distB - distA;
    });

  if (validTPs.length === 0) {
    // Fallback: create basic TP array from primary TP, enforcing min run-up
    if (Number.isFinite(primaryTP) && primaryTP > 0) {
      const rawDist = Math.abs(primaryTP - entryPrice) / entryPrice;
      const minRun = horizonConfig.minDistancePct;
      const scale = rawDist >= minRun ? 1 : minRun / Math.max(rawDist, 0.001);
      const baseDist = Math.abs(primaryTP - entryPrice) * scale;
      const tp1 = isLong
        ? entryPrice + baseDist
        : entryPrice - baseDist;
      const tp2 = isLong
        ? entryPrice + baseDist * 1.5
        : entryPrice - baseDist * 1.5;
      const tp3 = isLong
        ? entryPrice + baseDist * 2.0
        : entryPrice - baseDist * 2.0;

      return [
        { price: tp1, trimPct: 0.25, label: "TP1 (25%)" },
        { price: tp2, trimPct: 0.5, label: "TP2 (50%)" },
        { price: tp3, trimPct: 0.75, label: "TP3 (75%)" },
      ];
    }
    return [];
  }

  // Fuse raw TP candidates into a few "confluence" zones, then score those fused zones.
  // This prevents overreacting to noisy/clustered TP sets and yields more stable trim levels.
  const fusedTPs = fuseTPCandidates(
    validTPs,
    entryPrice,
    direction,
    risk,
    horizonConfig,
  );
  const baseForScoring = fusedTPs.length > 0 ? fusedTPs : validTPs;

  // Score all candidates (fused preferred; otherwise raw)
  const scoredTPs = baseForScoring.map((tpItem) => ({
    ...tpItem,
    score:
      tpItem && tpItem._fused && typeof tpItem._fused.score === "number"
        ? tpItem._fused.score
        : scoreTPLevel(tpItem, entryPrice, direction, validTPs, horizonConfig),
  }));

  // Prioritize HTF timeframes (Weekly/Daily) - these should be further away and more reliable
  // Sort by: HTF timeframe first, then by score
  scoredTPs.sort((a, b) => {
    const tfA = String(a.timeframe || "D").toUpperCase();
    const tfB = String(b.timeframe || "D").toUpperCase();

    // HTF priority: W > D > 4H > others
    const htfPriority = (tf) => {
      if (tf === "W") return 3;
      if (tf === "D") return 2;
      if (tf === "240" || tf === "4H") return 1;
      return 0;
    };

    const priorityA = htfPriority(tfA);
    const priorityB = htfPriority(tfB);

    // If same HTF priority, sort by score
    if (priorityA === priorityB) {
      return b.score - a.score;
    }

    // Higher HTF priority first
    return priorityB - priorityA;
  });

  // Build intelligent TP array with progressive trim levels
  // Strategy: Prioritize HTF timeframes (Weekly/Daily) and select 3-4 TPs that are well-spaced
  const selectedTPs = [];
  const minDistanceBetweenTPs = horizonConfig.minDistanceBetweenTPs;
  const maxTPs = horizonConfig.maxTPs;

  // First pass: Prioritize HTF timeframes (W, D) - these are more reliable and further away
  const htfTPs = scoredTPs.filter((tp) => {
    const tf = String(tp.timeframe || "D").toUpperCase();
    return tf === "W" || tf === "D";
  });

  // Second pass: If we don't have enough HTF TPs, add lower timeframe TPs
  const allTPsToConsider = htfTPs.length >= 3 ? htfTPs : scoredTPs;

  for (const tp of allTPsToConsider) {
    if (selectedTPs.length >= maxTPs) break;

    // Check if this TP is far enough from already selected TPs
    const tooClose = selectedTPs.some((selected) => {
      const distancePct = Math.abs(tp.price - selected.price) / entryPrice;
      return distancePct < minDistanceBetweenTPs;
    });

    if (!tooClose) {
      selectedTPs.push(tp);
    }
  }

  // If we don't have enough TPs, fill gaps intelligently
  if (selectedTPs.length < 3) {
    // Use top scored TPs and create intermediate levels
    const topTP = scoredTPs[0];
    if (topTP) {
      const baseDistance = Math.abs(topTP.price - entryPrice);
      const [m1, m2, m3] = horizonConfig.fallbackMultipliers || [0.6, 1.0, 1.5];

      // Create TP1 (closest)
      const tp1 = isLong
        ? entryPrice + baseDistance * m1
        : entryPrice - baseDistance * m1;

      // TP2 (middle) - use top scored TP
      const tp2 = topTP.price;

      // TP3 (farthest)
      const tp3 = isLong
        ? entryPrice + baseDistance * m3
        : entryPrice - baseDistance * m3;

      const trims = horizonConfig.trimLevels || [0.25, 0.5, 0.75];
      return [
        {
          price: tp1,
          trimPct: trims[0] || 0.25,
          label: `TP1 (${Math.round((trims[0] || 0.25) * 100)}%)`,
          source: topTP.source,
          timeframe: topTP.timeframe,
        },
        {
          price: tp2,
          trimPct: trims[1] || 0.5,
          label: `TP2 (${Math.round((trims[1] || 0.5) * 100)}%)`,
          source: topTP.source,
          timeframe: topTP.timeframe,
        },
        {
          price: tp3,
          trimPct: trims[2] || 0.75,
          label: `TP3 (${Math.round((trims[2] || 0.75) * 100)}%)`,
          source: topTP.source,
          timeframe: topTP.timeframe,
        },
      ];
    }
  }

  // Assign trim percentages to selected TPs
  // Closest TP = 25%, Middle = 50%, Farthest = 75%
  const sortedByDistance = [...selectedTPs].sort((a, b) => {
    const distA = Math.abs(a.price - entryPrice);
    const distB = Math.abs(b.price - entryPrice);
    return distA - distB;
  });

  const trimLevels = horizonConfig.trimLevels || [0.25, 0.5, 0.75];
  const tpArray = sortedByDistance.slice(0, 3).map((tp, idx) => ({
    price: tp.price,
    trimPct: trimLevels[idx] || 0.75,
    label: `TP${idx + 1} (${Math.round(trimLevels[idx] * 100)}%)`,
    source: tp.source,
    timeframe: tp.timeframe,
    confidence: tp.confidence,
  }));

  // If we have a 4th TP, add it as final exit
  if (sortedByDistance.length > 3 && trimLevels[3] != null) {
    const finalTP = sortedByDistance[3];
    tpArray.push({
      price: finalTP.price,
      trimPct: trimLevels[3],
      label: `TP4 (${Math.round(trimLevels[3] * 100)}%)`,
      source: finalTP.source,
      timeframe: finalTP.timeframe,
      confidence: finalTP.confidence,
    });
  }

  return tpArray;
}

// Helper: Get intelligent TP (best single or weighted blend) - for backward compatibility
function getIntelligentTP(tickerData, entryPrice, direction) {
  // Build TP array and return the first TP (25% trim level) as the primary TP
  const tpArray = buildIntelligentTPArray(tickerData, entryPrice, direction);
  if (tpArray.length > 0) {
    return tpArray[0].price;
  }

  // Fallback to original logic
  return getValidTP(tickerData, entryPrice, direction);
}

// Helper: Get valid TP based on direction and entry price (fallback)
function getValidTP(tickerData, entryPrice, direction) {
  const isLong = direction === "LONG";

  // Get TP from tickerData
  let tp = Number(tickerData.tp);

  // If tp_levels exists, extract all valid TP prices
  let tpPrices = [];
  if (
    tickerData.tp_levels &&
    Array.isArray(tickerData.tp_levels) &&
    tickerData.tp_levels.length > 0
  ) {
    tpPrices = tickerData.tp_levels
      .map((tpItem) => {
        if (
          typeof tpItem === "object" &&
          tpItem !== null &&
          tpItem.price != null
        ) {
          return Number(tpItem.price);
        }
        return typeof tpItem === "number" ? Number(tpItem) : null;
      })
      .filter((p) => Number.isFinite(p) && p > 0);
  }

  // Add the primary TP if it's valid
  if (Number.isFinite(tp) && tp > 0) {
    tpPrices.push(tp);
  }

  // Remove duplicates and sort
  tpPrices = [...new Set(tpPrices)].sort((a, b) => a - b);

  // Find first valid TP based on direction
  if (isLong) {
    // For LONG: TP must be above entry price
    const validTPs = tpPrices.filter((p) => p > entryPrice);
    if (validTPs.length > 0) {
      return validTPs[0]; // Return first (lowest) valid TP above entry
    }
    // If no valid TP found, check if primary TP is valid
    if (Number.isFinite(tp) && tp > entryPrice) {
      return tp;
    }
    // Fallback: use highest TP from levels (might still be invalid, but better than nothing)
    if (tpPrices.length > 0) {
      console.warn(
        `[TP VALIDATION] ⚠️ ${
          tickerData.ticker || "UNKNOWN"
        } LONG: No TP above entry $${entryPrice.toFixed(
          2,
        )}. Using highest TP: $${Math.max(...tpPrices).toFixed(2)}`,
      );
      return Math.max(...tpPrices);
    }
  } else {
    // For SHORT: TP must be below entry price
    const validTPs = tpPrices.filter((p) => p < entryPrice);
    if (validTPs.length > 0) {
      return validTPs[validTPs.length - 1]; // Return last (highest) valid TP below entry
    }
    // If no valid TP found, check if primary TP is valid
    if (Number.isFinite(tp) && tp < entryPrice) {
      return tp;
    }
    // Fallback: use lowest TP from levels
    if (tpPrices.length > 0) {
      console.warn(
        `[TP VALIDATION] ⚠️ ${
          tickerData.ticker || "UNKNOWN"
        } SHORT: No TP below entry $${entryPrice.toFixed(
          2,
        )}. Using lowest TP: $${Math.min(...tpPrices).toFixed(2)}`,
      );
      return Math.min(...tpPrices);
    }
  }

  // Last resort: return primary TP even if invalid
  if (Number.isFinite(tp) && tp > 0) {
    console.warn(
      `[TP VALIDATION] ⚠️ ${
        tickerData.ticker || "UNKNOWN"
      } ${direction}: Using invalid TP $${tp.toFixed(
        2,
      )} (entry: $${entryPrice.toFixed(2)})`,
    );
    return tp;
  }

  return null;
}

// Calculate RR at entry price (for trade creation) using intelligent TP array
function calculateRRAtEntry(tickerData, entryPrice) {
  const direction = getTradeDirection(tickerData.state);
  const sl = Number(tickerData.sl);

  if (!Number.isFinite(entryPrice) || !Number.isFinite(sl)) {
    return null;
  }

  // Build intelligent TP array and use max TP for RR calculation
  const tpArray = buildIntelligentTPArray(tickerData, entryPrice, direction);

  let maxTP = null;
  if (tpArray.length > 0) {
    // Use the highest TP from the array (farthest target)
    maxTP = Math.max(...tpArray.map((tp) => tp.price));
  } else {
    // Fallback to single TP
    const tp = getIntelligentTP(tickerData, entryPrice, direction);
    if (!Number.isFinite(tp)) return null;
    maxTP = tp;
  }

  const state = String(tickerData.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");

  let risk, gain;

  if (isLong) {
    risk = entryPrice - sl; // Risk from entry to SL
    gain = maxTP - entryPrice; // Gain from entry to max TP
  } else if (isShort) {
    risk = sl - entryPrice; // Risk from entry to SL
    gain = entryPrice - maxTP; // Gain from entry to max TP
  } else {
    risk = Math.abs(entryPrice - sl);
    gain = Math.abs(maxTP - entryPrice);
  }

  if (risk <= 0 || gain <= 0) return null;
  return gain / risk;
}

// Calculate trade P&L and status with progressive TP trimming (25%, 50%, 75%)
function calculateTradePnl(tickerData, entryPrice, existingTrade = null) {
  const direction = getTradeDirection(tickerData.state);
  if (!direction) return null;

  const sl = Number(tickerData.sl);
  const currentPrice = Number(tickerData.price);

  if (!Number.isFinite(sl) || !Number.isFinite(currentPrice)) {
    return null;
  }

  // Market is closed on weekends — never execute TP trims/exits on Sat/Sun.
  // (We still allow SL evaluation to be conservative.)
  const weekendNow = isNyWeekend(Date.now());

  const ticker = String(tickerData.ticker || "").toUpperCase();
  const isFutures = FUTURES_SPECS[ticker] || ticker.endsWith("1!");

  // For futures: trade 1 contract, calculate P&L based on point value
  // For stocks: calculate shares based on dollar amount
  let shares;
  let pointValue = 1; // Default for stocks (price per share)

  if (isFutures && FUTURES_SPECS[ticker]) {
    // Futures: always trade 1 contract
    shares = 1;
    pointValue = FUTURES_SPECS[ticker].pointValue;
  } else {
    // Stocks: calculate shares from dollar amount
    shares = TRADE_SIZE / entryPrice;
  }

  // Get or build 3-tier TP array
  let tpArray = existingTrade?.tpArray || [];
  if (tpArray.length === 0) {
    // Build 3-tier TP array if not stored in trade
    tpArray = build3TierTPArray(tickerData, entryPrice, direction);
  }

  // Defensive: If an entry price was corrected after the trade was created,
  // an older stored tpArray may no longer be on the profit side (e.g. TP < entry for LONG),
  // which can cause "TP trims" at a loss. Filter + rebuild if needed.
  const isLong = direction === "LONG";
  const minDistancePct = 0.01; // keep consistent with build3TierTPArray
  const isProfitSide = (tpPrice) =>
    isLong
      ? tpPrice > entryPrice &&
        (tpPrice - entryPrice) / entryPrice >= minDistancePct
      : tpPrice < entryPrice &&
        (entryPrice - tpPrice) / entryPrice >= minDistancePct;

  const sanitizedTpArray = Array.isArray(tpArray)
    ? tpArray
        .map((tp) => ({
          ...tp,
          price: Number(tp?.price),
          trimPct: Number(tp?.trimPct),
          tier: tp?.tier,
          label: tp?.label,
        }))
        .filter(
          (tp) =>
            Number.isFinite(tp.price) &&
            Number.isFinite(tp.trimPct) &&
            tp.trimPct > 0 &&
            tp.trimPct <= 1 &&
            isProfitSide(tp.price),
        )
        .sort((a, b) => (a.trimPct || 0) - (b.trimPct || 0))
    : [];

  // If the stored TP plan becomes invalid after entry corrections, rebuild it.
  if (sanitizedTpArray.length === 0) {
    const rebuilt = build3TierTPArray(tickerData, entryPrice, direction);
    if (Array.isArray(rebuilt) && rebuilt.length > 0) {
      tpArray = rebuilt;
    } else {
      tpArray = [];
    }
  } else {
    tpArray = sanitizedTpArray;
  }

  // Fallback to single TP if array is empty
  const fallbackTP =
    existingTrade?.tp || getIntelligentTP(tickerData, entryPrice, direction);
  if (tpArray.length === 0 && Number.isFinite(fallbackTP)) {
    tpArray = [{ price: fallbackTP, trimPct: 0.5, label: "TP (50%)" }];
  }

  const trimmedPct = existingTrade ? existingTrade.trimmedPct || 0 : 0;

  // Check which TP levels have been hit (sorted by trim percentage)
  const hitTPLevels = [];
  for (const tpLevel of tpArray) {
    const tpPrice = Number(tpLevel.price);
    if (!Number.isFinite(tpPrice)) continue;

    const hit = isLong ? currentPrice >= tpPrice : currentPrice <= tpPrice;
    if (hit) {
      hitTPLevels.push({
        ...tpLevel,
        price: tpPrice,
      });
    }
  }

  // Sort hit TPs by trim percentage (ascending)
  hitTPLevels.sort((a, b) => (a.trimPct || 0) - (b.trimPct || 0));

  // Check SL hit
  const hitSL = isLong ? currentPrice <= sl : currentPrice >= sl;

  let pnl = 0;
  let pnlPct = 0;
  let status = "OPEN";
  let newTrimmedPct = trimmedPct;
  let realizedPnl = 0; // P&L from trimmed portions

  if (hitSL) {
    // Stop Loss hit - close entire remaining position
    const slDiff = isLong ? sl - entryPrice : entryPrice - sl;

    // Calculate realized P&L from any previous trims
    for (const tpLevel of hitTPLevels) {
      const levelTrimPct = tpLevel.trimPct || 0;
      if (levelTrimPct <= trimmedPct) {
        const tpDiff = isLong
          ? tpLevel.price - entryPrice
          : entryPrice - tpLevel.price;
        // Only count the portion that was actually trimmed
        const alreadyCountedPct = Math.min(levelTrimPct, trimmedPct);
        realizedPnl += tpDiff * shares * pointValue * alreadyCountedPct;
      }
    }

    // Final P&L = realized from trims + remaining position at SL
    const remainingPct = 1 - trimmedPct;
    const remainingPnl = slDiff * shares * pointValue * remainingPct;
    pnl = realizedPnl + remainingPnl;
    pnlPct = ((sl - entryPrice) / entryPrice) * 100;
    status = "LOSS";
    return {
      shares,
      pnl,
      pnlPct,
      status,
      currentPrice,
      trimmedPct: trimmedPct,
      tpArray,
      exitPrice: sl,
      exitReason: "SL",
      exitCategory: "INVALIDATION",
    };
  } else if (hitTPLevels.length > 0 && !weekendNow) {
    // One or more TP levels hit - determine next trim action
    // Find the highest TP level hit that we haven't trimmed yet
    let nextTrimTP = null;
    for (const tpLevel of hitTPLevels) {
      const levelTrimPct = tpLevel.trimPct || 0;
      if (levelTrimPct > trimmedPct) {
        nextTrimTP = tpLevel;
        break; // Take the first (lowest) untrimmed TP
      }
    }

    if (nextTrimTP) {
      // Need to trim at this TP level
      const targetTrimPct = nextTrimTP.trimPct || 0.5;
      const trimAmount = targetTrimPct - trimmedPct;
      const tpDiff = isLong
        ? nextTrimTP.price - entryPrice
        : entryPrice - nextTrimTP.price;

      // Calculate realized P&L from all previous trims (including intermediate levels)
      for (const tpLevel of hitTPLevels) {
        const levelTrimPct = tpLevel.trimPct || 0;
        if (levelTrimPct < targetTrimPct && levelTrimPct > trimmedPct) {
          // Intermediate TP hit - calculate P&L for the portion between previous trim and this level
          const levelTpDiff = isLong
            ? tpLevel.price - entryPrice
            : entryPrice - tpLevel.price;
          const intermediateTrimAmount = levelTrimPct - trimmedPct;
          realizedPnl +=
            levelTpDiff * shares * pointValue * intermediateTrimAmount;
        }
      }

      // Calculate P&L from this trim
      const trimPnl = tpDiff * shares * pointValue * trimAmount;
      const trimPnlPct = ((nextTrimTP.price - entryPrice) / entryPrice) * 100;

      // If we've trimmed 100%, close the trade
      if (targetTrimPct >= 1.0) {
        // Full exit - calculate total P&L
        const totalRealizedPnl = realizedPnl + trimPnl;
        return {
          shares,
          pnl: totalRealizedPnl,
          pnlPct: trimPnlPct,
          status: totalRealizedPnl >= 0 ? "WIN" : "LOSS",
          currentPrice,
          trimmedPct: 1.0,
          tpArray,
          exitPrice: nextTrimTP.price,
          exitReason: "TP_FULL",
          exitCategory: "PROFIT_MANAGEMENT",
          trimPrice: nextTrimTP.price,
          trimTargetPct: targetTrimPct,
          trimDeltaPct: trimAmount,
        };
      }

      // Partial trim - return with new trimmed percentage
      return {
        shares,
        pnl: realizedPnl + trimPnl,
        pnlPct: trimPnlPct,
        status: "TP_HIT_TRIM",
        currentPrice,
        trimmedPct: targetTrimPct,
        tpArray, // Store TP array for next check
        decisionCategory: "PROFIT_MANAGEMENT",
        trimPrice: nextTrimTP.price,
        trimTargetPct: targetTrimPct,
        trimDeltaPct: trimAmount,
      };
    } else {
      // Already trimmed at all hit TP levels - check if we should hold winners
      // Calculate current price vs entry
      const priceDiff = isLong
        ? currentPrice - entryPrice
        : entryPrice - currentPrice;
      const priceDiffPct = (priceDiff / entryPrice) * 100;

      // Calculate realized P&L from all trims
      for (const tpLevel of hitTPLevels) {
        const levelTrimPct = tpLevel.trimPct || 0;
        if (levelTrimPct <= trimmedPct) {
          const levelTpDiff = isLong
            ? tpLevel.price - entryPrice
            : entryPrice - tpLevel.price;
          // Count the portion that was actually trimmed
          const trimmedAtThisLevel = Math.min(levelTrimPct, trimmedPct);
          const prevTrimmedPct = hitTPLevels
            .filter((tp) => (tp.trimPct || 0) < levelTrimPct)
            .reduce((sum, tp) => Math.max(sum, tp.trimPct || 0), 0);
          const trimAmount = trimmedAtThisLevel - prevTrimmedPct;
          if (trimAmount > 0) {
            realizedPnl += levelTpDiff * shares * pointValue * trimAmount;
          }
        }
      }

      // Check if we should hold winners (price above 4H 8-13 EMA cloud)
      // Use 4H EMA cloud position if available, otherwise fallback to price momentum
      let shouldHold = false;
      const fourHEMACloud = tickerData.fourh_ema_cloud;

      if (fourHEMACloud && fourHEMACloud.position) {
        // Use 4H EMA cloud position for hold decision
        if (isLong) {
          // For LONG: hold if price is above the 4H EMA cloud
          shouldHold = fourHEMACloud.position === "above" && trimmedPct < 1.0;
        } else {
          // For SHORT: hold if price is below the 4H EMA cloud
          shouldHold = fourHEMACloud.position === "below" && trimmedPct < 1.0;
        }
      } else {
        // Fallback: use price momentum and profit threshold
        // Hold if: price is significantly above entry (>2%) and we haven't trimmed everything
        shouldHold = priceDiffPct > 2.0 && trimmedPct < 1.0;
      }

      if (shouldHold) {
        // Hold remaining position - calculate unrealized P&L
        const remainingPct = 1 - trimmedPct;
        const unrealizedPnl = priceDiff * shares * pointValue * remainingPct;

        return {
          shares,
          pnl: realizedPnl + unrealizedPnl,
          pnlPct: priceDiffPct,
          status: "OPEN", // Still holding
          currentPrice,
          trimmedPct,
          tpArray,
          exitReason: null,
          decisionCategory: "PROFIT_MANAGEMENT",
        };
      }

      // Not holding - calculate current P&L
      const remainingPct = 1 - trimmedPct;
      const currentPnl = priceDiff * shares * pointValue * remainingPct;

      return {
        shares,
        pnl: realizedPnl + currentPnl,
        pnlPct: priceDiffPct,
        status: "OPEN",
        currentPrice,
        trimmedPct,
        tpArray,
        exitReason: null,
        decisionCategory: "PROFIT_MANAGEMENT",
      };
    }
  } else {
    // No TP hit yet - calculate unrealized P&L
    const priceDiff = isLong
      ? currentPrice - entryPrice
      : entryPrice - currentPrice;
    const remainingPct = 1 - trimmedPct;
    pnl = priceDiff * shares * pointValue * remainingPct;
    pnlPct = ((currentPrice - entryPrice) / entryPrice) * 100;

    // Add realized P&L from any previous trims (shouldn't happen if no TP hit, but handle edge case)
    if (trimmedPct > 0 && hitTPLevels.length > 0) {
      // Estimate realized P&L based on highest TP hit
      const highestTP = hitTPLevels[hitTPLevels.length - 1];
      const tpDiff = isLong
        ? highestTP.price - entryPrice
        : entryPrice - highestTP.price;
      realizedPnl = tpDiff * shares * pointValue * trimmedPct;
      pnl += realizedPnl;
    }

    status = "OPEN";
  }

  return {
    shares,
    pnl,
    pnlPct,
    status,
    currentPrice,
    trimmedPct: newTrimmedPct,
    tpArray,
    exitReason: null,
  };
}

// Pattern Recognition: Analyze winning patterns from trade history
function analyzeWinningPatterns(tradeHistory, currentTickers) {
  if (!tradeHistory || tradeHistory.length === 0) {
    return { summary: "No trade history available for pattern analysis" };
  }

  const wins = tradeHistory.filter((t) => t.status === "WIN");
  const losses = tradeHistory.filter((t) => t.status === "LOSS");
  const winRate = wins.length / tradeHistory.length;

  // Analyze by rank ranges
  const rankPatterns = {};
  tradeHistory.forEach((t) => {
    const rank = Math.floor((t.rank || 0) / 10) * 10; // Group by 10s
    const key = `Rank ${rank}-${rank + 9}`;
    if (!rankPatterns[key]) {
      rankPatterns[key] = { wins: 0, losses: 0, totalPnl: 0 };
    }
    if (t.status === "WIN") rankPatterns[key].wins++;
    if (t.status === "LOSS") rankPatterns[key].losses++;
    rankPatterns[key].totalPnl += t.pnl || 0;
  });

  // Analyze by RR ranges
  const rrPatterns = {};
  tradeHistory.forEach((t) => {
    const rr = t.rr || 0;
    let range = "Unknown";
    if (rr >= 2.0) range = "RR ≥ 2.0";
    else if (rr >= 1.5) range = "RR 1.5-2.0";
    else if (rr >= 1.0) range = "RR 1.0-1.5";
    else if (rr > 0) range = "RR < 1.0";

    if (!rrPatterns[range]) {
      rrPatterns[range] = { wins: 0, losses: 0, totalPnl: 0 };
    }
    if (t.status === "WIN") rrPatterns[range].wins++;
    if (t.status === "LOSS") rrPatterns[range].losses++;
    rrPatterns[range].totalPnl += t.pnl || 0;
  });

  // Find best performing patterns
  const bestRankPattern = Object.entries(rankPatterns)
    .filter(([_, stats]) => stats.wins + stats.losses >= 3)
    .sort((a, b) => {
      const aRate = a[1].wins / (a[1].wins + a[1].losses || 1);
      const bRate = b[1].wins / (b[1].wins + b[1].losses || 1);
      return bRate - aRate;
    })[0];

  const bestRRPattern = Object.entries(rrPatterns)
    .filter(([_, stats]) => stats.wins + stats.losses >= 3)
    .sort((a, b) => {
      const aRate = a[1].wins / (a[1].wins + a[1].losses || 1);
      const bRate = b[1].wins / (b[1].wins + b[1].losses || 1);
      return bRate - aRate;
    })[0];

  // Match current tickers to winning patterns
  const matchingSetups = currentTickers.filter((t) => {
    if (!bestRankPattern || !bestRRPattern) return false;
    const rankRange = bestRankPattern[0];
    const rrRange = bestRRPattern[0];
    const tickerRank = Math.floor((t.rank || 0) / 10) * 10;
    const rankMatch = rankRange.includes(`Rank ${tickerRank}`);
    const rrMatch =
      (rrRange === "RR ≥ 2.0" && t.rr >= 2.0) ||
      (rrRange === "RR 1.5-2.0" && t.rr >= 1.5 && t.rr < 2.0) ||
      (rrRange === "RR 1.0-1.5" && t.rr >= 1.0 && t.rr < 1.5);
    return rankMatch && rrMatch;
  });

  return {
    summary: `Analyzed ${tradeHistory.length} trades. Win rate: ${(
      winRate * 100
    ).toFixed(1)}%. Best pattern: ${bestRankPattern?.[0] || "N/A"} with ${
      bestRRPattern?.[0] || "N/A"
    } RR. ${matchingSetups.length} current setups match winning patterns.`,
    bestRankPattern: bestRankPattern?.[0] || null,
    bestRRPattern: bestRRPattern?.[0] || null,
    matchingSetups: matchingSetups.slice(0, 5).map((t) => t.ticker),
    winRate: winRate,
  };
}

// Process trade simulation for a ticker (called on ingest)
// options.replayBatchContext: { allTrades } - use pre-loaded trades, skip KV reads/writes for trades+exec (replay perf)
async function processTradeSimulation(
  KV,
  ticker,
  tickerData,
  prevData,
  env = null,
  options = {},
) {
  const forceUseIngestTs = !!options?.forceUseIngestTs;
  const replayCtx = options?.replayBatchContext;
  const isReplay = !!replayCtx;
  // During replay, use ingest timestamp for all event timestamps (not Date.now())
  const asOfMsRaw = options?.asOfTs ?? tickerData?.ts ?? tickerData?.ingest_ts;
  const asOfMs = (isReplay && asOfMsRaw != null)
    ? (Number(asOfMsRaw) < 1e12 ? Number(asOfMsRaw) * 1000 : Number(asOfMsRaw))
    : null;
  const eventTs = () =>
    Number.isFinite(asOfMs) ? new Date(asOfMs).toISOString() : new Date().toISOString();

  // ── Execution Adapter: all trade mutations go through this ──
  // During replay, skip adapter (no D1 writes or Alpaca calls — trades are in-memory only)
  const adapter = (!isReplay && env) ? createExecutionAdapter(env, {
    d1UpsertTrade,
    d1InsertTradeEvent,
    d1InsertPosition,
    d1UpdatePosition,
    d1UpdatePositionSL,
    d1InsertExecutionAction,
    d1InsertLot,
  }) : null;

  try {
    const tradesKey = "timed:trades:all";
    let allTrades;
    if (isReplay) {
      allTrades = replayCtx.allTrades || [];
    } else if (env?.DB) {
      allTrades = (await d1LoadTradesForSimulation(env)) ?? (await kvGetJSON(KV, tradesKey)) ?? [];
    } else {
      allTrades = (await kvGetJSON(KV, tradesKey)) || [];
    }

    const sym = String(ticker || "").toUpperCase();
    
    // Skip futures contracts - they require special handling that's not implemented
    if (FUTURES_TICKERS.has(sym)) {
      return { skipped: true, reason: "futures_not_supported" };
    }
    // Skip non-equity instruments (VIX, commodities, leveraged ETFs)
    if (NON_EQUITY_BLOCKLIST.has(sym)) {
      return { skipped: true, reason: "non_equity_blocked" };
    }
    
    // ═══════════════════════════════════════════════════════════════════════════
    // VIX-BASED VOLATILITY FILTER: Block entries during extreme volatility
    // VIX > 25: Block new LONG entries (too risky for pullback plays)
    // VIX > 30: Block ALL new entries (market regime is broken)
    // ═══════════════════════════════════════════════════════════════════════════
    let vixLevel = null;
    let vixSkipReason = null;
    // Skip VIX KV read during replay (too many subrequests)
    if (!isReplay) {
      try {
        const vixData = await kvGetJSON(KV, "timed:latest:VIX");
        if (vixData && Number.isFinite(Number(vixData.price))) {
          vixLevel = Number(vixData.price);
          // Get trade direction early for VIX check
          const entryPathCheck = String(tickerData?.__entry_path || tickerData?.entry_path || "").toLowerCase();
          const isLongEntry = entryPathCheck.includes("long") || 
            (tickerData.state === "HTF_BULL_LTF_PULLBACK" && !entryPathCheck.includes("short"));
          
          if (vixLevel > 30) {
            vixSkipReason = `vix_extreme_${vixLevel.toFixed(1)}`;
          } else if (vixLevel > 25 && isLongEntry) {
            vixSkipReason = `vix_high_long_blocked_${vixLevel.toFixed(1)}`;
          }
        }
      } catch (vixErr) {
        // VIX data unavailable - continue without filtering
        console.warn("[VIX_CHECK] Failed to get VIX data:", String(vixErr?.message || vixErr));
      }
    }
    
    // Determine trade direction based on entry path (for mean-reversion entries like gold_short)
    // or fall back to state-based direction
    const entryPath = String(tickerData?.__entry_path || tickerData?.entry_path || "").toLowerCase();
    const stateDirection = getTradeDirection(tickerData.state); // BULL->LONG, BEAR->SHORT
    let direction;
    if (entryPath.includes("short")) {
      // gold_short, gold_short_medium: SHORT
      direction = "SHORT";
    } else if (entryPath.includes("long")) {
      // gold_long, gold_long_shallow: LONG
      direction = "LONG";
    } else {
      // Fall back to state-based direction (momentum, squeeze, etc.)
      direction = stateDirection;
    }
    if (!direction) return;
    
    // ─────────────────────────────────────────────────────────────────────────
    // DIRECTION VALIDATION: Allow intentional mean-reversion entries (gold_short)
    // Gold Short is a DELIBERATE counter-trend play on blow-off tops:
    //   HTF_BULL_LTF_BULL + high HTF/LTF = overextended → SHORT (mean reversion)
    // Only block mismatches that are NOT from a recognized entry path.
    // Data: 82.7% of big DOWN moves start from HTF_BULL_LTF_BULL (Historical Movers)
    // ─────────────────────────────────────────────────────────────────────────
    const isGoldShortEntry = entryPath.includes("gold_short");
    const isGoldLongEntry = entryPath.includes("gold_long");
    const hasIntentionalEntryPath = isGoldShortEntry || isGoldLongEntry;
    
    // Only block direction mismatches for entries WITHOUT a recognized entry path
    // (e.g., momentum/squeeze entries where direction must align with state)
    const directionMismatch = stateDirection && direction !== stateDirection && !hasIntentionalEntryPath;
    if (directionMismatch) {
      console.log(`[DIRECTION_MISMATCH] ${sym}: entryPath=${entryPath} suggests ${direction}, but state=${tickerData.state} suggests ${stateDirection}. Blocking entry.`);
      return { skipped: true, reason: `direction_mismatch: ${direction} vs ${stateDirection}` };
    }

    // Phase 3: Prefer open position from D1 (single source of truth); fall back to KV
    let openTrade = null;
    let openPositionContext = null;  // D1 position with SL for stage classification
    if (env?.DB && !isReplay) {
      openPositionContext = await getPositionContext(env, sym);
      openTrade = await getOpenPositionAsTrade(env, sym, direction) ||
        await getOpenPositionAsTrade(env, sym, direction === "LONG" ? "SHORT" : "LONG");
    }
    if (openTrade == null) {
      openTrade = allTrades.find(
        (t) =>
          String(t?.ticker || "").toUpperCase() === sym &&
          isOpenTradeStatus(t?.status),
      ) || null;
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // FIX: Check for recent trades (ANY status) to prevent rapid re-entry
    // During replay, trades can be immediately marked WIN/LOSS in the same cycle,
    // causing isOpenTradeStatus to return false and allowing duplicate entries.
    // Block entry if there's ANY trade for this ticker within the last 30 minutes.
    // ─────────────────────────────────────────────────────────────────────────
    const RECENT_TRADE_WINDOW_MS = 10 * 60 * 1000; // 10 minutes (reduced from 30m to allow faster re-entry after quick exits)
    const recentTrade = allTrades.find((t) => {
      if (String(t?.ticker || "").toUpperCase() !== sym) return false;
      const entryTs = Number(t?.entry_ts) || isoToMs(t?.entryTime) || 0;
      const entryTsNorm = entryTs < 1e12 ? entryTs * 1000 : entryTs;
      const nowForCheck = isReplay && Number.isFinite(asOfMs) ? asOfMs : Date.now();
      const age = nowForCheck - entryTsNorm;
      return age >= 0 && age < RECENT_TRADE_WINDOW_MS;
    }) || null;
    
    // If we have an open trade from KV but no D1 context, try to use trade's SL
    if (openTrade && !openPositionContext && Number.isFinite(openTrade.sl)) {
      openPositionContext = {
        status: "OPEN",
        direction: openTrade.direction,
        sl: openTrade.sl,
        entryPrice: openTrade.entryPrice,
        avgEntry: openTrade.entryPrice,
      };
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // SECTOR ALIGNMENT: Refresh sector consensus cache (async, non-blocking).
    // This ensures qualifiesForEnter and classifyKanbanStage have fresh data.
    // During replay, skip (KV reads are expensive and sector data is stale).
    // ─────────────────────────────────────────────────────────────────────────
    if (!isReplay && KV) {
      try {
        // Fire-and-forget: compute sector alignment for this ticker's sector
        // Result is cached in _sectorAlignmentCache for sync access in pure functions
        await computeSectorAlignment(KV, sym);
      } catch { /* sector alignment is a boost, not a gate — never block on failure */ }
    }

    // ─────────────────────────────────────────────────────────────────────────
    // RE-COMPUTE KANBAN STAGE WITH POSITION CONTEXT
    // This ensures exit/trim detection uses the position's trailing SL
    // ─────────────────────────────────────────────────────────────────────────
    const storedStage = String(tickerData?.kanban_stage || "").trim().toLowerCase();
    const recomputedStage = openPositionContext 
      ? classifyKanbanStage(tickerData, openPositionContext)
      : storedStage;
    const stage = String(recomputedStage || storedStage || "").trim().toLowerCase();
    
    const prevStage = String(prevData?.kanban_stage || "")
      .trim()
      .toLowerCase();
    
    const openTradeDir =
      openTrade && String(openTrade.direction || "").toUpperCase();
    // CRITICAL: Use simulation time (asOfMs) during replay, not wall-clock time.
    // Without this, min hold timers are meaningless in replay because entries and exits
    // from different times of day are processed within milliseconds of each other.
    const now = (isReplay && Number.isFinite(asOfMs) && asOfMs > 0) ? asOfMs : Date.now();

    // Portfolio (cash gating + bookkeeping)
    let portfolio = isReplay
      ? { cash: 1e9 }
      : await getPortfolioState(KV);

    const stageTransition = stage && stage !== prevStage;
    // IMPORTANT:
    // Entering only on stage *transition* can miss entries if we don't ingest during the brief
    // window where a ticker first enters ENTER. If the ticker remains in ENTER and there
    // is still no open trade, we should re-attempt entry on subsequent ingests (cooldown + cycle guard
    // prevent churn / duplicate entries).
    // Support both new "enter" stage and legacy "enter_now" stage
    const isEnter = stage === "enter" || stage === "enter_now";
    // DEBUG: Log stage computation
    if (isReplay && (stage === "enter" || stage === "enter_now")) {
      console.log(`[REPLAY_ENTER_CHECK] ${sym} stage=${stage} storedStage=${storedStage} recomputedStage=${recomputedStage} isEnter=${isEnter} entryPath=${tickerData?.__entry_path}`);
    }
    // IMPORTANT:
    // Trimming only on stage *transition* can miss trims if we miss the first TRIM-lane ingest
    // (or if the TRIM lane persists). Use cooldown + trimmedPct guard to prevent churn.
    const isTrim = stage === "trim";
    // IMPORTANT:
    // Exiting only on stage *transition* can get stuck if we miss the first "enter exit lane"
    // ingest, or the exit is throttled by cooldown. If a ticker remains in the EXIT lane while
    // the ledger trade is still OPEN/TP_HIT_TRIM, we should re-attempt the exit on subsequent
    // ingests (cooldown prevents churn).
    const isExit = stage === "exit";

    // Idempotency / anti-flap guards (per ticker) — skipped in replay (no cooldown for historical)
    const execKey = `timed:exec:last:${sym}`;
    const execState = isReplay ? {} : (await kvGetJSON(KV, execKey)) || {};
    const lastEnterMs = Number(execState.lastEnterMs);
    const lastTrimMs = Number(execState.lastTrimMs);
    const lastExitMs = Number(execState.lastExitMs);
    const lastEnterTriggerTs = Number(execState.lastEnterTriggerTs);
    const lastEnterSide =
      execState.lastEnterSide != null ? String(execState.lastEnterSide) : null;
    const curTriggerTs = Number(tickerData?.trigger_ts);
    // DATA: 66% of entries were within 1hr of previous on same ticker. Most were losers.
    // Increase cooldown from 10m to 4hrs to prevent rapid re-entry churn.
    const ENTER_COOLDOWN_MS = 4 * 60 * 60 * 1000; // 4 hours
    const enterCooldownOk =
      !Number.isFinite(lastEnterMs) || now - lastEnterMs >= ENTER_COOLDOWN_MS;
    const trimCooldownOk =
      !Number.isFinite(lastTrimMs) || now - lastTrimMs >= 5 * 60 * 1000; // 5m
    // Require position to be open at least N minutes before allowing first/next trim
    // DATA: Winner median hold = 3min for trims, so 10min gives room without blocking good trims
    const MIN_MINUTES_SINCE_ENTRY_BEFORE_TRIM = 10;
    // Require position to be open at least N minutes before exit
    // DATA: 62/80 trades exited in <15min. Losers median hold = 5min.
    // Increasing to 25min forces trades to survive initial noise.
    // Only exception: hard SL breach (handled separately)
    const MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT = 25;
    const entryMs =
      openTrade == null
        ? null
        : Number(openTrade.entry_ts) ||
          isoToMs(openTrade.entryTime) ||
          isoToMs(openTrade.entry_time) ||
          null;
    const entryMsNorm = entryMs != null && entryMs < 1e12 ? entryMs * 1000 : entryMs;
    const minEntryAgeMs = MIN_MINUTES_SINCE_ENTRY_BEFORE_TRIM * 60 * 1000;
    const trimMinAgeOk =
      openTrade == null ||
      !Number.isFinite(entryMsNorm) ||
      now - entryMsNorm >= minEntryAgeMs;
    // Exit minimum age: position must be open for at least 15 min before exit is allowed
    const minExitAgeMs = MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT * 60 * 1000;
    const exitMinAgeOk =
      openTrade == null ||
      !Number.isFinite(entryMsNorm) ||
      now - entryMsNorm >= minExitAgeMs;
    const exitCooldownOk =
      !Number.isFinite(lastExitMs) || now - lastExitMs >= 5 * 60 * 1000; // 5m
    const sameEnterCycle =
      Number.isFinite(curTriggerTs) &&
      curTriggerTs > 0 &&
      Number.isFinite(lastEnterTriggerTs) &&
      lastEnterTriggerTs > 0 &&
      lastEnterTriggerTs === curTriggerTs &&
      !!lastEnterSide &&
      lastEnterSide === direction;

    const pxNow = Number(tickerData?.price);
    const entryPxCandidate =
      Number(tickerData?.entry_price) ||
      Number(tickerData?.entry_ref) ||
      Number(tickerData?.trigger_price) ||
      pxNow ||
      null;

    const move =
      tickerData?.move_status && typeof tickerData.move_status === "object"
        ? tickerData.move_status
        : null;
    const reasons = Array.isArray(move?.reasons) ? move.reasons : [];
    const reason =
      reasons.length > 0
        ? String(reasons[0])
        : stage
          ? `KANBAN_${stage.toUpperCase()}`
          : "KANBAN";

    const persistTrades = async () => {
      allTrades.sort((a, b) => {
        const timeA = new Date(a.entryTime || 0).getTime();
        const timeB = new Date(b.entryTime || 0).getTime();
        return timeB - timeA;
      });
      if (!isReplay) await kvPutJSON(KV, tradesKey, allTrades);
    };

    const upsertAlertSafe = async (alert) => {
      try {
        if (!env || isReplay) return; // Skip D1 alert writes during replay
        await d1UpsertAlert(env, alert);
      } catch (e) {
        console.error("[D1 LEDGER] alert upsert failed:", e);
      }
    };

    const closeTradeAtPrice = async (trade, closePrice, closeReason) => {
      const p = Number(closePrice);
      if (!Number.isFinite(p) || p <= 0) return;
      const trimmed = clamp(Number(trade.trimmedPct || 0), 0, 1);
      const remainingPct = Math.max(0, 1 - trimmed);
      const shares = Number(trade.shares);
      if (!Number.isFinite(shares)) return;
      const remainingShares = shares * remainingPct;

      const dirSign =
        String(trade.direction || "").toUpperCase() === "SHORT" ? -1 : 1;
      const pnlRemaining =
        (p - Number(trade.entryPrice)) *
        remainingShares *
        (Number(trade.pointValue) || 1) *
        dirSign;
      trade.realizedPnl = Number(trade.realizedPnl || 0) + pnlRemaining;

      const ev = {
        type: "EXIT",
        timestamp: eventTs(),
        price: p,
        shares: remainingShares,
        value: p * remainingShares,
        reason: closeReason,
        pnl_realized: pnlRemaining,
        note: `Exit at $${p.toFixed(2)} (${closeReason})`,
      };
      trade.history = Array.isArray(trade.history)
        ? [...trade.history, ev]
        : [ev];

      trade.exitReason = closeReason;
      trade.exitPrice = p;
      trade.status = trade.realizedPnl >= 0 ? "WIN" : "LOSS";
      trade.pnl = trade.realizedPnl;
      trade.pnlPct =
        Number.isFinite(Number(trade.notional)) && Number(trade.notional) > 0
          ? (trade.pnl / Number(trade.notional)) * 100
          : null;
      trade.lastUpdate = eventTs();

      // Portfolio cash increases by proceeds
      portfolio.cash = Number(portfolio.cash) + p * remainingShares;

      // Persist via execution adapter (D1 source of truth), then Discord
      if (adapter) {
        await adapter.closePosition(sym, {
          _price: p,
          _reason: closeReason,
          _trade: trade,
          _event: ev,
          _remainingShares: remainingShares,
          _pnl: pnlRemaining,
          _isPartialClose: false,
        }).catch((e) => {
          console.error("[EXEC] closeTradeAtPrice adapter failed:", e);
        });
        
        // Clear entry state from ticker's KV record to prevent stale position showing in kanban
        // This ensures ticker returns to opportunity lanes after position closes
        try {
          const latestKey = `timed:latest:${sym}`;
          const existingPayload = await kvGetJSON(KV, latestKey);
          if (existingPayload) {
            existingPayload.entry_ts = null;
            existingPayload.entry_price = null;
            existingPayload.kanban_cycle_enter_now_ts = null;
            existingPayload.kanban_cycle_trigger_ts = null;
            existingPayload.kanban_cycle_side = null;
            // Recompute kanban stage now that position is closed
            existingPayload.move_status = computeMoveStatus(existingPayload);
            if (existingPayload.flags) {
              existingPayload.flags.move_invalidated = existingPayload.move_status?.status === "INVALIDATED";
              existingPayload.flags.move_completed = existingPayload.move_status?.status === "COMPLETED";
              existingPayload.flags.position_closed_cleared = true;
            }
            const newStage = classifyKanbanStage(existingPayload, null);
            existingPayload.kanban_stage = newStage;
            existingPayload.kanban_meta = deriveKanbanMeta(existingPayload, newStage);
            await kvPutJSON(KV, latestKey, existingPayload);
            console.log(`[TRADE SIM] ${sym} position closed: cleared entry state, stage → ${newStage}`);
          }
        } catch (clearErr) {
          console.error(`[TRADE SIM] ${sym} failed to clear entry state:`, clearErr);
        }
      }

      // Discord + D1 alert (best-effort, deduped)
      if (env && trade?.id) {
        try {
          const tsMs = Date.now();
          const dedupe = await shouldSendTradeDiscordEvent(KV, {
            tradeId: trade.id,
            type: "TRADE_EXIT",
            ts: tsMs,
          });
          if (!dedupe.deduped) {
            const embed = createTradeClosedEmbed(
              sym,
              String(trade.direction || "").toUpperCase(),
              String(trade.status || "").toUpperCase(),
              Number(trade.entryPrice),
              Number(trade.exitPrice),
              Number(trade.pnl || trade.realizedPnl || 0),
              Number(trade.pnlPct || 0),
              Number(trade.rank || 0),
              Number(trade.rr || 0),
              tickerData,
              trade,
              {
                qty: remainingShares,
                value: p * remainingShares,
                pnl: pnlRemaining,
              },
            );
            const allow = shouldSendDiscordAlert(env, "TRADE_EXIT", {
              ticker: sym,
              direction: trade.direction,
            });
            const sendRes = allow
              ? await notifyDiscord(env, embed).catch((err) => ({
                  ok: false,
                  error: String(err),
                }))
              : { ok: false, skipped: true, reason: "critical_only" };
            await upsertAlertSafe({
              alert_id: buildAlertId(sym, tsMs, "TRADE_EXIT"),
              ticker: sym,
              ts: tsMs,
              side: String(trade.direction || "").toUpperCase(),
              state: tickerData?.state,
              rank: Number(trade.rank) || 0,
              rr_at_alert: Number(trade.rr) || 0,
              trigger_reason: closeReason || "TRADE_EXIT",
              dedupe_day: formatDedupDay(tsMs),
              discord_sent: !!sendRes?.ok,
              discord_status: sendRes?.status ?? null,
              discord_error: sendRes?.ok
                ? null
                : sendRes?.reason || sendRes?.statusText || sendRes?.error || null,
              payload_json: (() => {
                try {
                  return JSON.stringify(tickerData || null);
                } catch {
                  return null;
                }
              })(),
              meta_json: (() => {
                try {
                  return JSON.stringify({
                    type: "TRADE_EXIT",
                    trade_id: trade.id,
                    status: trade.status,
                    reason: closeReason,
                    exit_price: trade.exitPrice,
                  });
                } catch {
                  return null;
                }
              })(),
            });
          }
        } catch (e) {
          console.error("[KANBAN TRADE] exit discord error:", e);
        }
      }
    };

    const trimTradeToPct = async (
      trade,
      targetTrimPct,
      trimPrice,
      trimReason,
    ) => {
      const p = Number(trimPrice);
      if (!Number.isFinite(p) || p <= 0) return;
      const oldTrim = clamp(Number(trade.trimmedPct || 0), 0, 1);
      const tgt = clamp(Number(targetTrimPct), 0, 1);
      if (tgt <= oldTrim + 1e-6) return;
      const delta = tgt - oldTrim;
      const shares = Number(trade.shares);
      if (!Number.isFinite(shares)) return;
      const trimShares = shares * delta;

      const dirSign =
        String(trade.direction || "").toUpperCase() === "SHORT" ? -1 : 1;
      const pnlRealized =
        (p - Number(trade.entryPrice)) *
        trimShares *
        (Number(trade.pointValue) || 1) *
        dirSign;
      trade.realizedPnl = Number(trade.realizedPnl || 0) + pnlRealized;
      trade.trimmedPct = tgt;
      const isFullClose = tgt >= 0.9999;
      trade.status = isFullClose
        ? (trade.realizedPnl >= 0 ? "WIN" : "LOSS")
        : tgt > 0
          ? "TP_HIT_TRIM"
          : "OPEN";
      if (isFullClose) {
        trade.exitPrice = p;
        trade.exitReason = "TP_FULL";
        trade.pnl = trade.realizedPnl;
        trade.pnlPct =
          Number.isFinite(Number(trade.notional)) && Number(trade.notional) > 0
            ? (trade.realizedPnl / Number(trade.notional)) * 100
            : null;
      }

      // ─────────────────────────────────────────────────────────────────────
      // 3-TIER SL ADJUSTMENT: Move SL based on which tier was just hit
      // ─────────────────────────────────────────────────────────────────────
      const entryPrice = Number(trade.entryPrice);
      const oldSl = Number(trade.sl);
      const dir = String(trade.direction || "").toUpperCase();
      const tpArray = Array.isArray(trade.tpArray) ? trade.tpArray : [];
      let slAdjusted = false;
      let slAdjustReason = null;

      // Update trimTiers tracking if present
      if (Array.isArray(trade.trimTiers)) {
        for (const tier of trade.trimTiers) {
          if (!tier.hit && tgt >= tier.pct) {
            tier.hit = true;
            tier.hitTs = eventTs();
          }
        }
      }

      // Tier 1: TRIM TP hit (60%) -> Move SL to Breakeven (entry price)
      if (tgt >= THREE_TIER_CONFIG.TRIM.trimPct && oldTrim < THREE_TIER_CONFIG.TRIM.trimPct) {
        if (Number.isFinite(entryPrice) && entryPrice > 0) {
          const beStop = entryPrice;
          // For LONG: only tighten if new SL is higher; for SHORT: only if lower
          const shouldTighten = dir === "LONG"
            ? beStop > oldSl || !Number.isFinite(oldSl)
            : beStop < oldSl || !Number.isFinite(oldSl);
          if (shouldTighten) {
            trade.sl = beStop;
            slAdjusted = true;
            slAdjustReason = "TRIM_TP_HIT_SL_TO_BE";
            console.log(`[3-TIER] ${sym} TRIM TP hit: SL moved to BE at $${beStop.toFixed(2)}`);
          }
        }
      }

      // Tier 2: EXIT TP hit (80%) -> Move SL to TRIM TP price
      if (tgt >= THREE_TIER_CONFIG.EXIT.trimPct && oldTrim < THREE_TIER_CONFIG.EXIT.trimPct) {
        const trimTpItem = tpArray.find(tp => tp.tier === "TRIM");
        const trimTpPrice = trimTpItem?.price;
        if (Number.isFinite(trimTpPrice) && trimTpPrice > 0) {
          // For LONG: only tighten if new SL is higher; for SHORT: only if lower
          const currentSl = Number(trade.sl);
          const shouldTighten = dir === "LONG"
            ? trimTpPrice > currentSl || !Number.isFinite(currentSl)
            : trimTpPrice < currentSl || !Number.isFinite(currentSl);
          if (shouldTighten) {
            trade.sl = trimTpPrice;
            slAdjusted = true;
            slAdjustReason = "EXIT_TP_HIT_SL_TO_TRIM_TP";
            console.log(`[3-TIER] ${sym} EXIT TP hit: SL moved to TRIM TP at $${trimTpPrice.toFixed(2)}`);
          }
        }
      }

      if (slAdjusted) {
        trade.sl_protect_reason = slAdjustReason;
        trade.sl_last_tighten_ts = eventTs();
      }

      const tsNow = eventTs();
      const ev = {
        type: "TRIM",
        timestamp: tsNow,
        price: p,
        shares: trimShares,
        value: p * trimShares,
        trimPct: tgt,
        trimDeltaPct: delta,
        reason: trimReason,
        pnl_realized: pnlRealized,
        sl_adjusted: slAdjusted,
        sl_adjust_reason: slAdjustReason,
        new_sl: slAdjusted ? trade.sl : null,
        note: `Trimmed ${Math.round(delta * 100)}% at $${p.toFixed(2)} (${trimReason})${slAdjusted ? ` - SL moved to $${trade.sl.toFixed(2)}` : ""}`,
      };
      trade.history = Array.isArray(trade.history)
        ? [...trade.history, ev]
        : [ev];
      if (isFullClose) {
        const exitEv = {
          type: "EXIT",
          timestamp: tsNow,
          price: p,
          shares: trimShares,
          value: p * trimShares,
          reason: "TP_FULL",
          pnl_realized: pnlRealized,
          note: `Closed at $${p.toFixed(2)} (TP_FULL)`,
        };
        trade.history.push(exitEv);
        trade.exit_ts = isoToMs(tsNow) || Date.now();
        if (trade.exit_ts < 1e12) trade.exit_ts = trade.exit_ts * 1000;
      }
      trade.lastUpdate = tsNow;
      trade.trim_ts = Number.isFinite(asOfMs) ? asOfMs : (isoToMs(tsNow) || null);

      // Portfolio cash increases by proceeds
      portfolio.cash = Number(portfolio.cash) + p * trimShares;

      // Persist via execution adapter (D1 source of truth)
      if (adapter) {
        const exitEv = isFullClose ? trade.history.find((e) => e && e.type === "EXIT") : null;
        const tsTrim = ev.timestamp ? new Date(ev.timestamp).getTime() : Date.now();
        const newCostBasis = Number(trade.shares) * (1 - tgt) * Number(trade.entryPrice);
        await adapter.closePosition(sym, {
          _price: p,
          _reason: trimReason,
          _trade: trade,
          _event: ev,
          _exitEvent: exitEv,
          _trimShares: trimShares,
          _pnl: pnlRealized,
          _isPartialClose: true,
          _isFullClose: isFullClose,
          _positionUpdates: {
            total_qty: isFullClose ? 0 : Number(trade.shares) * (1 - tgt),
            cost_basis: isFullClose ? 0 : newCostBasis,
            updated_at: tsTrim,
            ...(isFullClose ? { status: "CLOSED", closed_at: tsTrim } : {}),
          },
        }).catch((e) => {
          console.error("[EXEC] trimTradeToPct adapter failed:", e);
        });
      }

      // Discord + D1 alert (best-effort, deduped)
      if (env && trade?.id) {
        try {
          const tsMs = Date.now();
          const dedupe = await shouldSendTradeDiscordEvent(KV, {
            tradeId: trade.id,
            type: "TRADE_TRIM",
            ts: tsMs,
          });
          if (!dedupe.deduped) {
            const dir = String(trade.direction || "").toUpperCase();
            const dirSign = dir === "SHORT" ? -1 : 1;
            const pnlPctAtTrim =
              Number.isFinite(Number(trade.entryPrice)) && Number(trade.entryPrice) > 0
                ? ((p - Number(trade.entryPrice)) / Number(trade.entryPrice)) *
                  100 *
                  dirSign
                : 0;
            const allow = shouldSendDiscordAlert(env, "TRADE_TRIM", {
              newTrimmedPct: tgt,
              trimDeltaPctRaw: delta,
            });
            const embed = createTradeTrimmedEmbed(
              sym,
              dir,
              Number(trade.entryPrice),
              Number(trade.currentPrice || p),
              Number(trade.tp || p),
              Number(pnlRealized || 0),
              Number(pnlPctAtTrim || 0),
              tgt,
              tickerData,
              trade,
              delta,
              { qty: trimShares, value: p * trimShares, pnl: pnlRealized },
            );
            const sendRes = allow
              ? await notifyDiscord(env, embed).catch((err) => ({
                  ok: false,
                  error: String(err),
                }))
              : { ok: false, skipped: true, reason: "critical_only" };
            await upsertAlertSafe({
              alert_id: buildAlertId(sym, tsMs, "TRADE_TRIM"),
              ticker: sym,
              ts: tsMs,
              side: dir,
              state: tickerData?.state,
              rank: Number(trade.rank) || 0,
              rr_at_alert: Number(trade.rr) || 0,
              trigger_reason: trimReason || "TRADE_TRIM",
              dedupe_day: formatDedupDay(tsMs),
              discord_sent: !!sendRes?.ok,
              discord_status: sendRes?.status ?? null,
              discord_error: sendRes?.ok
                ? null
                : sendRes?.reason || sendRes?.statusText || sendRes?.error || null,
              payload_json: (() => {
                try {
                  return JSON.stringify(tickerData || null);
                } catch {
                  return null;
                }
              })(),
              meta_json: (() => {
                try {
                  return JSON.stringify({
                    type: "TRADE_TRIM",
                    trade_id: trade.id,
                    trimmed_pct: tgt,
                    trim_delta_pct: delta,
                    trim_price: p,
                  });
                } catch {
                  return null;
                }
              })(),
            });
          }
        } catch (e) {
          console.error("[KANBAN TRADE] trim discord error:", e);
        }
      }
    };

    // Market is closed on weekends — never execute TP trims/exits on Sat/Sun.
    // (We still allow SL evaluation elsewhere to be conservative.)
    // During replay, use the simulation time (asOfMs) to check weekend, not wall-clock time.
    const weekendNow = isNyWeekend(isReplay && Number.isFinite(asOfMs) ? asOfMs : Date.now());

    // 1) EXIT: close any open trade while in EXIT lane
    // Guard: position must be open for at least MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT (15 min)
    // to prevent rapid enter→exit churn from volatile price movements
    // CRITICAL: Verify trade is actually still open before executing (prevents ghost events on closed trades)
    if (isExit && !weekendNow && exitCooldownOk && exitMinAgeOk && openTrade && isOpenTradeStatus(openTrade.status)) {
      // Use the specific exit reason from classifyKanbanStage if available, otherwise use move_status reason
      const exitReason = tickerData?.__exit_reason || reason || `KANBAN_EXIT`;
      await closeTradeAtPrice(openTrade, pxNow, exitReason);
      if (!isReplay) await kvPutJSON(KV, execKey, { ...execState, lastExitMs: now });
    } else if (isExit && openTrade && !exitMinAgeOk) {
      const ageMin = Number.isFinite(entryMsNorm) ? Math.round((now - entryMsNorm) / 60000) : 0;
      console.log(
        `[TRADE SIM] ${sym} exit blocked: position only ${ageMin}m old (min ${MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT}m)`
      );
    }

    // 2) DEFEND: Tighten SL to protect gains (warning signals, but not at extremes)
    // ─────────────────────────────────────────────────────────────────────────
    // DEFEND action: Move SL closer to entry to lock in gains or reduce loss
    // Does NOT trim - just protects the position
    // ─────────────────────────────────────────────────────────────────────────
    const isDefend = stage === "defend";
    const lastDefendMs = Number(execState.lastDefendMs);
    const defendCooldownOk = !Number.isFinite(lastDefendMs) || now - lastDefendMs >= 5 * 60 * 1000; // 5m
    
    if (isDefend && !weekendNow && defendCooldownOk && openTrade && Number.isFinite(pxNow)) {
      const entryPx = Number(openTrade.entryPrice);
      const dir = String(openTrade.direction || "").toUpperCase();
      const isLong = dir === "LONG";
      const currentSL = Number(openTrade.sl);
      
      if (Number.isFinite(entryPx) && entryPx > 0) {
        // Calculate P&L to determine SL strategy
        const pnlPct = isLong
          ? ((pxNow - entryPx) / entryPx) * 100
          : ((entryPx - pxNow) / entryPx) * 100;
        
        let newSL = currentSL;
        let defendAction = null;
        
        // DATA-DRIVEN SL TIGHTENING:
        // 62/80 trades exited in <15min because SL was tightened too aggressively.
        // Winners need room to breathe. Only tighten when gains are substantial.
        if (pnlPct >= 3) {
          // Strong profit >= 3%: Move SL to breakeven + 1% buffer
          // This protects meaningful gains while allowing normal retracement
          const buffer = entryPx * 0.01; // 1% buffer above breakeven
          newSL = isLong ? entryPx + buffer : entryPx - buffer;
          defendAction = "BREAKEVEN_PLUS";
        } else if (pnlPct >= 1.5) {
          // Good profit (1.5-3%): Move SL to breakeven
          // Only move to breakeven when we have a meaningful cushion
          newSL = entryPx;
          defendAction = "BREAKEVEN";
        }
        // NOTE: Removed the -2% to -5% "LIMIT_LOSS" tightening.
        // Data shows this causes premature exits. The original SL from entry
        // should handle risk management. Don't tighten on losses.
        
        // Only update if new SL is tighter (more protective)
        const slImproved = Number.isFinite(newSL) && (
          !Number.isFinite(currentSL) ||
          (isLong ? newSL > currentSL : newSL < currentSL)
        );
        
        if (slImproved && defendAction) {
          openTrade.sl = newSL;
          openTrade.lastUpdate = eventTs();
          
          // Persist SL update via execution adapter
          if (adapter) {
            await adapter.replaceOrder(`${openTrade.id}-SL`, {
              stop_price: newSL,
              _trade: openTrade,
              _reason: defendAction,
            }).catch(e => {
              console.error(`[DEFEND] ${sym} adapter.replaceOrder failed:`, e);
            });
          }
          
          console.log(
            `[DEFEND] ${sym} SL tightened: ${defendAction}, ` +
            `P&L ${pnlPct.toFixed(2)}%, SL ${currentSL?.toFixed(2) || 'none'} → $${newSL.toFixed(2)}`
          );
          
          // Discord alert for DEFEND action
          if (env) {
            try {
              const tsMs = Date.now();
              const dedupe = await shouldSendTradeDiscordEvent(KV, {
                tradeId: openTrade.id,
                type: "TRADE_DEFEND",
                ts: tsMs,
              });
              if (!dedupe.deduped) {
                // Use unified kanban stage embed for DEFEND (replaces inline embed)
                const embed = createKanbanStageEmbed(sym, "defend", "hold", tickerData, openTrade);
                const allow = shouldSendDiscordAlert(env, "KANBAN_DEFEND", { ticker: sym });
                if (allow) {
                  await notifyDiscord(env, embed).catch(() => {});
                }
              }
            } catch (e) {
              console.error("[DEFEND] discord error:", e);
            }
          }
          
          if (!isReplay) await kvPutJSON(KV, execKey, { ...execState, lastDefendMs: now });
        }
      }
    }

    // 3) TRIM: apply progressive trim on transition into TRIM lane (only after position has been open long enough)
    // ─────────────────────────────────────────────────────────────────────────
    // 3-TIER SYSTEM: TRIM TP (60%), EXIT TP (80%), RUNNER TP (100%)
    // Trim targets are based on which TP level price has reached
    // ─────────────────────────────────────────────────────────────────────────
    // CRITICAL: Verify trade is actually still open before trimming (prevents ghost events on closed trades)
    if (isTrim && !weekendNow && trimCooldownOk && trimMinAgeOk && openTrade && isOpenTradeStatus(openTrade.status) && Number.isFinite(pxNow)) {
      const tpArray = Array.isArray(openTrade.tpArray) ? openTrade.tpArray : [];
      const entryPx = Number(openTrade.entryPrice);
      const dir = String(openTrade.direction || "").toUpperCase();
      const isLong = dir === "LONG";
      
      // Find which TP level price has reached
      let target = THREE_TIER_CONFIG.TRIM.trimPct; // Default to TRIM (60%)
      
      if (tpArray.length > 0 && Number.isFinite(entryPx)) {
        // Check if price has reached each tier's TP
        const trimTp = tpArray.find(tp => tp.tier === "TRIM");
        const exitTp = tpArray.find(tp => tp.tier === "EXIT");
        const runnerTp = tpArray.find(tp => tp.tier === "RUNNER");
        
        const reachedTp = (tp) => {
          if (!tp || !Number.isFinite(tp.price)) return false;
          return isLong ? pxNow >= tp.price : pxNow <= tp.price;
        };
        
        if (reachedTp(runnerTp)) {
          target = THREE_TIER_CONFIG.RUNNER.trimPct; // 100%
          console.log(`[3-TIER] ${sym} price $${pxNow.toFixed(2)} reached RUNNER TP $${runnerTp?.price?.toFixed(2)}`);
        } else if (reachedTp(exitTp)) {
          target = THREE_TIER_CONFIG.EXIT.trimPct; // 80%
          console.log(`[3-TIER] ${sym} price $${pxNow.toFixed(2)} reached EXIT TP $${exitTp?.price?.toFixed(2)}`);
        } else if (reachedTp(trimTp)) {
          target = THREE_TIER_CONFIG.TRIM.trimPct; // 60%
          console.log(`[3-TIER] ${sym} price $${pxNow.toFixed(2)} reached TRIM TP $${trimTp?.price?.toFixed(2)}`);
        } else {
          // Price hasn't reached TRIM TP yet - use completion-based approach as fallback
          const comp = Number(tickerData?.completion);
          const phase = Number(tickerData?.phase_pct);
          // Progressive: start with 60% trim at 90% completion to TRIM TP
          const completionToTrim = computeCompletionToTier(tickerData, "TRIM");
          if (completionToTrim >= 0.9 || (Number.isFinite(comp) && comp >= 0.6)) {
            target = THREE_TIER_CONFIG.TRIM.trimPct; // 60%
          } else {
            // Don't trim yet if we're not close to TRIM TP
            target = 0;
          }
        }
      }
      
      if (target > 0) {
        await trimTradeToPct(openTrade, target, pxNow, reason);
        if (!isReplay) await kvPutJSON(KV, execKey, { ...execState, lastTrimMs: now });
      }
    }

    // 3) ENTER: open trade while in ENTER_NOW lane
    if (isEnter && !weekendNow && enterCooldownOk && !sameEnterCycle) {
      // If we already have an open trade in the opposite direction, close it first (flip).
      if (
        openTrade &&
        openTradeDir &&
        openTradeDir !== direction &&
        exitCooldownOk
      ) {
        await closeTradeAtPrice(openTrade, pxNow, `FLIP_${reason}`);
        if (!isReplay) await kvPutJSON(KV, execKey, { ...execState, lastExitMs: now });
        openTrade = null;
      }
    }

    // ─────────────────────────────────────────────────────────────────────────
    // GLOBAL POSITION LIMITS: Prevent over-trading
    // ─────────────────────────────────────────────────────────────────────────
    // DATA: 375 trades on Feb 5 was wildly overtrading. Quality over quantity.
    const MAX_OPEN_POSITIONS = 8;   // Max concurrent positions (was 15)
    const MAX_DAILY_ENTRIES = 5;    // Max new entries per day (was 8)
    
    let positionLimitBlocked = false;
    const db = env?.DB;
    // IMPORTANT: Skip position limits entirely during replay (we're processing historical data)
    if (isEnter && !weekendNow && enterCooldownOk && !sameEnterCycle && !openTrade && db && !isReplay) {
      try {
        // Check current open position count
        const countResult = await db.prepare(
          `SELECT COUNT(*) as cnt FROM positions WHERE status = 'OPEN'`
        ).first();
        const openCount = Number(countResult?.cnt) || 0;
        
        if (openCount >= MAX_OPEN_POSITIONS) {
          console.log(`[POSITION_LIMIT] Blocked entry for ${sym}: ${openCount} open positions >= ${MAX_OPEN_POSITIONS} max`);
          positionLimitBlocked = true;
        }
        
        // Check daily entry count
        if (!positionLimitBlocked) {
          const today = new Date().toISOString().slice(0, 10);
          const dailyResult = await db.prepare(
            `SELECT COUNT(*) as cnt FROM execution_actions WHERE type = 'ENTRY' AND day = ?`
          ).bind(today).first();
          const dailyCount = Number(dailyResult?.cnt) || 0;
          
          if (dailyCount >= MAX_DAILY_ENTRIES) {
            console.log(`[DAILY_LIMIT] Blocked entry for ${sym}: ${dailyCount} entries today >= ${MAX_DAILY_ENTRIES} max`);
            positionLimitBlocked = true;
          }
        }
      } catch (e) {
        console.error(`[POSITION_LIMIT] Error checking limits: ${e.message}`);
      }
    }

    // Check VIX filter before creating new trade
    if (vixSkipReason && !openTrade) {
      console.log(`[VIX_FILTER] Skipping ${sym} entry: ${vixSkipReason}`);
      return { skipped: true, reason: vixSkipReason };
    }

    // DEBUG: Capture condition values for enter-stage tickers during replay
    const storedStageDebug = String(tickerData?.kanban_stage || "").trim().toLowerCase();
    if (isReplay && (storedStageDebug === "enter" || storedStageDebug === "enter_now") && replayCtx?.processDebug && replayCtx.processDebug.length < 5) {
      replayCtx.processDebug.push({
        ts: options?.asOfTs,
        sym,
        storedStage: storedStageDebug,
        stage,
        isEnter,
        weekendNow,
        enterCooldownOk,
        sameEnterCycle,
        openTrade: !!openTrade,
        openTradeId: openTrade?.id,
        positionLimitBlocked,
        direction,
        entryPath: tickerData?.__entry_path,
      });
    }

    // Return early if conditions not met, with debug info
    // Block if there's a recent trade (prevents rapid re-entry after immediate WIN/LOSS)
    const recentTradeBlocked = !openTrade && !!recentTrade;
    if (recentTradeBlocked) {
      console.log(`[RECENT_TRADE_BLOCKED] ${sym}: Found recent trade ${recentTrade?.id} (status=${recentTrade?.status}), blocking new entry`);
    }
    
    if (isEnter && (!weekendNow || !enterCooldownOk || sameEnterCycle || openTrade || recentTradeBlocked || positionLimitBlocked)) {
      console.log(`[ENTRY_BLOCKED_EARLY] ${sym} weekendNow=${weekendNow} enterCooldownOk=${enterCooldownOk} sameEnterCycle=${sameEnterCycle} openTrade=${!!openTrade} recentTradeBlocked=${recentTradeBlocked} positionLimitBlocked=${positionLimitBlocked}`);
    }
    if (isEnter && !weekendNow && enterCooldownOk && !sameEnterCycle && !openTrade && !recentTradeBlocked && !positionLimitBlocked) {
      console.log(`[ENTRY_CREATE_START] ${sym} passed all gates, attempting trade creation`);
      const entryPx = Number(entryPxCandidate);
      let slCandidate = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
      let tpCandidate = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
      
      // Fallback TP calculation if missing
      if (!Number.isFinite(tpCandidate) || tpCandidate <= 0) {
        const tpFromLevels = computeTpMaxFromLevels(tickerData);
        tpCandidate = Number.isFinite(tpFromLevels) ? tpFromLevels : 0;
      }
      
      // Fallback SL calculation when TradingView doesn't provide one
      // DATA: Trades need room to breathe. 1.0x ATR was too tight (62/80 exited in <15min).
      // Using 1.5x ATR gives enough room for normal intraday noise.
      if (!Number.isFinite(slCandidate) || slCandidate <= 0) {
        const atr = Number(tickerData?.atr);
        if (Number.isFinite(atr) && atr > 0 && Number.isFinite(entryPx)) {
          slCandidate = direction === "LONG" 
            ? entryPx - (atr * 1.5) 
            : entryPx + (atr * 1.5);
        } else if (Number.isFinite(entryPx) && entryPx > 0) {
          // Fallback: 2.5% from entry (gives room for normal retracements)
          slCandidate = direction === "LONG" 
            ? entryPx * 0.975 
            : entryPx * 1.025;
        }
      }
      
      // Fallback TP if still missing: 6% from entry (2:1 R:R with 3% SL)
      if (!Number.isFinite(tpCandidate) || tpCandidate <= 0) {
        if (Number.isFinite(entryPx) && entryPx > 0) {
          tpCandidate = direction === "LONG" 
            ? entryPx * 1.06 
            : entryPx * 0.94;
        }
      }
      
      // Debug: log why trades might not be created
      const allValid = 
        Number.isFinite(entryPx) && entryPx > 0 &&
        Number.isFinite(pxNow) && pxNow > 0 &&
        Number.isFinite(slCandidate) && slCandidate > 0 &&
        Number.isFinite(tpCandidate) && tpCandidate > 0;
      
      // Capture debug for replay
      if (isReplay && replayCtx?.processDebug && replayCtx.processDebug.length < 3) {
        replayCtx.processDebug.push({
          sym,
          dir: direction,
          entryPx,
          pxNow,
          slCandidate,
          tpCandidate,
          atr: tickerData?.atr,
          allValid,
        });
      }
      if (!allValid) {
        console.log(`[TRADE ENTRY BLOCKED] ${sym} direction=${direction}:`, {
          entryPx: { value: entryPx, valid: Number.isFinite(entryPx) && entryPx > 0 },
          pxNow: { value: pxNow, valid: Number.isFinite(pxNow) && pxNow > 0 },
          slCandidate: { value: slCandidate, valid: Number.isFinite(slCandidate) && slCandidate > 0 },
          tpCandidate: { value: tpCandidate, valid: Number.isFinite(tpCandidate) && tpCandidate > 0 },
          atr: tickerData?.atr,
        });
      }
      
      if (
        Number.isFinite(entryPx) &&
        entryPx > 0 &&
        Number.isFinite(pxNow) &&
        pxNow > 0
        // Require valid SL/TP to avoid creating "unmanaged" trades
        && Number.isFinite(slCandidate) &&
        slCandidate > 0 &&
        Number.isFinite(tpCandidate) &&
        tpCandidate > 0
      ) {
        const confidence = computeTradeConfidence(tickerData);
        const cash = Number(portfolio.cash);
        const notional =
          Number.isFinite(cash) && cash >= MIN_TRADE_NOTIONAL
            ? tradeNotionalFromConfidence(confidence, cash)
            : null;
        if (notional != null) {
          const { shares, pointValue } = computeSharesForTrade(
            sym,
            entryPx,
            notional,
          );
          if (Number.isFinite(shares) && shares > 0) {
            const tradeId = `${sym}-${now}-${Math.random().toString(36).substr(2, 9)}`;
            const entryTime = eventTs();
            // Ingest/replay time in ms for D1 and display (not replay run time)
            const entryTsMs = Number.isFinite(asOfMs) ? asOfMs : (entryTime ? new Date(entryTime).getTime() : null);
            const ev = {
              type: "ENTRY",
              timestamp: entryTime,
              price: entryPx,
              shares: shares,
              value: entryPx * shares,
              reason: reason,
              note: `Entry from ENTER_NOW at $${entryPx.toFixed(2)}`,
            };

            // Build 3-tier TP array for this trade
            const tpArray = build3TierTPArray(tickerData, entryPx, direction);
            const validTP = tpArray.length > 0 ? tpArray[0].price : tpCandidate;
            
            // Calculate R:R using RUNNER TP (furthest target)
            const runnerTp = tpArray.find(tp => tp.tier === "RUNNER");
            
            // ── CRITICAL: Ensure SL is on the correct side of entry price ──
            // TradingView sends SL assuming LONG direction (below price).
            // For SHORT entries, if the raw SL is below entry, we MUST flip it.
            if (direction === "SHORT" && Number.isFinite(slCandidate) && slCandidate < entryPx) {
              const atr = Number(tickerData?.atr);
              const slDist = entryPx - slCandidate; // distance from entry to wrong-side SL
              // Mirror the SL distance to the correct side (above entry)
              slCandidate = entryPx + slDist;
              // If ATR is available, ensure at least 1.5x ATR buffer above entry
              if (Number.isFinite(atr) && atr > 0) {
                slCandidate = Math.max(slCandidate, entryPx + atr * 1.5);
              }
              console.log(`[SL_FLIP] ${sym} SHORT: flipped SL from below entry to $${slCandidate.toFixed(2)} (entry=$${entryPx.toFixed(2)})`);
            }
            // For LONG: ensure SL is below entry
            if (direction === "LONG" && Number.isFinite(slCandidate) && slCandidate > entryPx) {
              const atr = Number(tickerData?.atr);
              const slDist = slCandidate - entryPx;
              slCandidate = entryPx - slDist;
              if (Number.isFinite(atr) && atr > 0) {
                slCandidate = Math.min(slCandidate, entryPx - atr * 1.5);
              }
              console.log(`[SL_FLIP] ${sym} LONG: flipped SL from above entry to $${slCandidate.toFixed(2)} (entry=$${entryPx.toFixed(2)})`);
            }
            
            // Apply direction-specific SL adjustment based on gold standard patterns
            const slAdjustment = computeDirectionAwareSL(tickerData, slCandidate, direction, entryPx);
            const finalSL = slAdjustment.sl;
            if (slAdjustment.adjusted) {
              console.log(`[GOLD_STANDARD_SL] ${sym} ${direction} SL adjusted: ${slCandidate.toFixed(2)} → ${finalSL.toFixed(2)} (${slAdjustment.reason})`);
            }
            
            const calculatedRR = (() => {
              if (!runnerTp || !Number.isFinite(finalSL) || !Number.isFinite(entryPx)) {
                return Number(tickerData?.rr) || 0;
              }
              const risk = Math.abs(entryPx - finalSL);
              const reward = Math.abs(runnerTp.price - entryPx);
              return risk > 0 ? reward / risk : 0;
            })();
            
            const trade = {
              id: tradeId,
              ticker: sym,
              direction,
              entryPath: entryPath || null,  // Track which entry criteria was used
              entryPrice: entryPx,
              entryTime,
              entry_ts: entryTsMs || undefined,
              triggerTimestamp: Number(tickerData?.trigger_ts) || null,
              sl: finalSL,
              sl_original: slCandidate,
              sl_gs_adjusted: slAdjustment.adjusted,
              sl_gs_reason: slAdjustment.reason,
              tp: validTP, // Use TRIM TP (first tier) as primary TP
              tpArray: tpArray, // Store full 3-tier TP array
              // Track which tiers have been hit
              trimTiers: [
                { tier: "TRIM", pct: THREE_TIER_CONFIG.TRIM.trimPct, hit: false, hitTs: null },
                { tier: "EXIT", pct: THREE_TIER_CONFIG.EXIT.trimPct, hit: false, hitTs: null },
                { tier: "RUNNER", pct: THREE_TIER_CONFIG.RUNNER.trimPct, hit: false, hitTs: null },
              ],
              rr: calculatedRR,
              rank: Number(tickerData?.rank) || 0,
              state: tickerData?.state,
              flags: tickerData?.flags || {},
              scriptVersion: tickerData?.script_version || "unknown",
              status: "OPEN",
              trimmedPct: 0,
              history: [ev],
              notional: notional,
              confidence: confidence,
              shares: shares,
              pointValue: pointValue,
              realizedPnl: 0,
              currentPrice: pxNow,
              lastUpdate: eventTs(),
              source: "KANBAN_ENTER_NOW",
              // Sector alignment at entry time (for post-trade analysis)
              sectorAtEntry: (() => {
                const sa = getSectorAlignmentCached(sym);
                return sa ? { sector: sa.sector, aligned: sa.aligned, direction: sa.direction, strength: sa.strength } : null;
              })(),
            };

            // Portfolio cash decreases by cost
            portfolio.cash = Number(portfolio.cash) - entryPx * shares;

            allTrades.push(trade);
            console.log(`[ENTRY_CREATED] ${sym} dir=${direction} entry=${entryPx} sl=${finalSL} tp=${validTP} shares=${shares} isReplay=${isReplay}`);
            if (!isReplay) await kvPutJSON(KV, execKey, {
              ...execState,
              lastEnterMs: now,
              lastEnterTriggerTs:
                Number.isFinite(curTriggerTs) && curTriggerTs > 0
                  ? curTriggerTs
                  : null,
              lastEnterSide: direction,
            });
            // Persist via execution adapter (trade + position + lot + execution_action)
            if (adapter) {
              const tsPos = entryTsMs != null && Number.isFinite(entryTsMs) ? entryTsMs : Date.now();
              await adapter.submitOrder({
                symbol: sym,
                qty: shares,
                side: direction === "LONG" ? "buy" : "sell",
                type: "market",
                time_in_force: "gtc",
                order_class: "bracket",
                take_profit: { limit_price: validTP },
                stop_loss: { stop_price: finalSL },
                client_order_id: tradeId,
                _meta: {
                  trade,
                  position: {
                    position_id: tradeId,
                    ticker: sym,
                    direction,
                    status: "OPEN",
                    total_qty: shares,
                    cost_basis: entryPx * shares,
                    created_at: tsPos,
                    updated_at: tsPos,
                    script_version: trade.scriptVersion,
                    stop_loss: finalSL,
                    take_profit: validTP,
                  },
                },
              }).catch((e) => {
                console.error("[EXEC] ENTRY adapter.submitOrder failed:", e);
              });
            }

            // Discord + D1 alert (best-effort, deduped)
            if (env) {
              try {
                const tsMs = Date.now();
                const dedupe = await shouldSendTradeDiscordEvent(KV, {
                  tradeId,
                  type: "TRADE_ENTRY",
                  ts: tsMs,
                });
                if (!dedupe.deduped) {
                  const allow = shouldSendDiscordAlert(env, "TRADE_ENTRY", {
                    ticker: sym,
                    rr: Number(trade.rr || 0),
                    rank: Number(trade.rank || 0),
                    momentumElite: !!trade.flags?.momentum_elite,
                  });
                  const embed = createTradeEntryEmbed(
                    sym,
                    direction,
                    Number(entryPx),
                    Number(slCandidate),
                    Number(tpCandidate),
                    Number(trade.rr || 0),
                    Number(trade.rank || 0),
                    trade.state,
                    Number(pxNow),
                    false,
                    tickerData,
                    {
                      qty: Number(trade.shares),
                      value: Number(entryPx) * Number(trade.shares),
                      pnl: 0,
                    },
                  );
                  const sendRes = allow
                    ? await notifyDiscord(env, embed).catch((err) => ({
                        ok: false,
                        error: String(err),
                      }))
                    : { ok: false, skipped: true, reason: "critical_only" };
                  await upsertAlertSafe({
                    alert_id: buildAlertId(sym, tsMs, "TRADE_ENTRY"),
                    ticker: sym,
                    ts: tsMs,
                    side: direction,
                    state: tickerData?.state,
                    rank: Number(trade.rank) || 0,
                    rr_at_alert: Number(trade.rr) || 0,
                    trigger_reason: reason || "TRADE_ENTRY",
                    dedupe_day: formatDedupDay(tsMs),
                    discord_sent: !!sendRes?.ok,
                    discord_status: sendRes?.status ?? null,
                    discord_error: sendRes?.ok
                      ? null
                      : sendRes?.reason ||
                        sendRes?.statusText ||
                        sendRes?.error ||
                        null,
                    payload_json: (() => {
                      try {
                        return JSON.stringify(tickerData || null);
                      } catch {
                        return null;
                      }
                    })(),
                    meta_json: (() => {
                      try {
                        return JSON.stringify({
                          type: "TRADE_ENTRY",
                          trade_id: tradeId,
                          entry_price: entryPx,
                          sl: slCandidate,
                          tp: tpCandidate,
                        });
                      } catch {
                        return null;
                      }
                    })(),
                  });
                }
              } catch (e) {
                console.error("[KANBAN TRADE] entry discord error:", e);
              }
            }
          }
        } else {
          tickerData.flags =
            tickerData.flags && typeof tickerData.flags === "object"
              ? tickerData.flags
              : {};
          tickerData.flags.portfolio_no_cash = true;
        }
      }
    }

    // 4) Mark-to-market open trade (no auto TP/SL execution; Kanban lanes drive executions)
    if (openTrade && isOpenTradeStatus(openTrade.status)) {
      openTrade.currentPrice = Number.isFinite(pxNow)
        ? pxNow
        : openTrade.currentPrice;
      const mtm = computeTradePnlComponents(openTrade, tickerData);
      if (mtm.pnl != null) openTrade.pnl = mtm.pnl;
      if (mtm.pnlPct != null) openTrade.pnlPct = mtm.pnlPct;

      // Gain protection: tighten stale SL once trade is meaningfully in profit.
      // We DO NOT loosen stops; only tighten in the trade's favor.
      // ─────────────────────────────────────────────────────────────────────────
      // 3-TIER SL TRAILING: After EXIT TP (80% trimmed), use ATR-based trailing
      // ─────────────────────────────────────────────────────────────────────────
      try {
        const dir = String(openTrade.direction || "").toUpperCase();
        const entry = Number(openTrade.entryPrice);
        const mark = Number(openTrade.currentPrice);
        const oldSl = Number(openTrade.sl);
        const trimmedPct = clamp(Number(openTrade.trimmedPct || 0), 0, 1);
        const completion = Number(tickerData?.completion);
        const tpArray = Array.isArray(openTrade.tpArray) ? openTrade.tpArray : [];

        const sign = dir === "SHORT" ? -1 : 1;
        const pnlPct =
          Number.isFinite(entry) && entry > 0 && Number.isFinite(mark) && mark > 0
            ? ((mark - entry) / entry) * 100 * sign
            : NaN;

        const lastSlTightenMs = Number(execState.lastSlTightenMs);
        const slCooldownOk =
          !Number.isFinite(lastSlTightenMs) || now - lastSlTightenMs >= 15 * 60 * 1000; // 15m

        // Check if we're in RUNNER phase (80%+ trimmed)
        const isRunnerPhase = trimmedPct >= THREE_TIER_CONFIG.EXIT.trimPct;

        const shouldProtect =
          slCooldownOk &&
          !weekendNow &&
          Number.isFinite(pnlPct) &&
          (pnlPct >= 2.0 ||
            trimmedPct > 0 ||
            (Number.isFinite(completion) && completion >= 0.6));

        if (shouldProtect && (dir === "LONG" || dir === "SHORT")) {
          let candidate = null;
          let slReason = "PROTECT_GAINS";

          // ─────────────────────────────────────────────────────────────────────
          // RUNNER PHASE: ATR-based trailing stop (1.5x ATR below current high)
          // ─────────────────────────────────────────────────────────────────────
          if (isRunnerPhase) {
            // Get ATR from ticker data or infer from TP levels
            let atr = Number(tickerData?.atr);
            if (!Number.isFinite(atr) || atr <= 0) {
              atr = inferAtrFromTPLevels(tickerData, entry);
            }
            if (!Number.isFinite(atr) || atr <= 0) {
              // Fallback: use 2% of entry as ATR proxy
              atr = entry * 0.02;
            }

            // ATR trailing: 1.5x ATR from current price
            const atrMultiplier = 1.5;
            const trailStop = dir === "LONG"
              ? mark - (atr * atrMultiplier)
              : mark + (atr * atrMultiplier);

            // Only use ATR trail if it's better than current SL
            if (dir === "LONG" && trailStop > oldSl) {
              candidate = trailStop;
              slReason = "ATR_TRAILING_RUNNER";
              console.log(`[3-TIER] ${sym} RUNNER ATR trail: $${trailStop.toFixed(2)} (1.5x ATR=$${(atr * atrMultiplier).toFixed(2)})`);
            } else if (dir === "SHORT" && trailStop < oldSl) {
              candidate = trailStop;
              slReason = "ATR_TRAILING_RUNNER";
              console.log(`[3-TIER] ${sym} RUNNER ATR trail: $${trailStop.toFixed(2)} (1.5x ATR=$${(atr * atrMultiplier).toFixed(2)})`);
            }
          }

          // ─────────────────────────────────────────────────────────────────────
          // NON-RUNNER: Standard protection logic
          // ─────────────────────────────────────────────────────────────────────
          if (!isRunnerPhase || candidate == null) {
            // Candidate 1: break-even once +3% (or after trim with gains)
            // DATA: Breakeven at +2% was too aggressive - winners need room.
            // Only move to breakeven when we have a significant cushion.
            if (pnlPct >= 3.0 || (trimmedPct > 0 && pnlPct >= 1.0)) {
              candidate = entry;
            }

            // Candidate 2: use Daily EMA cloud boundary when available (acts as dynamic support/resistance)
            const dailyCloud =
              tickerData?.daily_ema_cloud && typeof tickerData.daily_ema_cloud === "object"
                ? tickerData.daily_ema_cloud
                : null;
            if (dailyCloud) {
              const upper = Number(dailyCloud.upper);
              const lower = Number(dailyCloud.lower);
              if (dir === "LONG" && Number.isFinite(lower) && lower > 0) {
                candidate = candidate == null ? lower : Math.max(candidate, lower);
              }
              if (dir === "SHORT" && Number.isFinite(upper) && upper > 0) {
                candidate = candidate == null ? upper : Math.min(candidate, upper);
              }
            }
          }

          // Bound the candidate so it remains a valid protective stop relative to current price
          let newSl = null;
          if (candidate != null && Number.isFinite(candidate) && candidate > 0) {
            if (dir === "LONG") {
              // Stop must be below current price; cap at 99.5% of mark.
              newSl = Math.min(candidate, mark * 0.995);
              // Only tighten if it moves up meaningfully.
              if (Number.isFinite(oldSl) && oldSl > 0) {
                if (newSl <= oldSl + entry * 0.0005) newSl = null;
              }
            } else if (dir === "SHORT") {
              // Stop must be above current price; floor at 100.5% of mark.
              newSl = Math.max(candidate, mark * 1.005);
              if (Number.isFinite(oldSl) && oldSl > 0) {
                if (newSl >= oldSl - entry * 0.0005) newSl = null;
              }
            }
          }

          if (newSl != null && Number.isFinite(newSl) && newSl > 0) {
            const prev = Number.isFinite(oldSl) ? oldSl : null;
            openTrade.sl = newSl;
            openTrade.sl_protect_reason = slReason;
            openTrade.sl_last_tighten_ts = eventTs();

            const ev = {
              type: "SL_TIGHTEN",
              timestamp: eventTs(),
              price: mark,
              oldSl: prev,
              newSl,
              pnlPct,
              reason: slReason,
              isRunnerPhase,
              note: isRunnerPhase
                ? `ATR trailing SL for RUNNER (${pnlPct.toFixed(2)}% unrealized)`
                : `Tightened SL to protect gains (${pnlPct.toFixed(2)}% unrealized)`,
            };
            openTrade.history = Array.isArray(openTrade.history)
              ? [...openTrade.history, ev]
              : [ev];

            // Persist SL tighten via execution adapter
            if (adapter && openTrade?.id) {
              await adapter.replaceOrder(`${openTrade.id}-SL`, {
                stop_price: newSl,
                _trade: openTrade,
                _event: ev,
                _reason: slReason,
              }).catch((e) => {
                console.error("[EXEC] SL_TIGHTEN adapter.replaceOrder failed:", e);
              });
            }
            if (!isReplay) await kvPutJSON(KV, execKey, {
              ...execState,
              lastSlTightenMs: now,
            });
          }
        }
      } catch (e) {
        console.error("[KANBAN TRADE] gain-protection SL tighten error:", e);
      }

      openTrade.lastUpdate = eventTs();
      if (env && !isReplay) {
        await d1UpsertTrade(env, openTrade).catch((e) => {
          console.error("[D1 LEDGER] mark-to-market upsert failed:", e);
        });
      }
    }

    if (!isReplay) portfolio = await putPortfolioState(KV, portfolio);
    await persistTrades();

    // Legacy price-based simulation path removed from Kanban-driven execution.
    // Keep the function returning successfully for callers.
    return;

    if (false) {
      // Check if entry price needs correction (was incorrectly set from trigger_price)
      let correctedEntryPrice = existingOpenTrade.entryPrice;
      const entryPriceCorrected =
        existingOpenTrade.entryPriceCorrected || false;

      if (!entryPriceCorrected && tickerData.price) {
        const currentEntryPrice = Number(existingOpenTrade.entryPrice);
        const currentPrice = Number(tickerData.price);
        const triggerPrice = tickerData.trigger_price
          ? Number(tickerData.trigger_price)
          : null;

        // Check if price is available and entry price differs significantly
        const priceAvailable = currentPrice > 0;
        const entryPriceDiffers =
          Math.abs(currentEntryPrice - currentPrice) / currentPrice > 0.01; // More than 1% difference

        console.log(
          `[TRADE SIM] Checking ${ticker} ${direction} entry price correction: entry=$${currentEntryPrice.toFixed(
            2,
          )}, current=$${currentPrice.toFixed(2)}, trigger=${
            triggerPrice ? "$" + triggerPrice.toFixed(2) : "null"
          }, differs=${entryPriceDiffers}, corrected=${entryPriceCorrected}`,
        );

        if (priceAvailable && entryPriceDiffers) {
          // Check if trade is old (backfill) - use entry time from trade
          const entryTime = existingOpenTrade.entryTime
            ? new Date(existingOpenTrade.entryTime).getTime()
            : null;
          const now = Date.now();
          const isOldTrade = entryTime && now - entryTime > 60 * 60 * 1000; // More than 1 hour old

          // Also check trigger timestamp if available
          const triggerTimestamp =
            tickerData.trigger_ts != null
              ? new Date(Number(tickerData.trigger_ts)).toISOString()
              : tickerData.ts != null
                ? new Date(Number(tickerData.ts)).toISOString()
                : null;
          const triggerTime = triggerTimestamp
            ? new Date(triggerTimestamp).getTime()
            : null;
          const isBackfill = triggerTime && now - triggerTime > 60 * 60 * 1000;

          // Determine if entry price was likely set incorrectly
          // Check if entry price matches trigger_price (if available) or if trade is old
          const entryMatchesTrigger =
            triggerPrice &&
            Math.abs(currentEntryPrice - triggerPrice) / triggerPrice < 0.001;

          console.log(
            `[TRADE SIM] ${ticker} correction check: isOldTrade=${isOldTrade}, isBackfill=${isBackfill}, entryMatchesTrigger=${entryMatchesTrigger}, entryTime=${existingOpenTrade.entryTime}`,
          );

          // For old trades: ALWAYS use current price (entry was likely wrong)
          // For trades where entry matches trigger_price: use current price (entry was likely wrong)
          // If entry differs significantly from current price, it's likely wrong
          if (isOldTrade || entryMatchesTrigger || entryPriceDiffers) {
            // For old trades or mismatched prices: ALWAYS use current price, never trigger_price
            correctedEntryPrice = currentPrice;
            console.log(
              `[TRADE SIM] 🔧 Correcting ${ticker} ${direction} entry price: $${currentEntryPrice.toFixed(
                2,
              )} -> $${correctedEntryPrice.toFixed(2)} (reason: ${
                isOldTrade
                  ? "old trade"
                  : entryMatchesTrigger
                    ? "matches trigger_price"
                    : "differs from current price"
              }, using current price)`,
            );
          } else if (isBackfill && triggerPrice) {
            // For backfills only (not old trades): use trigger_price if significantly different
            const priceDiff =
              Math.abs(triggerPrice - currentPrice) / currentPrice;
            if (priceDiff > 0.01) {
              // More than 1% difference - use trigger_price for backfill
              correctedEntryPrice = triggerPrice;
              console.log(
                `[TRADE SIM] 🔧 Correcting ${ticker} ${direction} entry price: $${currentEntryPrice.toFixed(
                  2,
                )} -> $${correctedEntryPrice.toFixed(
                  2,
                )} (backfill, using trigger_price)`,
              );
            } else {
              // Price is close - use current price even for backfills
              correctedEntryPrice = currentPrice;
              console.log(
                `[TRADE SIM] 🔧 Correcting ${ticker} ${direction} entry price: $${currentEntryPrice.toFixed(
                  2,
                )} -> $${correctedEntryPrice.toFixed(
                  2,
                )} (backfill, trigger_price close, using current price)`,
              );
            }
          }
        }
      }

      // Recalculate shares if entry price was corrected (to maintain $1000 position size for stocks, 1 contract for futures)
      let correctedShares = existingOpenTrade.shares;
      if (
        correctedEntryPrice !== existingOpenTrade.entryPrice &&
        !entryPriceCorrected
      ) {
        // Calculate shares based on asset type (futures vs stocks)
        const tickerUpper = String(ticker || "").toUpperCase();
        const isFutures =
          FUTURES_SPECS[tickerUpper] || tickerUpper.endsWith("1!");
        correctedShares =
          isFutures && FUTURES_SPECS[tickerUpper]
            ? 1
            : TRADE_SIZE / correctedEntryPrice;
        console.log(
          `[TRADE SIM] 🔧 Recalculating ${ticker} ${direction} shares: ${existingOpenTrade.shares?.toFixed(
            4,
          )} -> ${correctedShares.toFixed(4)} (due to entry price correction)`,
        );
      }

      // Check TD Sequential exit signals BEFORE calculating P&L
      // TD Sequential only relevant on D/W/M — ignore intraday (4H and below)
      const tdSeq = tickerData.td_sequential || {};
      const tdExitTf = String(tdSeq.timeframe || tdSeq.tf || "D").toUpperCase();
      const tdExitIsHTF = ["D", "W", "M", "1D", "1W", "1M", "DAILY", "WEEKLY", "MONTHLY"].includes(tdExitTf);
      const tdSeqExitLong = tdExitIsHTF &&
        (tdSeq.exit_long === true || tdSeq.exit_long === "true");
      const tdSeqExitShort = tdExitIsHTF &&
        (tdSeq.exit_short === true || tdSeq.exit_short === "true");

      // Check if TD Sequential signals an exit for this trade direction
      let shouldExitFromTDSeq =
        (direction === "LONG" && tdSeqExitLong) ||
        (direction === "SHORT" && tdSeqExitShort);

      let tradeCalc;
      if (shouldExitFromTDSeq) {
        // Market is closed on weekends — do not exit/defend based on TDSEQ on Sat/Sun.
        if (isNyWeekend(Date.now())) {
          shouldExitFromTDSeq = false;
        }
      }

      // Avoid instant churn: ignore TDSEQ exits shortly after entry.
      if (shouldExitFromTDSeq) {
        const entryMs =
          isoToMs(existingOpenTrade?.entryTime) ||
          Number(existingOpenTrade?.entryTs) ||
          Number(existingOpenTrade?.entry_ts) ||
          isoToMs(existingOpenTrade?.entry_time) ||
          null;
        const nowMs = Number(tickerData?.ts) || Date.now();
        const ageMs = Number.isFinite(entryMs) ? nowMs - entryMs : null;
        const MIN_TDSEQ_HOLD_MS = 4 * 60 * 60 * 1000; // 4 hours (TD9 is usually a pullback; don't flinch early)
        if (Number.isFinite(ageMs) && ageMs >= 0 && ageMs < MIN_TDSEQ_HOLD_MS) {
          shouldExitFromTDSeq = false;
          // Breadcrumb for debugging / review
          await appendActivity(KV, {
            ticker,
            type: "tdseq_ignored_early",
            direction,
            age_min: Math.round(ageMs / 60000),
            min_age_min: Math.round(MIN_TDSEQ_HOLD_MS / 60000),
            td9_bullish:
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
            td9_bearish:
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
            td13_bullish:
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
            td13_bearish:
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
          });
        }
      }

      // TDSEQ should protect gains, not force exits at a loss.
      // Require (a) some profit buffer and (b) meaningful progress (phase/completion/TP progress) before allowing a TDSEQ exit.
      if (shouldExitFromTDSeq) {
        const priceNow = Number(tickerData?.price);
        const entryPx =
          Number(existingOpenTrade?.entryPrice) ||
          Number(existingOpenTrade?.entry_price) ||
          Number(tickerData?.trigger_price) ||
          Number(tickerData?.price);
        const tpPx =
          Number(existingOpenTrade?.tp) ||
          Number(existingOpenTrade?.tp_price) ||
          Number(tickerData?.tp);
        const completion = Number(tickerData?.completion);
        const phasePct = Number(tickerData?.phase_pct);

        const pnlPctNow =
          Number.isFinite(priceNow) && Number.isFinite(entryPx) && entryPx > 0
            ? direction === "LONG"
              ? ((priceNow - entryPx) / entryPx) * 100
              : ((entryPx - priceNow) / entryPx) * 100
            : null;

        let tpProgress = null;
        if (
          Number.isFinite(priceNow) &&
          Number.isFinite(entryPx) &&
          Number.isFinite(tpPx) &&
          tpPx !== entryPx
        ) {
          const raw =
            direction === "LONG"
              ? (priceNow - entryPx) / (tpPx - entryPx)
              : (entryPx - priceNow) / (entryPx - tpPx);
          tpProgress = Number.isFinite(raw)
            ? Math.max(0, Math.min(1, raw))
            : null;
        }

        const hasProfitBuffer = Number.isFinite(pnlPctNow)
          ? pnlPctNow >= 0.35
          : false; // ~35 bps
        const hasMeaningfulProgress =
          (Number.isFinite(completion) && completion >= 0.7) ||
          (Number.isFinite(phasePct) && phasePct >= 0.7) ||
          (Number.isFinite(tpProgress) && tpProgress >= 0.35);

        if (!(hasProfitBuffer && hasMeaningfulProgress)) {
          shouldExitFromTDSeq = false;
          await appendActivity(KV, {
            ticker,
            type: "tdseq_ignored_not_ready",
            direction,
            pnl_pct: Number.isFinite(pnlPctNow) ? pnlPctNow : null,
            completion: Number.isFinite(completion) ? completion : null,
            phase_pct: Number.isFinite(phasePct) ? phasePct : null,
            tp_progress: Number.isFinite(tpProgress) ? tpProgress : null,
            td9_bullish:
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
            td9_bearish:
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
            td13_bullish:
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
            td13_bearish:
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
          });
        }
      }

      if (shouldExitFromTDSeq) {
        // Higher-TF confirmation: only allow TDSEQ exits when DAILY structure confirms.
        // If DAILY doesn't confirm (or is missing), defend by tightening SL and keep holding.
        const daily = tickerData?.daily_ema_cloud || null;
        const fourH = tickerData?.fourh_ema_cloud || null;

        const dailyPos = String(daily?.position || "").toLowerCase();
        const dailyUpper = Number(daily?.upper);
        const dailyLower = Number(daily?.lower);

        const fourHPos = String(fourH?.position || "").toLowerCase();
        const fourHUpper = Number(fourH?.upper);
        const fourHLower = Number(fourH?.lower);

        const priceNow = Number(tickerData.price || 0);

        const dailyExists =
          dailyPos ||
          (Number.isFinite(dailyUpper) && dailyUpper > 0) ||
          (Number.isFinite(dailyLower) && dailyLower > 0);

        const dailyConfirmsExit =
          direction === "LONG"
            ? dailyExists &&
              (dailyPos === "below" ||
                (Number.isFinite(dailyLower) &&
                  dailyLower > 0 &&
                  priceNow < dailyLower))
            : dailyExists &&
              (dailyPos === "above" ||
                (Number.isFinite(dailyUpper) &&
                  dailyUpper > 0 &&
                  priceNow > dailyUpper));

        // If daily doesn't confirm the reversal, prefer defending (tighten SL) over exiting.
        const shouldDefend = !dailyConfirmsExit;

        const defendUpper =
          dailyExists && Number.isFinite(dailyUpper) && dailyUpper > 0
            ? dailyUpper
            : Number.isFinite(fourHUpper) && fourHUpper > 0
              ? fourHUpper
              : null;
        const defendLower =
          dailyExists && Number.isFinite(dailyLower) && dailyLower > 0
            ? dailyLower
            : Number.isFinite(fourHLower) && fourHLower > 0
              ? fourHLower
              : null;

        const canDefendLong =
          direction === "LONG" &&
          shouldDefend &&
          (dailyPos ? dailyPos !== "below" : true) &&
          Number.isFinite(defendLower) &&
          defendLower > 0;
        const canDefendShort =
          direction === "SHORT" &&
          shouldDefend &&
          (dailyPos ? dailyPos !== "above" : true) &&
          Number.isFinite(defendUpper) &&
          defendUpper > 0;

        if (canDefendLong || canDefendShort) {
          const suggestedSl = canDefendLong ? defendLower : defendUpper;
          const oldSlRaw =
            existingOpenTrade?.sl != null
              ? Number(existingOpenTrade.sl)
              : Number(tickerData?.sl);
          const oldSl = Number.isFinite(oldSlRaw) ? oldSlRaw : null;

          const tighten =
            oldSl == null
              ? true
              : direction === "LONG"
                ? suggestedSl > oldSl
                : suggestedSl < oldSl;

          if (tighten) {
            existingOpenTrade.sl = suggestedSl;
          }

          // Add activity feed event (even if no tighten, it documents the decision)
          await appendActivity(KV, {
            ticker,
            type: "tdseq_defense",
            direction,
            price: priceNow,
            old_sl: oldSl,
            new_sl: tighten ? suggestedSl : oldSl,
            cloud_pos: dailyPos || fourHPos || null,
            cloud_upper: Number.isFinite(defendUpper) ? defendUpper : null,
            cloud_lower: Number.isFinite(defendLower) ? defendLower : null,
            td9_bullish:
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
            td9_bearish:
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
            td13_bullish:
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
            td13_bearish:
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
          });

          // Discord + D1 alert (deduped hourly)
          try {
            const discordEnable = env?.DISCORD_ENABLE || "false";
            const discordWebhook = env?.DISCORD_WEBHOOK_URL;
            const discordConfigured =
              discordEnable === "true" && !!discordWebhook;

            const nowMs = Date.now();
            const hourBucket = new Date(nowMs).toISOString().slice(0, 13); // YYYY-MM-DDTHH
            const dedupeKey = `timed:dedupe:tdseq_defense:${ticker}:${direction}:${hourBucket}`;
            const already = await KV.get(dedupeKey);

            if (!already) {
              await KV.put(dedupeKey, "1", { expirationTtl: 60 * 60 });

              if (
                discordConfigured &&
                shouldSendDiscordAlert(env, "KANBAN_DEFEND", {
                  ticker,
                  direction,
                })
              ) {
                // TD defense context folded into kanban DEFEND embed
                const embed = createKanbanStageEmbed(ticker, "defend", "hold", tickerData, existingOpenTrade);
                const sendRes = await notifyDiscord(env, embed).catch((err) => {
                  console.error(
                    `[TRADE SIM] ❌ Failed to send TDSEQ defense alert for ${ticker}:`,
                    err,
                  );
                  return { ok: false, error: String(err) };
                });

                d1UpsertAlert(env, {
                  alert_id: buildAlertId(ticker, nowMs, "TDSEQ_DEFENSE"),
                  ticker,
                  ts: nowMs,
                  side: direction,
                  state: tickerData.state,
                  rank: Number(existingOpenTrade.rank) || 0,
                  rr_at_alert: Number(existingOpenTrade.rr) || 0,
                  trigger_reason: "TDSEQ_DEFENSE",
                  dedupe_day: formatDedupDay(nowMs),
                  discord_sent: !!sendRes?.ok,
                  discord_status: sendRes?.status ?? null,
                  discord_error: sendRes?.ok
                    ? null
                    : sendRes?.reason ||
                      sendRes?.statusText ||
                      sendRes?.error ||
                      "discord_send_failed",
                  payload_json: JSON.stringify({
                    ticker,
                    direction,
                    price: priceNow,
                    old_sl: oldSl,
                    new_sl: tighten ? suggestedSl : oldSl,
                    cloud: dailyExists ? daily : fourH,
                    td_sequential: tdSeq,
                  }),
                  meta_json: JSON.stringify({ kind: "tdseq_defense" }),
                }).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to upsert TDSEQ defense alert:`,
                    e,
                  );
                });
              }
            }
          } catch (e) {
            console.error(`[TRADE SIM] TDSEQ defense alert error:`, e);
          }

          // Do not exit; continue with normal TP/SL evaluation using updated SL.
          shouldExitFromTDSeq = false;
        }

        // If DAILY doesn't confirm, do not exit (even if we couldn't tighten).
        if (shouldDefend && shouldExitFromTDSeq) {
          shouldExitFromTDSeq = false;
        }
      }

      if (shouldExitFromTDSeq) {
        console.log(
          `[TRADE SIM] 🚨 TD Sequential exit signal for ${ticker} ${direction}: ` +
            `TD9/TD13 ${
              direction === "LONG" ? "bearish" : "bullish"
            } reversal detected`,
        );

        // Force exit at current price (TD Sequential exhaustion signal)
        const currentPrice = Number(tickerData.price || 0);
        const shares = correctedShares || existingOpenTrade.shares || 0;
        let pnl = 0;
        let pnlPct = 0;

        if (direction === "LONG") {
          pnl = (currentPrice - correctedEntryPrice) * shares;
          pnlPct =
            ((currentPrice - correctedEntryPrice) / correctedEntryPrice) * 100;
        } else {
          pnl = (correctedEntryPrice - currentPrice) * shares;
          pnlPct =
            ((correctedEntryPrice - currentPrice) / correctedEntryPrice) * 100;
        }

        const tdSeqStatus = pnl >= 0 ? "WIN" : "LOSS";
        tradeCalc = {
          shares,
          pnl,
          pnlPct,
          status: tdSeqStatus,
          currentPrice,
          trimmedPct: existingOpenTrade.trimmedPct || 0,
          exitPrice: currentPrice,
          exitReason: "TDSEQ",
          exitCategory: "INVALIDATION",
        };

        // Add activity feed event for TD9 exit
        await appendActivity(KV, {
          ticker,
          type: "td9_exit",
          direction,
          side: direction === "LONG" ? "bearish" : "bullish",
          entryPrice: correctedEntryPrice,
          exitPrice: currentPrice,
          pnl,
          pnlPct,
          status: tdSeqStatus,
          td9_bullish:
            tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
          td9_bearish:
            tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
          td13_bullish:
            tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
          td13_bearish:
            tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
        });
      } else {
        // Normal TP/SL calculation
        tradeCalc = calculateTradePnl(tickerData, correctedEntryPrice, {
          ...existingOpenTrade,
          shares: correctedShares,
        });
      }

      if (tradeCalc) {
        // Ensure status matches actual P&L (fix for trades marked WIN with negative P&L)
        let newStatus =
          tradeCalc.status === "TP_HIT_TRIM" ? "TP_HIT_TRIM" : tradeCalc.status;
        if (
          (newStatus === "WIN" || newStatus === "LOSS") &&
          tradeCalc.pnl !== undefined
        ) {
          // Double-check: WIN must have positive P&L, LOSS must have negative P&L
          if (newStatus === "WIN" && tradeCalc.pnl < 0) {
            console.log(
              `[TRADE SIM] ⚠️ Correcting ${ticker} ${direction}: WIN with negative P&L (${tradeCalc.pnl.toFixed(
                2,
              )}) -> LOSS`,
            );
            newStatus = "LOSS";
          } else if (newStatus === "LOSS" && tradeCalc.pnl > 0) {
            console.log(
              `[TRADE SIM] ⚠️ Correcting ${ticker} ${direction}: LOSS with positive P&L (${tradeCalc.pnl.toFixed(
                2,
              )}) -> WIN`,
            );
            newStatus = "WIN";
          }
        }

        // Update history for trade lifecycle events (ENTRY / TRIM / EXIT)
        const history = Array.isArray(existingOpenTrade.history)
          ? [...existingOpenTrade.history]
          : [];
        const newHistoryEvents = [];

        const ensureEntryInHistory = () => {
          const hasEntry = history.some((e) => e && e.type === "ENTRY");
          if (hasEntry) return;
          history.unshift({
            type: "ENTRY",
            timestamp: existingOpenTrade.entryTime,
            price: existingOpenTrade.entryPrice,
            shares: existingOpenTrade.shares || 0,
            value:
              existingOpenTrade.entryPrice * (existingOpenTrade.shares || 0),
            note: `Initial entry at $${Number(
              existingOpenTrade.entryPrice,
            ).toFixed(2)}`,
            positionPct: 1.0,
          });
        };

        ensureEntryInHistory();

        // Add history entry if entry price was corrected
        if (
          correctedEntryPrice !== existingOpenTrade.entryPrice &&
          !entryPriceCorrected
        ) {
          const ev = {
            type: "ENTRY_CORRECTION",
            timestamp: eventTs(),
            price: correctedEntryPrice,
            shares: correctedShares,
            value: correctedEntryPrice * correctedShares,
            note: `Entry price corrected from $${existingOpenTrade.entryPrice.toFixed(
              2,
            )} to $${correctedEntryPrice.toFixed(
              2,
            )} (was incorrectly using trigger_price)`,
          };
          history.push(ev);
          newHistoryEvents.push(ev);
        }

        const oldStatus = existingOpenTrade.status || "OPEN";
        const oldTrimmedPct = Number(existingOpenTrade.trimmedPct || 0);
        const newTrimmedPct = Number(
          tradeCalc.trimmedPct != null ? tradeCalc.trimmedPct : oldTrimmedPct,
        );
        const trimDeltaPctRaw = newTrimmedPct - oldTrimmedPct;
        const EPS = 1e-6;
        const didTrim = trimDeltaPctRaw > EPS;

        // Determine prices/reasons used by the calc
        const currentPrice = Number(
          tickerData.price || tradeCalc.currentPrice || 0,
        );
        const trimPrice = Number(
          tradeCalc.trimPrice != null
            ? tradeCalc.trimPrice
            : tickerData.tp != null
              ? Number(tickerData.tp)
              : existingOpenTrade.tp,
        );
        const exitPrice = Number(
          tradeCalc.exitPrice != null ? tradeCalc.exitPrice : currentPrice,
        );
        const exitReason =
          tradeCalc.exitReason ||
          (shouldExitFromTDSeq
            ? "TDSEQ"
            : newStatus === "LOSS"
              ? "SL"
              : "TP_FULL");
        const exitCategory =
          tradeCalc.exitCategory ||
          (exitReason === "SL" || exitReason === "TDSEQ"
            ? "INVALIDATION"
            : exitReason === "TP_FULL"
              ? "PROFIT_MANAGEMENT"
              : null);

        // Add TRIM event whenever trimmedPct increases (supports progressive trims)
        if (didTrim) {
          const alreadyLogged = history.some((e) => {
            if (!e || e.type !== "TRIM") return false;
            const ePct = Number(
              e.trimPct != null
                ? e.trimPct
                : e.trimmedPct != null
                  ? e.trimmedPct
                  : 0,
            );
            return Math.abs(ePct - newTrimmedPct) < EPS;
          });

          if (!alreadyLogged) {
            const trimShares =
              (correctedShares || existingOpenTrade.shares || 0) *
              trimDeltaPctRaw; // Allow fractional shares
            const ev = {
              type: "TRIM",
              timestamp: eventTs(),
              price: Number.isFinite(trimPrice) ? trimPrice : null,
              shares: trimShares,
              value:
                Number.isFinite(trimPrice) && Number.isFinite(trimShares)
                  ? trimPrice * trimShares
                  : null,
              trimPct: newTrimmedPct, // total trimmed
              trimDeltaPct: trimDeltaPctRaw, // this trim step
              remainingPct: Math.max(0, 1 - newTrimmedPct),
              category:
                tradeCalc.decisionCategory ||
                tradeCalc.exitCategory ||
                "PROFIT_MANAGEMENT",
              note: `Trimmed ${Math.round(trimDeltaPctRaw * 100)}% at TP ${
                Number.isFinite(trimPrice)
                  ? `$${Number(trimPrice).toFixed(2)}`
                  : "—"
              } (total trimmed: ${Math.round(newTrimmedPct * 100)}%)`,
            };
            history.push(ev);
            newHistoryEvents.push(ev);
          }
        }

        // Add history entry for close
        if (
          (newStatus === "WIN" || newStatus === "LOSS") &&
          oldStatus !== "WIN" &&
          oldStatus !== "LOSS"
        ) {
          const remainingShares =
            (correctedShares || existingOpenTrade.shares || 0) *
            Math.max(0, 1 - oldTrimmedPct);
          const ev = {
            type: "EXIT",
            timestamp: eventTs(),
            price: exitPrice,
            shares: remainingShares,
            value: exitPrice * remainingShares,
            reason: exitReason,
            category: exitCategory,
            note: `Closed ${
              newStatus === "WIN" ? "profitably" : "at loss"
            } at $${Number(exitPrice).toFixed(2)} (${exitReason})`,
          };
          history.push(ev);
          newHistoryEvents.push(ev);
        }

        const updatedTrade = {
          ...existingOpenTrade,
          ...tradeCalc,
          entryPrice: correctedEntryPrice, // Use corrected entry price if it was corrected
          shares: correctedShares, // Use corrected shares if entry price was corrected
          entryPriceCorrected:
            correctedEntryPrice !== existingOpenTrade.entryPrice ||
            entryPriceCorrected, // Mark as corrected
          status: newStatus,
          trimmedPct: tradeCalc.trimmedPct || existingOpenTrade.trimmedPct || 0,
          lastUpdate: eventTs(),
          // Prefer the trade's current SL (may be tightened defensively)
          sl: Number.isFinite(Number(existingOpenTrade.sl))
            ? Number(existingOpenTrade.sl)
            : Number(tickerData.sl) || existingOpenTrade.sl,
          // Prefer the trade's TP plan (may be rebuilt after entry corrections)
          tpArray:
            tradeCalc.tpArray && Array.isArray(tradeCalc.tpArray)
              ? tradeCalc.tpArray
              : existingOpenTrade.tpArray,
          tp: (() => {
            const arr =
              tradeCalc.tpArray && Array.isArray(tradeCalc.tpArray)
                ? tradeCalc.tpArray
                : existingOpenTrade.tpArray;
            const first =
              Array.isArray(arr) && arr.length > 0
                ? arr
                    .map((x) => ({
                      price: Number(x?.price),
                      trimPct: Number(x?.trimPct),
                    }))
                    .filter(
                      (x) =>
                        Number.isFinite(x.price) && Number.isFinite(x.trimPct),
                    )
                    .sort((a, b) => a.trimPct - b.trimPct)[0]?.price
                : null;
            return Number.isFinite(first)
              ? first
              : Number(tickerData.tp) || existingOpenTrade.tp;
          })(),
          rr: (() => {
            const slVal = Number.isFinite(Number(existingOpenTrade.sl))
              ? Number(existingOpenTrade.sl)
              : Number(tickerData.sl) || existingOpenTrade.sl;
            const risk = Math.abs(correctedEntryPrice - Number(slVal));
            const arr =
              tradeCalc.tpArray && Array.isArray(tradeCalc.tpArray)
                ? tradeCalc.tpArray
                : existingOpenTrade.tpArray;
            const prices = Array.isArray(arr)
              ? arr
                  .map((x) => Number(x?.price))
                  .filter((p) => Number.isFinite(p))
              : [];
            const exitTp =
              prices.length > 0
                ? direction === "LONG"
                  ? Math.max(...prices)
                  : Math.min(...prices)
                : null;
            const gain =
              Number.isFinite(exitTp) && risk > 0
                ? direction === "LONG"
                  ? exitTp - correctedEntryPrice
                  : correctedEntryPrice - exitTp
                : null;
            const rrCalc =
              risk > 0 && gain != null && gain > 0 ? gain / risk : null;
            return rrCalc || Number(tickerData.rr) || existingOpenTrade.rr || 0;
          })(),
          rank: Number(tickerData.rank) || existingOpenTrade.rank,
          history: history,
          trim_ts: (() => {
            const trimEv = Array.isArray(newHistoryEvents) ? newHistoryEvents.find((e) => e && e.type === "TRIM") : null;
            if (trimEv) return Number.isFinite(asOfMs) ? asOfMs : (isoToMs(trimEv.timestamp) || null);
            return existingOpenTrade.trim_ts ?? null;
          })(),
          exitReason:
            newStatus === "WIN" || newStatus === "LOSS" ? exitReason : null,
          exitCategory:
            newStatus === "WIN" || newStatus === "LOSS" ? exitCategory : null,
          exitPrice:
            newStatus === "WIN" || newStatus === "LOSS" ? exitPrice : null,
        };

        const tradeIndex = allTrades.findIndex(
          (t) => t.id === existingOpenTrade.id,
        );
        if (tradeIndex >= 0) {
          allTrades[tradeIndex] = updatedTrade;

          // D1 first (source of truth), then KV — skip during replay (in-memory only)
          if (env && !isReplay) {
            await d1UpsertTrade(env, updatedTrade).catch((e) => {
              console.error(
                `[D1 LEDGER] Failed to upsert trade ${updatedTrade?.id}:`,
                e,
              );
            });
            if (
              updatedTrade?.id &&
              Array.isArray(newHistoryEvents) &&
              newHistoryEvents.length > 0
            ) {
              for (const ev of newHistoryEvents) {
                await d1InsertTradeEvent(env, updatedTrade.id, ev).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to insert trade event for ${updatedTrade.id}:`,
                    e,
                  );
                });
              }
            }
          }
          await kvPutJSON(KV, tradesKey, allTrades);
          console.log(
            `[TRADE SIM] Updated trade ${ticker} ${direction}: ${oldStatus} -> ${newStatus}`,
          );

          // Send Discord notifications for status changes
          if (env) {
            const pnl = updatedTrade.pnl || 0;
            const pnlPct = updatedTrade.pnlPct || 0;
            const findHistoryTs = (type) => {
              if (!Array.isArray(newHistoryEvents)) return Date.now();
              for (let i = newHistoryEvents.length - 1; i >= 0; i--) {
                const ev = newHistoryEvents[i];
                if (!ev || !ev.type) continue;
                if (String(ev.type).toUpperCase() === type) {
                  const ts =
                    isoToMs(ev.timestamp) || Number(ev.ts) || Date.now();
                  return Number.isFinite(ts) ? ts : Date.now();
                }
              }
              return Date.now();
            };

            // Send TRIM alert whenever a new TRIM event was created
            if (didTrim) {
              console.log(
                `[TRADE SIM] 📢 Preparing trim alert for ${ticker} ${direction} (trimmedPct ${oldTrimmedPct} -> ${newTrimmedPct})`,
              );
              const alertTs = findHistoryTs("TRIM");
              const dedupe = await shouldSendTradeDiscordEvent(KV, {
                tradeId: updatedTrade.id,
                type: "TRADE_TRIM",
                ts: alertTs,
              });
              if (dedupe.deduped) {
                console.log(
                  `[TRADE SIM] 🔁 Deduped TRIM alert for ${ticker} ${direction} (${dedupe.key})`,
                );
              } else if (
                shouldSendDiscordAlert(env, "TRADE_TRIM", {
                  newTrimmedPct,
                  trimDeltaPctRaw,
                })
              ) {
                const trimQtySim = Number(updatedTrade.shares) * Number(trimDeltaPctRaw || 0);
                const trimPriceSim = Number.isFinite(trimPrice) ? trimPrice : Number(updatedTrade.tp);
                const embed = createTradeTrimmedEmbed(
                  ticker,
                  direction,
                  updatedTrade.entryPrice,
                  currentPrice,
                  trimPriceSim,
                  pnl,
                  pnlPct,
                  newTrimmedPct,
                  tickerData,
                  updatedTrade,
                  trimDeltaPctRaw,
                  { qty: trimQtySim, value: trimPriceSim * trimQtySim, pnl },
                );
                const sendRes = await notifyDiscord(env, embed).catch((err) => {
                  console.error(
                    `[TRADE SIM] ❌ Failed to send trim alert for ${ticker}:`,
                    err,
                  );
                  return { ok: false, error: String(err) };
                }); // Don't let Discord errors break trade updates
                // persist alert (best-effort)
                const alertPayloadJson = (() => {
                  try {
                    return JSON.stringify(tickerData);
                  } catch {
                    return null;
                  }
                })();
                const alertMetaJson = (() => {
                  try {
                    return JSON.stringify({
                      type: "TRADE_TRIM",
                      trade_id: updatedTrade.id,
                      trimmed_pct: newTrimmedPct,
                      trim_delta_pct: trimDeltaPctRaw,
                    });
                  } catch {
                    return null;
                  }
                })();
                d1UpsertAlert(env, {
                  alert_id: buildAlertId(ticker, alertTs, "TRADE_TRIM"),
                  ticker,
                  ts: alertTs,
                  side: direction,
                  state: tickerData.state,
                  rank: updatedTrade.rank,
                  rr_at_alert: updatedTrade.rr,
                  trigger_reason: "TRADE_TRIM",
                  dedupe_day: formatDedupDay(alertTs),
                  discord_sent: !!sendRes?.ok,
                  discord_status: sendRes?.status ?? null,
                  discord_error: sendRes?.ok
                    ? null
                    : sendRes?.reason ||
                      sendRes?.statusText ||
                      sendRes?.error ||
                      "discord_send_failed",
                  payload_json: alertPayloadJson,
                  meta_json: alertMetaJson,
                }).catch((e) => {
                  console.error(`[D1 LEDGER] Failed to upsert trim alert:`, e);
                });
              } else {
                console.log(
                  `[TRADE SIM] (critical-only) Skipping TRIM discord for ${ticker} (${newTrimmedPct}% total trimmed)`,
                );
              }
            }

            // Send EXIT alert on first transition into WIN/LOSS
            if (
              (newStatus === "WIN" || newStatus === "LOSS") &&
              oldStatus !== "WIN" &&
              oldStatus !== "LOSS"
            ) {
              console.log(
                `[TRADE SIM] 📢 Preparing exit alert for ${ticker} ${direction} (${newStatus})`,
              );
              const exitTs = findHistoryTs("EXIT");
              const exitDedupe = await shouldSendTradeDiscordEvent(KV, {
                tradeId: updatedTrade.id,
                type: "TRADE_EXIT",
                ts: exitTs,
              });
              if (exitDedupe.deduped) {
                console.log(
                  `[TRADE SIM] 🔁 Deduped EXIT alert for ${ticker} ${direction} (${exitDedupe.key})`,
                );
              } else {
                const exitQty = Number(updatedTrade.shares) || 0;
                const embed = createTradeClosedEmbed(
                  ticker,
                  direction,
                  newStatus,
                  updatedTrade.entryPrice,
                  exitPrice,
                  pnl,
                  pnlPct,
                  updatedTrade.rank || existingOpenTrade.rank || 0,
                  updatedTrade.rr || existingOpenTrade.rr || 0,
                  tickerData,
                  updatedTrade,
                  {
                    qty: exitQty,
                    value: Number(exitPrice) * exitQty,
                    pnl,
                  },
                );
                const sendRes = await notifyDiscord(env, embed).catch((err) => {
                  console.error(
                    `[TRADE SIM] ❌ Failed to send exit alert for ${ticker}:`,
                    err,
                  );
                  return { ok: false, error: String(err) };
                }); // Don't let Discord errors break trade updates
                // persist alert (best-effort)
                const exitPayloadJson = (() => {
                  try {
                    return JSON.stringify(tickerData);
                  } catch {
                    return null;
                  }
                })();
                const exitMetaJson = (() => {
                  try {
                    return JSON.stringify({
                      type: "TRADE_EXIT",
                      trade_id: updatedTrade.id,
                      status: newStatus,
                      exit_reason: updatedTrade.exitReason || null,
                      pnl,
                      pnlPct,
                    });
                  } catch {
                    return null;
                  }
                })();
                d1UpsertAlert(env, {
                  alert_id: buildAlertId(ticker, exitTs, "TRADE_EXIT"),
                  ticker,
                  ts: exitTs,
                  side: direction,
                  state: tickerData.state,
                  rank: updatedTrade.rank,
                  rr_at_alert: updatedTrade.rr,
                  trigger_reason: updatedTrade.exitReason || "TRADE_EXIT",
                  dedupe_day: formatDedupDay(exitTs),
                  discord_sent: !!sendRes?.ok,
                  discord_status: sendRes?.status ?? null,
                  discord_error: sendRes?.ok
                    ? null
                    : sendRes?.reason ||
                      sendRes?.statusText ||
                      sendRes?.error ||
                      "discord_send_failed",
                  payload_json: exitPayloadJson,
                  meta_json: exitMetaJson,
                }).catch((e) => {
                  console.error(`[D1 LEDGER] Failed to upsert exit alert:`, e);
                });

                // If this was a TD exit, send additional TD9/TD13 alert
                if (
                  shouldExitFromTDSeq &&
                  shouldSendDiscordAlert(env, "TD9_EXIT", { ticker, direction })
                ) {
                  console.log(
                    `[TRADE SIM] 📢 Preparing TD9 exit alert for ${ticker} ${direction}`,
                  );
                  const td9Ts = exitTs || findHistoryTs("EXIT");
                  const td9Dedupe = await shouldSendTradeDiscordEvent(KV, {
                    tradeId: updatedTrade.id,
                    type: "TD9_EXIT",
                    ts: td9Ts,
                  });
                  if (td9Dedupe.deduped) {
                    console.log(
                      `[TRADE SIM] 🔁 Deduped TD9_EXIT alert for ${ticker} ${direction} (${td9Dedupe.key})`,
                    );
                  } else {
                    // TD9 exit context now folded into the standard TRADE_EXIT embed
                    const td9Embed = createTradeClosedEmbed(
                      ticker,
                      direction,
                      newStatus,
                      updatedTrade.entryPrice,
                      exitPrice,
                      pnl,
                      pnlPct,
                      updatedTrade.rank || existingOpenTrade.rank || 0,
                      updatedTrade.rr || existingOpenTrade.rr || 0,
                      tickerData,
                      updatedTrade,
                    );
                    const td9Res = await notifyDiscord(env, td9Embed).catch(
                      (err) => {
                        console.error(
                          `[TRADE SIM] ❌ Failed to send TD9 exit alert for ${ticker}:`,
                          err,
                        );
                        return { ok: false, error: String(err) };
                      },
                    );
                    d1UpsertAlert(env, {
                      alert_id: buildAlertId(ticker, td9Ts, "TD9_EXIT"),
                      ticker,
                      ts: td9Ts,
                      side: direction,
                      state: tickerData.state,
                      rank: updatedTrade.rank,
                      rr_at_alert: updatedTrade.rr,
                      trigger_reason: "TDSEQ_EXIT",
                      dedupe_day: formatDedupDay(td9Ts),
                      discord_sent: !!td9Res?.ok,
                      discord_status: td9Res?.status ?? null,
                      discord_error: td9Res?.ok
                        ? null
                        : td9Res?.reason ||
                          td9Res?.statusText ||
                          td9Res?.error ||
                          "discord_send_failed",
                      payload_json: exitPayloadJson,
                      meta_json: exitMetaJson,
                    }).catch((e) => {
                      console.error(
                        `[D1 LEDGER] Failed to upsert TD9 exit alert:`,
                        e,
                      );
                    });
                  }
                }
              }
            }
          } else {
            console.log(
              `[TRADE SIM] ⚠️ Skipping Discord alert for ${ticker} ${direction} status change (${oldStatus} -> ${newStatus}) - env not available`,
            );
          }
        }
      }
    } else {
      // Check if we should create a new trade
      // ALWAYS prefer price field from TradingView for entry price
      // Only use trigger_price as fallback if price is missing or invalid
      const currentPrice = tickerData.price ? Number(tickerData.price) : null;
      const triggerPrice = tickerData.trigger_price
        ? Number(tickerData.trigger_price)
        : null;

      // Detect backfill: if trigger_ts is significantly older
      const triggerTimestamp =
        tickerData.trigger_ts != null
          ? new Date(Number(tickerData.trigger_ts)).toISOString()
          : tickerData.ts != null
            ? new Date(Number(tickerData.ts)).toISOString()
            : null;
      const now = Date.now();
      const triggerTime = triggerTimestamp
        ? new Date(triggerTimestamp).getTime()
        : null;
      const isBackfill = triggerTime && now - triggerTime > 60 * 60 * 1000; // More than 1 hour old

      let entryPrice;
      let priceSource;

      // ALWAYS use current price if available and valid (> 0)
      // For new trades, we want the entry price to reflect the CURRENT market price,
      // not a historical trigger_price, so traders see accurate entry levels
      if (currentPrice && currentPrice > 0) {
        entryPrice = currentPrice;
        priceSource = isBackfill ? "price (backfill, using current)" : "price";
        console.log(
          `[TRADE SIM] Using current price $${currentPrice.toFixed(
            2,
          )} as entry price${
            isBackfill
              ? " (backfill detected, but using current price for accuracy)"
              : " (real-time)"
          }`,
        );
      } else if (triggerPrice && triggerPrice > 0) {
        // Fallback: only use trigger_price if price is not available
        entryPrice = triggerPrice;
        priceSource = "trigger_price (fallback)";
        console.log(
          `[TRADE SIM] ⚠️ Using trigger_price $${triggerPrice.toFixed(
            2,
          )} as fallback (price not available)`,
        );
      } else {
        // No valid price available - cannot create trade
        console.log(
          `[TRADE SIM] ⚠️ Cannot create trade for ${ticker}: no valid price or trigger_price`,
        );
        return; // Exit early if no valid price
      }

      console.log(
        `[TRADE SIM] ${ticker} entry price: $${entryPrice.toFixed(
          2,
        )} (from ${priceSource}${
          isBackfill ? ", BACKFILL" : ""
        }), current price: $${Number(tickerData.price || 0).toFixed(
          2,
        )}, trigger_price: ${
          tickerData.trigger_price
            ? "$" + Number(tickerData.trigger_price).toFixed(2)
            : "null"
        }`,
      );
      const entryRR = calculateRRAtEntry(tickerData, entryPrice);

      // Create a temporary tickerData with entry RR for checking conditions
      const tickerDataForCheck = {
        ...tickerData,
        rr: entryRR, // Use entry RR instead of current RR
      };

      const shouldTrigger = shouldTriggerTradeSimulation(
        ticker,
        tickerDataForCheck,
        prevData,
      );

      // Log detailed check results for debugging
      const h = Number(tickerData.htf_score);
      const l = Number(tickerData.ltf_score);
      const state = String(tickerData.state || "");
      const alignedLong = state === "HTF_BULL_LTF_BULL";
      const alignedShort = state === "HTF_BEAR_LTF_BEAR";
      const inCorridor =
        Number.isFinite(h) &&
        Number.isFinite(l) &&
        ((h > 0 && l >= -10 && l <= 22) || (h < 0 && l >= -12 && l <= 10));
      const side =
        h > 0 && l >= -10 && l <= 22
          ? "LONG"
          : h < 0 && l >= -12 && l <= 10
            ? "SHORT"
            : null;
      const corridorAlignedOK =
        (side === "LONG" && alignedLong) || (side === "SHORT" && alignedShort);

      const flags = tickerData.flags || {};
      const momentumElite = !!flags.momentum_elite;
      const baseMinRR = 1.5;
      const minRR = momentumElite ? Math.max(1.2, baseMinRR * 0.9) : baseMinRR;

      const rrOk = (entryRR || 0) >= minRR;
      const compOk =
        (Number(tickerData.completion) || 0) <= (momentumElite ? 0.5 : 0.4);
      const phaseOk =
        (Number(tickerData.phase_pct) || 0) <= (momentumElite ? 0.7 : 0.6);

      console.log(
        `[TRADE SIM] ${ticker} ${direction}: shouldTrigger=${shouldTrigger}, entryRR=${
          entryRR?.toFixed(2) || "null"
        }, currentRR=${tickerData.rr?.toFixed(2) || "null"}, rank=${
          tickerData.rank || 0
        }, state=${state}`,
      );
      console.log(
        `[TRADE SIM] ${ticker} checks: inCorridor=${inCorridor}, corridorAlignedOK=${corridorAlignedOK}, rrOk=${rrOk} (${
          entryRR?.toFixed(2) || "null"
        } >= ${minRR}), compOk=${compOk}, phaseOk=${phaseOk}`,
      );

      if (!shouldTrigger) {
        console.log(
          `[TRADE SIM] ❌ ${ticker} ${direction}: Trade creation BLOCKED - conditions not met`,
        );
        return; // Exit early - do not create trade
      }

      if (shouldTrigger) {
        const now = Date.now();
        const recentCloseWindow = 5 * 60 * 1000; // 5 minutes

        // Check for recently closed trade (prevent rapid re-entry)
        const recentlyClosedTrade = allTrades.find(
          (t) =>
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "WIN" || t.status === "LOSS") &&
            t.entryTime &&
            now - new Date(t.entryTime).getTime() < recentCloseWindow,
        );

        // Check for existing open trade
        // Allow new position if entry price is significantly different (>5%) - enables scaling in
        const anyOpenTrade = allTrades.find(
          (t) =>
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM"),
        );

        // If open trade exists, check if entry price is significantly different
        let shouldBlockOpenTrade = false;
        if (anyOpenTrade && anyOpenTrade.entryPrice) {
          const existingEntryPrice = Number(anyOpenTrade.entryPrice);
          const priceDiffPct =
            Math.abs(entryPrice - existingEntryPrice) / existingEntryPrice;
          // Block only if entry prices are within 5% of each other (too similar to be scaling in)
          shouldBlockOpenTrade = priceDiffPct < 0.05; // 5% threshold

          if (shouldBlockOpenTrade) {
            console.log(
              `[TRADE SIM] ⚠️ ${ticker} ${direction}: Open trade exists with similar entry price (${existingEntryPrice.toFixed(
                2,
              )} vs ${entryPrice.toFixed(2)}, diff: ${(
                priceDiffPct * 100
              ).toFixed(2)}%)`,
            );
          } else {
            // Scaling in - merge into existing trade
            console.log(
              `[TRADE SIM] ℹ️ ${ticker} ${direction}: Scaling in - entry price differs significantly (${existingEntryPrice.toFixed(
                2,
              )} vs ${entryPrice.toFixed(2)}, diff: ${(
                priceDiffPct * 100
              ).toFixed(2)}%)`,
            );

            // Calculate new average entry price and total shares
            const existingShares = anyOpenTrade.shares || 0;
            const existingValue = existingEntryPrice * existingShares;
            // Calculate shares based on asset type (futures vs stocks)
            const tickerUpper = String(ticker || "").toUpperCase();
            const isFutures =
              FUTURES_SPECS[tickerUpper] || tickerUpper.endsWith("1!");
            const newShares =
              isFutures && FUTURES_SPECS[tickerUpper]
                ? 1
                : TRADE_SIZE / entryPrice;
            const newValue = entryPrice * newShares;
            const totalShares = existingShares + newShares;
            const totalValue = existingValue + newValue;
            const avgEntryPrice =
              totalShares > 0 ? totalValue / totalShares : entryPrice;

            // Update existing trade with scaled-in position
            const tradeCalc = calculateTradePnl(
              tickerData,
              avgEntryPrice,
              anyOpenTrade,
            );
            if (tradeCalc) {
              // Add history entry for scaling in
              const history = anyOpenTrade.history || [
                {
                  type: "ENTRY",
                  timestamp: anyOpenTrade.entryTime,
                  price: existingEntryPrice,
                  shares: existingShares,
                  value: existingValue,
                  note: `Initial entry at $${existingEntryPrice.toFixed(2)}`,
                },
              ];

              history.push({
                type: "SCALE_IN",
                timestamp: eventTs(),
                price: entryPrice,
                shares: newShares,
                value: newValue,
                note: `Scaled in at $${entryPrice.toFixed(
                  2,
                )} (avg entry now $${avgEntryPrice.toFixed(2)})`,
              });

              const updatedTrade = {
                ...anyOpenTrade,
                entryPrice: avgEntryPrice, // Update to average entry price
                shares: totalShares,
                ...tradeCalc,
                history: history,
                lastUpdate: eventTs(),
              };

              const tradeIndex = allTrades.findIndex(
                (t) => t.id === anyOpenTrade.id,
              );
              if (tradeIndex >= 0) {
                allTrades[tradeIndex] = updatedTrade;

                // D1 first (source of truth), then KV — skip during replay
                if (env && !isReplay) {
                  await d1UpsertTrade(env, updatedTrade).catch((e) => {
                    console.error(
                      `[D1 LEDGER] Failed to upsert scaled-in trade:`,
                      e,
                    );
                  });
                  const scaleEvent = history[history.length - 1];
                  if (scaleEvent && updatedTrade?.id) {
                    await d1InsertTradeEvent(env, updatedTrade.id, scaleEvent).catch(
                      (e) => {
                        console.error(
                          `[D1 LEDGER] Failed to insert SCALE_IN event:`,
                          e,
                        );
                      },
                    );
                  }
                  // Phase 2: ADD_ENTRY (new lot + action, update position)
                  const posId = anyOpenTrade.id;
                  const tsScale = scaleEvent?.timestamp ? new Date(scaleEvent.timestamp).getTime() : Date.now();
                  const lotIdScale = `${posId}-lot-${tsScale}`;
                  const actionIdScale = `${posId}-ADD_ENTRY-${tsScale}`;
                  await d1InsertLot(env, {
                    lot_id: lotIdScale,
                    position_id: posId,
                    ts: tsScale,
                    qty: newShares,
                    price: entryPrice,
                    value: newValue,
                    remaining_qty: newShares,
                  }).catch(() => {});
                  await d1InsertExecutionAction(env, {
                    action_id: actionIdScale,
                    position_id: posId,
                    ts: tsScale,
                    action_type: "ADD_ENTRY",
                    qty: newShares,
                    price: entryPrice,
                    value: newValue,
                    pnl_realized: null,
                    reason: "SCALE_IN",
                  }).catch(() => {});
                  await d1UpdatePosition(env, posId, {
                    total_qty: totalShares,
                    cost_basis: totalShares * avgEntryPrice,
                    updated_at: tsScale,
                  }).catch(() => {});
                }
                await kvPutJSON(KV, tradesKey, allTrades);
                console.log(
                  `[TRADE SIM] ✅ Scaled in ${ticker} ${direction} - Avg Entry: $${avgEntryPrice.toFixed(
                    2,
                  )}, Total Shares: ${totalShares}`,
                );

                // Send Discord notification for scaling in
                if (env) {
                  const embed = {
                    title: `📈 Position Scaled In: ${ticker} ${direction}`,
                    color: 0x00ff00,
                    fields: [
                      {
                        name: "New Entry Price",
                        value: `$${entryPrice.toFixed(2)}`,
                        inline: true,
                      },
                      {
                        name: "Average Entry Price",
                        value: `$${avgEntryPrice.toFixed(2)}`,
                        inline: true,
                      },
                      {
                        name: "Total Shares",
                        value: `${totalShares}`,
                        inline: true,
                      },
                      {
                        name: "Current Price",
                        value: `$${Number(tickerData.price).toFixed(2)}`,
                        inline: true,
                      },
                      {
                        name: "Current P&L",
                        value: `$${tradeCalc.pnl?.toFixed(2) || "0.00"} (${
                          tradeCalc.pnlPct?.toFixed(2) || "0.00"
                        }%)`,
                        inline: true,
                      },
                    ],
                    footer: {
                      text: "Timed Trading Simulator",
                    },
                    timestamp: new Date().toISOString(),
                  };
                  if (
                    shouldSendDiscordAlert(env, "SYSTEM", {
                      ticker,
                      kind: "trade_merge",
                    })
                  ) {
                    await notifyDiscord(env, embed).catch(() => {});
                  }
                }
              }
            }

            // Don't create a new trade - we've merged into existing
            return;
          }
        } else if (anyOpenTrade) {
          // Open trade exists but no entry price - block to be safe
          shouldBlockOpenTrade = true;
        }

        // Check for closed trades on subsequent days with similar entry price
        // Allow scaling/pyramiding if price differs significantly (>2%), but block if price is nearly the same
        const priceThreshold = entryPrice * 0.02; // 2% threshold for "nearly the same"
        const today = new Date(now);
        today.setHours(0, 0, 0, 0);
        const todayStart = today.getTime();

        // Find closed trades from previous days (not today) with similar entry price
        const similarPriceClosedTrade = allTrades.find((t) => {
          if (
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "WIN" || t.status === "LOSS") &&
            t.entryPrice &&
            t.entryTime
          ) {
            const entryDate = new Date(t.entryTime);
            entryDate.setHours(0, 0, 0, 0);
            const entryDayStart = entryDate.getTime();

            // Only check trades from previous days (not today)
            const isPreviousDay = entryDayStart < todayStart;

            // Check if price is nearly the same (within 2%)
            const priceDiff = Math.abs(Number(t.entryPrice) - entryPrice);
            const isSimilarPrice = priceDiff < priceThreshold;

            return isPreviousDay && isSimilarPrice;
          }
          return false;
        });

        // Check for open trades with similar price (existing logic - keep this)
        const similarPriceOpenTrade = allTrades.find(
          (t) =>
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM") &&
            t.entryPrice &&
            Math.abs(Number(t.entryPrice) - entryPrice) < priceThreshold,
        );

        // Log why trade was rejected if applicable
        if (recentlyClosedTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - recently closed trade (within 5 min)`,
          );
        } else if (shouldBlockOpenTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - open trade already exists with similar entry price`,
          );
        } else if (similarPriceOpenTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - open trade exists with similar entry price (${Number(
              similarPriceOpenTrade.entryPrice,
            ).toFixed(2)} vs ${entryPrice.toFixed(2)}, diff: ${(
              (Math.abs(Number(similarPriceOpenTrade.entryPrice) - entryPrice) /
                entryPrice) *
              100
            ).toFixed(2)}%)`,
          );
        } else if (similarPriceClosedTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - closed trade from previous day with similar entry price (${Number(
              similarPriceClosedTrade.entryPrice,
            ).toFixed(2)} vs ${entryPrice.toFixed(2)}, diff: ${(
              (Math.abs(
                Number(similarPriceClosedTrade.entryPrice) - entryPrice,
              ) /
                entryPrice) *
              100
            ).toFixed(2)}%, closed: ${similarPriceClosedTrade.entryTime})`,
          );
        } else {
          // Price differs significantly or no similar trade found - allow scaling/pyramiding
          if (similarPriceClosedTrade === undefined && anyOpenTrade) {
            console.log(
              `[TRADE SIM] ℹ️ ${ticker} ${direction}: Price differs significantly from previous day's closed trade - allowing scaling/pyramiding`,
            );
          }
        }

        if (
          !recentlyClosedTrade &&
          !shouldBlockOpenTrade &&
          !similarPriceOpenTrade &&
          !similarPriceClosedTrade
        ) {
          const tradeCalc = calculateTradePnl(tickerData, entryPrice);

          if (tradeCalc) {
            console.log(
              `[TRADE SIM] ✅ Creating new trade ${ticker} ${direction} - Entry: $${entryPrice.toFixed(
                2,
              )}, RR: ${entryRR?.toFixed(2) || "N/A"}`,
            );
            // Determine entry time: use ingest ts when reprocessing/replay (not replay run time)
            const entryTsMs =
              Number.isFinite(asOfMs)
                ? asOfMs
                : forceUseIngestTs && tickerData?.ts != null
                  ? (Number(tickerData.ts) < 1e12 ? Number(tickerData.ts) * 1000 : Number(tickerData.ts))
                  : forceUseIngestTs && triggerTimestamp
                    ? new Date(triggerTimestamp).getTime()
                    : isBackfill && triggerTimestamp
                      ? new Date(triggerTimestamp).getTime()
                      : Date.now();
            const entryTime = new Date(entryTsMs).toISOString();

            // ─────────────────────────────────────────────────────────────────────
            // BUILD 3-TIER TP ARRAY (TRIM 60%, EXIT 80%, RUNNER 100%)
            // ─────────────────────────────────────────────────────────────────────
            const tpArray = build3TierTPArray(
              tickerData,
              entryPrice,
              direction,
            );
            if (tpArray.length === 0) {
              console.error(
                `[TRADE SIM] ❌ ${ticker} ${direction}: Cannot create trade - no valid TP array found`,
              );
              return; // Exit early if no valid TP array
            }

            // Use first TP (TRIM level, 60%) as primary TP for backward compatibility
            const validTP = tpArray[0].price;

            // Calculate RR using RUNNER TP (max/furthest) from array
            const runnerTp = tpArray.find(tp => tp.tier === "RUNNER");
            const maxTP = runnerTp?.price || Math.max(...tpArray.map((tp) => tp.price));
            const baseSL = Number(tickerData.sl);
            
            // Apply direction-specific SL adjustment based on gold standard patterns
            const slAdjustment = computeDirectionAwareSL(tickerData, baseSL, direction, entryPrice);
            const finalSL = slAdjustment.sl;
            if (slAdjustment.adjusted) {
              console.log(`[GOLD_STANDARD_SL] ${ticker} ${direction} SL adjusted: ${baseSL.toFixed(2)} → ${finalSL.toFixed(2)} (${slAdjustment.reason})`);
            }
            
            const risk = Math.abs(entryPrice - finalSL);
            const gain =
              direction === "LONG" ? maxTP - entryPrice : entryPrice - maxTP;
            const calculatedRR = risk > 0 && gain > 0 ? gain / risk : null;

            // Log the 3-tier TP array for debugging
            console.log(`[3-TIER] ${ticker} ${direction} TP array:`, tpArray.map(tp => 
              `${tp.tier} $${tp.price.toFixed(2)} (${Math.round(tp.trimPct * 100)}%)`
            ).join(", "));

            const trade = {
              id: `${ticker}-${now}-${Math.random().toString(36).substr(2, 9)}`,
              ticker,
              direction,
              entryPath: entryPath || null,  // Track which entry criteria was used
              entryPrice,
              entryTime, // When trade was actually created (ingest time in replay)
              entry_ts: entryTsMs, // Numeric ms for D1/display (ingest time, not replay run time)
              triggerTimestamp: triggerTimestamp, // When signal was generated (for reference)
              sl: finalSL,
              sl_original: baseSL,
              sl_gs_adjusted: slAdjustment.adjusted,
              sl_gs_reason: slAdjustment.reason,
              tp: validTP, // Primary TP (TRIM level, 60% off)
              tpArray: tpArray, // Store full 3-tier TP array
              // Track which tiers have been hit
              trimTiers: [
                { tier: "TRIM", pct: THREE_TIER_CONFIG.TRIM.trimPct, hit: false, hitTs: null },
                { tier: "EXIT", pct: THREE_TIER_CONFIG.EXIT.trimPct, hit: false, hitTs: null },
                { tier: "RUNNER", pct: THREE_TIER_CONFIG.RUNNER.trimPct, hit: false, hitTs: null },
              ],
              rr: calculatedRR || entryRR || Number(tickerData.rr) || 0, // Use calculated RR from RUNNER TP
              rank: Number(tickerData.rank) || 0,
              state: tickerData.state,
              flags: tickerData.flags || {},
              scriptVersion: tickerData.script_version || "unknown",
              trimmedPct: 0, // Start with 0% trimmed
              // Trade history/audit trail
              history: [
                {
                  type: "ENTRY",
                  timestamp: entryTime,
                  price: entryPrice,
                  shares: tradeCalc.shares || 0,
                  value: entryPrice * (tradeCalc.shares || 0),
                  note: `Initial entry at $${entryPrice.toFixed(2)}${
                    triggerTimestamp
                      ? ` (signal: ${new Date(
                          triggerTimestamp,
                        ).toLocaleString()})`
                      : ""
                  }`,
                },
              ],
              ...tradeCalc,
            };

            allTrades.push(trade);
            allTrades.sort((a, b) => {
              const timeA = new Date(a.entryTime || 0).getTime();
              const timeB = new Date(b.entryTime || 0).getTime();
              return timeB - timeA;
            });

            // CRITICAL: Save trade to KV with retry logic to ensure it persists
            // This ensures the trade is saved even if the request is canceled
            // Use retry with verification to handle race conditions
            const saveResult = await kvPutJSONWithRetry(
              KV,
              tradesKey,
              allTrades,
            );
            if (saveResult.success) {
              console.log(
                `[TRADE SIM] ✅ Created new trade ${ticker} ${direction} (Rank ${
                  trade.rank
                }, Entry RR ${trade.rr.toFixed(2)}) - Saved to KV (attempt ${
                  saveResult.attempt
                }${saveResult.note ? `, ${saveResult.note}` : ""})`,
              );
            } else {
              console.error(
                `[TRADE SIM] ❌ Failed to save trade ${ticker} ${direction} after ${saveResult.attempts} attempts:`,
                saveResult.error,
              );
              // Still log the trade creation even if save failed
              // The trade will be recreated on next ingestion if conditions are met
              console.log(
                `[TRADE SIM] ⚠️ Trade ${ticker} ${direction} created but NOT saved - will retry on next ingestion`,
              );
            }

            // Persist new trade + ENTRY event to D1 ledger (best-effort) — skip during replay
            if (!isReplay) {
              d1UpsertTrade(env, trade).catch((e) => {
                console.error(
                  `[D1 LEDGER] Failed to upsert new trade ${ticker}:`,
                  e,
                );
              });
              const entryEvent =
                Array.isArray(trade.history) && trade.history.length > 0
                  ? trade.history[0]
                  : null;
              if (entryEvent && trade?.id) {
                d1InsertTradeEvent(env, trade.id, entryEvent).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to insert ENTRY event for ${ticker}:`,
                    e,
                  );
                });
              }
            }

            // Send Discord notification for new trade entry
            // Only send alert if this is a real-time trade (not a backfill)
            // Backfills can have misleading entry prices and confuse traders
            if (env && !isBackfill) {
              console.log(
                `[TRADE SIM] 📢 Preparing entry alert for ${ticker} ${direction}`,
              );

              // CRITICAL: If we're sending a Discord alert, ensure the trade is saved
              // Retry KV write if it failed, since we have enough confidence to alert
              if (!saveResult.success) {
                console.log(
                  `[TRADE SIM] 🔄 Retrying KV save for ${ticker} ${direction} before sending alert`,
                );
                const retryResult = await kvPutJSONWithRetry(
                  KV,
                  tradesKey,
                  allTrades,
                  null,
                  5,
                );
                if (retryResult.success) {
                  console.log(
                    `[TRADE SIM] ✅ Trade ${ticker} ${direction} saved on retry (attempt ${retryResult.attempt})`,
                  );
                } else {
                  console.error(
                    `[TRADE SIM] ❌ Trade ${ticker} ${direction} STILL not saved after retry - alerting anyway but trade may be lost`,
                  );
                }
              }

              const allowDiscord = shouldSendDiscordAlert(env, "TRADE_ENTRY", {
                ticker,
                rank: trade.rank || 0,
                rr: entryRR || 0,
                momentumElite: !!tickerData?.flags?.momentum_elite,
              });

              const embed = allowDiscord
                ? createTradeEntryEmbed(
                    ticker,
                    direction,
                    entryPrice,
                    Number(tickerData.sl),
                    validTP, // Use validated TP
                    entryRR || 0,
                    trade.rank || 0,
                    tickerData.state || "N/A",
                    Number(tickerData.price), // Current price for comparison
                    isBackfill,
                    tickerData, // Pass full ticker data for comprehensive embed
                  )
                : null;
              const sendRes = allowDiscord
                ? await notifyDiscord(env, embed).catch((err) => {
                    console.error(
                      `[TRADE SIM] ❌ Failed to send entry alert for ${ticker}:`,
                      err,
                    );
                    return { ok: false, error: String(err) };
                  }) // Don't let Discord errors break trade creation
                : {
                    ok: false,
                    skipped: true,
                    reason: "suppressed_critical_only",
                  };

              const entryTs =
                isoToMs(trade.entryTime) ||
                Number(trade.entry_ts) ||
                Date.now();
              const entryPayloadJson = (() => {
                try {
                  return JSON.stringify(tickerData);
                } catch {
                  return null;
                }
              })();
              const entryMetaJson = (() => {
                try {
                  return JSON.stringify({
                    type: "TRADE_ENTRY",
                    trade_id: trade.id,
                    entry_price: entryPrice,
                    sl: Number(tickerData.sl),
                    tp: validTP,
                  });
                } catch {
                  return null;
                }
              })();
              d1UpsertAlert(env, {
                alert_id: buildAlertId(ticker, entryTs, "TRADE_ENTRY"),
                ticker,
                ts: entryTs,
                side: direction,
                state: tickerData.state,
                rank: trade.rank || 0,
                rr_at_alert: entryRR || 0,
                trigger_reason: "TRADE_ENTRY",
                dedupe_day: formatDedupDay(entryTs),
                discord_sent: !!sendRes?.ok,
                discord_status: sendRes?.status ?? null,
                discord_error: sendRes?.ok
                  ? null
                  : sendRes?.reason ||
                    sendRes?.statusText ||
                    sendRes?.error ||
                    "discord_send_failed",
                payload_json: entryPayloadJson,
                meta_json: entryMetaJson,
              }).catch((e) => {
                console.error(`[D1 LEDGER] Failed to upsert entry alert:`, e);
              });

              // Log trade entry to activity feed
              try {
                await appendActivity(KV, {
                  ticker,
                  type: "trade_entry",
                  direction: direction,
                  action: "entry",
                  entryPrice: entryPrice,
                  sl: Number(tickerData.sl),
                  tp: validTP,
                  maxTP:
                    tickerData.tp_levels &&
                    Array.isArray(tickerData.tp_levels) &&
                    tickerData.tp_levels.length > 0
                      ? Math.max(
                          ...tickerData.tp_levels
                            .map((tp) =>
                              typeof tp === "object" && tp.price
                                ? Number(tp.price)
                                : Number(tp),
                            )
                            .filter((p) => Number.isFinite(p)),
                        )
                      : validTP,
                  rr: entryRR || 0,
                  rank: trade.rank || 0,
                  state: tickerData.state || "N/A",
                  htf_score: tickerData.htf_score,
                  ltf_score: tickerData.ltf_score,
                  completion: tickerData.completion,
                  phase_pct: tickerData.phase_pct,
                  price: Number(tickerData.price),
                  tradeId: trade.id,
                });
              } catch (activityErr) {
                console.error(
                  `[TRADE SIM] Failed to log trade entry to activity feed for ${ticker}:`,
                  activityErr,
                );
              }
            } else if (env && isBackfill) {
              console.log(
                `[TRADE SIM] ⚠️ Skipping Discord alert for ${ticker} ${direction} - backfill trade (entry: $${entryPrice.toFixed(
                  2,
                )}, current: $${Number(tickerData.price).toFixed(2)})`,
              );
            } else if (!env) {
              console.log(
                `[TRADE SIM] ⚠️ Skipping Discord alert for ${ticker} ${direction} - env not available`,
              );
            }
          } else {
            console.log(
              `[TRADE SIM] ⚠️ ${ticker} ${direction}: tradeCalc returned null`,
            );
          }
        }
      } else {
        // Log why trade wasn't created
        const rr = entryRR || Number(tickerData.rr) || 0;
        const comp = Number(tickerData.completion) || 0;
        const phase = Number(tickerData.phase_pct) || 0;
        const rank = Number(tickerData.rank) || 0;
        const h = Number(tickerData.htf_score);
        const l = Number(tickerData.ltf_score);
        const hFinite = Number.isFinite(h);
        const lFinite = Number.isFinite(l);
        const inCorridor =
          hFinite &&
          lFinite &&
          ((h > 0 && l >= -8 && l <= 12) || (h < 0 && l >= -12 && l <= 8));
        const aligned =
          tickerData.state === "HTF_BULL_LTF_BULL" ||
          tickerData.state === "HTF_BEAR_LTF_BEAR";

        // Determine why inCorridor is false
        let corridorReason = "";
        if (!hFinite || !lFinite) {
          corridorReason = `HTF/LTF scores invalid (HTF: ${
            hFinite ? h.toFixed(2) : "invalid"
          }, LTF: ${lFinite ? l.toFixed(2) : "invalid"})`;
        } else if (h > 0) {
          // LONG corridor check
          if (l < -8) {
            corridorReason = `LTF too low for LONG corridor (LTF: ${l.toFixed(
              2,
            )} < -8)`;
          } else if (l > 12) {
            corridorReason = `LTF too high for LONG corridor (LTF: ${l.toFixed(
              2,
            )} > 12)`;
          } else {
            corridorReason = `Should be in LONG corridor (HTF: ${h.toFixed(
              2,
            )} > 0, LTF: ${l.toFixed(2)} in [-8, 12])`;
          }
        } else if (h < 0) {
          // SHORT corridor check
          if (l < -12) {
            corridorReason = `LTF too low for SHORT corridor (LTF: ${l.toFixed(
              2,
            )} < -12)`;
          } else if (l > 8) {
            corridorReason = `LTF too high for SHORT corridor (LTF: ${l.toFixed(
              2,
            )} > 8)`;
          } else {
            corridorReason = `Should be in SHORT corridor (HTF: ${h.toFixed(
              2,
            )} < 0, LTF: ${l.toFixed(2)} in [-12, 8])`;
          }
        } else {
          corridorReason = `HTF is zero (HTF: ${h.toFixed(
            2,
          )}, neither LONG nor SHORT corridor)`;
        }

        // Check shouldTriggerTradeSimulation conditions
        const shouldTrigger = shouldTriggerTradeSimulation(
          ticker,
          tickerData,
          prevData,
        );

        console.log(
          `[TRADE SIM] ❌ ${ticker} ${direction}: Conditions not met`,
          {
            entryRR: entryRR?.toFixed(2),
            currentRR: tickerData.rr?.toFixed(2),
            comp,
            phase,
            rank,
            state: tickerData.state,
            htf_score: hFinite ? h.toFixed(2) : "invalid",
            ltf_score: lFinite ? l.toFixed(2) : "invalid",
            inCorridor,
            corridorReason,
            aligned,
            shouldTrigger,
            // Show what shouldTriggerTradeSimulation checks
            hasPrice: !!tickerData.price,
            hasSL: !!tickerData.sl,
            hasTP: !!tickerData.tp,
            trigger_reason: tickerData.trigger_reason || "none",
            sq30_release: !!(tickerData.flags && tickerData.flags.sq30_release),
            momentum_elite: !!(
              tickerData.flags && tickerData.flags.momentum_elite
            ),
          },
        );
      }
    }
  } catch (err) {
    console.error(`[TRADE SIM ERROR] ${ticker}:`, err);
  }
}

//─────────────────────────────────────────────────────────────────────────────
// Momentum Elite Calculation (Worker-Based with Caching)
//─────────────────────────────────────────────────────────────────────────────

// Fetch market cap from external API (placeholder - implement with your preferred API)
async function fetchMarketCap(ticker) {
  // TODO: Implement with Alpha Vantage, Yahoo Finance, or other API
  // For now, return null to skip market cap check
  // Example: const response = await fetch(`https://api.example.com/marketcap/${ticker}`);
  return null; // Will be implemented with actual API
}

// Calculate Average Daily Range (ADR) from price data
function calculateADR(price, high, low) {
  if (!price || price <= 0) return null;
  const dailyRange = (high - low) / price;
  return dailyRange;
}

// Calculate percentage change over period
function calculatePctChange(current, previous) {
  if (!previous || previous <= 0) return null;
  return (current - previous) / previous;
}

// Check if ticker meets Momentum Elite criteria
async function computeMomentumElite(KV, ticker, payload) {
  const cacheKey = `timed:momentum:${ticker}`;
  const now = Date.now();

  // Check cache (5 minute TTL for final status)
  const cached = await kvGetJSON(KV, cacheKey);
  if (cached && now - cached.timestamp < 5 * 60 * 1000) {
    return cached;
  }

  const price = Number(payload.price) || 0;

  // All base criteria must be true:
  // 1. Price > $4
  const priceOver4 = price >= 4.0;

  // 2. Market Cap > $1B (cached for 24 hours)
  // NOTE: Market cap is not enforced for Momentum Elite in this build (UI expectation),
  // but we still compute it for informational/debug purposes.
  const marketCapKey = `timed:momentum:marketcap:${ticker}`;
  let marketCapOver1B = true; // Default to true if we can't check
  const marketCapCache = await kvGetJSON(KV, marketCapKey);
  if (marketCapCache && now - marketCapCache.timestamp < 24 * 60 * 60 * 1000) {
    marketCapOver1B = marketCapCache.value;
  } else {
    // Fetch fresh market cap
    const marketCap = await fetchMarketCap(ticker);
    if (marketCap !== null) {
      marketCapOver1B = marketCap >= 1000000000;
      await kvPutJSON(
        KV,
        marketCapKey,
        { value: marketCapOver1B, timestamp: now },
        24 * 60 * 60,
      );
    }
  }

  // 3. Average Daily Range (ADR) (looser, cached for 1 hour)
  // Prefer TradingView heartbeat fields when present.
  const adrKey = `timed:momentum:adr:${ticker}`;
  let adrOk = true; // Looser: if we can't compute ADR, don't block
  const adrCache = await kvGetJSON(KV, adrKey);
  if (adrCache && now - adrCache.timestamp < 60 * 60 * 1000) {
    adrOk = !!adrCache.value;
  } else {
    // Prefer ADR from payload:
    // - Heartbeat sends `adr_14` as an absolute $ range
    // - Some sources may provide `adr_pct_14` as a fraction (0.02 == 2%)
    const adrAbs = Number(payload.adr_14);
    const adrPctDirect = Number(payload.adr_pct_14);

    const priceForAdr = price > 0 ? price : Number(payload.price) || 0;
    const adrPct =
      Number.isFinite(adrPctDirect) && adrPctDirect > 0
        ? adrPctDirect
        : Number.isFinite(adrAbs) && adrAbs > 0 && priceForAdr > 0
          ? adrAbs / priceForAdr
          : null;

    if (Number.isFinite(adrAbs) && adrAbs > 0) {
      // Looser than $2: treat >= $1 as "OK"
      adrOk = adrAbs >= 1.0;
    } else if (Number.isFinite(adrPct) && adrPct > 0) {
      // Looser than 2%: treat >= 1.5% as "OK"
      adrOk = adrPct >= 0.015;
    } else {
      // Fallback: if only OHLC is available, estimate ADR as a percent of price (legacy).
      const high = Number(payload.high ?? payload.h) || price;
      const low = Number(payload.low ?? payload.l) || price;
      const adrPct = calculateADR(price, high, low); // fraction of price
      // Looser: accept >= 1.5% if computed
      adrOk = adrPct != null && Number.isFinite(adrPct) && adrPct >= 0.015;
    }
    await kvPutJSON(KV, adrKey, { value: adrOk, timestamp: now }, 60 * 60);
  }

  // 4. Average Volume (30 days) > 2M (cached for 1 hour)
  // Prefer TradingView heartbeat fields when present (most accurate).
  const volumeKey = `timed:momentum:volume:${ticker}`;
  let volumeOver2M = false;
  const volumeCache = await kvGetJSON(KV, volumeKey);
  if (volumeCache && now - volumeCache.timestamp < 60 * 60 * 1000) {
    volumeOver2M = volumeCache.value;
  } else {
    const avgVol30 = Number(payload.avg_vol_30);
    const avgVol50 = Number(payload.avg_vol_50);
    const avgVol =
      Number.isFinite(avgVol30) && avgVol30 > 0
        ? avgVol30
        : Number.isFinite(avgVol50) && avgVol50 > 0
          ? avgVol50
          : Number(payload.volume) || 0;
    volumeOver2M = avgVol >= 2000000;
    await kvPutJSON(
      KV,
      volumeKey,
      { value: volumeOver2M, timestamp: now },
      60 * 60,
    );
  }

  // All base criteria (looser ADR gate)
  const allBaseCriteria = priceOver4 && adrOk && volumeOver2M;

  // Any momentum criteria (cached for 15 minutes):
  // Prefer TradingView payload data (most accurate), fallback to trail history
  const momentumKey = `timed:momentum:changes:${ticker}`;
  let anyMomentumCriteria = false;
  const momentumCache = await kvGetJSON(KV, momentumKey);
  if (momentumCache && now - momentumCache.timestamp < 15 * 60 * 1000) {
    anyMomentumCriteria = momentumCache.value;
  } else {
    // First, try to use momentum_pct from TradingView payload (most accurate)
    const momentumPct = payload.momentum_pct || {};
    const weekPct = momentumPct.week != null ? Number(momentumPct.week) : null;
    const monthPct =
      momentumPct.month != null ? Number(momentumPct.month) : null;
    const threeMonthsPct =
      momentumPct.three_months != null
        ? Number(momentumPct.three_months)
        : null;
    const sixMonthsPct =
      momentumPct.six_months != null ? Number(momentumPct.six_months) : null;

    if (monthPct != null) {
      // Align to TradingView screener-style filter: 1M change >= 25%
      anyMomentumCriteria = Number.isFinite(monthPct) && monthPct >= 25.0;
    } else {
      // Fallback: Calculate from trail history (for older data or if TradingView doesn't send it)
      const trailKey = `timed:trail:${ticker}`;
      const trail = (await kvGetJSON(KV, trailKey)) || [];

      if (trail.length > 0 && price > 0) {
        const currentPrice = price;
        const now = Date.now();

        // Time periods in milliseconds
        const oneWeekAgo = now - 7 * 24 * 60 * 60 * 1000;
        const oneMonthAgo = now - 30 * 24 * 60 * 60 * 1000;
        const threeMonthsAgo = now - 90 * 24 * 60 * 60 * 1000;
        const sixMonthsAgo = now - 180 * 24 * 60 * 60 * 1000;

        // Find closest trail points to these times (by timestamp)
        const findClosestPrice = (targetTime) => {
          let closest = null;
          let minDiff = Infinity;
          for (const point of trail) {
            if (!point.ts) continue;
            const diff = Math.abs(point.ts - targetTime);
            if (diff < minDiff) {
              minDiff = diff;
              // Try to get price from point (might be in different fields)
              const pointPrice =
                Number(point.price) || Number(point.close) || null;
              if (pointPrice && pointPrice > 0) {
                closest = pointPrice;
              }
            }
          }
          return closest;
        };

        const priceWeekAgo = findClosestPrice(oneWeekAgo);
        const priceMonthAgo = findClosestPrice(oneMonthAgo);
        const price3MonthsAgo = findClosestPrice(threeMonthsAgo);
        const price6MonthsAgo = findClosestPrice(sixMonthsAgo);

        // Calculate percentage changes
        const monthOver25Pct =
          priceMonthAgo && priceMonthAgo > 0
            ? (currentPrice - priceMonthAgo) / priceMonthAgo >= 0.25
            : false;
        anyMomentumCriteria = !!monthOver25Pct;
      } else {
        // No trail data yet, default to false
        anyMomentumCriteria = false;
      }
    }

    // Cache result
    await kvPutJSON(
      KV,
      momentumKey,
      { value: anyMomentumCriteria, timestamp: now },
      15 * 60,
    );
  }

  const momentumElite = allBaseCriteria && anyMomentumCriteria;

  // Store result with metadata
  const result = {
    momentum_elite: momentumElite,
    criteria: {
      priceOver4,
      marketCapOver1B,
      // Back-compat name: still called adrOver2 in UI, but now means "ADR gate passed (looser)".
      adrOver2: adrOk,
      volumeOver2M,
      allBaseCriteria,
      anyMomentumCriteria,
    },
    timestamp: now,
  };

  // Check for status change and log history
  const prevStatus = cached ? cached.momentum_elite : false;
  if (momentumElite !== prevStatus) {
    const historyKey = `timed:momentum:history:${ticker}`;
    const history = (await kvGetJSON(KV, historyKey)) || [];
    history.push({
      status: momentumElite,
      timestamp: now,
      criteria: result.criteria,
    });
    // Keep last 100 status changes
    const trimmedHistory = history.slice(-100);
    await kvPutJSON(KV, historyKey, trimmedHistory);
  }

  // Cache result (keep long enough for UI filtering between bar closes)
  await kvPutJSON(KV, cacheKey, result, 6 * 60 * 60);

  return result;
}

function computeRank(d) {
  const htf = Number(d.htf_score);
  const ltf = Number(d.ltf_score);
  const comp = completionForSize(d);
  const phase = Number(d.phase_pct);
  const rr = d.rr != null ? Number(d.rr) : computeRR(d);

  const flags = d.flags || {};
  const sqRel = !!flags.sq30_release;
  const sqOn = !!flags.sq30_on;
  const phaseZoneChange = !!flags.phase_zone_change;
  const momentumElite = !!flags.momentum_elite;
  const emaCross1H1348 = !!flags.ema_cross_1h_13_48;
  const buyableDip1H1348 = !!flags.buyable_dip_1h_13_48;

  const state = String(d.state || "");
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  const setup =
    state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";

  // ADJUSTED SCORING: More discriminating, lower base
  let score = 30; // Reduced from 50 to make scoring more selective

  // Data completeness: slightly down-rank incomplete payloads so “Today/Prime” stays sane.
  const completeness = d?.data_completeness || computeDataCompleteness(d);
  if (completeness && typeof completeness === "object") {
    if (completeness.score < 70) score -= 10;
    else if (completeness.score < 85) score -= 5;
    else if (completeness.score < 95) score -= 2;
  }

  // Per-TF technical structure alignment (bonus/penalty).
  const tfAlign = d?.tf_summary || tfTechAlignmentSummary(d);
  if (
    tfAlign &&
    typeof tfAlign === "object" &&
    Number.isFinite(tfAlign.score)
  ) {
    score += tfAlign.score;
  }

  // Explicit triggers[] “why now” boost.
  const trig = d?.trigger_summary || triggerSummaryAndScore(d);
  if (trig && typeof trig === "object" && Number.isFinite(trig.score)) {
    score += trig.score;
  }

  // Move status: invalidate/completed moves should fall out of “best setups”
  const ms = d?.move_status || computeMoveStatus(d);
  if (ms && typeof ms === "object") {
    if (ms.status === "INVALIDATED") score -= 25;
    else if (ms.status === "COMPLETED") score -= 15;
  }

  // State bonuses (reduced)
  if (aligned) score += 12; // Reduced from 15
  if (setup) score += 4; // Reduced from 5

  // HTF/LTF contributions (more selective - require stronger signals)
  if (Number.isFinite(htf)) {
    const htfAbs = Math.abs(htf);
    // Only give full credit for strong HTF signals (>= 25)
    if (htfAbs >= 25) score += Math.min(10, htfAbs * 0.4);
    else if (htfAbs >= 15)
      score += Math.min(7, htfAbs * 0.35); // Reduced for moderate signals
    else score += Math.min(4, htfAbs * 0.25); // Minimal for weak signals
  }

  if (Number.isFinite(ltf)) {
    const ltfAbs = Math.abs(ltf);
    // Only give full credit for strong LTF signals (>= 20)
    if (ltfAbs >= 20) score += Math.min(10, ltfAbs * 0.3);
    else if (ltfAbs >= 12)
      score += Math.min(6, ltfAbs * 0.25); // Reduced for moderate signals
    else score += Math.min(3, ltfAbs * 0.2); // Minimal for weak signals
  }

  // Completion bonus (reduced and more selective)
  if (Number.isFinite(comp)) {
    // Early completion gets more points, but cap reduced
    if (comp <= 0.2)
      score += 15; // Excellent (0-20% completion)
    else if (comp <= 0.4)
      score += 10; // Good (20-40% completion)
    else if (comp <= 0.6) score += 5; // Moderate (40-60% completion)
    // No bonus for completion > 60%
  }

  // Phase penalty (starts earlier, more aggressive)
  if (Number.isFinite(phase)) {
    if (phase > 0.5) score -= Math.max(0, (phase - 0.5) * 30); // Penalty starts at 50% instead of 60%
    // Early phase (< 50%) gets small bonus
    if (phase <= 0.3) score += 3; // Early phase bonus
  }

  // Squeeze bonuses (reduced)
  if (sqRel)
    score += 12; // Reduced from 15
  else if (sqOn) score += 4; // Reduced from 6

  // Phase zone change bonus (reduced)
  if (phaseZoneChange) score += 2; // Reduced from 3

  // RR contribution (more selective - requires better RR)
  if (Number.isFinite(rr)) {
    if (rr >= 2.0)
      score += 10; // Excellent RR (2.0+)
    else if (rr >= 1.5)
      score += 7; // Good RR (1.5-2.0)
    else if (rr >= 1.2) score += 4; // Acceptable RR (1.2-1.5)
    // No bonus for RR < 1.2
  }

  // Momentum Elite boost (reduced but still significant)
  if (momentumElite) score += 15; // Reduced from 20

  // 1H 13/48 cross + buyable-dip nuance
  // - Cross is a strong pivot/confirmation marker
  // - Dip-after-cross is a premium pullback entry opportunity
  if (emaCross1H1348) score += 5;
  if (buyableDip1H1348) score += 7;

  // RSI Divergence boost/penalty
  const rsi = d.rsi;
  if (rsi && rsi.divergence) {
    const divType = String(rsi.divergence.type || "none");
    const divStrength = Number(rsi.divergence.strength || 0);
    if (divType === "bullish") {
      score += 3 + Math.min(2, divStrength * 0.1); // Boost for bullish divergence
    } else if (divType === "bearish") {
      score -= 3 - Math.min(2, divStrength * 0.1); // Penalty for bearish divergence
    }
  }

  // TD Sequential boost/penalty — only relevant on Daily/Weekly/Monthly timeframes.
  // Ignore TD Sequential from 4H and below (intraday noise).
  const tdSeq = d.td_sequential || {};
  const tdTf = String(tdSeq.timeframe || tdSeq.tf || d.tf || "D").toUpperCase();
  const tdIsHigherTF = ["D", "W", "M", "1D", "1W", "1M", "DAILY", "WEEKLY", "MONTHLY"].includes(tdTf);
  const tdSeqBoost = tdIsHigherTF ? (Number(tdSeq.boost) || 0) : 0;
  if (Number.isFinite(tdSeqBoost) && tdSeqBoost !== 0) {
    score += tdSeqBoost;
  }

  score = Math.max(0, Math.min(100, score));
  return Math.round(score);
}

// ─────────────────────────────────────────────────────────────
// Live Thesis features (seq + deltas) computed from trail
// Mirrors feature families used in scripts/analyze-best-setups.js
// ─────────────────────────────────────────────────────────────

function clamp01(x) {
  const n = Number(x);
  if (!Number.isFinite(n)) return 0;
  return Math.max(0, Math.min(1, n));
}

function flagOn(flags, k) {
  if (!flags || typeof flags !== "object") return false;
  const v = flags[k];
  return v === true || v === 1 || v === "true";
}

function orderedWithin(a, b, maxMs) {
  if (!Number.isFinite(a) || !Number.isFinite(b) || !Number.isFinite(maxMs))
    return false;
  return b >= a && b - a <= maxMs;
}

function normalizeTrailPoint(p) {
  if (!p || typeof p !== "object") return null;
  const ts = Number(p.ts ?? p.timestamp ?? p.ingest_ts ?? p.ingest_time);
  const price = Number(p.price ?? p.__price);
  return {
    __ts: Number.isFinite(ts) ? ts : null,
    __price: Number.isFinite(price) ? price : null,
    htf_score: p.htf_score != null ? Number(p.htf_score) : null,
    ltf_score: p.ltf_score != null ? Number(p.ltf_score) : null,
    completion: p.completion != null ? Number(p.completion) : null,
    phase_pct: p.phase_pct != null ? Number(p.phase_pct) : null,
    state: p.state != null ? String(p.state) : "",
    rank: p.rank != null ? Number(p.rank) : null,
    trigger_reason: p.trigger_reason != null ? String(p.trigger_reason) : null,
    trigger_dir:
      p.trigger_dir != null ? String(p.trigger_dir).trim().toUpperCase() : null,
    __flags: p.flags && typeof p.flags === "object" ? p.flags : {},
  };
}

function directionForThesis(p, fallbackPayload = null) {
  const fromTrig =
    (fallbackPayload && fallbackPayload.trigger_dir) || (p && p.trigger_dir);
  const td = String(fromTrig || "")
    .trim()
    .toUpperCase();
  if (td === "LONG" || td === "SHORT") return td;

  const st = String(
    (fallbackPayload && fallbackPayload.state) || (p && p.state) || "",
  );
  if (st.includes("BEAR")) return "SHORT";
  if (st.includes("BULL")) return "LONG";

  const htf = Number(
    (fallbackPayload && fallbackPayload.htf_score) || (p && p.htf_score),
  );
  if (Number.isFinite(htf) && htf < 0) return "SHORT";
  if (Number.isFinite(htf) && htf > 0) return "LONG";
  return null;
}

function lowerBoundTs(points, tsTarget, idxHiExclusive) {
  let lo = 0;
  let hi = Math.max(
    0,
    Number.isFinite(idxHiExclusive) ? idxHiExclusive : points.length,
  );
  while (lo < hi) {
    const mid = (lo + hi) >> 1;
    const ts = Number(points[mid]?.__ts);
    if (!Number.isFinite(ts) || ts < tsTarget) lo = mid + 1;
    else hi = mid;
  }
  return lo;
}

function lookbackDeltas(points, idx0, lookbackMs) {
  const p0 = points[idx0];
  const t0 = Number(p0?.__ts);
  if (!Number.isFinite(t0) || !Number.isFinite(lookbackMs) || lookbackMs <= 0)
    return null;
  const idxHi = Math.max(0, idx0);
  if (idxHi <= 0) return null;
  const tsTarget = t0 - lookbackMs;
  const idx = lowerBoundTs(points, tsTarget, idxHi);
  const p1 = points[Math.min(idx, idxHi - 1)];
  if (!p1) return null;

  const htf0 = Number(p0?.htf_score);
  const ltf0 = Number(p0?.ltf_score);
  const px0 = Number(p0?.__price);
  const t1 = Number(p1?.__ts);
  const htf1 = Number(p1?.htf_score);
  const ltf1 = Number(p1?.ltf_score);
  const px1 = Number(p1?.__price);

  const dtMs = Number.isFinite(t1) ? t0 - t1 : null;
  const dHtf =
    Number.isFinite(htf0) && Number.isFinite(htf1) ? htf0 - htf1 : null;
  const dLtf =
    Number.isFinite(ltf0) && Number.isFinite(ltf1) ? ltf0 - ltf1 : null;
  const dPxPct =
    Number.isFinite(px0) && Number.isFinite(px1) && px1 > 0
      ? (px0 - px1) / px1
      : null;

  return {
    lookbackMs,
    t1: Number.isFinite(t1) ? t1 : null,
    dtMs,
    deltaHtf: dHtf,
    deltaLtf: dLtf,
    deltaPricePct: dPxPct,
  };
}

function isWinnerSignatureSnapshotForThesis(p) {
  const flags = p?.__flags || {};
  const state = String(p?.state || "");
  const isSetup = state.includes("PULLBACK");
  const inCorridor = corridorSide(p) != null;
  const completion = clamp01(p?.completion);
  const phasePct = clamp01(p?.phase_pct);
  const inSqueeze = flagOn(flags, "sq30_on") && !flagOn(flags, "sq30_release");
  return (
    isSetup && inCorridor && completion < 0.15 && (phasePct < 0.6 || inSqueeze)
  );
}

function isPrimeLikeSnapshotForThesis(p) {
  const flags = p?.__flags || {};
  const state = String(p?.state || "");
  const inCorridor = corridorSide(p) != null;
  const rank = Number(p?.rank);
  const completion = clamp01(p?.completion);
  const phase = clamp01(p?.phase_pct);
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  const sqRel = flagOn(flags, "sq30_release");
  const phaseZoneChange = flagOn(flags, "phase_zone_change");
  return (
    inCorridor &&
    (Number.isFinite(rank) ? rank >= 75 : false) &&
    completion < 0.4 &&
    phase < 0.6 &&
    (aligned || sqRel || phaseZoneChange)
  );
}

function computeLiveThesisFeaturesFromTrail(trailPoints, payload) {
  const H1 = 60 * 60 * 1000;
  const LOOKBACK_4H = 4 * H1;
  const LOOKBACK_1D = 24 * H1;

  const raw = Array.isArray(trailPoints) ? trailPoints : [];
  const pts = raw
    .map(normalizeTrailPoint)
    .filter((x) => x && Number.isFinite(x.__ts))
    .sort((a, b) => Number(a.__ts) - Number(b.__ts));

  const empty = {
    seq: {
      recentSqueezeRelease_6h: false,
      recentSqueezeOn_6h: false,
      corridorEntry_60m: false,
      pattern: {
        squeezeReleaseToMomentum_6h: false,
        squeezeOnToRelease_24h: false,
      },
    },
    deltas: { htf_4h: null, ltf_4h: null, htf_1d: null },
    flags: {
      htf_improving_4h: false,
      htf_improving_1d: false,
      htf_move_4h_ge_5: false,
      thesis_match: false,
    },
  };
  if (pts.length < 2) return empty;

  let lastCorridorEntryTs = null;
  let lastSqueezeOnTs = null;
  let lastSqueezeReleaseTs = null;
  let lastSetupToMomentumTs = null;

  for (let i = 1; i < pts.length; i++) {
    const p = pts[i];
    const prev = pts[i - 1];
    const ts = Number(p.__ts);
    if (!Number.isFinite(ts)) continue;

    const ent = corridorSide(p) != null;
    const entPrev = corridorSide(prev) != null;

    const flags = p.__flags || {};
    const flagsPrev = prev.__flags || {};

    const st = String(p.state || "");
    const stPrev = String(prev.state || "");
    const isPullback = st.includes("PULLBACK");
    const wasPullback = stPrev.includes("PULLBACK");
    const isMomentum =
      (st.includes("LTF_BULL") || st.includes("LTF_BEAR")) && !isPullback;

    if (!entPrev && ent) lastCorridorEntryTs = ts;
    if (flagOn(flags, "sq30_on") && !flagOn(flagsPrev, "sq30_on"))
      lastSqueezeOnTs = ts;
    if (flagOn(flags, "sq30_release") && !flagOn(flagsPrev, "sq30_release"))
      lastSqueezeReleaseTs = ts;
    if (wasPullback && isMomentum) lastSetupToMomentumTs = ts;
  }

  const latest = pts[pts.length - 1];
  const nowTs = Number(latest.__ts);
  const since = {
    corridorEntryMs: Number.isFinite(lastCorridorEntryTs)
      ? Math.max(0, nowTs - lastCorridorEntryTs)
      : null,
    squeezeOnMs: Number.isFinite(lastSqueezeOnTs)
      ? Math.max(0, nowTs - lastSqueezeOnTs)
      : null,
    squeezeReleaseMs: Number.isFinite(lastSqueezeReleaseTs)
      ? Math.max(0, nowTs - lastSqueezeReleaseTs)
      : null,
  };

  const deltas4h = lookbackDeltas(pts, pts.length - 1, LOOKBACK_4H);
  const deltas1d = lookbackDeltas(pts, pts.length - 1, LOOKBACK_1D);

  const dir = directionForThesis(latest, payload);
  const htf_4h = deltas4h ? deltas4h.deltaHtf : null;
  const ltf_4h = deltas4h ? deltas4h.deltaLtf : null;
  const htf_1d = deltas1d ? deltas1d.deltaHtf : null;

  const htf_improving_4h =
    !!dir &&
    Number.isFinite(htf_4h) &&
    ((dir === "LONG" && htf_4h > 0) || (dir === "SHORT" && htf_4h < 0));
  const htf_improving_1d =
    !!dir &&
    Number.isFinite(htf_1d) &&
    ((dir === "LONG" && htf_1d > 0) || (dir === "SHORT" && htf_1d < 0));
  const htf_move_4h_ge_5 = Number.isFinite(htf_4h) && Math.abs(htf_4h) >= 5;

  const seq = {
    recentSqueezeRelease_6h:
      since.squeezeReleaseMs != null && since.squeezeReleaseMs <= 6 * H1,
    recentSqueezeOn_6h:
      since.squeezeOnMs != null && since.squeezeOnMs <= 6 * H1,
    corridorEntry_60m:
      since.corridorEntryMs != null && since.corridorEntryMs <= 60 * 60 * 1000,
    pattern: {
      squeezeReleaseToMomentum_6h: orderedWithin(
        lastSqueezeReleaseTs,
        lastSetupToMomentumTs,
        6 * H1,
      ),
      squeezeOnToRelease_24h: orderedWithin(
        lastSqueezeOnTs,
        lastSqueezeReleaseTs,
        24 * H1,
      ),
    },
  };

  const primeLike = isPrimeLikeSnapshotForThesis(latest);
  const winnerSignature = isWinnerSignatureSnapshotForThesis(latest);

  const rank = Number(payload?.rank ?? latest?.rank);
  const completion = clamp01(payload?.completion ?? latest?.completion);
  const phase = clamp01(payload?.phase_pct ?? latest?.phase_pct);
  const rr = (() => {
    const n = Number(payload?.rr);
    if (Number.isFinite(n)) return n;
    const v = computeRR(payload);
    return Number.isFinite(v) ? Number(v) : null;
  })();

  const baseGate =
    Number.isFinite(rank) &&
    rank >= 74 &&
    Number.isFinite(rr) &&
    rr >= 1.5 &&
    Number.isFinite(completion) &&
    completion <= 0.6 + 1e-9 &&
    Number.isFinite(phase) &&
    phase <= 0.6 + 1e-9;

  const A = seq.pattern.squeezeReleaseToMomentum_6h && htf_move_4h_ge_5;
  const B = seq.recentSqueezeRelease_6h && htf_improving_4h;
  const C =
    (primeLike && htf_move_4h_ge_5) || (winnerSignature && htf_improving_4h);
  const thesis_match = !!baseGate && (A || B || C);

  return {
    seq,
    deltas: { htf_4h, ltf_4h, htf_1d },
    flags: {
      htf_improving_4h,
      htf_improving_1d,
      htf_move_4h_ge_5,
      thesis_match,
    },
  };
}

async function appendTrail(KV, ticker, point, maxN = 8) {
  const key = `timed:trail:${ticker}`;
  const cur = (await kvGetJSON(KV, key)) || [];
  cur.push(point);
  const keep = cur.length > maxN ? cur.slice(cur.length - maxN) : cur;
  await kvPutJSON(KV, key, keep);
  return keep;
}

async function appendCaptureTrail(KV, ticker, point, maxN = 48) {
  const key = `timed:capture:trail:${ticker}`;
  const cur = (await kvGetJSON(KV, key)) || [];
  cur.push(point);
  const keep = cur.length > maxN ? cur.slice(cur.length - maxN) : cur;
  await kvPutJSON(KV, key, keep);
}

/** Data lifecycle: aggregate timed_trail older than 48h into trail_5m_facts, then purge old raw data. */
const DATA_LIFECYCLE_48H_MS = 48 * 60 * 60 * 1000;
const DATA_LIFECYCLE_7D_MS = 7 * 24 * 60 * 60 * 1000;
const PURGE_BATCH = 5000;

/** Tiered candle retention: shorter TFs expire sooner, D/W kept forever. */
const CANDLE_RETENTION_DAYS = {
  "3m": 7,
  "10m": 14,
  "30m": 30,
  "1h": 30,
  "4h": 90,
  // "D", "W", and "M" are intentionally omitted → kept forever
};

async function runDataLifecycle(env, opts = {}) {
  const db = env?.DB;
  if (!db) {
    console.error("[DATA LIFECYCLE] No DB binding");
    return;
  }
  const now = Date.now();
  // Allow override for manual backfill scenarios (e.g., force recent data through)
  const cutoff48h = opts.cutoffMs != null && Number.isFinite(opts.cutoffMs)
    ? opts.cutoffMs
    : now - DATA_LIFECYCLE_48H_MS;
  const cutoff7d = now - DATA_LIFECYCLE_7D_MS;

  try {
    // 1. Aggregate timed_trail (ts < 48h) into trail_5m_facts
    // Uses subqueries for first/last values per bucket (kanban_stage, price open/close)
    const agg = await db
      .prepare(
        `INSERT OR REPLACE INTO trail_5m_facts
         (ticker, bucket_ts, price_open, price_high, price_low, price_close,
          htf_score_avg, htf_score_min, htf_score_max,
          ltf_score_avg, ltf_score_min, ltf_score_max,
          state, rank, completion, phase_pct,
          had_squeeze_release, had_ema_cross, had_st_flip, had_momentum_elite, had_flip_watch,
          kanban_stage_start, kanban_stage_end, kanban_changed,
          sample_count, created_at)
         SELECT
          t.ticker,
          (t.ts / 300000) * 300000 AS bucket,
          -- Price OHLC: first price in bucket = open, last = close
          (SELECT price FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND price IS NOT NULL ORDER BY ts ASC LIMIT 1),
          MAX(t.price),
          MIN(t.price),
          (SELECT price FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND price IS NOT NULL ORDER BY ts DESC LIMIT 1),
          ROUND(AVG(t.htf_score), 2), MIN(t.htf_score), MAX(t.htf_score),
          ROUND(AVG(t.ltf_score), 2), MIN(t.ltf_score), MAX(t.ltf_score),
          -- End-of-bucket state: last row's state
          (SELECT state FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND state IS NOT NULL ORDER BY ts DESC LIMIT 1),
          MAX(t.rank), MAX(t.completion), MAX(t.phase_pct),
          -- Flags: check flags_json for any occurrence (1 if any row had it)
          MAX(CASE WHEN t.flags_json LIKE '%squeeze_release%' OR t.flags_json LIKE '%sq30_release%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%ema_cross%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%st_flip%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%momentum_elite%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%flip_watch%' THEN 1 ELSE 0 END),
          -- Kanban: first and last kanban_stage in the bucket
          (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts ASC LIMIT 1),
          (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts DESC LIMIT 1),
          -- kanban_changed: 1 if first != last kanban_stage in bucket
          CASE WHEN
            (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts ASC LIMIT 1)
            IS NOT
            (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts DESC LIMIT 1)
          THEN 1 ELSE 0 END,
          COUNT(*),
          (strftime('%s', 'now') * 1000)
         FROM timed_trail t
         WHERE t.ts < ?1
         GROUP BY t.ticker, (t.ts / 300000) * 300000`,
      )
      .bind(cutoff48h)
      .run();
    console.log("[DATA LIFECYCLE] Aggregated trail → 5m facts:", agg?.meta?.changes ?? "ok");

    // 2. Purge timed_trail in batches to avoid D1 overload
    let trailDeleted = 0;
    for (;;) {
      const del = await db
        .prepare(
          `DELETE FROM timed_trail WHERE rowid IN (SELECT rowid FROM timed_trail WHERE ts < ?1 LIMIT ?2)`,
        )
        .bind(cutoff48h, PURGE_BATCH)
        .run();
      const n = del?.meta?.changes ?? 0;
      trailDeleted += n;
      if (n < PURGE_BATCH) break;
    }
    console.log("[DATA LIFECYCLE] Purged timed_trail rows:", trailDeleted);

    // 3. Purge ingest_receipts older than 7 days in batches
    let receiptsDeleted = 0;
    for (;;) {
      const del = await db
        .prepare(
          `DELETE FROM ingest_receipts WHERE rowid IN (SELECT rowid FROM ingest_receipts WHERE received_ts < ?1 LIMIT ?2)`,
        )
        .bind(cutoff7d, PURGE_BATCH)
        .run();
      const n = del?.meta?.changes ?? 0;
      receiptsDeleted += n;
      if (n < PURGE_BATCH) break;
    }
    console.log("[DATA LIFECYCLE] Purged ingest_receipts rows:", receiptsDeleted);

    // 4. Roll up trail_5m_facts into trail_daily_summary (permanent archive)
    // Only roll up complete days (yesterday and older, not today's partial data)
    const yesterday = new Date(now - 24 * 60 * 60 * 1000);
    const yesterdayStr = yesterday.toISOString().slice(0, 10); // YYYY-MM-DD
    // Convert to ET for market-day alignment (9:30 AM ET to 4:00 PM ET)
    // Bucket_ts is UTC ms; a market day in ET spans ~14:30 UTC to ~21:00 UTC
    try {
      const dailyAgg = await db
        .prepare(
          `INSERT OR REPLACE INTO trail_daily_summary
           (ticker, date, price_open, price_high, price_low, price_close, price_change_pct,
            htf_score_avg, ltf_score_avg,
            minutes_bull_bull, minutes_bull_pullback, minutes_bear_bear, minutes_bear_pullback,
            squeeze_releases, ema_crosses, st_flips,
            enter_now_count,
            trades_opened, trades_closed, trade_pnl,
            sample_count, created_at)
           SELECT
            f.ticker,
            ?2,
            -- OHLC: first/last bucket's open/close
            (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1),
            MAX(f.price_high),
            MIN(f.price_low),
            (SELECT price_close FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts DESC LIMIT 1),
            CASE WHEN
              (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1) > 0
            THEN ROUND(
              ((SELECT price_close FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts DESC LIMIT 1)
               - (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1))
              / (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1) * 100, 2)
            ELSE NULL END,
            ROUND(AVG(f.htf_score_avg), 2),
            ROUND(AVG(f.ltf_score_avg), 2),
            -- State distribution: each 5m bucket = 5 minutes
            SUM(CASE WHEN f.state LIKE '%BULL%BULL%' THEN 5 ELSE 0 END),
            SUM(CASE WHEN f.state LIKE '%BULL%PULLBACK%' OR f.state LIKE '%BULL%BEAR%' THEN 5 ELSE 0 END),
            SUM(CASE WHEN f.state LIKE '%BEAR%BEAR%' THEN 5 ELSE 0 END),
            SUM(CASE WHEN f.state LIKE '%BEAR%PULLBACK%' OR f.state LIKE '%BEAR%BULL%' THEN 5 ELSE 0 END),
            -- Signal counts
            SUM(f.had_squeeze_release),
            SUM(f.had_ema_cross),
            SUM(f.had_st_flip),
            -- Kanban enter_now count
            SUM(CASE WHEN f.kanban_stage_end = 'enter_now' AND f.kanban_changed = 1 THEN 1 ELSE 0 END),
            -- Trade activity (placeholder - filled from trades table below)
            0, 0, 0,
            SUM(f.sample_count),
            (strftime('%s', 'now') * 1000)
           FROM trail_5m_facts f
           WHERE f.bucket_ts >= ?3 AND f.bucket_ts < ?4
           GROUP BY f.ticker`,
        )
        .bind(
          cutoff48h,
          yesterdayStr,
          // Yesterday's market day: 9:30 AM ET = 14:30 UTC, 4:00 PM ET = 21:00 UTC
          // Use broad window: start of day UTC to end of day UTC to catch all buckets
          new Date(yesterdayStr + "T00:00:00Z").getTime(),
          new Date(yesterdayStr + "T23:59:59Z").getTime(),
        )
        .run();
      console.log("[DATA LIFECYCLE] Daily summary roll-up:", dailyAgg?.meta?.changes ?? "ok");

      // Backfill trade counts from trades table for yesterday
      try {
        await db
          .prepare(
            `UPDATE trail_daily_summary SET
              trades_opened = COALESCE((SELECT COUNT(*) FROM trades WHERE ticker = trail_daily_summary.ticker AND entry_ts >= ?1 AND entry_ts < ?2), 0),
              trades_closed = COALESCE((SELECT COUNT(*) FROM trades WHERE ticker = trail_daily_summary.ticker AND exit_ts >= ?1 AND exit_ts < ?2), 0),
              trade_pnl = COALESCE((SELECT SUM(pnl_pct) FROM trades WHERE ticker = trail_daily_summary.ticker AND exit_ts >= ?1 AND exit_ts < ?2), 0)
            WHERE date = ?3`,
          )
          .bind(
            new Date(yesterdayStr + "T00:00:00Z").getTime(),
            new Date(yesterdayStr + "T23:59:59Z").getTime(),
            yesterdayStr,
          )
          .run();
      } catch (tradeErr) {
        console.error("[DATA LIFECYCLE] Daily trade backfill error:", tradeErr);
      }
    } catch (dailyErr) {
      console.error("[DATA LIFECYCLE] Daily summary error:", dailyErr);
    }

    // 5. Tiered candle purge: short TFs expire sooner, D/W kept forever
    let totalCandlesPurged = 0;
    for (const [tf, retentionDays] of Object.entries(CANDLE_RETENTION_DAYS)) {
      const cutoffMs = now - retentionDays * 24 * 60 * 60 * 1000;
      try {
        let tfPurged = 0;
        for (;;) {
          const del = await db
            .prepare(
              `DELETE FROM ticker_candles WHERE rowid IN (
                SELECT rowid FROM ticker_candles WHERE tf = ?1 AND ts < ?2 LIMIT ?3
              )`,
            )
            .bind(tf, cutoffMs, PURGE_BATCH)
            .run();
          const n = del?.meta?.changes ?? 0;
          tfPurged += n;
          if (n < PURGE_BATCH) break;
        }
        if (tfPurged > 0) {
          console.log(`[DATA LIFECYCLE] Purged ${tf} candles: ${tfPurged} (>${retentionDays}d old)`);
          totalCandlesPurged += tfPurged;
        }
      } catch (candleErr) {
        console.error(`[DATA LIFECYCLE] Candle purge error for ${tf}:`, candleErr);
      }
    }
    if (totalCandlesPurged > 0) {
      console.log(`[DATA LIFECYCLE] Total candles purged: ${totalCandlesPurged}`);
    }
  } catch (err) {
    console.error("[DATA LIFECYCLE] Error:", err);
  }
}

// ─────────────────────────────────────────────────────────────
// D1 Latest Snapshot Storage (fast reads for UI)
// ─────────────────────────────────────────────────────────────

async function d1EnsureLatestSchema(env) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  // Throttle schema checks to ~once/day
  const KV = env?.KV_TIMED;
  const throttleKey = "timed:d1:latest:schema_ok_ms";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 24 * 60 * 60 * 1000) {
        return { ok: true, skipped: true, reason: "throttled" };
      }
    }
  } catch {
    // ignore
  }

  try {
    // Index of tickers we know about (baseline)
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ticker_index (
          ticker TEXT PRIMARY KEY,
          first_seen_ts INTEGER NOT NULL,
          last_seen_ts INTEGER NOT NULL
        )`,
      )
      .run();

    // Latest snapshot per ticker (for UI reads)
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ticker_latest (
          ticker TEXT PRIMARY KEY,
          ts INTEGER NOT NULL,
          updated_at INTEGER NOT NULL,
          kanban_stage TEXT,
          prev_kanban_stage TEXT,
          payload_json TEXT NOT NULL
        )`,
      )
      .run();

    // Best-effort schema migration for existing deployments (D1/SQLite doesn't support IF NOT EXISTS for ADD COLUMN)
    try {
      await db
        .prepare(`ALTER TABLE ticker_latest ADD COLUMN prev_kanban_stage TEXT`)
        .run();
    } catch {
      // ignore (already exists)
    }

    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ticker_latest_ts ON ticker_latest (ts)`,
      )
      .run();
    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ticker_latest_kanban_stage ON ticker_latest (kanban_stage)`,
      )
      .run();
    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ticker_latest_prev_kanban_stage ON ticker_latest (prev_kanban_stage)`,
      )
      .run();

    try {
      if (KV)
        await KV.put(throttleKey, String(Date.now()), {
          expirationTtl: 7 * 24 * 60 * 60,
        });
    } catch {
      // ignore
    }

    return { ok: true };
  } catch (err) {
    console.error("[D1 LATEST] Schema ensure failed:", err);
    return { ok: false, error: String(err) };
  }
}

// ─────────────────────────────────────────────────────────────
// D1 Candle Storage (multi-timeframe OHLCV)
// ─────────────────────────────────────────────────────────────

async function d1EnsureCandleSchema(env) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  // Throttle schema checks to ~once/hour (reduced from 24h to ensure migrations run promptly)
  const KV = env?.KV_TIMED;
  const throttleKey = "timed:d1:candles:schema_ok_ms";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 60 * 60 * 1000) {
        return { ok: true, skipped: true, reason: "throttled" };
      }
    }
  } catch {
    // ignore
  }

  try {
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ticker_candles (
          ticker TEXT NOT NULL,
          tf TEXT NOT NULL,
          ts INTEGER NOT NULL,
          o REAL,
          h REAL,
          l REAL,
          c REAL,
          v REAL,
          updated_at INTEGER NOT NULL,
          PRIMARY KEY (ticker, tf, ts)
        )`,
      )
      .run();

    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ticker_candles_ticker_tf_ts
         ON ticker_candles (ticker, tf, ts DESC)`,
      )
      .run();

    // Add session column for extended-hours tagging (PM/RTH/AH/CLOSED)
    // Uses ALTER TABLE which is idempotent — silently fails if column exists
    try {
      await db.prepare(`ALTER TABLE ticker_candles ADD COLUMN session TEXT`).run();
      console.log("[D1 CANDLES] Added session column to ticker_candles");
    } catch {
      // Column already exists — expected on subsequent runs
    }

    try {
      if (KV)
        await KV.put(throttleKey, String(Date.now()), {
          expirationTtl: 7 * 24 * 60 * 60,
        });
    } catch {
      // ignore
    }

    return { ok: true };
  } catch (err) {
    console.error("[D1 CANDLES] Schema ensure failed:", err);
    return { ok: false, error: String(err) };
  }
}

// ─────────────────────────────────────────────────────────────
// ML v1 (online, lightweight) — schema + model utils
// ─────────────────────────────────────────────────────────────

// Keep KV key stable for admin reset + migrations.
const ML_V1_MODEL_KEY = "timed:model:ml_v1";
let ML_V1_CACHE = { model: null, loadedAt: 0 };

function mlV1Sigmoid(z) {
  const n = Number(z);
  if (!Number.isFinite(n)) return 0.5;
  // Clamp to avoid overflow
  const x = Math.max(-30, Math.min(30, n));
  return 1 / (1 + Math.exp(-x));
}

function mlV1DefaultModel() {
  // Keep this small + stable; we can expand later once backfill exists.
  const featureNames = [
    "bias",
    "rank_n",
    "rr_n",
    "completion",
    "phase",
    "abs_htf_n",
    "abs_ltf_n",
    "aligned",
    "setup",
    "sq_rel",
    "in_corridor",
    "momentum_elite",
  ];
  return {
    version: 1,
    featureNames,
    w: featureNames.map(() => 0),
    n: 0,
    lr: 0.05,
    l2: 0.001,
    updated_at: Date.now(),
  };
}

async function mlV1GetModel(KV) {
  const now = Date.now();
  if (ML_V1_CACHE.model && now - ML_V1_CACHE.loadedAt < 60 * 1000) {
    return ML_V1_CACHE.model;
  }
  let model = null;
  try {
    model = KV ? await kvGetJSON(KV, ML_V1_MODEL_KEY) : null;
  } catch {
    model = null;
  }
  if (!model || typeof model !== "object" || !Array.isArray(model.w)) {
    model = mlV1DefaultModel();
  }
  ML_V1_CACHE = { model, loadedAt: now };
  return model;
}

async function mlV1PutModel(KV, model) {
  if (!KV) return;
  const out =
    model && typeof model === "object" ? { ...model, updated_at: Date.now() } : null;
  if (!out) return;
  await kvPutJSON(KV, ML_V1_MODEL_KEY, out);
  ML_V1_CACHE = { model: out, loadedAt: Date.now() };
}

function mlV1ExtractX(d) {
  const flags = d?.flags && typeof d.flags === "object" ? d.flags : {};
  const state = String(d?.state || "");
  const rank = Number(d?.rank);
  const rr = Number(d?.rr);
  const completion = clamp01(d?.completion);
  const phase = clamp01(d?.phase_pct);
  const htf = Number(d?.htf_score);
  const ltf = Number(d?.ltf_score);
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR" ? 1 : 0;
  const setup =
    state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK"
      ? 1
      : 0;

  // Normalize to roughly [-1,1] where possible.
  const rank_n = Number.isFinite(rank) ? (rank - 50) / 50 : 0;
  const rr_n = Number.isFinite(rr) ? Math.max(0, Math.min(4, rr)) / 4 : 0;
  const abs_htf_n = Number.isFinite(htf) ? Math.min(1, Math.abs(htf) / 100) : 0;
  const abs_ltf_n = Number.isFinite(ltf) ? Math.min(1, Math.abs(ltf) / 100) : 0;

  const inCorridor = (() => {
    try {
      return entryType(d)?.corridor ? 1 : 0;
    } catch {
      return 0;
    }
  })();

  return [
    1,
    rank_n,
    rr_n,
    completion,
    phase,
    abs_htf_n,
    abs_ltf_n,
    aligned,
    setup,
    flagOn(flags, "sq30_release") ? 1 : 0,
    inCorridor,
    flagOn(flags, "momentum_elite") ? 1 : 0,
  ];
}

function mlV1PredictProba(model, x) {
  const w = Array.isArray(model?.w) ? model.w : [];
  const n = Math.min(w.length, Array.isArray(x) ? x.length : 0);
  let z = 0;
  for (let i = 0; i < n; i++) z += Number(w[i] || 0) * Number(x[i] || 0);
  return mlV1Sigmoid(z);
}

function mlV1AttachScore(d, model) {
  const x = mlV1ExtractX(d);
  const p = mlV1PredictProba(model, x);
  const rr = Number(d?.rr);
  const rrUnit = Number.isFinite(rr) && rr > 0 ? Math.min(4, rr) : 1;
  // EV in "R units" (treat loss as -1R, win as +RR R). Expose as percent-ish for UI.
  const evUnits = p * rrUnit - (1 - p) * 1;
  const out = {
    v: 1,
    p_win_4h: p,
    ev_4h: evUnits * 100,
    p_win_1d: p,
    ev_1d: evUnits * 100,
    n: Number(model?.n) || 0,
    updated_at: model?.updated_at || null,
  };
  d.ml_v1 = out;
  // Back-compat alias used by UI snippets
  if (d.ml == null) d.ml = out;
  if (d.model == null) d.model = out;
  return out;
}

// Back-compat helper used by ingest/latest/all to attach model fields.
async function mlV1AttachToPayload(KV, payload) {
  if (!payload || typeof payload !== "object") return payload;
  const model = await mlV1GetModel(KV);
  mlV1AttachScore(payload, model);
  return payload;
}

async function d1EnsureMlV1Schema(env) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  try {
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ml_v1_queue (
          id TEXT PRIMARY KEY,
          ticker TEXT NOT NULL,
          ts INTEGER NOT NULL,
          horizon_ms INTEGER NOT NULL,
          dir TEXT,
          entry_price REAL,
          features_json TEXT,
          label_due_ts INTEGER NOT NULL,
          y INTEGER,
          labeled_at INTEGER,
          created_at INTEGER NOT NULL
        )`,
      )
      .run();
    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ml_v1_queue_due ON ml_v1_queue (label_due_ts)`,
      )
      .run();
    return { ok: true };
  } catch (e) {
    console.error("[D1 ML] Schema ensure failed:", e);
    return { ok: false, error: String(e) };
  }
}

async function d1EnqueueMlV1(env, ticker, payload, horizonsMs) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const ts = Number(payload?.ts);
  const price = Number(payload?.price);
  if (!Number.isFinite(ts) || !Number.isFinite(price) || price <= 0)
    return { ok: false, skipped: true, reason: "bad_ts_or_price" };
  await d1EnsureMlV1Schema(env);

  const dir = sideFromStateOrScores(payload);
  const x = mlV1ExtractX(payload);
  const createdAt = Date.now();

  const sym = String(ticker || "").toUpperCase();
  const hs = Array.isArray(horizonsMs) ? horizonsMs : [];
  for (const h of hs) {
    const hm = Number(h);
    if (!Number.isFinite(hm) || hm <= 0) continue;
    const due = ts + hm;
    const id = `${sym}:${ts}:${hm}`;
    try {
      await db
        .prepare(
          `INSERT OR IGNORE INTO ml_v1_queue
           (id, ticker, ts, horizon_ms, dir, entry_price, features_json, label_due_ts, y, labeled_at, created_at)
           VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, NULL, NULL, ?9)`,
        )
        .bind(
          id,
          sym,
          ts,
          hm,
          dir != null ? String(dir) : null,
          price,
          JSON.stringify({ x }),
          due,
          createdAt,
        )
        .run();
    } catch (e) {
      console.error(`[D1 ML] enqueue failed for ${id}:`, String(e));
    }
  }
  return { ok: true };
}

async function d1NearestClose(env, ticker, tsTarget) {
  const db = env?.DB;
  if (!db) return null;
  const sym = String(ticker || "").toUpperCase();
  const t = Number(tsTarget);
  if (!sym || !Number.isFinite(t)) return null;
  
  // Query timed_trail for ingest data (has price from TradingView scripts)
  try {
    const row = await db
      .prepare(
        `SELECT ts, payload_json FROM timed_trail
         WHERE ticker=?1 AND ts>=?2
         ORDER BY ts ASC LIMIT 1`,
      )
      .bind(sym, t)
      .first();
    if (row && row.payload_json) {
      try {
        const p = JSON.parse(row.payload_json);
        const price = Number(p?.price || p?.close);
        if (Number.isFinite(price) && price > 0) return price;
      } catch {
        // ignore parse error
      }
    }
  } catch (e) {
    console.error(`[ML LABEL] Failed to get exit price for ${sym}:`, String(e));
  }
  
  // Fallback to ticker_candles if available (for chart backfill data)
  const tfs = ["3", "10", "30"];
  for (const tf of tfs) {
    try {
      const row = await db
        .prepare(
          `SELECT ts, c FROM ticker_candles
           WHERE ticker=?1 AND tf=?2 AND ts>=?3
           ORDER BY ts ASC LIMIT 1`,
        )
        .bind(sym, tf, t)
        .first();
      if (row && Number.isFinite(Number(row.c))) return Number(row.c);
    } catch {
      // ignore
    }
  }
  // Fallback to last known <= target
  for (const tf of tfs) {
    try {
      const row = await db
        .prepare(
          `SELECT ts, c FROM ticker_candles
           WHERE ticker=?1 AND tf=?2 AND ts<=?3
           ORDER BY ts DESC LIMIT 1`,
        )
        .bind(sym, tf, t)
        .first();
      if (row && Number.isFinite(Number(row.c))) return Number(row.c);
    } catch {
      // ignore
    }
  }
  return null;
}

function mlV1LabelFromHorizon(entryPrice, exitPrice, dir) {
  const ep = Number(entryPrice);
  const xp = Number(exitPrice);
  if (!Number.isFinite(ep) || !Number.isFinite(xp) || ep <= 0) return null;
  const side = String(dir || "").toUpperCase();
  const ret = (xp - ep) / ep;
  if (side === "SHORT") return ret < 0 ? 1 : 0;
  if (side === "LONG") return ret > 0 ? 1 : 0;
  // If direction unknown, just ask "up?"
  return ret > 0 ? 1 : 0;
}

async function mlV1TrainFromQueue(env, KV, maxN = 75, force = false) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  await d1EnsureMlV1Schema(env);
  const now = Date.now();
  
  // Force mode: ignore label_due_ts check (for backfilling old data)
  const query = force
    ? `SELECT id, ticker, ts, horizon_ms, dir, entry_price, features_json, label_due_ts
       FROM ml_v1_queue
       WHERE y IS NULL
       ORDER BY ts ASC
       LIMIT ?1`
    : `SELECT id, ticker, ts, horizon_ms, dir, entry_price, features_json, label_due_ts
       FROM ml_v1_queue
       WHERE y IS NULL AND label_due_ts <= ?1
       ORDER BY label_due_ts ASC
       LIMIT ?2`;
  
  const rows = force
    ? await db.prepare(query).bind(Math.max(1, Math.min(250, Number(maxN) || 75))).all()
    : await db.prepare(query).bind(now, Math.max(1, Math.min(250, Number(maxN) || 75))).all();
  const due = Array.isArray(rows?.results) ? rows.results : [];
  console.log(`[ML TRAIN] Found ${due.length} entries to process (force=${force})`);
  if (due.length === 0) return { ok: true, trained: 0 };

  let model = await mlV1GetModel(KV);
  let trained = 0;
  let skipped = { no_exit: 0, no_label: 0, no_features: 0 };

  for (const r of due) {
    const exit = await d1NearestClose(env, r.ticker, Number(r.label_due_ts));
    if (exit == null) {
      skipped.no_exit++;
      continue;
    }
    const y = mlV1LabelFromHorizon(r.entry_price, exit, r.dir);
    if (y == null) {
      skipped.no_label++;
      continue;
    }
    let x = null;
    try {
      const fj = r.features_json ? JSON.parse(String(r.features_json)) : null;
      x = Array.isArray(fj?.x) ? fj.x : null;
    } catch {
      x = null;
    }
    if (!Array.isArray(x)) continue;

    const p = mlV1PredictProba(model, x);
    const err = Number(y) - p;
    const lr = Number(model?.lr) || 0.05;
    const l2 = Number(model?.l2) || 0.001;
    const w = Array.isArray(model?.w) ? model.w.slice() : mlV1DefaultModel().w;

    for (let i = 0; i < Math.min(w.length, x.length); i++) {
      const wi = Number(w[i] || 0);
      const xi = Number(x[i] || 0);
      w[i] = wi + lr * (err * xi - l2 * wi);
    }
    model = { ...model, w, n: (Number(model?.n) || 0) + 1 };

    try {
      await db
        .prepare(
          `UPDATE ml_v1_queue SET y=?2, labeled_at=?3 WHERE id=?1`,
        )
        .bind(String(r.id), Number(y), now)
        .run();
      trained++;
    } catch {
      // ignore
    }
  }

  if (trained > 0) {
    await mlV1PutModel(KV, model);
  }
  console.log(`[ML TRAIN] Result: trained=${trained}, skipped=${JSON.stringify(skipped)}`);
  return { ok: true, trained, model_n: model.n, skipped, checked: due.length };
}

async function d1UpsertCandle(env, ticker, tf, candle) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const tfKey = normalizeTfKey(tf);
  if (!sym || !tfKey) return { ok: false, error: "bad_params" };

  const ts = Number(candle?.ts);
  if (!Number.isFinite(ts)) return { ok: false, error: "bad_ts" };
  const o = Number(candle?.o);
  const h = Number(candle?.h);
  const l = Number(candle?.l);
  const c = Number(candle?.c);
  const v = candle?.v != null ? Number(candle?.v) : null;
  if (![o, h, l, c].every((x) => Number.isFinite(x))) {
    return { ok: false, error: "bad_ohlc" };
  }
  const updatedAt = Date.now();
  try {
    await d1EnsureCandleSchema(env);
    // Try INSERT with session column first; fall back to without if column doesn't exist yet
    try {
      const session = candle?.session || null; // PM / RTH / AH / CLOSED (set by alpacaBarToCandle)
      await db
        .prepare(
          `INSERT INTO ticker_candles (ticker, tf, ts, o, h, l, c, v, session, updated_at)
           VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)
           ON CONFLICT(ticker, tf, ts) DO UPDATE SET
             o=excluded.o, h=excluded.h, l=excluded.l, c=excluded.c, v=excluded.v,
             session=excluded.session, updated_at=excluded.updated_at`,
        )
        .bind(sym, tfKey, ts, o, h, l, c, v, session, updatedAt)
        .run();
    } catch (sessionErr) {
      // Session column may not exist yet — fallback without it
      if (String(sessionErr).includes("no such column: session")) {
        await db
          .prepare(
            `INSERT INTO ticker_candles (ticker, tf, ts, o, h, l, c, v, updated_at)
             VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)
             ON CONFLICT(ticker, tf, ts) DO UPDATE SET
               o=excluded.o, h=excluded.h, l=excluded.l, c=excluded.c, v=excluded.v,
               updated_at=excluded.updated_at`,
          )
          .bind(sym, tfKey, ts, o, h, l, c, v, updatedAt)
          .run();
      } else {
        throw sessionErr;
      }
    }
    return { ok: true };
  } catch (err) {
    console.error(`[D1 CANDLES] Upsert failed for ${sym} ${tfKey}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1GetCandles(env, ticker, tf, limit = 200) {
  const db = env?.DB;
  if (!db) return { ok: false, error: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const tfKey = normalizeTfKey(tf);
  const n = Math.max(10, Math.min(3000, Number(limit) || 200));
  if (!sym || !tfKey) return { ok: false, error: "bad_params" };

  try {
    await d1EnsureCandleSchema(env);
    const rows = await db
      .prepare(
        `SELECT ts, o, h, l, c, v
         FROM ticker_candles
         WHERE ticker = ?1 AND tf = ?2
         ORDER BY ts DESC
         LIMIT ?3`,
      )
      .bind(sym, tfKey, n)
      .all();
    const out = (rows?.results || [])
      .map((r) => ({
        ts: Number(r?.ts),
        o: Number(r?.o),
        h: Number(r?.h),
        l: Number(r?.l),
        c: Number(r?.c),
        v: r?.v != null ? Number(r?.v) : null,
      }))
      .filter((x) => Number.isFinite(x.ts) && Number.isFinite(x.o))
      .sort((a, b) => a.ts - b.ts);
    return { ok: true, ticker: sym, tf: tfKey, candles: out };
  } catch (err) {
    console.error(`[D1 CANDLES] Read failed for ${sym} ${tfKey}:`, err);
    return { ok: false, error: String(err) };
  }
}

// "As-of" variant: only returns candles with ts <= asOfTs (for historical replay)
async function d1GetCandlesAsOf(env, ticker, tf, limit = 200, asOfTs = null) {
  if (!asOfTs || !Number.isFinite(asOfTs)) return d1GetCandles(env, ticker, tf, limit);
  const db = env?.DB;
  if (!db) return { ok: false, error: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const tfKey = normalizeTfKey(tf);
  const n = Math.max(10, Math.min(3000, Number(limit) || 200));
  if (!sym || !tfKey) return { ok: false, error: "bad_params" };
  try {
    await d1EnsureCandleSchema(env);
    const rows = await db
      .prepare(
        `SELECT ts, o, h, l, c, v
         FROM ticker_candles
         WHERE ticker = ?1 AND tf = ?2 AND ts <= ?4
         ORDER BY ts DESC
         LIMIT ?3`,
      )
      .bind(sym, tfKey, n, asOfTs)
      .all();
    const out = (rows?.results || [])
      .map((r) => ({
        ts: Number(r?.ts),
        o: Number(r?.o),
        h: Number(r?.h),
        l: Number(r?.l),
        c: Number(r?.c),
        v: r?.v != null ? Number(r?.v) : null,
      }))
      .filter((x) => Number.isFinite(x.ts) && Number.isFinite(x.o))
      .sort((a, b) => a.ts - b.ts);
    return { ok: true, ticker: sym, tf: tfKey, candles: out };
  } catch (err) {
    console.error(`[D1 CANDLES AS-OF] Read failed for ${sym} ${tfKey}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1UpsertTickerIndex(env, ticker, ts) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const nowTs = Number(ts) || Date.now();

  try {
    await d1EnsureLatestSchema(env);
    await db
      .prepare(
        `INSERT INTO ticker_index (ticker, first_seen_ts, last_seen_ts)
         VALUES (?1, ?2, ?3)
         ON CONFLICT(ticker) DO UPDATE SET last_seen_ts = excluded.last_seen_ts`,
      )
      .bind(sym, nowTs, nowTs)
      .run();
    return { ok: true };
  } catch (err) {
    console.error(`[D1 LATEST] Index upsert failed for ${sym}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1UpsertTickerLatest(env, ticker, payload) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const ts = Number(payload?.ts) || Date.now();
  const updatedAt = Date.now();
  const stage =
    payload?.kanban_stage != null ? String(payload.kanban_stage) : null;
  const prevStage =
    payload?.prev_kanban_stage != null
      ? String(payload.prev_kanban_stage)
      : null;

  const D1_MAX = 50000;
  let payloadJson = null;
  try {
    let slim = slimPayloadForD1(payload);
    let s = JSON.stringify(slim);
    if (s.length > D1_MAX) {
      slim = minimalPayloadForD1(payload);
      s = JSON.stringify(slim);
    }
    payloadJson = s.length <= D1_MAX ? s : null;
  } catch {
    payloadJson = null;
  }
  if (!payloadJson)
    return { ok: false, skipped: true, reason: "payload_json_failed" };

  try {
    await d1EnsureLatestSchema(env);
    await db
      .prepare(
        `INSERT INTO ticker_latest (ticker, ts, updated_at, kanban_stage, prev_kanban_stage, payload_json)
         VALUES (?1, ?2, ?3, ?4, ?5, ?6)
         ON CONFLICT(ticker) DO UPDATE SET
           ts = excluded.ts,
           updated_at = excluded.updated_at,
           kanban_stage = excluded.kanban_stage,
           prev_kanban_stage = excluded.prev_kanban_stage,
           payload_json = excluded.payload_json`,
      )
      .bind(sym, ts, updatedAt, stage, prevStage, payloadJson)
      .run();
    return { ok: true };
  } catch (err) {
    console.error(`[D1 LATEST] Latest upsert failed for ${sym}:`, err);
    return { ok: false, error: String(err) };
  }
}

// Patch selected fields inside ticker_latest.payload_json without rewriting the whole row.
// Uses SQLite JSON1 `json_set` to avoid a read+merge cycle.
async function d1PatchTickerLatestFields(env, ticker, patch) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  if (!sym) return { ok: false, skipped: true, reason: "bad_ticker" };
  if (!patch || typeof patch !== "object")
    return { ok: false, skipped: true, reason: "bad_patch" };

  const pairs = [];
  const binds = [];
  const add = (k, v) => {
    if (v == null) return;
    // Keep numbers as numbers; booleans as 1/0; strings as strings.
    let val = v;
    if (typeof v === "boolean") val = v ? 1 : 0;
    pairs.push(`'$.${k}', ?${binds.length + 1}`);
    binds.push(val);
  };

  add("prev_close", patch.prev_close);
  add("day_change", patch.day_change);
  add("day_change_pct", patch.day_change_pct);
  add("change", patch.change);
  add("change_pct", patch.change_pct);
  add("session", patch.session);
  add("is_rth", patch.is_rth);

  if (pairs.length === 0)
    return { ok: false, skipped: true, reason: "no_fields" };

  try {
    await d1EnsureLatestSchema(env);
    const sql = `UPDATE ticker_latest
                 SET payload_json = json_set(payload_json, ${pairs.join(", ")})
                 WHERE ticker = ?${binds.length + 1} AND payload_json IS NOT NULL`;
    binds.push(sym);
    await db
      .prepare(sql)
      .bind(...binds)
      .run();
    return { ok: true };
  } catch (err) {
    console.error(`[D1 LATEST] Patch failed for ${sym}:`, err);
    return { ok: false, error: String(err) };
  }
}

// Periodic KV → D1 latest sync (batched) to bootstrap /timed/all quickly after deploy.
async function d1SyncLatestBatchFromKV(env, ctx, batchSize = 50) {
  const KV = env?.KV_TIMED;
  const db = env?.DB;
  if (!KV || !db)
    return { ok: false, skipped: true, reason: "missing_kv_or_db" };

  try {
    await d1EnsureLatestSchema(env);
  } catch {
    // ignore
  }

  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
  if (!Array.isArray(tickers) || tickers.length === 0) {
    return { ok: false, skipped: true, reason: "no_tickers_index" };
  }

  const cursorKey = "timed:d1:latest_sync_cursor";
  let cursor = 0;
  try {
    cursor = Number(await KV.get(cursorKey)) || 0;
    if (!Number.isFinite(cursor) || cursor < 0) cursor = 0;
  } catch {
    cursor = 0;
  }

  const start = Date.now();
  const end = Math.min(cursor + batchSize, tickers.length);
  const slice = tickers.slice(cursor, end);

  for (const t of slice) {
    const sym = String(t || "").toUpperCase();
    if (!sym) continue;
    try {
      // Always index the ticker (even if no latest yet)
      await d1UpsertTickerIndex(env, sym, Date.now());
      const latest = await kvGetJSON(KV, `timed:latest:${sym}`);
      if (latest && typeof latest === "object") {
        // Attach ML predictions before syncing to D1
        try {
          await mlV1AttachToPayload(KV, latest);
        } catch (e) {
          console.warn(`[D1 SYNC] ML attach failed for ${sym}:`, String(e));
        }
        
        // Ensure stage exists for D1 consumers
        try {
          if (latest.kanban_stage == null) {
            const stage = classifyKanbanStage(latest);
            if (stage) latest.kanban_stage = stage;
          }
        } catch {
          // ignore
        }
        await d1UpsertTickerLatest(env, sym, latest);
      }
    } catch (e) {
      console.error(`[D1 SYNC] Failed for ${sym}:`, String(e));
    }
  }

  const nextCursor = end >= tickers.length ? 0 : end;
  try {
    await KV.put(cursorKey, String(nextCursor), {
      expirationTtl: 7 * 24 * 60 * 60,
    });
  } catch {
    // ignore
  }

  const ms = Date.now() - start;
  console.log(
    `[D1 SYNC] Synced ${slice.length}/${tickers.length} tickers in ${ms}ms (cursor ${cursor}→${nextCursor})`,
  );
  return {
    ok: true,
    synced: slice.length,
    total: tickers.length,
    ms,
    cursor,
    nextCursor,
  };
}

async function d1CleanupOldTrail(env, ttlDays = 35) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  const KV = env?.KV_TIMED;
  // throttle cleanup to at most once per hour
  const throttleKey = "timed:d1:trail:last_cleanup_ms";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 60 * 60 * 1000) {
        return { ok: true, skipped: true, reason: "throttled" };
      }
    }
  } catch {
    // ignore throttle failures
  }

  const cutoff = Date.now() - Number(ttlDays) * 24 * 60 * 60 * 1000;
  try {
    const r = await db
      .prepare(`DELETE FROM timed_trail WHERE ts < ?1`)
      .bind(cutoff)
      .run();

    if (KV) {
      await KV.put(throttleKey, String(Date.now()), {
        expirationTtl: 2 * 60 * 60, // 2 hours
      });
    }

    return { ok: true, deleted: r?.meta?.changes || 0, cutoff };
  } catch (err) {
    console.error(`[D1 TRAIL] Cleanup failed:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1GetTrailRange(env, ticker, sinceTs = null, limit = 5000, includeKanban = false) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const t = String(ticker || "").toUpperCase();
  const lim = Math.max(1, Math.min(20000, Number(limit) || 5000));

  try {
    // Always include kanban_stage column (lightweight). Include payload_json only when full kanban data is requested.
    const cols = includeKanban
      ? `ts, price, htf_score, ltf_score, completion, phase_pct, state, rank, flags_json, trigger_reason, trigger_dir, kanban_stage, payload_json`
      : `ts, price, htf_score, ltf_score, completion, phase_pct, state, rank, flags_json, trigger_reason, trigger_dir, kanban_stage`;
    
    let stmt;
    if (sinceTs != null && Number.isFinite(Number(sinceTs))) {
      stmt = db
        .prepare(
          `SELECT ${cols}
           FROM timed_trail
           WHERE ticker = ?1 AND ts >= ?2
           ORDER BY ts ASC
           LIMIT ?3`,
        )
        .bind(t, Number(sinceTs), lim);
    } else {
      stmt = db
        .prepare(
          `SELECT ${cols}
           FROM timed_trail
           WHERE ticker = ?1
           ORDER BY ts DESC
           LIMIT ?2`,
        )
        .bind(t, lim);
    }

    const rows = await stmt.all();
    const out = Array.isArray(rows?.results) ? rows.results : [];
    const trail = out
      .map((r) => {
        const base = {
          ts: Number(r.ts),
          price: r.price != null ? Number(r.price) : null,
          htf_score: r.htf_score != null ? Number(r.htf_score) : null,
          ltf_score: r.ltf_score != null ? Number(r.ltf_score) : null,
          completion: r.completion != null ? Number(r.completion) : null,
          phase_pct: r.phase_pct != null ? Number(r.phase_pct) : null,
          state: r.state != null ? String(r.state) : null,
          rank: r.rank != null ? Number(r.rank) : null,
          flags:
            r.flags_json && typeof r.flags_json === "string"
              ? (() => {
                  try {
                    return JSON.parse(r.flags_json);
                  } catch {
                    return {};
                  }
                })()
              : {},
          momentum_elite: false, // derived in UI/logic from flags when needed
          trigger_reason:
            r.trigger_reason != null ? String(r.trigger_reason) : null,
          trigger_dir: r.trigger_dir != null ? String(r.trigger_dir) : null,
          kanban_stage: r.kanban_stage != null ? String(r.kanban_stage) : null,
        };
        
        // Extract extended kanban data from payload_json if requested
        if (includeKanban && r.payload_json) {
          try {
            const payload = JSON.parse(r.payload_json);
            if (!base.kanban_stage && payload.kanban_stage) base.kanban_stage = payload.kanban_stage;
            base.entry_ts = payload.entry_ts || null;
            base.entry_price = payload.entry_price || null;
            base.move_status = payload.move_status || null;
            base.kanban_meta = payload.kanban_meta || null;
          } catch {
            // kanban_stage already populated from direct column
          }
        }
        
        return base;
      })
      .filter((p) => Number.isFinite(p.ts));

    // If we queried DESC (no since), normalize to ASC for consumers
    trail.sort((a, b) => a.ts - b.ts);

    return { ok: true, trail, source: "d1" };
  } catch (err) {
    console.error(`[D1 TRAIL] Query failed for ${ticker}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1GetTrailPayloadRange(
  env,
  ticker,
  sinceTs = null,
  untilTs = null,
  limit = 5000,
) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const t = String(ticker || "").toUpperCase();
  const lim = Math.max(1, Math.min(20000, Number(limit) || 5000));

  const since =
    sinceTs != null && Number.isFinite(Number(sinceTs))
      ? Number(sinceTs)
      : null;
  const until =
    untilTs != null && Number.isFinite(Number(untilTs))
      ? Number(untilTs)
      : null;

  try {
    let stmt;
    if (since != null && until != null) {
      stmt = db
        .prepare(
          `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3
         ORDER BY ts ASC
         LIMIT ?4`,
        )
        .bind(t, since, until, lim);
    } else if (since != null) {
      stmt = db
        .prepare(
          `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1 AND ts >= ?2
         ORDER BY ts ASC
         LIMIT ?3`,
        )
        .bind(t, since, lim);
    } else {
      stmt = db
        .prepare(
          `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1
         ORDER BY ts DESC
         LIMIT ?2`,
        )
        .bind(t, lim);
    }

    const rows = await stmt.all();
    const results = Array.isArray(rows?.results) ? rows.results : [];
    const payloads = results
      .map((r) => {
        const ts = Number(r.ts);
        const raw = r.payload_json;
        if (!raw || typeof raw !== "string") return null;
        try {
          const p = JSON.parse(raw);
          p.ts = ts; // trust DB ts
          return p;
        } catch {
          return null;
        }
      })
      .filter(Boolean)
      .sort((a, b) => Number(a.ts) - Number(b.ts));

    return { ok: true, payloads, source: "d1" };
  } catch (err) {
    console.error(`[D1 TRAIL] Payload query failed for ${ticker}:`, err);
    return { ok: false, error: String(err) };
  }
}

// ─────────────────────────────────────────────────────────────
// D1 Ledger Storage (alerts + trades + trade_events)
// ─────────────────────────────────────────────────────────────

function isoToMs(v) {
  if (v == null) return null;
  if (typeof v === "number" && Number.isFinite(v)) return v;
  const s = String(v);
  const ms = Date.parse(s);
  return Number.isFinite(ms) ? ms : null;
}

function formatDedupDay(ts) {
  if (!Number.isFinite(ts)) return null;
  return new Date(ts).toISOString().split("T")[0];
}

function buildAlertId(ticker, ts, type) {
  const t = String(ticker || "").toUpperCase();
  const kind = String(type || "ALERT").toUpperCase();
  return `${t}:${ts}:${kind}`;
}

async function d1UpsertAlert(env, alert) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  const ticker = String(alert?.ticker || "").toUpperCase();
  const ts = Number(alert?.ts);
  if (!ticker || !Number.isFinite(ts))
    return { ok: false, skipped: true, reason: "bad_key" };

  const alertId = String(alert?.alert_id || `${ticker}:${ts}`);
  const discordSent = alert?.discord_sent ? 1 : 0;

  try {
    await db
      .prepare(
        `INSERT OR REPLACE INTO alerts
          (alert_id, ticker, ts, side, state, rank, rr_at_alert, trigger_reason, dedupe_day,
           discord_sent, discord_status, discord_error, payload_json, meta_json)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14)`,
      )
      .bind(
        alertId,
        ticker,
        ts,
        alert?.side != null ? String(alert.side) : null,
        alert?.state != null ? String(alert.state) : null,
        alert?.rank != null ? Number(alert.rank) : null,
        alert?.rr_at_alert != null ? Number(alert.rr_at_alert) : null,
        alert?.trigger_reason != null ? String(alert.trigger_reason) : null,
        alert?.dedupe_day != null ? String(alert.dedupe_day) : null,
        discordSent,
        alert?.discord_status != null ? Number(alert.discord_status) : null,
        alert?.discord_error != null ? String(alert.discord_error) : null,
        alert?.payload_json != null ? String(alert.payload_json) : null,
        alert?.meta_json != null ? String(alert.meta_json) : null,
      )
      .run();

    return { ok: true, alert_id: alertId };
  } catch (err) {
    console.error(`[D1 LEDGER] Alert upsert failed for ${ticker}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1UpsertTrade(env, trade) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  if (!trade) return { ok: false, skipped: true, reason: "missing_trade" };

  const tradeId = String(trade.id || trade.trade_id || "").trim();
  if (!tradeId) return { ok: false, skipped: true, reason: "missing_trade_id" };

  const ticker = String(trade.ticker || "").toUpperCase();
  const direction = String(trade.direction || "").toUpperCase();
  // Prefer numeric entry_ts (ms); normalize seconds to ms so display is correct
  let entryTs = Number(trade.entry_ts);
  if (!Number.isFinite(entryTs) || entryTs <= 0)
    entryTs = isoToMs(trade.entryTime) || null;
  if (Number.isFinite(entryTs) && entryTs < 1e12) entryTs = entryTs * 1000;
  const createdAt = entryTs || Date.now();
  const updatedAt = Date.now();

  // Best-effort exit ts from trade.exit_ts, then history EXIT event
  let exitTs = Number(trade.exit_ts);
  if (!Number.isFinite(exitTs) || exitTs <= 0) exitTs = null;
  if (exitTs != null && exitTs < 1e12) exitTs = exitTs * 1000;
  let exitEvent = null;
  if (exitTs == null && Array.isArray(trade.history)) {
    for (let i = trade.history.length - 1; i >= 0; i--) {
      const e = trade.history[i];
      if (e && e.type === "EXIT") {
        exitEvent = e;
        exitTs = isoToMs(e.timestamp);
        break;
      }
    }
  }

  // Best-effort exit price/reason from history for legacy trades (so backfill becomes useful)
  const derivedExitPrice =
    trade.exitPrice != null
      ? Number(trade.exitPrice)
      : exitEvent && exitEvent.price != null
        ? Number(exitEvent.price)
        : null;
  const derivedExitReason =
    trade.exitReason != null
      ? String(trade.exitReason)
      : inferExitReasonForLegacyTrade(trade, exitEvent);

  let trimTs = Number(trade.trim_ts);
  if (!Number.isFinite(trimTs) && Array.isArray(trade.history)) {
    for (let i = trade.history.length - 1; i >= 0; i--) {
      const e = trade.history[i];
      if (e && e.type === "TRIM") {
        trimTs = isoToMs(e.timestamp) || Number(e.ts) || 0;
        if (trimTs < 1e12) trimTs = trimTs * 1000;
        break;
      }
    }
  }
  if (Number.isFinite(trimTs) && trimTs < 1e12) trimTs = trimTs * 1000;

  let trimPrice = Number(trade.trim_price ?? trade.trimPrice);
  if (!Number.isFinite(trimPrice) && Array.isArray(trade.history)) {
    for (let i = trade.history.length - 1; i >= 0; i--) {
      const e = trade.history[i];
      if (e && e.type === "TRIM" && e.price != null) {
        trimPrice = Number(e.price);
        break;
      }
    }
  }

  const insertWithTrimPrice = `INSERT OR IGNORE INTO trades
          (trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
           exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct, script_version,
           created_at, updated_at, trim_ts, trim_price)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18, ?19)`;
  const insertWithoutTrimPrice = `INSERT OR IGNORE INTO trades
          (trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
           exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct, script_version,
           created_at, updated_at, trim_ts)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18)`;

  try {
    // Preserve created_at by inserting once.
    await db
      .prepare(insertWithTrimPrice)
      .bind(
        tradeId,
        ticker || null,
        direction || null,
        entryTs != null ? Number(entryTs) : null,
        trade.entryPrice != null ? Number(trade.entryPrice) : null,
        trade.rank != null ? Number(trade.rank) : null,
        trade.rr != null ? Number(trade.rr) : null,
        trade.status != null ? String(trade.status) : null,
        exitTs != null ? Number(exitTs) : null,
        Number.isFinite(derivedExitPrice) ? derivedExitPrice : null,
        derivedExitReason != null ? String(derivedExitReason) : null,
        trade.trimmedPct != null ? Number(trade.trimmedPct) : null,
        trade.pnl != null ? Number(trade.pnl) : null,
        trade.pnlPct != null ? Number(trade.pnlPct) : null,
        trade.scriptVersion != null
          ? String(trade.scriptVersion)
          : trade.script_version != null
            ? String(trade.script_version)
            : null,
        createdAt,
        updatedAt,
        Number.isFinite(trimTs) ? trimTs : null,
        Number.isFinite(trimPrice) ? trimPrice : null,
      )
      .run();

    await db
      .prepare(
        `UPDATE trades SET
          ticker=?2, direction=?3, entry_ts=?4, entry_price=?5, rank=?6, rr=?7, status=?8,
          exit_ts=?9, exit_price=?10, exit_reason=?11,
          trimmed_pct=?12, pnl=?13, pnl_pct=?14, script_version=?15,
          updated_at=?16, trim_ts=?17, trim_price=?18
         WHERE trade_id=?1`,
      )
      .bind(
        tradeId,
        ticker || null,
        direction || null,
        entryTs != null ? Number(entryTs) : null,
        trade.entryPrice != null ? Number(trade.entryPrice) : null,
        trade.rank != null ? Number(trade.rank) : null,
        trade.rr != null ? Number(trade.rr) : null,
        trade.status != null ? String(trade.status) : null,
        exitTs != null ? Number(exitTs) : null,
        Number.isFinite(derivedExitPrice) ? derivedExitPrice : null,
        derivedExitReason != null ? String(derivedExitReason) : null,
        trade.trimmedPct != null ? Number(trade.trimmedPct) : null,
        trade.pnl != null ? Number(trade.pnl) : null,
        trade.pnlPct != null ? Number(trade.pnlPct) : null,
        trade.scriptVersion != null
          ? String(trade.scriptVersion)
          : trade.script_version != null
            ? String(trade.script_version)
            : null,
        updatedAt,
        Number.isFinite(trimTs) ? trimTs : null,
        Number.isFinite(trimPrice) ? trimPrice : null,
      )
      .run();

    return { ok: true, trade_id: tradeId };
  } catch (err) {
    console.error(`[D1 LEDGER] Trade upsert failed for ${tradeId}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1InsertTradeEvent(env, tradeId, event) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  if (!tradeId) return { ok: false, skipped: true, reason: "missing_trade_id" };
  if (!event) return { ok: false, skipped: true, reason: "missing_event" };

  const ts = isoToMs(event.timestamp) || Number(event.ts) || null;
  const type = String(event.type || "").toUpperCase();
  if (!Number.isFinite(ts) || !type)
    return { ok: false, skipped: true, reason: "bad_event_key" };

  const eventId = `${tradeId}:${type}:${ts}`;

  // Quantity fields: for TRIM, represent trimmed percentages.
  const qtyPctTotal =
    event.trimPct != null
      ? Number(event.trimPct)
      : event.trimmedPct != null
        ? Number(event.trimmedPct)
        : null;
  const qtyPctDelta =
    event.trimDeltaPct != null ? Number(event.trimDeltaPct) : null;

  const meta = (() => {
    try {
      return JSON.stringify(event);
    } catch {
      return null;
    }
  })();

  try {
    await db
      .prepare(
        `INSERT OR IGNORE INTO trade_events
          (event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)`,
      )
      .bind(
        eventId,
        String(tradeId),
        Number(ts),
        type,
        event.price != null ? Number(event.price) : null,
        qtyPctDelta != null && Number.isFinite(qtyPctDelta)
          ? qtyPctDelta
          : null,
        qtyPctTotal != null && Number.isFinite(qtyPctTotal)
          ? qtyPctTotal
          : null,
        event.pnl_realized != null ? Number(event.pnl_realized) : null,
        event.reason != null ? String(event.reason) : null,
        meta,
      )
      .run();

    return { ok: true, event_id: eventId };
  } catch (err) {
    console.error(`[D1 LEDGER] Trade event insert failed for ${tradeId}:`, err);
    return { ok: false, error: String(err) };
  }
}

// --- Phase 2: positions / lots / execution_actions (lot-based model) ---

async function d1InsertPosition(env, row) {
  const db = env?.DB;
  if (!db || !row) return { ok: false, skipped: true };
  const { position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at, closed_at, script_version, stop_loss, take_profit } = row;
  if (!position_id || !ticker || !direction) return { ok: false, skipped: true, reason: "missing_key" };
  try {
    await db.prepare(
      `INSERT OR IGNORE INTO positions (position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at, closed_at, script_version, stop_loss, take_profit)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12)`
    ).bind(
      position_id,
      String(ticker).toUpperCase(),
      String(direction).toUpperCase(),
      status || "OPEN",
      Number(total_qty) || 0,
      Number(cost_basis) || 0,
      Number(created_at) || Date.now(),
      Number(updated_at) || Date.now(),
      closed_at != null ? Number(closed_at) : null,
      script_version || null,
      Number.isFinite(Number(stop_loss)) ? Number(stop_loss) : null,
      Number.isFinite(Number(take_profit)) ? Number(take_profit) : null,
    ).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true, reason: "schema" };
    console.error("[D1 LEDGER] positions insert failed:", err);
    return { ok: false, error: String(err) };
  }
}

async function d1InsertLot(env, row) {
  const db = env?.DB;
  if (!db || !row) return { ok: false, skipped: true };
  const { lot_id, position_id, ts, qty, price, value, remaining_qty } = row;
  if (!lot_id || !position_id || ts == null) return { ok: false, skipped: true, reason: "missing_key" };
  try {
    await db.prepare(
      `INSERT OR IGNORE INTO lots (lot_id, position_id, ts, qty, price, value, remaining_qty)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)`
    ).bind(
      lot_id,
      position_id,
      Number(ts),
      Number(qty) || 0,
      Number(price) || 0,
      Number(value) || 0,
      Number(remaining_qty) ?? Number(qty) ?? 0,
    ).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true, reason: "schema" };
    console.error("[D1 LEDGER] lots insert failed:", err);
    return { ok: false, error: String(err) };
  }
}

async function d1InsertExecutionAction(env, row) {
  const db = env?.DB;
  if (!db || !row) return { ok: false, skipped: true };
  const { action_id, position_id, ts, action_type, qty, price, value, pnl_realized, lot_id, reason, meta_json } = row;
  if (!action_id || !position_id || ts == null || !action_type) return { ok: false, skipped: true, reason: "missing_key" };
  try {
    await db.prepare(
      `INSERT OR IGNORE INTO execution_actions (action_id, position_id, ts, action_type, qty, price, value, pnl_realized, lot_id, reason, meta_json)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11)`
    ).bind(
      action_id,
      position_id,
      Number(ts),
      String(action_type).toUpperCase(),
      Number(qty) || 0,
      Number(price) || 0,
      Number(value) || 0,
      pnl_realized != null ? Number(pnl_realized) : null,
      lot_id || null,
      reason || null,
      meta_json || null,
    ).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true, reason: "schema" };
    console.error("[D1 LEDGER] execution_actions insert failed:", err);
    return { ok: false, error: String(err) };
  }
}

async function d1GetOpenPosition(env, ticker, direction) {
  const db = env?.DB;
  if (!db || !ticker) return null;
  try {
    const row = await db.prepare(
      `SELECT position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at
       FROM positions WHERE ticker = ?1 AND direction = ?2 AND status = 'OPEN' LIMIT 1`
    ).bind(String(ticker).toUpperCase(), String(direction || "LONG").toUpperCase()).first();
    return row || null;
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    console.error("[D1 LEDGER] get open position failed:", err);
    return null;
  }
}

/** Get any open position for ticker (either direction). Returns null if none. */
async function d1GetAnyOpenPosition(env, ticker) {
  const db = env?.DB;
  if (!db || !ticker) return null;
  try {
    const row = await db.prepare(
      `SELECT position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at
       FROM positions WHERE ticker = ?1 AND status = 'OPEN' LIMIT 1`
    ).bind(String(ticker).toUpperCase()).first();
    return row || null;
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    return null;
  }
}

/**
 * ANTI-CHURNING: Check per-ticker daily trade frequency.
 * 
 * Data shows excessive trading hurts performance:
 * - TLN: 276 trades in 2 days, -$111 total P&L
 * - Top churners all have ~50% win rate (coin flip)
 * 
 * Rule: Max 3 trades per ticker per day, min 30 min cooldown.
 * 
 * @param {object} env - Worker environment with DB binding
 * @param {string} ticker - Ticker symbol
 * @returns {object} - { blocked, reason, todayTrades, lastEntryAge }
 */
async function checkTradeFrequency(env, ticker) {
  const db = env?.DB;
  if (!db || !ticker) {
    return { blocked: false, todayTrades: 0 };
  }
  
  const sym = String(ticker).toUpperCase();
  const now = Date.now();
  const dayStartMs = now - (24 * 60 * 60 * 1000); // 24 hours ago
  const cooldownMs = 30 * 60 * 1000; // 30 minutes
  
  try {
    // Count entries in last 24 hours and get most recent entry time
    const result = await db.prepare(`
      SELECT 
        COUNT(*) as count,
        MAX(ts) as last_entry_ts
      FROM execution_actions 
      WHERE ticker = ?1 AND action_type = 'ENTRY' AND ts > ?2
    `).bind(sym, dayStartMs).first();
    
    const todayTrades = Number(result?.count) || 0;
    const lastEntryTs = Number(result?.last_entry_ts) || 0;
    const lastEntryAge = lastEntryTs > 0 ? now - lastEntryTs : null;
    
    // Rule 1: Max 3 trades per ticker per day
    if (todayTrades >= 3) {
      return {
        blocked: true,
        reason: "max_daily_trades",
        message: `Max 3 trades per ticker per day reached (${todayTrades} trades)`,
        todayTrades,
        lastEntryAge,
      };
    }
    
    // Rule 2: Minimum 30 minute cooldown between entries
    if (lastEntryAge !== null && lastEntryAge < cooldownMs) {
      const minutesRemaining = Math.ceil((cooldownMs - lastEntryAge) / 60000);
      return {
        blocked: true,
        reason: "cooldown_active",
        message: `Cooldown active: ${minutesRemaining} min remaining`,
        todayTrades,
        lastEntryAge,
        cooldownRemaining: cooldownMs - lastEntryAge,
      };
    }
    
    return {
      blocked: false,
      todayTrades,
      lastEntryAge,
    };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) {
      return { blocked: false, todayTrades: 0 };
    }
    console.error("[D1] checkTradeFrequency failed:", err);
    return { blocked: false, todayTrades: 0, error: err.message };
  }
}

/**
 * Get comprehensive position context for a ticker from D1.
 * This is the SINGLE SOURCE OF TRUTH for open position state.
 * 
 * Returns:
 * - position_id, ticker, direction, status
 * - avg_entry_price (calculated from lots)
 * - total_shares (current qty)
 * - entry_ts (first entry timestamp)
 * - realized_pnl (sum of all realized P&L)
 * - last_action (most recent action type)
 * 
 * @param {object} env - Worker environment with DB binding
 * @param {string} ticker - Ticker symbol
 * @returns {object|null} - Position context or null if no open position
 */
async function getPositionContext(env, ticker) {
  const db = env?.DB;
  if (!db || !ticker) return null;
  const sym = String(ticker).toUpperCase();
  
  try {
    // Get position with aggregated data from lots and actions
    const row = await db.prepare(`
      SELECT 
        p.position_id,
        p.ticker,
        p.direction,
        p.status,
        p.total_qty,
        p.cost_basis,
        p.stop_loss,
        p.take_profit,
        p.created_at as entry_ts,
        p.updated_at,
        p.closed_at,
        COALESCE(
          (SELECT SUM(pnl_realized) FROM execution_actions WHERE position_id = p.position_id),
          0
        ) as realized_pnl,
        (SELECT action_type FROM execution_actions WHERE position_id = p.position_id ORDER BY ts DESC LIMIT 1) as last_action,
        CASE 
          WHEN p.total_qty > 0 THEN ROUND(p.cost_basis / p.total_qty, 4)
          ELSE NULL 
        END as avg_entry_price
      FROM positions p
      WHERE p.ticker = ?1 AND p.status = 'OPEN'
      LIMIT 1
    `).bind(sym).first();
    
    if (!row) return null;
    
    return {
      position_id: row.position_id,
      ticker: row.ticker,
      direction: row.direction,
      status: row.status,
      total_shares: row.total_qty || 0,
      avg_entry_price: row.avg_entry_price || 0,
      entryPrice: row.avg_entry_price || 0,  // Alias for compatibility
      avgEntry: row.avg_entry_price || 0,    // Alias for compatibility
      cost_basis: row.cost_basis || 0,
      sl: row.stop_loss || null,              // Trailing stop loss
      tp: row.take_profit || null,            // Take profit target
      entry_ts: row.entry_ts,
      updated_at: row.updated_at,
      realized_pnl: row.realized_pnl || 0,
      last_action: row.last_action,
    };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    console.error("[D1] getPositionContext failed:", err);
    return null;
  }
}

async function d1UpdatePosition(env, position_id, updates) {
  const db = env?.DB;
  if (!db || !position_id) return { ok: false };
  try {
    const updatedAt = Number(updates.updated_at) || Date.now();
    
    // Build dynamic update based on what's provided
    const setClauses = ["updated_at = ?"];
    const params = [position_id, updatedAt];
    let paramIdx = 3;
    
    if (updates.total_qty != null) {
      setClauses.push(`total_qty = ?${paramIdx++}`);
      params.push(Number(updates.total_qty) || 0);
    }
    if (updates.cost_basis != null) {
      setClauses.push(`cost_basis = ?${paramIdx++}`);
      params.push(Number(updates.cost_basis) || 0);
    }
    if (updates.status != null) {
      setClauses.push(`status = ?${paramIdx++}`);
      params.push(String(updates.status));
    }
    if (updates.closed_at !== undefined) {
      setClauses.push(`closed_at = ?${paramIdx++}`);
      params.push(updates.closed_at != null ? Number(updates.closed_at) : null);
    }
    if (updates.stop_loss !== undefined) {
      setClauses.push(`stop_loss = ?${paramIdx++}`);
      params.push(updates.stop_loss != null && Number.isFinite(Number(updates.stop_loss)) ? Number(updates.stop_loss) : null);
    }
    if (updates.take_profit !== undefined) {
      setClauses.push(`take_profit = ?${paramIdx++}`);
      params.push(updates.take_profit != null && Number.isFinite(Number(updates.take_profit)) ? Number(updates.take_profit) : null);
    }
    
    const sql = `UPDATE positions SET ${setClauses.join(", ")} WHERE position_id = ?1`;
    await db.prepare(sql).bind(...params).run();
    
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true };
    console.error("[D1 LEDGER] position update failed:", err);
    return { ok: false, error: String(err) };
  }
}

// Update position's stop-loss in D1
async function d1UpdatePositionSL(env, ticker, newSL) {
  const db = env?.DB;
  if (!db || !ticker) return { ok: false };
  const sym = String(ticker).toUpperCase();
  try {
    await db.prepare(
      `UPDATE positions SET stop_loss = ?2, updated_at = ?3 WHERE ticker = ?1 AND status = 'OPEN'`
    ).bind(sym, Number.isFinite(newSL) ? newSL : null, Date.now()).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true };
    console.error("[D1 LEDGER] SL update failed:", err);
    return { ok: false, error: String(err) };
  }
}

/** Phase 3: Load open position from D1 as a trade-like object (for ingest). Returns null if no position or table missing. */
async function getOpenPositionAsTrade(env, ticker, direction) {
  const pos = await d1GetOpenPosition(env, ticker, direction);
  if (!pos || !pos.position_id) return null;
  const db = env?.DB;
  if (!db) return null;
  let history = [];
  try {
    const actionsRes = await db.prepare(
      `SELECT action_id, ts, action_type, qty, price, value, pnl_realized, reason
       FROM execution_actions WHERE position_id = ? ORDER BY ts ASC`
    ).bind(pos.position_id).all();
    const actions = Array.isArray(actionsRes?.results) ? actionsRes.results : [];
    history = actions.map((a) => ({
      type: a.action_type,
      timestamp: Number.isFinite(Number(a.ts)) ? new Date(Number(a.ts)).toISOString() : undefined,
      ts: a.ts,
      price: a.price,
      shares: a.qty,
      value: a.value,
      pnl_realized: a.pnl_realized,
      reason: a.reason,
    }));
  } catch (err) {
    if (err && !(err.message || "").includes("no such table")) console.error("[D1 LEDGER] getOpenPositionAsTrade actions:", err);
  }
  const totalQty = Number(pos.total_qty) || 0;
  const costBasis = Number(pos.cost_basis) || 0;
  const created = Number(pos.created_at) || 0;
  const vwap = totalQty > 0 ? costBasis / totalQty : 0;
  const realizedPnl = history.reduce((sum, ev) => sum + (Number(ev.pnl_realized) || 0), 0);
  let trimmedPct = 0;
  const trimEvents = history.filter((e) => String(e.type || "").toUpperCase() === "TRIM");
  if (trimEvents.length && totalQty > 0) {
    const trimmedQty = trimEvents.reduce((s, e) => s + (Number(e.shares) || 0), 0);
    trimmedPct = Math.min(1, trimmedQty / totalQty);
  }
  return {
    id: pos.position_id,
    trade_id: pos.position_id,
    ticker: String(pos.ticker || "").toUpperCase(),
    direction: String(pos.direction || "LONG").toUpperCase(),
    status: pos.status || "OPEN",
    entryPrice: vwap,
    entry_price: vwap,
    entry_ts: created,
    entryTime: created ? new Date(created).toISOString() : undefined,
    entryTs: created,
    shares: totalQty,
    history,
    realizedPnl,
    trimmedPct,
    pointValue: 1,
  };
}

/** GET /timed/trades?source=positions — Load from positions/lots/execution_actions (Phase 2). Returns same shape as KV. */
async function d1GetAllPositionsAsTrades(env) {
  const db = env?.DB;
  if (!db) return null;
  try {
    const posRes = await db.prepare(
      `SELECT position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at, closed_at, script_version, stop_loss, take_profit
       FROM positions ORDER BY created_at DESC`
    ).all();
    const positions = Array.isArray(posRes?.results) ? posRes.results : [];
    if (positions.length === 0) return [];

    const positionIds = positions.map((p) => p.position_id).filter(Boolean);
    const placeholders = positionIds.map(() => "?").join(",");
    const actionsRes = await db.prepare(
      `SELECT action_id, position_id, ts, action_type, qty, price, value, pnl_realized, reason
       FROM execution_actions WHERE position_id IN (${placeholders}) ORDER BY position_id, ts ASC`
    ).bind(...positionIds).all();
    const actionRows = Array.isArray(actionsRes?.results) ? actionsRes.results : [];
    const actionsByPos = {};
    for (const a of actionRows) {
      const id = a.position_id;
      if (!actionsByPos[id]) actionsByPos[id] = [];
      actionsByPos[id].push({
        type: a.action_type,
        ts: a.ts,
        timestamp: Number.isFinite(Number(a.ts)) ? new Date(Number(a.ts)).toISOString() : undefined,
        price: a.price,
        shares: a.qty,
        value: a.value,
        pnl_realized: a.pnl_realized,
        reason: a.reason,
      });
    }

    return positions.map((p) => {
      const history = actionsByPos[p.position_id] || [];
      const created = Number(p.created_at) || 0;
      
      // Calculate entry price: use VWAP if position is open, or ENTRY action price if closed
      let entryPrice = Number(p.total_qty) > 0 ? Number(p.cost_basis) / Number(p.total_qty) : null;
      const entryAction = history.find(h => h.type === "ENTRY");
      if (!entryPrice && entryAction) {
        entryPrice = entryAction.price;
      }
      
      // Calculate P&L from exit action if closed
      let pnlPct = null;
      let exitReason = null;
      let exitPrice = null;
      const exitAction = history.find(h => h.type === "EXIT");
      if (exitAction) {
        exitPrice = exitAction.price;
        exitReason = exitAction.reason;
        if (entryPrice && Number.isFinite(entryPrice) && entryPrice > 0 && Number.isFinite(exitPrice)) {
          pnlPct = p.direction === "LONG"
            ? ((exitPrice - entryPrice) / entryPrice) * 100
            : ((entryPrice - exitPrice) / entryPrice) * 100;
        }
      }
      
      return {
        id: p.position_id,
        trade_id: p.position_id,
        ticker: String(p.ticker || "").toUpperCase(),
        direction: p.direction,
        entryPrice,
        avgEntry: entryPrice,
        entry_ts: created,
        entryTime: created ? new Date(created).toISOString() : undefined,
        status: p.status,
        stop_loss: p.stop_loss,
        take_profit: p.take_profit,
        trimmedPct: null,
        pnl: null,
        pnlPct,
        exitReason,
        scriptVersion: p.script_version,
        script_version: p.script_version,
        shares: Number(p.total_qty) || 0,
        created_at: p.created_at,
        updated_at: p.updated_at,
        history,
      };
    });
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    console.error("[D1 LEDGER] d1GetAllPositionsAsTrades failed:", err);
    return null;
  }
}

/** Load all trades from D1 for simulation (same shape as KV). Includes shares from positions. */
async function d1LoadTradesForSimulation(env) {
  const db = env?.DB;
  if (!db) return null;
  try {
    let rows;
    try {
      const tradesRes = await db.prepare(
        `SELECT t.trade_id, t.ticker, t.direction, t.entry_ts, t.entry_price, t.rank, t.rr, t.status,
          t.exit_ts, t.exit_price, t.exit_reason, t.trimmed_pct, t.pnl, t.pnl_pct,
          t.script_version, t.created_at, t.updated_at, t.trim_ts, t.trim_price,
          COALESCE(p.total_qty, 0) AS pos_qty
         FROM trades t
         LEFT JOIN positions p ON p.position_id = t.trade_id
         ORDER BY t.entry_ts DESC`
      ).all();
      rows = Array.isArray(tradesRes?.results) ? tradesRes.results : [];
    } catch (joinErr) {
      if ((joinErr?.message || "").includes("no such table") && (joinErr?.message || "").includes("positions")) {
        const tradesRes = await db.prepare(
          `SELECT trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at, trim_ts, trim_price
           FROM trades ORDER BY entry_ts DESC`
        ).all();
        rows = (Array.isArray(tradesRes?.results) ? tradesRes.results : []).map((r) => ({ ...r, pos_qty: 0 }));
      } else throw joinErr;
    }
    if (rows.length === 0) return [];

    const tradeIds = rows.map((r) => r.trade_id).filter(Boolean);
    const placeholders = tradeIds.map(() => "?").join(",");
    const eventsRes = await db.prepare(
      `SELECT event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
       FROM trade_events WHERE trade_id IN (${placeholders}) ORDER BY trade_id, ts ASC`
    ).bind(...tradeIds).all();
    const eventRows = Array.isArray(eventsRes?.results) ? eventsRes.results : [];
    const eventsByTradeId = {};
    for (const e of eventRows) {
      const id = e.trade_id;
      if (!eventsByTradeId[id]) eventsByTradeId[id] = [];
      eventsByTradeId[id].push({
        type: e.type,
        ts: e.ts,
        timestamp: Number.isFinite(Number(e.ts)) ? new Date(Number(e.ts)).toISOString() : undefined,
        price: e.price != null ? Number(e.price) : undefined,
        trimPct: e.qty_pct_total,
        trimDeltaPct: e.qty_pct_delta,
        pnl_realized: e.pnl_realized != null ? Number(e.pnl_realized) : undefined,
        reason: e.reason || undefined,
        ...(e.meta_json ? (() => { try { return JSON.parse(e.meta_json); } catch { return {}; } })() : {}),
      });
    }

    return rows.map((r) => {
      const history = eventsByTradeId[r.trade_id] || [];
      const entryTs = r.entry_ts != null ? Number(r.entry_ts) : null;
      const posQty = Number(r.pos_qty) || 0;
      const trimmedPct = r.trimmed_pct != null ? Number(r.trimmed_pct) : 0;
      const shares = trimmedPct > 0 && trimmedPct < 1 && posQty > 0
        ? posQty / (1 - trimmedPct)
        : posQty;
      return {
        id: r.trade_id,
        trade_id: r.trade_id,
        ticker: String(r.ticker || "").toUpperCase(),
        direction: r.direction,
        entryPrice: r.entry_price != null ? Number(r.entry_price) : undefined,
        entry_ts: entryTs,
        entryTime: entryTs != null ? new Date(entryTs).toISOString() : undefined,
        rank: r.rank,
        rr: r.rr,
        status: r.status,
        exit_ts: r.exit_ts != null ? Number(r.exit_ts) : undefined,
        exitPrice: r.exit_price != null ? Number(r.exit_price) : undefined,
        exitReason: r.exit_reason || undefined,
        trimmedPct: r.trimmed_pct != null ? Number(r.trimmed_pct) : undefined,
        trim_ts: r.trim_ts != null ? Number(r.trim_ts) : undefined,
        trim_price: r.trim_price != null ? Number(r.trim_price) : undefined,
        pnl: r.pnl != null ? Number(r.pnl) : undefined,
        pnlPct: r.pnl_pct != null ? Number(r.pnl_pct) : undefined,
        scriptVersion: r.script_version,
        script_version: r.script_version,
        created_at: r.created_at,
        updated_at: r.updated_at,
        shares: Number.isFinite(shares) && shares > 0 ? shares : undefined,
        history,
      };
    });
  } catch (err) {
    console.error("[D1 LEDGER] d1LoadTradesForSimulation failed:", err);
    return null;
  }
}

/** GET /timed/trades?source=d1 — Alias for backward compatibility. */
async function d1GetAllTradesWithEvents(env) {
  return d1LoadTradesForSimulation(env);
}

function encodeCursor(obj) {
  try {
    const s = JSON.stringify(obj);
    if (typeof btoa === "function") return btoa(s);
    // Node fallback
    return Buffer.from(s, "utf8").toString("base64");
  } catch {
    return null;
  }
}

function decodeCursor(s) {
  if (!s) return null;
  try {
    const raw =
      typeof atob === "function"
        ? atob(String(s))
        : Buffer.from(String(s), "base64").toString("utf8");
    return JSON.parse(raw);
  } catch {
    return null;
  }
}

function parseExitReasonFromText(text) {
  const s = String(text || "").toUpperCase();
  if (!s) return null;
  if (s.includes("TDSEQ") || s.includes("TD9") || s.includes("TD13"))
    return "TDSEQ";
  // Prefer explicit SL phrasing
  if (s.includes("STOP LOSS") || s.includes("STOP-LOSS")) return "SL";
  // Avoid mapping generic "SL" inside words; still helpful for legacy notes
  if (/\bSL\b/.test(s)) return "SL";
  if (s.includes("TP_FULL")) return "TP_FULL";
  if (s.includes("TAKE PROFIT")) return "TP_FULL";
  // Avoid mapping any "TP" occurrence too aggressively
  if (/\bTP\b/.test(s)) return "TP_FULL";
  return null;
}

function parseTrimPctFromText(text) {
  const s = String(text || "");
  const m = s.match(/Trimmed\s+(\d{1,3})%/i);
  if (!m) return null;
  const pct = Number(m[1]);
  if (!Number.isFinite(pct) || pct <= 0) return null;
  return Math.max(0, Math.min(1, pct / 100));
}

function inferExitReasonForLegacyTrade(trade, exitEvent) {
  const explicit =
    (exitEvent && exitEvent.reason) ||
    (trade && trade.exitReason) ||
    (trade && trade.exit_reason);
  if (explicit) return String(explicit);

  const parsed =
    parseExitReasonFromText(exitEvent?.note) ||
    parseExitReasonFromText(exitEvent?.meta_json) ||
    parseExitReasonFromText(exitEvent?.text) ||
    parseExitReasonFromText(exitEvent?.type);
  if (parsed) return parsed;

  // Heuristic fallback for legacy trades with no reason recorded
  const status = String(trade?.status || "").toUpperCase();
  if (status === "LOSS") return "SL";
  if (status === "WIN") return "TP_FULL";
  return "unknown";
}

async function d1GetNearestTrailPayload(
  db,
  ticker,
  targetTs,
  windowMs = 2 * 60 * 60 * 1000,
) {
  if (!db) return null;
  const sym = String(ticker || "").toUpperCase();
  const ts = Number(targetTs);
  if (!sym || !Number.isFinite(ts)) return null;
  const w = Math.max(60 * 1000, Number(windowMs) || 0);
  const lo = ts - w;
  const hi = ts + w;
  try {
    const row = await db
      .prepare(
        `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1 AND ts BETWEEN ?2 AND ?3 AND payload_json IS NOT NULL
         ORDER BY ABS(ts - ?4) ASC
         LIMIT 1`,
      )
      .bind(sym, lo, hi, ts)
      .first();
    if (!row || !row.payload_json) return null;
    try {
      return {
        ts: Number(row.ts),
        payload: JSON.parse(String(row.payload_json)),
      };
    } catch {
      return null;
    }
  } catch {
    return null;
  }
}

// Activity feed tracking (1 week history)
async function appendActivity(KV, event) {
  const key = "timed:activity:feed";
  const now = Date.now();
  const oneWeekAgo = now - 7 * 24 * 60 * 60 * 1000;

  const feed = (await kvGetJSON(KV, key)) || [];

  // Add new event with timestamp
  const activityEvent = {
    ...event,
    ts: now,
    id: `${event.ticker}-${now}-${Math.random().toString(36).substr(2, 9)}`,
  };

  feed.unshift(activityEvent); // Add to beginning

  // Remove events older than 1 week
  const filtered = feed.filter((e) => e.ts > oneWeekAgo);

  // Keep max 500 events
  const keep = filtered.slice(0, 500);

  await kvPutJSON(KV, key, keep);
}

// Version management and migration
const CURRENT_DATA_VERSION = "2.5.0"; // Must match SCRIPT_VERSION in Pine Script

async function getStoredVersion(KV) {
  const versionKey = "timed:data_version";
  const stored = await KV.get(versionKey);
  return stored ? stored : null;
}

async function setStoredVersion(KV, version) {
  const versionKey = "timed:data_version";
  await kvPutText(KV, versionKey, version);
}

async function checkAndMigrate(KV, incomingVersion) {
  const storedVersion = await getStoredVersion(KV);
  return checkAndMigrateWithStoredVersion(KV, storedVersion, incomingVersion);
}

async function checkAndMigrateWithStoredVersion(
  KV,
  storedVersion,
  incomingVersion,
) {
  // If no stored version, this is first run - set it and continue
  if (!storedVersion) {
    await setStoredVersion(KV, incomingVersion);
    return { migrated: false, reason: "initial_setup" };
  }

  // If versions match, no migration needed
  if (storedVersion === incomingVersion) {
    return { migrated: false, reason: "version_match" };
  }

  // Version changed - trigger migration
  console.log(
    `Version change detected: ${storedVersion} -> ${incomingVersion}`,
  );

  // Get tickers before purging (for archive)
  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];

  // Archive old data (optional - store timestamp of migration)
  const archiveKey = `timed:archive:${storedVersion}:${Date.now()}`;
  const archiveData = {
    version: storedVersion,
    migratedAt: Date.now(),
    tickerCount: tickers.length,
    tickers: tickers.slice(0, 10), // Store sample of tickers for reference
  };
  await kvPutJSON(KV, archiveKey, archiveData, 30 * 24 * 60 * 60); // Keep archive for 30 days

  // Purge old data
  const purgeResult = await purgeOldData(KV);

  // Update to new version
  await setStoredVersion(KV, incomingVersion);

  return {
    migrated: true,
    reason: "version_changed",
    oldVersion: storedVersion,
    newVersion: incomingVersion,
    archived: true,
    tickerCount: purgeResult.tickerCount,
    purged: purgeResult.purged,
  };
}

async function purgeOldData(KV) {
  // Get tickers BEFORE clearing the index
  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
  const tickerCount = tickers.length;

  // Build all delete operations in parallel for faster execution
  const deletePromises = [];

  // Clear ticker index first (to prevent race conditions)
  deletePromises.push(KV.delete("timed:tickers"));

  // Create all delete operations for each ticker in parallel
  for (const ticker of tickers) {
    // Latest data
    deletePromises.push(KV.delete(`timed:latest:${ticker}`));
    // Trails
    deletePromises.push(KV.delete(`timed:trail:${ticker}`));
    // Momentum data (all keys)
    deletePromises.push(KV.delete(`timed:momentum:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:marketcap:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:adr:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:volume:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:changes:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:history:${ticker}`));
    // State tracking
    deletePromises.push(KV.delete(`timed:prevstate:${ticker}`));
    // Additional state tracking keys
    deletePromises.push(KV.delete(`timed:prevcorridor:${ticker}`));
    deletePromises.push(KV.delete(`timed:prevsqueeze:${ticker}`));
    deletePromises.push(KV.delete(`timed:prevsqueezerel:${ticker}`));
    deletePromises.push(KV.delete(`timed:prevmomentumelite:${ticker}`));
  }

  // Execute all deletes in parallel (much faster than sequential)
  await Promise.all(deletePromises);

  return { purged: tickerCount, tickerCount };
}

async function ensureCaptureIndex(KV, ticker) {
  try {
    const key = "timed:capture:tickers";
    const existing = (await kvGetJSON(KV, key)) || [];
    const upper = String(ticker || "").toUpperCase();
    if (!upper) return;
    if (!existing.includes(upper)) {
      existing.push(upper);
      existing.sort();
      await kvPutJSON(KV, key, existing);
    }
  } catch (err) {
    console.error(`[CAPTURE INDEX] Failed to update index:`, err);
  }
}

// Helper: Generate natural language interpretation for trade actions
function generateTradeActionInterpretation(
  action,
  tickerData,
  trade = null,
  trimPct = null,
) {
  const ticker = tickerData.ticker || "UNKNOWN";
  const direction =
    trade?.direction ||
    (tickerData.state?.includes("BULL")
      ? "LONG"
      : tickerData.state?.includes("BEAR")
        ? "SHORT"
        : null);
  const state = tickerData.state || "";
  const flags = tickerData.flags || {};
  const htfScore = Number(tickerData.htf_score || 0);
  const ltfScore = Number(tickerData.ltf_score || 0);
  const completion = Number(tickerData.completion || 0);
  const phase = Number(tickerData.phase_pct || 0);
  const rr = Number(tickerData.rr || trade?.rr || 0);
  const rank = Number(tickerData.rank || trade?.rank || 0);
  const sqRel = !!flags.sq30_release;
  const sqOn = !!flags.sq30_on;
  const momentumElite = !!flags.momentum_elite;
  const tdSeq = tickerData.td_sequential || {};
  const rsi = tickerData.rsi || {};
  const fourHEMACloud = tickerData.fourh_ema_cloud || {};

  let reasons = [];
  let actionText = "";

  if (action === "ENTRY") {
    actionText = `**Entering a ${direction} position** because:`;

    // State-based reasons
    if (state === "HTF_BULL_LTF_BULL") {
      reasons.push(
        "✅ **HTF and LTF are both bullish** - Strong alignment in favor of upward movement",
      );
    } else if (state === "HTF_BEAR_LTF_BEAR") {
      reasons.push(
        "✅ **HTF and LTF are both bearish** - Strong alignment in favor of downward movement",
      );
    } else if (state === "HTF_BULL_LTF_PULLBACK") {
      reasons.push(
        "✅ **HTF bullish with LTF pullback** - Prime setup for long entry on pullback",
      );
    } else if (state === "HTF_BEAR_LTF_PULLBACK") {
      reasons.push(
        "✅ **HTF bearish with LTF pullback** - Prime setup for short entry on pullback",
      );
    }

    // Score-based reasons
    if (htfScore >= 25) {
      reasons.push(
        `📈 **Strong HTF score (${htfScore.toFixed(
          1,
        )})** - High timeframe momentum is very favorable`,
      );
    } else if (htfScore >= 15) {
      reasons.push(
        `📈 **Good HTF score (${htfScore.toFixed(
          1,
        )})** - High timeframe momentum is favorable`,
      );
    }

    if (ltfScore >= 20) {
      reasons.push(
        `📊 **Strong LTF score (${ltfScore.toFixed(
          1,
        )})** - Low timeframe momentum is very favorable`,
      );
    } else if (ltfScore >= 12) {
      reasons.push(
        `📊 **Good LTF score (${ltfScore.toFixed(
          1,
        )})** - Low timeframe momentum is favorable`,
      );
    }

    // Squeeze reasons
    if (sqRel) {
      reasons.push(
        "🚀 **Squeeze release detected** - Momentum breakout from compression, strong directional move expected",
      );
    } else if (sqOn) {
      reasons.push(
        "💥 **In squeeze** - Building energy for potential explosive move",
      );
    }

    // Completion reasons
    if (completion <= 0.2) {
      reasons.push(
        `🎯 **Early in move (${(completion * 100).toFixed(
          0,
        )}% complete)** - Plenty of room to run`,
      );
    } else if (completion <= 0.4) {
      reasons.push(
        `🎯 **Good entry timing (${(completion * 100).toFixed(
          0,
        )}% complete)** - Still early in the move`,
      );
    }

    // Phase reasons
    if (phase <= 0.3) {
      reasons.push(
        `⚡ **Early phase (${(phase * 100).toFixed(
          0,
        )}%)** - Strong momentum building`,
      );
    }

    // RR reasons
    if (rr >= 2.0) {
      reasons.push(
        `💰 **Excellent Risk/Reward (${rr.toFixed(
          2,
        )}:1)** - High potential reward relative to risk`,
      );
    } else if (rr >= 1.5) {
      reasons.push(
        `💰 **Good Risk/Reward (${rr.toFixed(
          2,
        )}:1)** - Favorable reward relative to risk`,
      );
    }

    // Rank reasons
    if (rank >= 80) {
      reasons.push(
        `⭐ **Top-ranked setup (Rank: ${rank})** - One of the best opportunities in the watchlist`,
      );
    } else if (rank >= 70) {
      reasons.push(
        `⭐ **High-ranked setup (Rank: ${rank})** - Strong opportunity`,
      );
    }

    // Momentum Elite
    if (momentumElite) {
      reasons.push(
        "🚀 **Momentum Elite** - High-quality momentum stock with strong fundamentals",
      );
    }

    // TD Sequential
    if (tdSeq.td9_bullish && direction === "LONG") {
      reasons.push(
        "🔢 **TD9 Bullish signal** - DeMark exhaustion pattern suggests upward reversal",
      );
    } else if (tdSeq.td9_bearish && direction === "SHORT") {
      reasons.push(
        "🔢 **TD9 Bearish signal** - DeMark exhaustion pattern suggests downward reversal",
      );
    }

    // RSI Divergence
    if (rsi.divergence?.type === "bullish" && direction === "LONG") {
      reasons.push(
        "📊 **RSI Bullish Divergence** - Price making lower lows while RSI makes higher lows, suggesting upward reversal",
      );
    } else if (rsi.divergence?.type === "bearish" && direction === "SHORT") {
      reasons.push(
        "📊 **RSI Bearish Divergence** - Price making higher highs while RSI makes lower highs, suggesting downward reversal",
      );
    }

    // EMA Cloud position
    if (fourHEMACloud.position === "above" && direction === "LONG") {
      reasons.push(
        "☁️ **Price above 4H EMA cloud** - Strong trend continuation signal",
      );
    } else if (fourHEMACloud.position === "below" && direction === "SHORT") {
      reasons.push(
        "☁️ **Price below 4H EMA cloud** - Strong trend continuation signal",
      );
    }
  } else if (action === "TRIM") {
    const trimPercent = Math.round((trimPct || 0.5) * 100);
    actionText = `**Trimming ${trimPercent}%** because:`;

    reasons.push(
      `🎯 **Take Profit level hit** - Price reached TP target, locking in ${trimPercent}% of profits`,
    );

    if (trimPct === 0.25) {
      reasons.push(
        "📈 **First trim (25%)** - Securing initial profits while letting the rest run",
      );
    } else if (trimPct === 0.5) {
      reasons.push(
        "📈 **Second trim (50%)** - Locking in half the position, remaining 50% continues to run",
      );
    } else if (trimPct === 0.75) {
      reasons.push(
        "📈 **Third trim (75%)** - Securing most profits, trailing stop on remaining 25%",
      );
    }

    // EMA Cloud position for hold decision
    if (fourHEMACloud.position === "above" && direction === "LONG") {
      reasons.push(
        "☁️ **Price still above 4H EMA cloud** - Trend intact, holding remaining position",
      );
    } else if (fourHEMACloud.position === "below" && direction === "SHORT") {
      reasons.push(
        "☁️ **Price still below 4H EMA cloud** - Trend intact, holding remaining position",
      );
    }
  } else if (action === "CLOSE") {
    // Simplified: the embed now handles exit reason and P&L display directly.
    // This function just provides the "why" context.
    const exitReason = trade?.exitReason || null;
    actionText = `**Closing position**`;

    if (exitReason === "TDSEQ") {
      reasons.push("TD Sequential exhaustion detected");
    } else if (exitReason === "SL" || exitReason === "sl_breached") {
      reasons.push("Stop loss triggered");
    } else if (exitReason === "TP_FULL") {
      reasons.push("All take profit levels achieved");
    } else if (exitReason === "max_loss") {
      reasons.push("Max loss threshold reached");
    }
  }

  // If no reasons found, add generic ones
  if (reasons.length === 0) {
    reasons.push(
      "📊 **System signal detected** - Automated trade management triggered",
    );
  }

  return {
    action: actionText,
    reasons: reasons.join("\n"),
  };
}

// Helper: Create Discord embed for trade entry
function createTradeEntryEmbed(
  ticker,
  direction,
  entryPrice,
  sl,
  tp,
  rr,
  rank,
  state,
  currentPrice = null,
  isBackfill = false,
  tickerData = null,
  execution = null, // { qty, value, pnl } for verifiable history
) {
  const color = direction === "LONG" ? 0x00ff00 : 0xff0000;

  // Build concise description
  const slDist = Number.isFinite(sl) && entryPrice > 0
    ? (Math.abs(entryPrice - sl) / entryPrice * 100).toFixed(1)
    : null;
  const descParts = [`${direction} at $${entryPrice.toFixed(2)}`];
  if (Number.isFinite(rr) && rr > 0) descParts.push(`R:R ${rr.toFixed(1)}:1`);
  if (slDist) descParts.push(`SL ${slDist}% away`);
  const description = descParts.join(" | ");

  const fields = [];

  // 1. Entry/SL/TP block
  const entryLines = [`**Entry:** $${entryPrice.toFixed(2)} | **SL:** $${sl.toFixed(2)} | **TP:** $${tp.toFixed(2)}`];
  if (execution && Number.isFinite(execution.qty)) {
    entryLines.push(`**Qty:** ${execution.qty.toFixed(4)} | **Value:** $${Number(execution.value || 0).toFixed(2)}`);
  }
  fields.push({ name: "💰 Position", value: entryLines.join("\n"), inline: false });

  // 2. Scores (single consolidated field)
  if (tickerData) {
    const htf = Number(tickerData.htf_score || 0);
    const ltf = Number(tickerData.ltf_score || 0);
    const comp = Number(tickerData.completion || 0);
    const phase = Number(tickerData.phase_pct || 0);
    const scoreParts = [`HTF ${htf.toFixed(1)} | LTF ${ltf.toFixed(1)}`];
    if (Number.isFinite(comp)) scoreParts.push(`Comp ${(comp * 100).toFixed(0)}%`);
    if (Number.isFinite(phase)) scoreParts.push(`Phase ${(phase * 100).toFixed(0)}%`);
    fields.push({ name: "📈 Scores", value: scoreParts.join(" | "), inline: true });
  }

  // 3. Quality (rank + R:R + state)
  const qualParts = [];
  if (Number.isFinite(rank) && rank > 0) qualParts.push(`**Rank:** ${rank}`);
  if (Number.isFinite(rr) && rr > 0) qualParts.push(`**R:R:** ${rr.toFixed(2)}:1`);
  if (state) qualParts.push(`**State:** ${state}`);
  if (qualParts.length > 0) {
    fields.push({ name: "⭐ Quality", value: qualParts.join("\n"), inline: true });
  }

  // 4. Active signals (consolidated: flags + TD + RSI divergence)
  const signalItems = [];
  if (tickerData?.flags) {
    const f = tickerData.flags;
    if (f.sq30_release) signalItems.push("Squeeze Release");
    else if (f.sq30_on) signalItems.push("In Squeeze");
    if (f.momentum_elite) signalItems.push("Momentum Elite");
  }
  if (tickerData?.td_sequential) {
    const td = tickerData.td_sequential;
    if (td.td9_bullish || td.td9_bearish) signalItems.push("TD9");
    if (td.td13_bullish || td.td13_bearish) signalItems.push("TD13");
  }
  if (tickerData?.rsi?.divergence?.type && tickerData.rsi.divergence.type !== "none") {
    signalItems.push(`RSI ${tickerData.rsi.divergence.type} div`);
  }
  if (signalItems.length > 0) {
    fields.push({ name: "🚩 Signals", value: signalItems.join(" | "), inline: false });
  }

  return {
    title: `🎯 Trade Entered: ${ticker} ${direction}${isBackfill ? " (backfill)" : ""}`,
    description: description,
    color: color,
    fields: fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Timed Trading Simulator" },
  };
}

// Helper: Create Discord embed for trade trimmed
function createTradeTrimmedEmbed(
  ticker,
  direction,
  entryPrice,
  currentPrice,
  tp,
  pnl,
  pnlPct,
  trimmedPct = 0.5,
  tickerData = null,
  trade = null,
  trimDeltaPct = null,
  execution = null, // { qty, value, pnl } for verifiable history
) {
  const trimPercent = Math.round(trimmedPct * 100);
  const remainingPct = Math.round((1 - trimmedPct) * 100);
  const stepPct = Number.isFinite(trimDeltaPct) ? Math.round(trimDeltaPct * 100) : null;

  // Next TP level
  const nextTp = (trade?.tpArray && Array.isArray(trade.tpArray))
    ? [...trade.tpArray]
        .map(x => ({ price: Number(x?.price), trimPct: Number(x?.trimPct), label: x?.label }))
        .filter(x => Number.isFinite(x.price) && Number.isFinite(x.trimPct))
        .sort((a, b) => a.trimPct - b.trimPct)
        .find(x => x.trimPct > trimmedPct + 1e-6) || null
    : null;

  // Concise description
  const descParts = [];
  if (stepPct) descParts.push(`Trimmed ${stepPct}%`);
  descParts.push(`${trimPercent}% total`);
  descParts.push(`${remainingPct}% remaining`);
  const description = descParts.join(" | ");

  const fields = [];

  // 1. Position + P&L (merged)
  const posLines = [
    `**Entry:** $${entryPrice.toFixed(2)} | **Current:** $${currentPrice.toFixed(2)} | **TP:** $${tp.toFixed(2)}`,
    `**P&L:** ${pnl >= 0 ? "+" : ""}$${pnl.toFixed(2)} (${pnlPct >= 0 ? "+" : ""}${pnlPct.toFixed(2)}%)`,
  ];
  if (execution && Number.isFinite(execution.qty)) {
    posLines.push(`**Qty trimmed:** ${Number(execution.qty).toFixed(4)} | **Value:** $${Number(execution.value || 0).toFixed(2)}`);
  }
  fields.push({ name: "💰 Position & P&L", value: posLines.join("\n"), inline: false });

  // 2. Trim Status
  const statusParts = [`**Trimmed:** ${trimPercent}% | **Remaining:** ${remainingPct}%`];
  if (nextTp) {
    statusParts.push(`**Next TP:** $${nextTp.price.toFixed(2)} (${Math.round(nextTp.trimPct * 100)}% - ${nextTp.label || "next tier"})`);
  }
  fields.push({ name: "✂️ Trim Status", value: statusParts.join("\n"), inline: false });

  return {
    title: `✂️ Trade Trimmed: ${ticker} ${direction} - ${trimPercent}%`,
    description: description,
    color: 0xffaa00,
    fields: fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Timed Trading Simulator" },
  };
}

// Helper: Create Discord embed for trade closed
function createTradeClosedEmbed(
  ticker,
  direction,
  status,
  entryPrice,
  exitPrice,
  pnl,
  pnlPct,
  rank,
  rr,
  tickerData = null,
  trade = null,
  execution = null, // { qty, value, pnl } for verifiable history
) {
  const color = status === "WIN" ? 0x00ff00 : 0xff0000;
  const emoji = status === "WIN" ? "✅" : "❌";

  // Always compute P&L% from prices (fixes 0.00% bug when trade.pnlPct not set)
  const computedPnlPct = Number.isFinite(entryPrice) && entryPrice > 0
    ? ((exitPrice - entryPrice) / entryPrice) * 100
    : Number(pnlPct) || 0;
  const finalPnlPct = Math.abs(computedPnlPct) > 0.001 ? computedPnlPct : (Number(pnlPct) || 0);

  // Map exit reason to human-readable text
  const exitReason = trade?.exitReason || null;
  const exitReasonMap = {
    sl_breached: "Stop Loss Hit",
    SL: "Stop Loss Hit",
    TDSEQ: "TD Sequential Exhaustion",
    TP_FULL: "All TP Levels Hit",
    max_loss: "Max Loss Threshold",
    critical: "Critical Invalidation",
  };
  const humanExitReason = exitReason
    ? (exitReasonMap[exitReason] || exitReason.replace(/_/g, " "))
    : null;

  // Build concise description (1-line "why")
  const descParts = [];
  if (humanExitReason) descParts.push(humanExitReason);
  descParts.push(`$${exitPrice.toFixed(2)} (${finalPnlPct >= 0 ? "+" : ""}${finalPnlPct.toFixed(2)}%)`);
  const description = descParts.join(" at ");

  // Build fields (max 5)
  const fields = [];

  // 1. Trade Summary: entry/exit/P&L in one block
  const summaryLines = [
    `**Entry:** $${entryPrice.toFixed(2)} | **Exit:** $${exitPrice.toFixed(2)}`,
    `**P&L:** ${pnl >= 0 ? "+" : ""}$${pnl.toFixed(2)} (${finalPnlPct >= 0 ? "+" : ""}${finalPnlPct.toFixed(2)}%)`,
  ];
  if (execution && Number.isFinite(execution.qty)) {
    summaryLines.push(`**Qty:** ${Number(execution.qty).toFixed(4)} | **Value:** $${Number(execution.value || 0).toFixed(2)}`);
  }
  fields.push({ name: "💰 Trade Summary", value: summaryLines.join("\n"), inline: false });

  // 2. Exit Reason (if available)
  if (humanExitReason) {
    fields.push({ name: "📌 Exit Reason", value: humanExitReason, inline: true });
  }

  // 3. Price Movement
  const priceChange = exitPrice - entryPrice;
  fields.push({
    name: "📈 Price Movement",
    value: `${priceChange >= 0 ? "+" : ""}$${priceChange.toFixed(2)} (${finalPnlPct >= 0 ? "+" : ""}${finalPnlPct.toFixed(2)}%)`,
    inline: true,
  });

  // 4. Quality Metrics (only if values are meaningful)
  const metricParts = [];
  if (Number.isFinite(rank) && rank > 0) metricParts.push(`**Rank:** ${rank}`);
  if (Number.isFinite(rr) && rr > 0) metricParts.push(`**R:R:** ${rr.toFixed(2)}:1`);
  if (metricParts.length > 0) {
    fields.push({ name: "⭐ Metrics", value: metricParts.join(" | "), inline: true });
  }

  return {
    title: `${emoji} Trade Closed: ${ticker} ${direction} - ${status}`,
    description: description,
    color: color,
    fields: fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Timed Trading Simulator" },
  };
}

// [DEPRECATED] createTD9ExitEmbed — TD exit context now folded into createTradeClosedEmbed
// [DEPRECATED] createTDSeqDefenseEmbed — TD defense context now folded into createKanbanStageEmbed (defend stage)

// Helper: Create Discord embed for Kanban stage transition
function createKanbanStageEmbed(ticker, stage, prevStage, tickerData = null, openTrade = null) {
  const stageLabels = {
    enter: "🎯 Enter",
    enter_now: "🎯 Enter",
    hold: "📌 Hold",
    defend: "🛡️ Defend",
    trim: "✂️ Trim",
    exit: "🚪 Exit",
  };
  const label = stageLabels[stage] || stage?.replace(/_/g, " ").toUpperCase();
  const direction =
    tickerData?.state?.includes("BULL") ? "LONG"
    : tickerData?.state?.includes("BEAR") ? "SHORT"
    : openTrade?.direction || null;
  const price = Number(tickerData?.price);
  const rr = Number(tickerData?.rr);
  const rank = Number(tickerData?.rank ?? tickerData?.score);

  // Color by stage
  const color =
    stage === "enter_now" || stage === "enter" ? 0x22c55e
    : stage === "defend" ? 0xf59e0b
    : stage === "trim" ? 0x8b5cf6
    : stage === "exit" ? 0xef4444
    : 0x3b82f6;

  // Build concise description
  const descParts = [];
  if (direction) descParts.push(direction);
  if (Number.isFinite(price) && price > 0) descParts.push(`$${price.toFixed(2)}`);
  const description = descParts.length > 0 ? descParts.join(" | ") : `Stage: ${stage}`;

  const fields = [];

  // For ENTER: show scoring context (absorbs ALERT_ENTRY + TD9_ENTRY info)
  if (stage === "enter" || stage === "enter_now") {
    const entryParts = [];
    if (Number.isFinite(rr) && rr > 0) entryParts.push(`**R:R:** ${rr.toFixed(2)}:1`);
    if (Number.isFinite(rank) && rank > 0) entryParts.push(`**Rank:** ${rank}`);
    if (tickerData) {
      const htf = Number(tickerData.htf_score || 0);
      const ltf = Number(tickerData.ltf_score || 0);
      entryParts.push(`**HTF:** ${htf.toFixed(1)} | **LTF:** ${ltf.toFixed(1)}`);
    }
    if (entryParts.length > 0) {
      fields.push({ name: "📈 Entry Signal", value: entryParts.join("\n"), inline: false });
    }
    // Signals (TD, squeeze, etc.)
    const sigs = [];
    if (tickerData?.td_sequential) {
      const td = tickerData.td_sequential;
      if (td.td9_bullish || td.td9_bearish) sigs.push("TD9");
      if (td.td13_bullish || td.td13_bearish) sigs.push("TD13");
    }
    if (tickerData?.flags?.sq30_release) sigs.push("Squeeze Release");
    if (tickerData?.flags?.momentum_elite) sigs.push("Momentum Elite");
    if (sigs.length > 0) {
      fields.push({ name: "🚩 Signals", value: sigs.join(" | "), inline: true });
    }
    // TradingView link (absorbed from deprecated ALERT_ENTRY)
    if (ticker) {
      fields.push({
        name: "📊 Chart",
        value: `[TradingView](https://www.tradingview.com/chart/?symbol=${encodeURIComponent(ticker)})`,
        inline: true,
      });
    }
  }

  // For DEFEND: show what triggered it + P&L + SL context (absorbs TDSEQ_DEFENSE)
  if (stage === "defend" && openTrade) {
    const entryPx = Number(openTrade.entryPrice);
    const pnlPct = Number.isFinite(entryPx) && entryPx > 0 && Number.isFinite(price)
      ? ((price - entryPx) / entryPx * 100 * (openTrade.direction === "SHORT" ? -1 : 1))
      : null;
    const defendParts = [];
    if (Number.isFinite(pnlPct)) defendParts.push(`**P&L:** ${pnlPct >= 0 ? "+" : ""}${pnlPct.toFixed(2)}%`);
    if (Number.isFinite(entryPx)) defendParts.push(`**Entry:** $${entryPx.toFixed(2)}`);
    const sl = Number(openTrade.sl);
    if (Number.isFinite(sl)) defendParts.push(`**SL:** $${sl.toFixed(2)}`);
    if (defendParts.length > 0) {
      fields.push({ name: "🛡️ Position", value: defendParts.join(" | "), inline: false });
    }
    // TD context if present
    if (tickerData?.td_sequential) {
      const td = tickerData.td_sequential;
      const tdSigs = [];
      if (td.td9_bullish || td.td9_bearish) tdSigs.push("TD9 active");
      if (td.td13_bullish || td.td13_bearish) tdSigs.push("TD13 active");
      if (tdSigs.length > 0) {
        fields.push({ name: "🔢 TD Sequential", value: tdSigs.join(" | "), inline: true });
      }
    }
  }

  // For TRIM/EXIT: show P&L context
  if ((stage === "trim" || stage === "exit") && openTrade) {
    const entryPx = Number(openTrade.entryPrice);
    const pnlPct = Number.isFinite(entryPx) && entryPx > 0 && Number.isFinite(price)
      ? ((price - entryPx) / entryPx * 100 * (openTrade.direction === "SHORT" ? -1 : 1))
      : null;
    const posParts = [];
    if (Number.isFinite(pnlPct)) posParts.push(`**P&L:** ${pnlPct >= 0 ? "+" : ""}${pnlPct.toFixed(2)}%`);
    if (Number.isFinite(entryPx)) posParts.push(`**Entry:** $${entryPx.toFixed(2)}`);
    const trimmedPct = Number(openTrade.trimmedPct);
    if (Number.isFinite(trimmedPct) && trimmedPct > 0) posParts.push(`**Trimmed:** ${Math.round(trimmedPct * 100)}%`);
    if (posParts.length > 0) {
      fields.push({ name: "💰 Position", value: posParts.join(" | "), inline: false });
    }
    // Metrics
    const completion = Number(tickerData?.completion) * 100;
    const phase = Number(tickerData?.phase_pct) * 100;
    const metricParts = [];
    if (Number.isFinite(completion)) metricParts.push(`Comp ${completion.toFixed(0)}%`);
    if (Number.isFinite(phase)) metricParts.push(`Phase ${phase.toFixed(0)}%`);
    if (metricParts.length > 0) {
      fields.push({ name: "📈 Metrics", value: metricParts.join(" | "), inline: true });
    }
  }

  return {
    title: `${label}: ${ticker}`,
    description: description,
    color,
    fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Kanban Lane Transition" },
  };
}

// [DEPRECATED] createTD9EntryEmbed — TD entry context now folded into createKanbanStageEmbed (enter stage)
// [DEPRECATED] createFlipWatchEmbed — Flip watch now routes to "setup" kanban stage

// ─────────────────────────────────────────────────────────────
// Sector Mapping & Ratings
// ─────────────────────────────────────────────────────────────

const SECTOR_MAP = {
  // Consumer Discretionary
  AMZN: "Consumer Discretionary",
  TSLA: "Consumer Discretionary",
  NKE: "Consumer Discretionary",
  TJX: "Consumer Discretionary",
  HD: "Consumer Discretionary",
  MCD: "Consumer Discretionary",
  SBUX: "Consumer Discretionary",
  LOW: "Consumer Discretionary",
  BKNG: "Consumer Discretionary",
  CMG: "Consumer Discretionary",
  ABNB: "Consumer Discretionary",
  EXPE: "Consumer Discretionary",
  RBLX: "Consumer Discretionary",
  ULTA: "Consumer Discretionary",
  SHOP: "Consumer Discretionary",
  // Industrials
  CAT: "Industrials",
  GE: "Industrials",
  BA: "Industrials",
  HON: "Industrials",
  RTX: "Industrials",
  EMR: "Industrials",
  ETN: "Industrials",
  DE: "Industrials",
  PH: "Industrials",
  CSX: "Industrials",
  UNP: "Industrials",
  UPS: "Industrials",
  FDX: "Industrials",
  LMT: "Industrials",
  NOC: "Industrials",
  GD: "Industrials",
  TT: "Industrials",
  PWR: "Industrials",
  AWI: "Industrials",
  WTS: "Industrials",
  DY: "Industrials",
  FIX: "Industrials",
  ITT: "Industrials",
  STRL: "Industrials",
  // Information Technology
  AAPL: "Information Technology",
  MSFT: "Information Technology",
  NVDA: "Information Technology",
  AVGO: "Information Technology",
  AMD: "Information Technology",
  ORCL: "Information Technology",
  CRM: "Information Technology",
  ADBE: "Information Technology",
  INTC: "Information Technology",
  CSCO: "Information Technology",
  QCOM: "Information Technology",
  TXN: "Information Technology",
  AMAT: "Information Technology",
  LRCX: "Information Technology",
  KLAC: "Information Technology",
  ANET: "Information Technology",
  CDNS: "Information Technology",
  CRWD: "Information Technology",
  PANW: "Information Technology",
  PLTR: "Information Technology",
  MDB: "Information Technology",
  PATH: "Information Technology",
  QLYS: "Information Technology",
  PEGA: "Information Technology",
  IOT: "Information Technology",
  PSTG: "Information Technology",
  MU: "Information Technology",
  APLD: "Information Technology",
  // Communication Services
  META: "Communication Services",
  GOOGL: "Communication Services",
  GOOG: "Communication Services",
  NFLX: "Communication Services",
  DIS: "Communication Services",
  CMCSA: "Communication Services",
  VZ: "Communication Services",
  T: "Communication Services",
  TWLO: "Communication Services",
  RDDT: "Communication Services",
  // Basic Materials
  LIN: "Basic Materials",
  APD: "Basic Materials",
  ECL: "Basic Materials",
  SHW: "Basic Materials",
  PPG: "Basic Materials",
  FCX: "Basic Materials",
  NEM: "Basic Materials",
  ALB: "Basic Materials",
  MP: "Basic Materials",
  NEU: "Basic Materials",
  AU: "Basic Materials",
  CCJ: "Basic Materials",
  RGLD: "Basic Materials",
  SN: "Basic Materials",
  // Energy
  XOM: "Energy",
  CVX: "Energy",
  SLB: "Energy",
  EOG: "Energy",
  COP: "Energy",
  MPC: "Energy",
  PSX: "Energy",
  VST: "Energy",
  FSLR: "Energy",
  // Financials
  JPM: "Financials",
  BAC: "Financials",
  WFC: "Financials",
  GS: "Financials",
  MS: "Financials",
  C: "Financials",
  AXP: "Financials",
  COF: "Financials",
  SPGI: "Financials",
  MCO: "Financials",
  BLK: "Financials",
  SCHW: "Financials",
  PNC: "Financials",
  BK: "Financials",
  TFC: "Financials",
  USB: "Financials",
  ALLY: "Financials",
  EWBC: "Financials",
  WAL: "Financials",
  SOFI: "Financials",
  HOOD: "Financials",
  // Real Estate
  AMT: "Real Estate",
  PLD: "Real Estate",
  EQIX: "Real Estate",
  PSA: "Real Estate",
  WELL: "Real Estate",
  SPG: "Real Estate",
  O: "Real Estate",
  DLR: "Real Estate",
  VICI: "Real Estate",
  EXPI: "Real Estate",
  // Consumer Staples
  PG: "Consumer Staples",
  KO: "Consumer Staples",
  PEP: "Consumer Staples",
  WMT: "Consumer Staples",
  COST: "Consumer Staples",
  MDLZ: "Consumer Staples",
  CL: "Consumer Staples",
  KMB: "Consumer Staples",
  STZ: "Consumer Staples",
  TGT: "Consumer Staples",
  // Health Care
  UNH: "Health Care",
  JNJ: "Health Care",
  LLY: "Health Care",
  ABBV: "Health Care",
  MRK: "Health Care",
  TMO: "Health Care",
  ABT: "Health Care",
  DHR: "Health Care",
  BMY: "Health Care",
  AMGN: "Health Care",
  GILD: "Health Care",
  REGN: "Health Care",
  VRTX: "Health Care",
  BIIB: "Health Care",
  UTHR: "Health Care",
  HIMS: "Health Care",
  NBIS: "Health Care",
  // Utilities
  NEE: "Utilities",
  DUK: "Utilities",
  SO: "Utilities",
  D: "Utilities",
  AEP: "Utilities",
  SRE: "Utilities",
  EXC: "Utilities",
  XEL: "Utilities",
  WEC: "Utilities",
  ES: "Utilities",
  PEG: "Utilities",
  ETR: "Utilities",
  FE: "Utilities",
  AEE: "Utilities",
};

const SECTOR_RATINGS = {
  "Consumer Discretionary": { rating: "neutral", boost: 0 },
  Industrials: { rating: "overweight", boost: 5 },
  "Information Technology": { rating: "neutral", boost: 0 },
  "Communication Services": { rating: "neutral", boost: 0 },
  "Basic Materials": { rating: "neutral", boost: 0 },
  Energy: { rating: "overweight", boost: 5 },
  Financials: { rating: "overweight", boost: 5 },
  "Real Estate": { rating: "underweight", boost: -3 },
  "Consumer Staples": { rating: "underweight", boost: -3 },
  Healthcare: { rating: "overweight", boost: 5 }, // Fixed: "Health Care" -> "Healthcare" to match SECTOR_MAP
  Utilities: { rating: "overweight", boost: 5 },
};

function getSector(ticker) {
  return SECTOR_MAP[ticker?.toUpperCase()] || null;
}

// Load sector mappings from KV (called on startup)
async function loadSectorMappingsFromKV(KV) {
  try {
    if (!KV) {
      console.log(
        `[SECTOR LOAD] KV not available, skipping sector mapping load`,
      );
      return;
    }
    // Get all tickers from watchlist
    const tickersList = await KV.get("timed:tickers", "json");
    if (!tickersList || !Array.isArray(tickersList)) {
      console.log(`[SECTOR LOAD] No tickers list found in KV, skipping`);
      return;
    }

    let loadedCount = 0;
    for (const ticker of tickersList) {
      const tickerUpper = String(ticker).toUpperCase();
      const sectorKey = `timed:sector_map:${tickerUpper}`;
      const sector = await KV.get(sectorKey, "text");

      if (sector && sector.trim() !== "") {
        SECTOR_MAP[tickerUpper] = sector.trim();
        loadedCount++;
      }
    }

    if (loadedCount > 0) {
      console.log(
        `[SECTOR LOAD] Loaded ${loadedCount} sector mappings from KV`,
      );
    }
  } catch (err) {
    console.error(`[SECTOR LOAD] Error loading sector mappings:`, err);
  }
}

function getSectorRating(sector) {
  return SECTOR_RATINGS[sector] || { rating: "neutral", boost: 0 };
}

function getTickersInSector(sector) {
  return Object.keys(SECTOR_MAP).filter(
    (ticker) => SECTOR_MAP[ticker] === sector,
  );
}

// ═══════════════════════════════════════════════════════════════════════════
// SECTOR ALIGNMENT: Measures HTF consensus across all tickers in a sector.
// When multiple tickers in the same sector are HTF aligned, entries in that
// sector have higher conviction and positions deserve more patience.
//
// REAL WORLD VALIDATION (2/5/26): NVDA, AVGO, TSM all flagged LONG at open.
// They dipped initially but recovered strongly because the ENTIRE semiconductor
// sector was HTF bullish (SOXL +28.77, LRCX +27.35, ON +25.26, TSM +24.46,
// INTC +22.59, KLAC +17.48). Sector alignment predicted the recovery.
// ═══════════════════════════════════════════════════════════════════════════

// In-memory cache: { [sector]: { bullCount, bearCount, totalWithData, avgHTF, ts } }
const _sectorAlignmentCache = {};
const SECTOR_ALIGNMENT_TTL_MS = 5 * 60 * 1000; // 5 minute cache

/**
 * Compute sector alignment from latest KV data for all tickers in the sector.
 * Returns: { aligned: bool, direction: "BULL"|"BEAR"|null, strength: 0-100,
 *            bullCount, bearCount, totalWithData, avgHTF, tickers: [...] }
 */
async function computeSectorAlignment(KV, ticker) {
  const sector = getSector(ticker);
  if (!sector) return null;

  // Check cache
  const cached = _sectorAlignmentCache[sector];
  if (cached && Date.now() - cached.ts < SECTOR_ALIGNMENT_TTL_MS) {
    return cached;
  }

  const sectorTickers = getTickersInSector(sector);
  if (sectorTickers.length < 2) return null;

  let bullCount = 0;
  let bearCount = 0;
  let totalWithData = 0;
  let htfSum = 0;
  const tickerDetails = [];

  // Batch read latest data for all sector tickers
  const promises = sectorTickers.map(async (t) => {
    try {
      const data = await kvGetJSON(KV, `timed:latest:${t}`);
      if (!data || data.htf_score == null) return null;
      return { ticker: t, htf: Number(data.htf_score), state: data.state };
    } catch { return null; }
  });
  const results = await Promise.all(promises);

  for (const r of results) {
    if (!r || !Number.isFinite(r.htf)) continue;
    totalWithData++;
    htfSum += r.htf;
    if (r.htf > 5) {
      bullCount++;
      tickerDetails.push({ ticker: r.ticker, htf: r.htf, side: "BULL" });
    } else if (r.htf < -5) {
      bearCount++;
      tickerDetails.push({ ticker: r.ticker, htf: r.htf, side: "BEAR" });
    } else {
      tickerDetails.push({ ticker: r.ticker, htf: r.htf, side: "NEUTRAL" });
    }
  }

  if (totalWithData < 2) return null;

  const avgHTF = htfSum / totalWithData;
  const bullPct = bullCount / totalWithData;
  const bearPct = bearCount / totalWithData;

  // Aligned if >= 60% of sector tickers agree on direction
  const isBullAligned = bullPct >= 0.6;
  const isBearAligned = bearPct >= 0.6;
  const aligned = isBullAligned || isBearAligned;
  const direction = isBullAligned ? "BULL" : isBearAligned ? "BEAR" : null;

  // Strength: 0-100 based on consensus percentage and average HTF magnitude
  // 60% agreement = 50 strength, 80% = 75, 100% = 100
  // Boosted by average HTF magnitude (stronger convictions = higher strength)
  const consensusPct = Math.max(bullPct, bearPct);
  const htfMagnitude = Math.min(Math.abs(avgHTF) / 30, 1); // Normalize to 0-1 (30 = max HTF)
  const strength = aligned
    ? Math.round(((consensusPct - 0.5) * 2) * 70 + htfMagnitude * 30) // 0-100
    : 0;

  const result = {
    sector,
    aligned,
    direction,
    strength: Math.min(100, Math.max(0, strength)),
    bullCount,
    bearCount,
    totalWithData,
    avgHTF: Math.round(avgHTF * 10) / 10,
    tickers: tickerDetails.sort((a, b) => Math.abs(b.htf) - Math.abs(a.htf)).slice(0, 8),
    ts: Date.now(),
  };

  _sectorAlignmentCache[sector] = result;
  return result;
}

/**
 * Synchronous version for use inside pure functions (qualifiesForEnter, classifyKanbanStage).
 * Uses only the cached data, returns null if no cache exists.
 */
function getSectorAlignmentCached(ticker) {
  const sector = getSector(ticker);
  if (!sector) return null;
  const cached = _sectorAlignmentCache[sector];
  if (!cached || Date.now() - cached.ts > SECTOR_ALIGNMENT_TTL_MS * 2) return null; // 10 min stale tolerance
  return cached;
}

function getAllSectors() {
  return Object.keys(SECTOR_RATINGS);
}

// ─────────────────────────────────────────────────────────────
// Historical P/E Percentile Calculation
// ─────────────────────────────────────────────────────────────

// Calculate percentile from sorted array
function calculatePercentile(sortedArray, percentile) {
  if (!sortedArray || sortedArray.length === 0) return null;
  const index = Math.floor((percentile / 100) * sortedArray.length);
  return sortedArray[Math.min(index, sortedArray.length - 1)];
}

// Calculate all percentiles from P/E history
function calculatePEPercentiles(peHistory) {
  if (!peHistory || peHistory.length < 10) return null; // Need at least 10 data points

  const sorted = [...peHistory].sort((a, b) => a - b);

  return {
    p10: calculatePercentile(sorted, 10),
    p25: calculatePercentile(sorted, 25),
    p50: calculatePercentile(sorted, 50), // Median
    p75: calculatePercentile(sorted, 75),
    p90: calculatePercentile(sorted, 90),
    avg: peHistory.reduce((a, b) => a + b, 0) / peHistory.length,
    count: peHistory.length,
  };
}

// Determine percentile position
function getPercentilePosition(currentPE, percentiles) {
  if (!currentPE || !percentiles) return null;

  if (currentPE < percentiles.p25) return "Bottom 25%";
  if (currentPE < percentiles.p50) return "Below Median";
  if (currentPE < percentiles.p75) return "Above Median";
  return "Top 25%";
}

// ─────────────────────────────────────────────────────────────
// Fair Value Calculation
// ─────────────────────────────────────────────────────────────

// Calculate fair value P/E using multiple methods
function calculateFairValuePE(peHistory, epsGrowthRate, targetPEG = 1.0) {
  const methods = {};

  // Method 1: Historical Average
  if (peHistory && peHistory.length > 0) {
    methods.historical_avg =
      peHistory.reduce((a, b) => a + b, 0) / peHistory.length;
  }

  // Method 2: Historical Median
  if (peHistory && peHistory.length > 0) {
    const sorted = [...peHistory].sort((a, b) => a - b);
    methods.historical_median = sorted[Math.floor(sorted.length / 2)];
  }

  // Method 3: Growth-Adjusted (PEG-based)
  if (epsGrowthRate && epsGrowthRate > 0) {
    const growthBasedPE = epsGrowthRate * targetPEG;
    // Cap at reasonable levels (min: historical avg if available, max: 40x)
    const minPE = methods.historical_avg || 15;
    const maxPE = 40;
    methods.growth_adjusted = Math.max(minPE, Math.min(growthBasedPE, maxPE));
  }

  // Preferred method: Use growth-adjusted if available, otherwise historical median, fallback to avg
  methods.preferred =
    methods.growth_adjusted ||
    methods.historical_median ||
    methods.historical_avg;

  return methods;
}

// Calculate fair value price
function calculateFairValuePrice(eps, fairValuePE) {
  if (!eps || !fairValuePE || eps <= 0) return null;
  return eps * fairValuePE;
}

// Calculate premium/discount percentage
function calculatePremiumDiscount(currentPrice, fairValuePrice) {
  if (!currentPrice || !fairValuePrice || fairValuePrice <= 0) return null;
  return ((currentPrice - fairValuePrice) / fairValuePrice) * 100;
}

// ─────────────────────────────────────────────────────────────
// Valuation Signals
// ─────────────────────────────────────────────────────────────

// Determine valuation signal based on multiple factors
function calculateValuationSignal(
  currentPE,
  fairValuePE,
  pegRatio,
  premiumDiscount,
  percentiles,
) {
  // Default thresholds
  const UNDERVALUED_THRESHOLD = -15; // 15% below fair value
  const OVERVALUED_THRESHOLD = 15; // 15% above fair value
  const PEG_UNDERVALUED = 0.8;
  const PEG_OVERVALUED = 1.5;

  let signals = {
    signal: "fair", // undervalued, fair, overvalued
    is_undervalued: false,
    is_overvalued: false,
    confidence: "medium", // low, medium, high
    reasons: [],
  };

  // Factor 1: Premium/Discount to Fair Value
  if (premiumDiscount !== null) {
    if (premiumDiscount < UNDERVALUED_THRESHOLD) {
      signals.is_undervalued = true;
      signals.reasons.push(
        `Price ${Math.abs(premiumDiscount).toFixed(1)}% below fair value`,
      );
    } else if (premiumDiscount > OVERVALUED_THRESHOLD) {
      signals.is_overvalued = true;
      signals.reasons.push(
        `Price ${premiumDiscount.toFixed(1)}% above fair value`,
      );
    }
  }

  // Factor 2: PEG Ratio
  if (pegRatio !== null) {
    if (pegRatio < PEG_UNDERVALUED) {
      signals.is_undervalued = true;
      signals.reasons.push(
        `PEG ratio ${pegRatio.toFixed(2)} suggests undervalued growth`,
      );
    } else if (pegRatio > PEG_OVERVALUED) {
      signals.is_overvalued = true;
      signals.reasons.push(
        `PEG ratio ${pegRatio.toFixed(2)} suggests overvalued`,
      );
    }
  }

  // Factor 3: Historical P/E Percentile
  if (currentPE && percentiles) {
    if (currentPE < percentiles.p25) {
      signals.is_undervalued = true;
      signals.reasons.push(`P/E in bottom 25% historically`);
    } else if (currentPE > percentiles.p75) {
      signals.is_overvalued = true;
      signals.reasons.push(`P/E in top 25% historically`);
    }
  }

  // Determine final signal
  if (signals.is_undervalued && !signals.is_overvalued) {
    signals.signal = "undervalued";
    signals.confidence = signals.reasons.length >= 2 ? "high" : "medium";
  } else if (signals.is_overvalued && !signals.is_undervalued) {
    signals.signal = "overvalued";
    signals.confidence = signals.reasons.length >= 2 ? "high" : "medium";
  } else {
    signals.signal = "fair";
    signals.confidence = "medium";
  }

  return signals;
}

// ─────────────────────────────────────────────────────────────
// Valuation Boost/Penalty for Ranking
// ─────────────────────────────────────────────────────────────

// Calculate valuation boost/penalty to add to rank
function calculateValuationBoost(fundamentals) {
  if (!fundamentals) return 0;

  let boost = 0;

  // Factor 1: Valuation Signal (primary factor)
  if (fundamentals.is_undervalued) {
    if (fundamentals.valuation_confidence === "high") {
      boost += 5; // Strong undervaluation signal
    } else {
      boost += 3; // Moderate undervaluation signal
    }
  } else if (fundamentals.is_overvalued) {
    if (fundamentals.valuation_confidence === "high") {
      boost -= 5; // Strong overvaluation signal
    } else {
      boost -= 3; // Moderate overvaluation signal
    }
  }

  // Factor 2: PEG Ratio (secondary factor for growth stocks)
  if (fundamentals.peg_ratio !== null && fundamentals.peg_ratio > 0) {
    if (fundamentals.peg_ratio < 0.8) {
      boost += 2; // Excellent PEG (undervalued growth)
    } else if (fundamentals.peg_ratio < 1.0) {
      boost += 1; // Good PEG (fairly valued growth)
    } else if (fundamentals.peg_ratio > 1.5) {
      boost -= 1; // Poor PEG (overvalued)
    } else if (fundamentals.peg_ratio > 2.0) {
      boost -= 3; // Very poor PEG (highly overvalued)
    }
  }

  // Factor 3: Premium/Discount to Fair Value (tertiary factor)
  if (fundamentals.premium_discount_pct !== null) {
    if (fundamentals.premium_discount_pct < -20) {
      boost += 2; // Significantly below fair value
    } else if (fundamentals.premium_discount_pct < -10) {
      boost += 1; // Moderately below fair value
    } else if (fundamentals.premium_discount_pct > 20) {
      boost -= 2; // Significantly above fair value
    } else if (fundamentals.premium_discount_pct > 10) {
      boost -= 1; // Moderately above fair value
    }
  }

  // Cap the boost/penalty to reasonable bounds
  return Math.max(-8, Math.min(8, boost));
}

// Rank tickers within a sector by technical score + sector boost
async function rankTickersInSector(KV, sector, limit = 10) {
  const sectorTickers = getTickersInSector(sector);
  const sectorRating = getSectorRating(sector);

  const tickerData = [];

  // Get data for all tickers in sector
  for (const ticker of sectorTickers) {
    const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
    if (data) {
      const baseRank = Number(data.rank) || 0;
      const sectorBoost = sectorRating.boost;

      // Get valuation boost from fundamentals
      const fundamentals =
        data.fundamentals ||
        (await kvGetJSON(KV, `timed:fundamentals:${ticker}`));
      const valuationBoost = calculateValuationBoost(fundamentals);

      // Calculate total boosted rank: base + sector + valuation
      const boostedRank = baseRank + sectorBoost + valuationBoost;

      tickerData.push({
        ticker,
        rank: baseRank,
        boostedRank,
        sector,
        sectorRating: sectorRating.rating,
        sectorBoost: sectorRating.boost,
        valuationBoost: valuationBoost,
        ...data,
      });
    }
  }

  // Sort by boosted rank (descending)
  tickerData.sort((a, b) => b.boostedRank - a.boostedRank);

  return tickerData.slice(0, limit);
}

// Module-level variable for lazy initialization (persists across requests in same isolate)
let sectorMappingsLoaded = false;

export default {
  async fetch(req, env, ctx) {
    // Top-level error handler to prevent 500 errors from crashing the worker
    try {
      const url = new URL(req.url);

      // Serve Trade Tracker dashboard at / and /dashboard (no KV required)
      if (req.method === "GET" && (url.pathname === "/" || url.pathname === "/dashboard")) {
        return new Response(DASHBOARD_HTML, {
          headers: { "Content-Type": "text/html; charset=utf-8" },
        });
      }

      // Always satisfy CORS preflight before touching bindings.
      // This prevents the dashboard from being blocked by CORS when KV/D1 are misconfigured.
      if (req.method === "OPTIONS") {
        return new Response("", {
          status: 204,
          headers: corsHeaders(env, req),
        });
      }

      const KV = env.KV_TIMED;

      // Verify KV binding is available
      if (!KV) {
        console.error(`[FETCH ERROR] KV_TIMED binding is not available`, {
          hasEnv: !!env,
          envKeys: env ? Object.keys(env) : [],
          url: req?.url,
        });
        return sendJSON(
          {
            ok: false,
            error: "kv_not_configured",
            message:
              "KV binding is not configured. Please add KV_TIMED binding in Cloudflare Dashboard.",
          },
          500,
          corsHeaders(env, req),
        );
      }

      // Use waitUntil to ensure critical operations complete even after response
      // This helps prevent race conditions with request cancellation

      // Load sector mappings from KV on first request (lazy initialization)
      // Wrap in try-catch to prevent crashes if KV is unavailable
      if (!sectorMappingsLoaded && KV) {
        try {
          // Never let a slow KV read block the entire Worker (can cause all endpoints to hang)
          const withTimeout = (p, ms) =>
            Promise.race([
              p,
              new Promise((_, reject) =>
                setTimeout(
                  () => reject(new Error("sector_mappings_timeout")),
                  ms,
                ),
              ),
            ]);

          await withTimeout(loadSectorMappingsFromKV(KV), 1000);
          sectorMappingsLoaded = true;
        } catch (sectorLoadErr) {
          console.error(`[SECTOR LOAD] Failed to load sector mappings:`, {
            error: String(sectorLoadErr),
            message: sectorLoadErr?.message,
          });
          // Continue anyway - sector mappings are optional
          sectorMappingsLoaded = true; // Mark as loaded to prevent retry loops
        }
      }

      // url already parsed above
      const routeKey = getRouteKey(req.method, url.pathname);
      if (!routeKey) {
        return sendJSON(
          { ok: false, error: "not_found" },
          404,
          corsHeaders(env, req),
        );
      }

      // POST /timed/ingest
      // Accepts ALL tickers — no allowlist/restrictions. Add a ticker in TradingView, update the
      // alert to your watchlist, and the system automatically accepts, scores, and displays it.
      // Purge (cleanup-tickers --strict) is manual/one-off only.
      if (routeKey === "POST /timed/ingest") {
        let body = null; // Declare outside try for catch block access
        try {
          // Early logging to confirm request reception
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          console.log(
            `[INGEST REQUEST RECEIVED] IP: ${ip}, User-Agent: ${
              req.headers.get("User-Agent") || "none"
            }`,
          );

          const authFail = requireKeyOr401(req, env);
          if (authFail) {
            console.log(`[INGEST AUTH FAILED] IP: ${ip}`);
            return authFail;
          }

          console.log(`[INGEST AUTH PASSED] Processing request from IP: ${ip}`);
          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData; // Assign to outer variable
          if (!body) {
            console.log(
              `[INGEST JSON PARSE FAILED] IP: ${ip}, Error: ${String(
                err || "unknown",
              )}, Raw sample: ${String(raw || "").slice(0, 200)}`,
            );
            return ackJSON(
              env,
              {
                ok: false,
                error: "bad_json",
                sample: String(raw || "").slice(0, 200),
                parseError: String(err || ""),
              },
              400,
              req,
            );
          }

          // Log raw payload for debugging (especially for missing tickers)
          const tickerFromBody = normTicker(body?.ticker);
          console.log(`[INGEST RAW] ${tickerFromBody || "UNKNOWN"}:`, {
            hasTicker: !!body?.ticker,
            hasTs: body?.ts !== undefined,
            hasHtf: body?.htf_score !== undefined,
            hasLtf: body?.ltf_score !== undefined,
            ts: body?.ts,
            htf: body?.htf_score,
            ltf: body?.ltf_score,
            tsType: typeof body?.ts,
            htfType: typeof body?.htf_score,
            ltfType: typeof body?.ltf_score,
          });

          const v = validateTimedPayload(body);
          if (!v.ok) {
            console.log(
              `[INGEST VALIDATION FAILED] ${tickerFromBody || "UNKNOWN"}:`,
              {
                error: v.error,
                ticker: body?.ticker,
                ts: body?.ts,
                htf: body?.htf_score,
                ltf: body?.ltf_score,
              },
            );
            return ackJSON(env, v, 400, req);
          }

          const ticker = v.ticker;
          const payload = v.payload;

          const rawPayload =
            typeof raw === "string"
              ? raw
              : (() => {
                  try {
                    return JSON.stringify(body);
                  } catch {
                    return "";
                  }
                })();

          // Store raw webhook receipt (KV + D1) before any filtering or derived logic
          try {
            if (rawPayload) {
              await kvPutText(
                KV,
                `timed:ingest:raw:${ticker}`,
                rawPayload,
                2 * 24 * 60 * 60,
              );
            }
          } catch (rawErr) {
            console.error(
              `[INGEST RAW] KV store failed for ${ticker}:`,
              rawErr,
            );
          }

          d1InsertIngestReceipt(env, ticker, payload, rawPayload).catch(
            (err) => {
              console.error(
                `[D1 INGEST] Receipt insert exception for ${ticker}:`,
                err,
              );
            },
          );

          // Migrate BRK.B to BRK-B if needed (TradingView sends BRK.B, but we use BRK-B)
          // Check BEFORE normalization to catch BRK.B from TradingView
          const rawTicker = body?.ticker;
          if (
            rawTicker === "BRK.B" ||
            rawTicker === "BRK-B" ||
            ticker === "BRK-B"
          ) {
            // Check if old BRK.B data exists and migrate it
            const oldData = await kvGetJSON(KV, `timed:latest:BRK.B`);
            const newData = await kvGetJSON(KV, `timed:latest:BRK-B`);

            if (
              oldData &&
              (!newData ||
                (oldData.ts && newData.ts && oldData.ts > newData.ts))
            ) {
              console.log(
                `[MIGRATE BRK] Migrating BRK.B data to BRK-B (old ts: ${
                  oldData.ts
                }, new ts: ${newData?.ts || "none"})`,
              );
              // Copy data to BRK-B (use newer data if both exist)
              const dataToUse =
                newData && newData.ts > oldData.ts ? newData : oldData;
              await kvPutJSON(KV, `timed:latest:BRK-B`, dataToUse);
              // Copy trail if exists
              const oldTrail = await kvGetJSON(KV, `timed:trail:BRK.B`);
              const newTrail = await kvGetJSON(KV, `timed:trail:BRK-B`);
              if (oldTrail) {
                await kvPutJSON(KV, `timed:trail:BRK-B`, oldTrail);
              } else if (newTrail) {
                await kvPutJSON(KV, `timed:trail:BRK-B`, newTrail);
              }
              // Ensure BRK-B is in index (should already be, but double-check)
              await ensureTickerIndex(KV, "BRK-B");
              // Delete old BRK.B data only if we migrated it
              if (dataToUse === oldData) {
                await KV.delete(`timed:latest:BRK.B`);
                await KV.delete(`timed:trail:BRK.B`);
                console.log(
                  `[MIGRATE BRK] Migration complete: BRK.B → BRK-B (deleted old BRK.B)`,
                );
              } else {
                console.log(
                  `[MIGRATE BRK] BRK-B already has newer data, keeping both`,
                );
              }
            }
          }

          // Log ingestion for debugging
          console.log(`[INGEST] ${ticker}:`, {
            ts: payload.ts,
            htf: payload.htf_score,
            ltf: payload.ltf_score,
            state: payload.state,
            price: payload.price,
            script_version: payload.script_version,
          });

          // Check version and migrate if needed (non-blocking for large migrations)
          const incomingVersion = payload.script_version || "unknown";
          const storedVersion = await getStoredVersion(KV);
          let migration = { migrated: false, reason: "version_match" };

          if (!storedVersion) {
            // First run - set version immediately
            await setStoredVersion(KV, incomingVersion);
          } else if (storedVersion !== incomingVersion) {
            // Version changed - run migration in background to avoid timeout
            console.log(
              `Version change detected: ${storedVersion} -> ${incomingVersion}, starting background migration`,
            );

            // Update version immediately to prevent concurrent migrations from multiple requests
            // Migration will still run (it checks storedVersion at start, before we update)
            // But subsequent requests won't trigger migration again
            await setStoredVersion(KV, incomingVersion);

            // Start migration in background (fire and forget) - don't wait for completion
            // This prevents timeout on large data sets (133+ tickers)
            // Use storedVersion from before update to run migration correctly
            const migrationPromise = checkAndMigrateWithStoredVersion(
              KV,
              storedVersion,
              incomingVersion,
            );
            migrationPromise
              .then((result) => {
                if (result.migrated) {
                  console.log(
                    `Background migration completed: ${result.oldVersion} -> ${
                      result.newVersion
                    }, purged ${result.tickerCount || 0} tickers`,
                  );
                  // Optionally notify Discord about migration
                  // Notify Discord about migration with embed card
                  const migrationEmbed = {
                    title: "🔄 Data Model Migration",
                    color: 0x0099ff, // Blue
                    fields: [
                      {
                        name: "Version",
                        value: `${result.oldVersion} → ${result.newVersion}`,
                        inline: true,
                      },
                      {
                        name: "Tickers Purged",
                        value: `${result.tickerCount || 0}`,
                        inline: true,
                      },
                      {
                        name: "Archive Created",
                        value: result.archived ? "Yes" : "No",
                        inline: true,
                      },
                    ],
                    description: "Migration completed in background",
                    timestamp: new Date().toISOString(),
                    footer: {
                      text: "Timed Trading System",
                    },
                  };
                  if (
                    shouldSendDiscordAlert(env, "SYSTEM", { kind: "migration" })
                  ) {
                    notifyDiscord(env, migrationEmbed).catch(() => {}); // Don't let Discord notification errors break anything
                  }
                }
              })
              .catch((err) => {
                console.error(`[MIGRATION ERROR]`, {
                  error: String(err),
                  stack: err.stack,
                  fromVersion: storedVersion,
                  toVersion: incomingVersion,
                });
              });

            migration = {
              migrated: true,
              reason: "version_changed",
              inProgress: true,
            };
          }

          // Dedupe rapid repeats (only if exact same data within 60s)
          // Note: For Force Baseline, TV sends all alerts with same timestamp/data structure
          // We still want to index all tickers, so dedupe only prevents duplicate alert processing
          // but ticker indexing happens regardless
          const basis = JSON.stringify({
            ts: payload.ts,
            htf: payload.htf_score,
            ltf: payload.ltf_score,
            state: payload.state || "",
            completion: payload.completion,
            phase_pct: payload.phase_pct,
            rr: payload.rr,
            trigger_ts: payload.trigger_ts,
            // Note: We don't include ticker in hash because Force Baseline sends same data structure for all
            // Dedupe is per-ticker, so each ticker gets processed even if data is identical
          });

          const hash = stableHash(basis);
          const dedupeKey = `timed:dedupe:${ticker}:${hash}`;
          const alreadyDeduped = await KV.get(dedupeKey);
          const isRapidDeduped = !!alreadyDeduped;
          if (isRapidDeduped) {
            console.log(
              `[INGEST DEDUPED] ${ticker} - same data within 60s (hash: ${hash.substring(
                0,
                8,
              )})`,
            );
          } else {
            await kvPutText(KV, dedupeKey, "1", 60);
            console.log(
              `[INGEST NOT DEDUPED] ${ticker} - new or changed data (hash: ${hash.substring(
                0,
                8,
              )})`,
            );
          }

          // Derived: staleness
          const stale = stalenessBucket(ticker, payload.ts);
          payload.market_type = stale.mt;
          payload.age_min = stale.ageMin;
          payload.staleness = stale.bucket;

          // Derived: rr/rank
          payload.rr = payload.rr ?? computeRR(payload);
          // (optional clamp to prevent any bizarre edge cases)
          if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
          
          // RR Warning: Data-driven warning based on historical win rates
          payload.rr_warning = computeRRWarning(payload.rr);

          // Calculate Momentum Elite (worker-based with caching)
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] About to compute Momentum Elite`);
          }
          const momentumEliteData = await computeMomentumElite(
            KV,
            ticker,
            payload,
          );
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Momentum Elite computed:`, {
              momentum_elite: momentumEliteData?.momentum_elite,
              hasCriteria: !!momentumEliteData?.criteria,
            });
          }
          if (momentumEliteData && momentumEliteData.momentum_elite) {
            // Update flags with Momentum Elite status
            if (!payload.flags) payload.flags = {};
            payload.flags.momentum_elite = true;
            // Store full criteria for debugging/display
            payload.momentum_elite_criteria = momentumEliteData.criteria;
          } else {
            // Ensure flag is set to false if not elite
            if (!payload.flags) payload.flags = {};
            payload.flags.momentum_elite = false;
          }

          // Data completeness + TF/trigger summaries (used by UI + scoring)
          try {
            payload.data_completeness = computeDataCompleteness(payload);
            const tfSum = tfTechAlignmentSummary(payload);
            if (tfSum) payload.tf_summary = tfSum;
            payload.trigger_summary = triggerSummaryAndScore(payload);
            payload.move_status = computeMoveStatus(payload);
            payload.flags =
              payload.flags && typeof payload.flags === "object"
                ? payload.flags
                : {};
            payload.flags.move_invalidated =
              payload.move_status?.status === "INVALIDATED";
            payload.flags.move_completed =
              payload.move_status?.status === "COMPLETED";
            const trigCorr = triggerReasonCorroboration(payload);
            payload.trigger_reason_corroborated = !!trigCorr.corroborated;
            payload.trigger_reason_note = trigCorr.note || "";
          } catch (e) {
            console.error(
              `[ENRICH] Failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          payload.rank = computeRank(payload);
          payload.score = payload.rank;
          
          // Gold Standard Score: Data-driven scoring based on historical winners
          // Pass existing data for state transition detection
          payload.gold_score = computeGoldScore(payload, existing);

          // Derived: horizon + % metrics (ETA v2 + risk/return)
          try {
            const derived = deriveHorizonAndMetrics(payload);
            Object.assign(payload, derived);
          } catch (e) {
            console.error(`[DERIVED METRICS] Failed for ${ticker}:`, String(e));
          }

          // Trail (light) - store immediately after derived metrics
          try {
            // Load previous state for Flip Watch, Kanban lifecycle, and stage transition detection
            const existing =
              (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
            const trailPoint = {
              ts: payload.ts,
              price: payload.price, // Add price to trail for momentum calculations
              htf_score: payload.htf_score,
              ltf_score: payload.ltf_score,
              completion: payload.completion,
              phase_pct: payload.phase_pct,
              state: payload.state,
              rank: payload.rank,
              flags: payload.flags || {},
              momentum_elite: !!(payload.flags && payload.flags.momentum_elite),
              trigger_reason: payload.trigger_reason,
              trigger_dir: payload.trigger_dir,
            };

            const trail = await appendTrail(KV, ticker, trailPoint, 320); // ~26h at 5m cadence (enables 4h/1d deltas)

            // Compute live thesis features from the updated trail
            try {
              const computed = computeLiveThesisFeaturesFromTrail(
                trail,
                payload,
              );
              if (computed && typeof computed === "object") {
                payload.seq = computed.seq;
                payload.deltas = computed.deltas;
                payload.flags =
                  payload.flags && typeof payload.flags === "object"
                    ? payload.flags
                    : {};
                payload.flags.htf_improving_4h =
                  !!computed.flags?.htf_improving_4h;
                payload.flags.htf_improving_1d =
                  !!computed.flags?.htf_improving_1d;
                payload.flags.htf_move_4h_ge_5 =
                  !!computed.flags?.htf_move_4h_ge_5;
                payload.flags.thesis_match = !!computed.flags?.thesis_match;
              }

              // Flip Watch detection - tickers about to transition from setup to momentum
              try {
                const nowMs = Number(
                  payload?.ts ?? payload?.ingest_ts ?? Date.now(),
                );
                const state = String(payload?.state || "");
                const inPullback =
                  state === "HTF_BULL_LTF_PULLBACK" ||
                  state === "HTF_BEAR_LTF_PULLBACK";
                const isMomentum =
                  state === "HTF_BULL_LTF_BULL" ||
                  state === "HTF_BEAR_LTF_BEAR";

                const flipWatch = detectFlipWatch(payload, trail);
                const prevUntilRaw = Number(existing?.flip_watch_until_ts);
                const prevUntil = Number.isFinite(prevUntilRaw)
                  ? prevUntilRaw
                  : null;
                const prevScore = Number(existing?.flip_watch_score);
                const prevReasons = Array.isArray(existing?.flip_watch_reasons)
                  ? existing.flip_watch_reasons
                  : null;

                // Sticky window: once triggered, keep Flip Watch for 60m *while still in pullback*.
                // If it flips into momentum, release immediately so it can progress (Just Flipped / Enter Now).
                const STICKY_MS = 60 * 60 * 1000;
                const stickyActive =
                  !isMomentum &&
                  inPullback &&
                  prevUntil != null &&
                  Number.isFinite(nowMs) &&
                  nowMs <= prevUntil;

                if (flipWatch) {
                  payload.flags.flip_watch = true;
                  payload.flip_watch_score = flipWatch.score;
                  payload.flip_watch_reasons = flipWatch.reasons;
                  payload.flip_watch_until_ts = nowMs + STICKY_MS;
                } else if (stickyActive) {
                  payload.flags.flip_watch = true;
                  if (Number.isFinite(prevScore))
                    payload.flip_watch_score = prevScore;
                  if (prevReasons) payload.flip_watch_reasons = prevReasons;
                  payload.flip_watch_until_ts = prevUntil;
                } else {
                  payload.flags.flip_watch = false;
                  payload.flip_watch_until_ts = null;
                }
              } catch (e) {
                console.error(
                  `[FLIP WATCH] Detection failed for ${ticker}:`,
                  String(e),
                );
              }
            } catch (e) {
              console.error(
                `[THESIS FEATURES] Compute failed for ${ticker}:`,
                String(e),
              );
            }

            // Kanban Stage classification - ALWAYS run (independent of thesis/flip-watch logic)
            // CRITICAL: Merge entry_ts/entry_price from existing BEFORE classifyKanbanStage.
            // Otherwise computeMoveStatus sees hasEntered=false and tickers that should be HOLD
            // (move passed) end up in Watch. Same for cycle fields (lifecycle gate).
            try {
              if (existing?.entry_ts != null || existing?.entry_price != null) {
                if (payload.entry_ts == null && Number.isFinite(Number(existing?.entry_ts)))
                  payload.entry_ts = Number(existing.entry_ts);
                if (payload.entry_price == null && Number.isFinite(Number(existing?.entry_price)))
                  payload.entry_price = Number(existing.entry_price);
              }
              if (existing?.kanban_cycle_enter_now_ts != null)
                payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
              if (existing?.kanban_cycle_trigger_ts != null)
                payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
              if (existing?.kanban_cycle_side != null)
                payload.kanban_cycle_side = existing.kanban_cycle_side;

              // ═══════════════════════════════════════════════════════════════════
              // D1 SINGLE SOURCE OF TRUTH: Get position context from D1 only
              // KV trade lookup deprecated - D1 positions table is authoritative
              // ═══════════════════════════════════════════════════════════════════
              const openPosition = env?.DB ? await getPositionContext(env, ticker) : null;
              const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
              
              // Inject entry data from D1 position if missing from payload
              if (hasOpenPosition) {
                if (payload.entry_ts == null && openPosition.entry_ts) {
                  payload.entry_ts = openPosition.entry_ts;
                }
                if (payload.entry_price == null && openPosition.avg_entry_price > 0) {
                  payload.entry_price = openPosition.avg_entry_price;
                }
                // Store position context for downstream use
                payload.__position_context = openPosition;
              }
              
              // Recompute move_status so stored payload reflects merged entry_ts
              payload.move_status = computeMoveStatus(payload);
              if (payload.flags) {
                payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
                payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
                payload.flags.has_open_position = hasOpenPosition;
              }

              // ═══════════════════════════════════════════════════════════════════
              // PATTERN LIBRARY ENRICHMENT: Match payload against active patterns
              // Non-blocking: uses in-memory cache, refreshes every 5 minutes
              // Enriches payload with pattern match data for UI + Kanban boost
              // ═══════════════════════════════════════════════════════════════════
              try {
                const cachedPatterns = await getCachedPatterns(env?.DB);
                const patternMatch = matchPatternsForPayload(payload, cachedPatterns);
                if (patternMatch) {
                  payload.pattern_match = patternMatch;
                  // Boost entry confidence when high-confidence bull patterns match
                  if (patternMatch.direction === "BULLISH" && patternMatch.bestBull?.conf > 0.6) {
                    payload.__pattern_boost = "high";
                  } else if (patternMatch.direction === "BULLISH" && patternMatch.bullCount > 0) {
                    payload.__pattern_boost = "medium";
                  } else if (patternMatch.direction === "BEARISH" && patternMatch.bestBear?.conf > 0.6) {
                    payload.__pattern_caution = "high";
                  }
                }
              } catch (e) {
                // Pattern matching is a boost, not a gate — never block on failure
              }

              // Pass open position to classifyKanbanStage for position-aware classification
              const stage = classifyKanbanStage(payload, openPosition);
              const prevStage = existing?.kanban_stage;
              
              // ═══════════════════════════════════════════════════════════════════
              // RECYCLE RULE: Position always wins
              // If there's an open position, NEVER recycle to watch - stay in management mode
              // Only apply recycle rule for non-position tickers
              // ═══════════════════════════════════════════════════════════════════
              let finalStage = stage;
              const prevStageLegacy = prevStage === "archive" || prevStage === "closed";
              const isManagementStage = stage === "active" || stage === "trim" || stage === "exit" ||
                                        stage === "hold" || stage === "just_entered"; // legacy names
              
              if (prevStageLegacy && isManagementStage && !hasOpenPosition) {
                // No open position, was archived - must re-enter via discovery lanes
                finalStage = "watch";
                payload.flags =
                  payload.flags && typeof payload.flags === "object"
                    ? payload.flags
                    : {};
                payload.flags.recycled_from_archive = true;
              }
              // If has open position, position wins - stay in management stage regardless of previous

              // Lifecycle gate: Management stages require open position
              // Exception: first bar of day after AH/PM gap — accept management stages (move in progress)
              try {
                const tsNow = Number(payload?.ts) || Date.now();
                const dayKey = nyTradingDayKey(tsNow);
                const marketOpen = dayKey ? nyWallTimeToUtcMs(dayKey, 9, 30, 0) : null;
                const existingTs = existing?.ts ?? existing?.ingest_ts;
                const firstBarAfterGap = isFirstBarOfDayAfterGap(existingTs, tsNow, marketOpen);

                // Check if stage is a management stage (new or legacy names)
                const mgmt =
                  finalStage === "active" ||
                  finalStage === "trim" ||
                  finalStage === "exit" ||
                  finalStage === "hold" ||        // legacy
                  finalStage === "just_entered";  // legacy
                  
                // Verify open position exists before allowing management lanes
                // If no position exists, clear stale entry data and force to watch
                if (mgmt && !hasOpenPosition) {
                  // Position closed but ticker still shows in management lane
                  // Clear stale entry data and force to discovery lanes
                  payload.entry_ts = null;
                  payload.entry_price = null;
                  payload.kanban_cycle_enter_now_ts = null;
                  payload.kanban_cycle_trigger_ts = null;
                  payload.kanban_cycle_side = null;
                  finalStage = "watch";
                  payload.flags =
                    payload.flags && typeof payload.flags === "object"
                      ? payload.flags
                      : {};
                  payload.flags.position_closed_cleared = true;
                  payload.flags.forced_watch_no_position = true;
                  console.log(
                    `[KANBAN] ${ticker} forced to watch: was in ${prevStage} but no open position in D1`
                  );
                }
                  
                if (mgmt && hasOpenPosition) {
                  const curTriggerTs = Number(payload?.trigger_ts);
                  const curSide = sideFromStateOrScores(payload); // "LONG" | "SHORT" | null
                  const cycleEnterTs = Number(
                    existing?.kanban_cycle_enter_now_ts,
                  );
                  const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
                  const cycleSide =
                    existing?.kanban_cycle_side != null
                      ? String(existing.kanban_cycle_side)
                      : null;
                  const sameTrig =
                    Number.isFinite(curTriggerTs) &&
                    curTriggerTs > 0 &&
                    Number.isFinite(cycleTrig) &&
                    cycleTrig > 0 &&
                    cycleTrig === curTriggerTs;
                  const cycleOk =
                    Number.isFinite(cycleEnterTs) &&
                    cycleEnterTs > 0 &&
                    sameTrig &&
                    !!cycleSide &&
                    !!curSide &&
                    cycleSide === curSide;

                  if (firstBarAfterGap) {
                    if (!payload.flags) payload.flags = {};
                    payload.flags.first_bar_of_day_bridge = true;
                  } else {
                    if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                      finalStage = "watch";
                      payload.flags =
                        payload.flags && typeof payload.flags === "object"
                          ? payload.flags
                          : {};
                      payload.flags.forced_watch_missing_trigger = true;
                    } else if (!cycleOk) {
                      finalStage = "enter_now";
                      payload.flags =
                        payload.flags && typeof payload.flags === "object"
                          ? payload.flags
                          : {};
                      payload.flags.forced_enter_now_gate = true;
                    }
                  }
                }

                if (finalStage === "enter_now") {
                  const curTriggerTs = Number(payload?.trigger_ts);
                  const curSide = sideFromStateOrScores(payload);
                  payload.kanban_cycle_enter_now_ts = tsNow;
                  payload.kanban_cycle_trigger_ts =
                    Number.isFinite(curTriggerTs) && curTriggerTs > 0
                      ? curTriggerTs
                      : null;
                  payload.kanban_cycle_side =
                    curSide != null ? String(curSide) : null;
                } else if (
                  finalStage === "hold" ||
                  finalStage === "just_entered" ||
                  finalStage === "trim" ||
                  finalStage === "exit"
                ) {
                  if (firstBarAfterGap) {
                    payload.kanban_cycle_enter_now_ts = tsNow;
                    payload.kanban_cycle_trigger_ts =
                      Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : tsNow;
                    payload.kanban_cycle_side = sideFromStateOrScores(payload) != null ? String(sideFromStateOrScores(payload)) : null;
                    if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                    if (payload.entry_ts == null && Number.isFinite(tsNow)) payload.entry_ts = tsNow;
                  } else {
                    payload.kanban_cycle_enter_now_ts =
                      existing?.kanban_cycle_enter_now_ts || null;
                    payload.kanban_cycle_trigger_ts =
                      existing?.kanban_cycle_trigger_ts || null;
                    payload.kanban_cycle_side =
                      existing?.kanban_cycle_side || null;
                  }
                } else {
                  // Reset cycle when we're not in ENTER_NOW or management lanes.
                  payload.kanban_cycle_enter_now_ts = null;
                  payload.kanban_cycle_trigger_ts = null;
                  payload.kanban_cycle_side = null;
                }
              } catch (e) {
                console.error(
                  `[KANBAN] lifecycle gate failed for ${ticker}:`,
                  String(e),
                );
              }

              // Stage monotonicity: open positions can only move forward in management lanes
              // Prevents bouncing EXIT→TRIM→ACTIVE due to price fluctuations
              const preMonotonicityStage = finalStage;
              finalStage = enforceStageMonotonicity(finalStage, prevStage, hasOpenPosition);
              if (finalStage !== preMonotonicityStage) {
                if (!payload.flags) payload.flags = {};
                payload.flags.stage_monotonicity_enforced = true;
                payload.flags.stage_before_monotonicity = preMonotonicityStage;
                console.log(
                  `[KANBAN] ${ticker} stage monotonicity: ${preMonotonicityStage} → ${finalStage} (enforced, has open position: ${hasOpenPosition})`
                );
              }

              payload.kanban_stage = finalStage;
              payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
              // Persist last transition source lane so UI can show "from: <lane>".
              // If stage changed: stamp prev_kanban_stage = previous lane (if known).
              // If stage did NOT change: carry forward the last stamped prev_kanban_stage.
              if (
                prevStage != null &&
                finalStage != null &&
                String(prevStage) !== String(finalStage)
              ) {
                payload.prev_kanban_stage = String(prevStage);
                payload.prev_kanban_stage_ts =
                  Number(payload?.ts) || Date.now();
              } else if (existing?.prev_kanban_stage != null) {
                payload.prev_kanban_stage = String(existing.prev_kanban_stage);
                payload.prev_kanban_stage_ts = Number.isFinite(
                  Number(existing?.prev_kanban_stage_ts),
                )
                  ? Number(existing.prev_kanban_stage_ts)
                  : null;
              } else {
                payload.prev_kanban_stage = null;
                payload.prev_kanban_stage_ts = null;
              }

              // Track entry price when entering "enter_now" stage
              if (finalStage === "enter_now" && prevStage !== "enter_now") {
                const price = Number(payload?.price);
                if (Number.isFinite(price) && price > 0) {
                  payload.entry_price = price;
                  payload.entry_ts = payload.ts;
                  console.log(
                    `[KANBAN] ${ticker} entered ENTER_NOW at $${price.toFixed(2)}`,
                  );
                }
              }

              // Discord notification for kanban lane transitions (aligned with 7-lane system)
              const actionableStages = [
                "enter",
                "enter_now", // Legacy alias → treated as "enter"
                "defend",
                "trim",
                "exit",
              ];
              if (
                prevStage != null &&
                finalStage != null &&
                String(prevStage) !== String(finalStage) &&
                actionableStages.includes(finalStage)
              ) {
                const alertType = `KANBAN_${finalStage.toUpperCase()}`;
                const tsMs = Number(payload?.ts) || Date.now();
                const dedupeBucket = Math.floor(tsMs / 900000); // 15 min
                const dedupeKey = `timed:discord:kanban:${ticker}:${finalStage}:${dedupeBucket}`;
                ctx.waitUntil(
                  (async () => {
                    try {
                      const already = await KV.get(dedupeKey);
                      if (already) return;
                      await kvPutText(KV, dedupeKey, "1", 60 * 60); // 1h TTL
                      if (!shouldSendDiscordAlert(env, alertType, { ticker }))
                        return;
                      const embed = createKanbanStageEmbed(
                        ticker,
                        finalStage,
                        prevStage,
                        payload,
                      );
                      await notifyDiscord(env, embed).catch((err) => {
                        console.error(
                          `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                          err,
                        );
                      });
                    } catch (e) {
                      console.error(
                        `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                        e,
                      );
                    }
                  })(),
                );
              }

              // Preserve entry_price if already set and still in the pipeline
              if (finalStage && existing?.entry_price) {
                payload.entry_price = existing.entry_price;
                payload.entry_ts = existing.entry_ts;
              }

              // Calculate % change from entry if we have entry_price
              if (payload.entry_price) {
                const entryPrice = Number(payload.entry_price);
                const currentPrice = Number(payload.price);
                if (
                  Number.isFinite(entryPrice) &&
                  Number.isFinite(currentPrice) &&
                  entryPrice > 0
                ) {
                  payload.entry_change_pct =
                    ((currentPrice - entryPrice) / entryPrice) * 100;
                }
              }

              if (finalStage) console.log(`[KANBAN] ${ticker} → ${finalStage}`);
              
              // Update the last KV trail point with kanban data for Time Travel replay
              try {
                const trailKey = `timed:trail:${ticker}`;
                const currentTrail = await kvGetJSON(KV, trailKey);
                if (Array.isArray(currentTrail) && currentTrail.length > 0) {
                  const lastPoint = currentTrail[currentTrail.length - 1];
                  if (lastPoint && lastPoint.ts === payload.ts) {
                    lastPoint.kanban_stage = finalStage;
                    lastPoint.entry_ts = payload.entry_ts || null;
                    lastPoint.entry_price = payload.entry_price || null;
                    lastPoint.move_status = payload.move_status?.status || null;
                    lastPoint.kanban_meta = payload.kanban_meta || null;
                    await kvPutJSON(KV, trailKey, currentTrail);
                  }
                }
              } catch (trailUpdateErr) {
                // Non-critical - don't fail ingestion
                console.error(`[TRAIL] Failed to update KV trail with kanban for ${ticker}:`, trailUpdateErr);
              }
            } catch (e) {
              console.error(
                `[KANBAN] Stage classification failed for ${ticker}:`,
                String(e),
              );
              payload.kanban_stage = existing?.kanban_stage || null;
              payload.prev_kanban_stage = existing?.prev_kanban_stage || null;
              payload.prev_kanban_stage_ts =
                existing?.prev_kanban_stage_ts || null;
            }

            // Also store into D1 (if configured) for 7-day history.
            // Don't let D1 failures affect ingestion.
            d1InsertTrailPoint(env, ticker, payload).catch((e) => {
              console.error(`[D1 TRAIL] Insert exception for ${ticker}:`, e);
            });

            // Periodic cleanup (throttled) to keep ~35 days retention
            d1CleanupOldTrail(env, 35).catch((e) => {
              console.error(`[D1 TRAIL] Cleanup exception:`, e);
            });
          } catch (trailErr) {
            console.error(
              `[TRAIL ERROR] Failed to append trail for ${ticker}:`,
              {
                error: String(trailErr),
                message: trailErr.message,
                stack: trailErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if trail fails
          }

          // Auto-populate sector: PRIORITIZE SECTOR_MAP over TradingView data
          // TradingView uses industry classifications (e.g., "Electronic Technology", "Retail Trade")
          // but we use GICS sectors (e.g., "Information Technology", "Consumer Discretionary")
          // So we always check SECTOR_MAP first, then fall back to TradingView data for unmapped tickers
          const tickerUpper = String(payload.ticker || ticker).toUpperCase();
          let sectorToUse = null;

          // First, check our SECTOR_MAP (GICS sectors)
          sectorToUse = getSector(tickerUpper);

          // If not in SECTOR_MAP, use TradingView's sector (for new/unmapped tickers)
          if (!sectorToUse) {
            if (
              payload.sector &&
              typeof payload.sector === "string" &&
              payload.sector.trim() !== ""
            ) {
              sectorToUse = payload.sector.trim();
              // Store TradingView sector in KV for reference (but don't override SECTOR_MAP)
              const sectorMapKey = `timed:sector_map:${tickerUpper}`;
              await kvPutText(KV, sectorMapKey, sectorToUse);
              console.log(
                `[SECTOR AUTO-MAP] ${tickerUpper} → ${sectorToUse} (from TradingView, not in SECTOR_MAP)`,
              );
            }
          } else {
            // Ticker is in SECTOR_MAP - use our GICS sector classification
            console.log(
              `[SECTOR] ${tickerUpper} → ${sectorToUse} (from SECTOR_MAP, ignoring TradingView sector: ${
                payload.sector || "none"
              })`,
            );
          }

          // Set sector at top level if we have one
          if (sectorToUse) {
            payload.sector = sectorToUse;
          }

          // Store sector and industry in payload (even if no fundamental data)
          // These are safe fields that work for all asset types
          if (payload.sector && typeof payload.sector === "string") {
            payload.sector = payload.sector.trim();
          }
          if (payload.industry && typeof payload.industry === "string") {
            payload.industry = payload.industry.trim();
          }

          // Store fundamental data if provided
          if (
            payload.pe_ratio !== undefined ||
            payload.eps !== undefined ||
            payload.market_cap !== undefined ||
            payload.eps_growth_rate !== undefined ||
            payload.peg_ratio !== undefined
          ) {
            const currentPE = payload.pe_ratio
              ? Number(payload.pe_ratio)
              : null;
            const eps = payload.eps ? Number(payload.eps) : null;
            const epsGrowthRate = payload.eps_growth_rate
              ? Number(payload.eps_growth_rate)
              : null;
            const pegRatio = payload.peg_ratio
              ? Number(payload.peg_ratio)
              : null;
            const currentPrice = Number(payload.price) || null;

            // ─────────────────────────────────────────────────────────────
            // Historical P/E Percentiles
            // ─────────────────────────────────────────────────────────────
            let peHistory = [];
            let percentiles = null;
            let percentilePosition = null;

            if (currentPE && currentPE > 0 && currentPE < 1000) {
              // Load existing P/E history
              const peHistoryKey = `timed:pe_history:${ticker}`;
              const existingHistory = await kvGetJSON(KV, peHistoryKey);

              if (existingHistory && Array.isArray(existingHistory)) {
                peHistory = existingHistory;
              }

              // Add current P/E to history
              peHistory.push(currentPE);

              // Keep last ~1260 data points (approximately 5 years of daily data)
              const maxHistoryLength = 1260;
              if (peHistory.length > maxHistoryLength) {
                peHistory = peHistory.slice(-maxHistoryLength);
              }

              // Save updated history
              await kvPutJSON(KV, peHistoryKey, peHistory);

              // Calculate percentiles
              percentiles = calculatePEPercentiles(peHistory);
              if (percentiles) {
                percentilePosition = getPercentilePosition(
                  currentPE,
                  percentiles,
                );
              }
            }

            // ─────────────────────────────────────────────────────────────
            // Fair Value Calculation
            // ─────────────────────────────────────────────────────────────
            const fairValuePE = calculateFairValuePE(peHistory, epsGrowthRate);
            const fairValuePrice = calculateFairValuePrice(
              eps,
              fairValuePE?.preferred,
            );
            const premiumDiscount = calculatePremiumDiscount(
              currentPrice,
              fairValuePrice,
            );

            // ─────────────────────────────────────────────────────────────
            // Valuation Signals
            // ─────────────────────────────────────────────────────────────
            const valuationSignals = calculateValuationSignal(
              currentPE,
              fairValuePE?.preferred,
              pegRatio,
              premiumDiscount,
              percentiles,
            );

            // ─────────────────────────────────────────────────────────────
            // Build Fundamentals Object
            // ─────────────────────────────────────────────────────────────
            payload.fundamentals = {
              // Basic metrics
              pe_ratio: currentPE,
              eps: eps,
              eps_growth_rate: epsGrowthRate,
              peg_ratio: pegRatio,
              market_cap: payload.market_cap
                ? Number(payload.market_cap)
                : null,
              industry: payload.industry || null,

              // Historical P/E Percentiles
              pe_percentiles: percentiles
                ? {
                    p10: percentiles.p10,
                    p25: percentiles.p25,
                    p50: percentiles.p50,
                    p75: percentiles.p75,
                    p90: percentiles.p90,
                    avg: percentiles.avg,
                    count: percentiles.count,
                  }
                : null,
              pe_percentile_position: percentilePosition,

              // Fair Value
              fair_value_pe: fairValuePE
                ? {
                    historical_avg: fairValuePE.historical_avg || null,
                    historical_median: fairValuePE.historical_median || null,
                    growth_adjusted: fairValuePE.growth_adjusted || null,
                    preferred: fairValuePE.preferred || null,
                  }
                : null,
              fair_value_price: fairValuePrice,
              premium_discount_pct: premiumDiscount,

              // Valuation Signals
              valuation_signal: valuationSignals.signal,
              is_undervalued: valuationSignals.is_undervalued,
              is_overvalued: valuationSignals.is_overvalued,
              valuation_confidence: valuationSignals.confidence,
              valuation_reasons: valuationSignals.reasons,
            };

            // Store fundamentals in KV for persistence
            const fundamentalsKey = `timed:fundamentals:${ticker}`;
            await kvPutJSON(KV, fundamentalsKey, payload.fundamentals);

            // Apply valuation boost to rank (if fundamentals available)
            if (payload.fundamentals) {
              const valuationBoost = calculateValuationBoost(
                payload.fundamentals,
              );
              if (valuationBoost !== 0) {
                const baseRank = payload.rank || 0;
                payload.rank = Math.max(
                  0,
                  Math.min(100, baseRank + valuationBoost),
                );
                payload.score = payload.rank;

                // Store valuation boost for debugging/display
                if (!payload.rank_components) payload.rank_components = {};
                payload.rank_components.valuation_boost = valuationBoost;
                payload.rank_components.base_rank = baseRank;

                console.log(
                  `[RANK] ${ticker}: Base=${baseRank}, Valuation Boost=${valuationBoost}, Final=${payload.rank}`,
                );
              }
            }
          } else {
            // No fundamental data provided, but still store sector/industry if available
            // Create minimal fundamentals object for UI compatibility
            if (payload.sector || payload.industry) {
              payload.fundamentals = {
                pe_ratio: null,
                eps: null,
                eps_growth_rate: null,
                peg_ratio: null,
                market_cap: null,
                industry: payload.industry
                  ? String(payload.industry).trim()
                  : null,
                sector: payload.sector ? String(payload.sector).trim() : null,
                pe_percentiles: null,
                pe_percentile_position: null,
                fair_value_pe: null,
                fair_value_price: null,
                premium_discount_pct: null,
                valuation_signal: "fair",
                is_undervalued: false,
                is_overvalued: false,
                valuation_confidence: "low",
                valuation_reasons: [],
              };
            }
          }

          // Detect state transition into aligned (enter Q2/Q3)
          const prevKey = `timed:prevstate:${ticker}`;
          const prevState = await KV.get(prevKey);
          await kvPutText(
            KV,
            prevKey,
            String(payload.state || ""),
            7 * 24 * 60 * 60,
          );

          const state = String(payload.state || "");
          const alignedLong = state === "HTF_BULL_LTF_BULL";
          const alignedShort = state === "HTF_BEAR_LTF_BEAR";
          const aligned = alignedLong || alignedShort;
          const enteredAligned = aligned && prevState !== state;

          const trigReason = String(payload.trigger_reason || "");
          const trigOk =
            trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
            trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");

          const flags = payload.flags || {};
          const sqRel = !!flags.sq30_release;

          // Activity feed tracking - detect events (load BEFORE alert logic to check for corridor entry)
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] About to load activity tracking state`);
          }
          const prevCorridorKey = `timed:prevcorridor:${ticker}`;
          const prevInCorridor = await KV.get(prevCorridorKey);

          // Corridor-only logic (must match UI)
          const side = corridorSide(payload); // LONG/SHORT/null
          const inCorridor = !!side;
          const enteredCorridor = inCorridor && prevInCorridor !== "true";

          // corridor must match alignment
          const corridorAlignedOK =
            (side === "LONG" && alignedLong) ||
            (side === "SHORT" && alignedShort);

          // Allow alerts if:
          // 1. ENTERED corridor (just entered) AND aligned AND (entered aligned OR trigger OR squeeze release)
          // 2. OR in corridor AND aligned AND (entered aligned OR trigger OR squeeze release)
          // 3. OR in corridor AND squeeze release (squeeze release is a strong signal even if not fully aligned)
          const shouldConsiderAlert =
            (enteredCorridor &&
              corridorAlignedOK &&
              (enteredAligned || trigOk || sqRel)) ||
            (inCorridor &&
              ((corridorAlignedOK && (enteredAligned || trigOk || sqRel)) ||
                (sqRel && side))); // Squeeze release in corridor is a valid trigger even if not fully aligned
          payload.entry_decision = buildEntryDecision(
            ticker,
            payload,
            prevState,
          );
          const prevSqueezeKey = `timed:prevsqueeze:${ticker}`;
          const prevSqueezeOn = await KV.get(prevSqueezeKey);
          const prevSqueezeRelKey = `timed:prevsqueezerel:${ticker}`;
          const prevSqueezeRel = await KV.get(prevSqueezeRelKey);
          const prevMomentumEliteKey = `timed:prevmomentumelite:${ticker}`;
          const prevMomentumElite = await KV.get(prevMomentumEliteKey);
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Activity tracking state loaded`);
          }

          // Track corridor entry
          // Wrap activity tracking in try-catch to prevent errors from breaking ingestion
          try {
            const actionableOnly = true;
            const enteredCorridor = inCorridor && prevInCorridor !== "true";
            const exitedCorridor = !inCorridor && prevInCorridor === "true";

            if (enteredCorridor) {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "corridor_entry",
                  ticker: ticker,
                  side: side,
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
              await kvPutText(KV, prevCorridorKey, "true", 7 * 24 * 60 * 60);
            } else if (exitedCorridor) {
              await kvPutText(KV, prevCorridorKey, "false", 7 * 24 * 60 * 60);
            }

            // Track squeeze start
            if (flags.sq30_on && prevSqueezeOn !== "true") {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "squeeze_start",
                  ticker: ticker,
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
              await kvPutText(KV, prevSqueezeKey, "true", 7 * 24 * 60 * 60);
            } else if (!flags.sq30_on && prevSqueezeOn === "true") {
              await kvPutText(KV, prevSqueezeKey, "false", 7 * 24 * 60 * 60);
            }

            // Track squeeze release
            if (sqRel && prevSqueezeRel !== "true") {
              await appendActivity(KV, {
                type: "squeeze_release",
                ticker: ticker,
                side:
                  side ||
                  (alignedLong ? "LONG" : alignedShort ? "SHORT" : null),
                price: payload.price,
                state: payload.state,
                rank: payload.rank,
                trigger_dir: payload.trigger_dir,
                sl: payload.sl,
                tp: payload.tp,
                tp_levels: payload.tp_levels,
                rr: payload.rr,
                phase_pct: payload.phase_pct,
                completion: payload.completion,
              });
              await kvPutText(KV, prevSqueezeRelKey, "true", 7 * 24 * 60 * 60);
            } else if (!sqRel && prevSqueezeRel === "true") {
              await kvPutText(KV, prevSqueezeRelKey, "false", 7 * 24 * 60 * 60);
            }

            // Track flip watch (tickers about to flip from PULLBACK to momentum)
            const prevFlipWatchKey = `timed:prev_flip_watch:${ticker}`;
            const prevFlipWatch = await KV.get(prevFlipWatchKey);
            const nowFlipWatch = !!flags.flip_watch;

            if (nowFlipWatch && prevFlipWatch !== "true") {
              // New flip watch - send Discord alert
              const discordEnable = env?.DISCORD_ENABLE || "false";
              const discordWebhook = env?.DISCORD_WEBHOOK_URL;
              const discordConfigured =
                discordEnable === "true" && !!discordWebhook;

              const nowMs = Date.now();
              const hourBucket = new Date(nowMs).toISOString().slice(0, 13);
              const dedupeKey = `timed:dedupe:flip_watch:${ticker}:${hourBucket}`;
              const already = await KV.get(dedupeKey);

              // [DEPRECATED] Flip watch Discord notification removed — routes to "setup" stage now
              // Detection logic preserved for internal tracking, just no separate Discord notification
              if (!already && discordConfigured) {
                await KV.put(dedupeKey, "1", { expirationTtl: 60 * 60 * 4 });
                console.log(
                  `[FLIP WATCH] ${ticker} detected, score=${payload.flip_watch_score} (Discord suppressed — setup stage)`,
                );
              }

              await appendActivity(KV, {
                type: "flip_watch",
                ticker: ticker,
                side: side,
                price: payload.price,
                state: payload.state,
                rank: payload.rank,
                flip_watch_score: payload.flip_watch_score,
                flip_watch_reasons: payload.flip_watch_reasons,
                sl: payload.sl,
                tp: payload.tp,
                tp_levels: payload.tp_levels,
                rr: payload.rr,
                phase_pct: payload.phase_pct,
                completion: payload.completion,
              });

              await kvPutText(KV, prevFlipWatchKey, "true", 7 * 24 * 60 * 60);
            } else if (!nowFlipWatch && prevFlipWatch === "true") {
              await kvPutText(KV, prevFlipWatchKey, "false", 7 * 24 * 60 * 60);
            }

            // Track state change to aligned
            if (enteredAligned) {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "state_aligned",
                  ticker: ticker,
                  side: alignedLong ? "LONG" : "SHORT",
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
            }

            // Track Momentum Elite status change
            const currentMomentumElite = !!(
              payload.flags && payload.flags.momentum_elite
            );
            if (currentMomentumElite && prevMomentumElite !== "true") {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "momentum_elite",
                  ticker: ticker,
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
              await kvPutText(
                KV,
                prevMomentumEliteKey,
                "true",
                7 * 24 * 60 * 60,
              );
            } else if (!currentMomentumElite && prevMomentumElite === "true") {
              await kvPutText(
                KV,
                prevMomentumEliteKey,
                "false",
                7 * 24 * 60 * 60,
              );
            }
          } catch (activityErr) {
            console.error(
              `[ACTIVITY ERROR] Failed to track activity for ${ticker}:`,
              {
                error: String(activityErr),
                message: activityErr.message,
                stack: activityErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if activity tracking fails
          }

          // Add ingestion timestamp to payload for per-ticker tracking
          const now = Date.now();
          payload.ingest_ts = now; // Timestamp when this data was ingested
          payload.ingest_time = new Date(now).toISOString(); // Human-readable format

          // Attach ML v1 score so UI can display model fields immediately.
          try {
            await mlV1AttachToPayload(KV, payload);
          } catch (e) {
            console.warn(
              `[ML V1] attach failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] About to get previous data and store`);
          }

          // Get previous data BEFORE storing new data (for trade simulation comparison)
          const prevLatest = await kvGetJSON(KV, `timed:latest:${ticker}`);

          // ─────────────────────────────────────────────────────────────
          // Daily change support (watchlist-style)
          // We persist a "yesterday close" per ticker in KV and compute day_change/day_change_pct.
          // ─────────────────────────────────────────────────────────────
          try {
            const curTs = Number(payload.ts ?? now);
            const curDay = nyTradingDayKey(curTs);
            const price = Number(payload.price);

            let prevClose = null;
            const prevCloseKey = `timed:prev_close:${ticker}`;
            const storedPrev = await kvGetJSON(KV, prevCloseKey);
            if (
              storedPrev &&
              storedPrev.day &&
              storedPrev.day !== curDay &&
              Number.isFinite(Number(storedPrev.close)) &&
              Number(storedPrev.close) > 0
            ) {
              prevClose = Number(storedPrev.close);
            }

            // If no stored prev close, derive it on day-boundary from the last stored tick
            if (!Number.isFinite(prevClose) && prevLatest) {
              const prevTs = Number(
                prevLatest.ts ?? prevLatest.ingest_ts ?? prevLatest.ingest_time,
              );
              const prevDay = nyTradingDayKey(prevTs);
              const prevPrice = Number(prevLatest.price);
              if (
                curDay &&
                prevDay &&
                prevDay !== curDay &&
                Number.isFinite(prevPrice) &&
                prevPrice > 0
              ) {
                prevClose = prevPrice;
                // Store for up to ~2 weeks
                await kvPutJSON(
                  KV,
                  prevCloseKey,
                  { day: prevDay, close: prevPrice },
                  14 * 24 * 60 * 60,
                );
              }
            }

            if (
              Number.isFinite(price) &&
              price > 0 &&
              Number.isFinite(prevClose) &&
              prevClose > 0
            ) {
              payload.prev_close = prevClose;
              payload.day_change = price - prevClose;
              payload.day_change_pct = ((price - prevClose) / prevClose) * 100;
            }
          } catch (e) {
            console.warn(
              `[DAILY CHANGE] Failed to compute daily change for ${ticker}:`,
              String(e?.message || e),
            );
          }

          if (ticker === "ETHT") {
            console.log(
              `[ETHT DEBUG] Previous data retrieved, about to store latest`,
            );
          }

          // Attach ML score (v1) so UI can display model output immediately.
          // This is lightweight and does not require D1.
          try {
            await mlV1AttachToPayload(KV, payload);
          } catch (e) {
            console.warn(`[ML_V1] attach failed for ${ticker}:`, String(e));
          }

          // Store latest (do this BEFORE alert so UI has it)
          // Delta-based write: skip if no meaningful change to reduce KV write pressure
          const _kvWriteNeeded = hasPayloadChangedMeaningfully(existing, payload);
          if (_kvWriteNeeded) {
            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
          }

          // Enqueue for ML training (4h and 1d horizons)
          try {
            await d1EnqueueMlV1(env, ticker, payload, [4 * 60 * 60 * 1000, 24 * 60 * 60 * 1000]);
          } catch (e) {
            console.error(`[ML ENQUEUE] Failed for ${ticker}:`, String(e));
          }

          // ═══════════════════════════════════════════════════════════════════
          // MODEL PREDICTION LOGGING (Phase 2 — Self-Learning Model)
          // Check if this scoring update warrants a prediction. Non-blocking.
          // ═══════════════════════════════════════════════════════════════════
          try {
            const DB = env?.DB;
            if (DB) {
              const predCheck = shouldLogPrediction(payload, existing);
              if (predCheck) {
                ctx.waitUntil((async () => {
                  try {
                    // Match against active pattern library
                    const activePatterns = await getActivePatterns(DB);
                    const matched = matchPatterns(payload, activePatterns);
                    const matchedIds = matched.map((m) => m.pattern_id).join(",");

                    // Use highest-confidence pattern's direction if available
                    const bestMatch = matched.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];

                    // Merge structural flags + TD Sequential features for model persistence
                    const flagsWithTD = {
                      ...(payload.flags || {}),
                      ...(extractTDSeqFeatures(payload) || {}),
                    };

                    await logPrediction(DB, {
                      ticker,
                      ts: Number(payload.ts) || Date.now(),
                      price: Number(payload.price) || 0,
                      direction: predCheck.direction,
                      trigger_type: predCheck.trigger_type,
                      confidence: bestMatch?.confidence > 0.7 ? "high" : bestMatch?.confidence > 0.4 ? "medium" : predCheck.confidence || "low",
                      horizon_days: 5,
                      htf_score: payload.htf_score,
                      ltf_score: payload.ltf_score,
                      state: payload.state,
                      completion: payload.completion,
                      phase_pct: payload.phase_pct,
                      rank: payload.rank,
                      kanban_stage: payload.kanban_stage,
                      entry_path: predCheck.entry_path || payload.__entry_path,
                      entry_reason: predCheck.entry_reason || payload.__entry_reason,
                      sector: payload.sector,
                      flags_json: JSON.stringify(flagsWithTD),
                      matched_patterns: matchedIds || null,
                    });
                  } catch (e) {
                    console.warn(`[MODEL] Prediction log failed for ${ticker}:`, String(e?.message || e).slice(0, 200));
                  }
                })());
              }
            }
          } catch (e) {
            // Model logging should never break the ingest flow
            console.warn(`[MODEL] Prediction check failed:`, String(e?.message || e).slice(0, 100));
          }

          // Upsert latest snapshot to D1 for fast UI reads (best-effort)
          try {
            ctx.waitUntil(d1UpsertTickerLatest(env, ticker, payload));
            ctx.waitUntil(d1UpsertTickerIndex(env, ticker, payload?.ts));
          } catch {
            // ignore
          }

          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Successfully stored latest data`);
          }

          // Store version-specific snapshot for historical access
          const snapshotVersion = payload.script_version || "unknown";
          if (snapshotVersion !== "unknown") {
            await kvPutJSON(
              KV,
              `timed:snapshot:${ticker}:${snapshotVersion}`,
              payload,
            );
            // Also store timestamp of when this version was last seen
            await kvPutText(
              KV,
              `timed:version:${ticker}:${snapshotVersion}:last_seen`,
              String(payload.ts || Date.now()),
            );
          }

          console.log(
            `[INGEST STORED] ${ticker} - latest data saved at ${new Date(
              now,
            ).toISOString()}`,
          );

          // CRITICAL: Ensure ticker is in index IMMEDIATELY after storage
          // This ensures ticker appears on dashboard even if request is canceled later
          await ensureTickerIndex(KV, ticker);
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Indexing completed`);
          }

          // CRITICAL: Trade simulation runs BEFORE alert evaluation
          // If a trade is entered, we suppress the alert for this ticker.
          // Wrap in try-catch to prevent trade simulation errors from breaking ingestion
          try {
            // Pre-check: Calculate entry RR first to avoid unnecessary processing
            // Use trigger_price if available, otherwise use current price
            const entryPriceForCheck = payload.trigger_price
              ? Number(payload.trigger_price)
              : payload.price
                ? Number(payload.price)
                : null;

            if (entryPriceForCheck && entryPriceForCheck > 0) {
              const entryRRForCheck = computeRRAtTrigger(payload);
              const payloadWithEntryRR = {
                ...payload,
                rr: entryRRForCheck || payload.rr || 0,
              };

              // Only proceed if initial check passes
              if (
                shouldTriggerTradeSimulation(
                  ticker,
                  payloadWithEntryRR,
                  prevLatest,
                )
              ) {
                await processTradeSimulation(
                  KV,
                  ticker,
                  payload,
                  prevLatest,
                  env,
                );
              } else {
                console.log(
                  `[TRADE SIM] ${ticker}: Pre-check failed - entryRR=${
                    entryRRForCheck?.toFixed(2) || "null"
                  }, rank=${payload.rank || 0}, state=${payload.state || "N/A"}`,
                );
              }
            } else {
              console.log(
                `[TRADE SIM] ${ticker}: Skipping - no valid entry price (trigger_price=${payload.trigger_price}, price=${payload.price})`,
              );
            }
          } catch (tradeSimErr) {
            console.error(
              `[TRADE SIM ERROR] Failed to process trade simulation for ${ticker}:`,
              {
                error: String(tradeSimErr),
                message: tradeSimErr.message,
                stack: tradeSimErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if trade simulation fails
          }

          // CRITICAL: Alert evaluation runs after trade simulation
          // Alert evaluation uses corridor state variables loaded above (prevInCorridor, etc.)
          // Wrap in try-catch to prevent alert errors from breaking ingestion
          try {
            // Threshold gates (with Momentum Elite adjustments)
            const momentumElite = !!flags.momentum_elite;

            // Momentum Elite gets relaxed thresholds (higher quality stocks)
            const baseMinRR = Number(env.ALERT_MIN_RR || "1.5");
            const baseMaxComp = Number(env.ALERT_MAX_COMPLETION || "0.4");
            const baseMaxPhase = Number(env.ALERT_MAX_PHASE || "0.6");
            // Adjust thresholds for Momentum Elite (more lenient for quality stocks)
            const minRR = momentumElite
              ? Math.max(1.2, baseMinRR * 0.9)
              : baseMinRR; // Lower RR requirement
            const maxComp = momentumElite
              ? Math.min(0.5, baseMaxComp * 1.25)
              : baseMaxComp; // Allow higher completion
            const maxPhase = momentumElite
              ? Math.min(0.7, baseMaxPhase * 1.17)
              : baseMaxPhase; // Allow higher phase

            // Use current price for dynamic RR calculation (real-time risk/reward)
            // This shows the current R:R based on where price is now, not where it was at trigger
            // This is more accurate for alerts as it reflects the actual current opportunity
            const currentRR = computeRR(payload);
            const rrToUse =
              currentRR != null
                ? currentRR
                : payload.rr != null
                  ? Number(payload.rr)
                  : 0;
            const rrOk = rrToUse >= minRR;
            const compOk =
              payload.completion == null
                ? true
                : Number(payload.completion) <= maxComp;
            const phaseOk =
              payload.phase_pct == null
                ? true
                : Number(payload.phase_pct) <= maxPhase;

            // Also consider Momentum Elite as a trigger condition (quality signal)
            // Momentum Elite can trigger even if not fully aligned, as long as in corridor
            const momentumEliteTrigger =
              momentumElite && inCorridor && (corridorAlignedOK || sqRel);

            // Enhanced trigger: original conditions OR Momentum Elite in good setup
            const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

            // Debug logging for alert conditions - log all tickers in corridor or entering corridor
            if (inCorridor || enteredCorridor) {
              console.log(`[ALERT DEBUG] ${ticker}:`, {
                inCorridor,
                enteredCorridor,
                prevInCorridor,
                corridorAlignedOK,
                side,
                state: payload.state,
                enteredAligned,
                trigOk,
                trigReason,
                sqRel,
                shouldConsiderAlert,
                momentumEliteTrigger,
                enhancedTrigger,
                rrOk,
                rr: rrToUse,
                rrFromPayload: payload.rr,
                calculatedAtCurrentPrice: currentRR,
                minRR,
                compOk,
                completion: payload.completion,
                maxComp,
                phaseOk,
                phase: payload.phase_pct,
                maxPhase,
                momentumElite,
                flags: payload.flags,
              });
            }

            // Log alert evaluation summary
            console.log(`[ALERT EVAL] ${ticker}:`, {
              enhancedTrigger,
              rrOk,
              rr: rrToUse,
              rrFromPayload: payload.rr,
              calculatedAtCurrentPrice: currentRR,
              compOk,
              completion: payload.completion,
              phaseOk,
              phase: payload.phase_pct,
              allConditionsMet: enhancedTrigger && rrOk && compOk && phaseOk,
            });

            // Enhanced logging for alert conditions - log what's blocking alerts
            if (inCorridor && !(enhancedTrigger && rrOk && compOk && phaseOk)) {
              const blockers = [];
              if (!enhancedTrigger) blockers.push("trigger conditions");
              if (!rrOk)
                blockers.push(
                  `RR (${
                    rrToUse?.toFixed(2) || "null"
                  } < ${minRR}, payload.rr=${
                    payload.rr?.toFixed(2) || "null"
                  }, currentRR=${currentRR?.toFixed(2) || "null"})`,
                );
              if (!compOk)
                blockers.push(
                  `Completion (${
                    payload.completion?.toFixed(2) || "null"
                  } > ${maxComp})`,
                );
              if (!phaseOk)
                blockers.push(
                  `Phase (${
                    payload.phase_pct?.toFixed(2) || "null"
                  } > ${maxPhase})`,
                );

              console.log(
                `[ALERT BLOCKED] ${ticker}: Alert blocked by: ${blockers.join(
                  ", ",
                )}`,
              );
            }

            // Trade simulation already processed above (before alert logic)

            // Check Discord configuration before evaluating conditions
            const discordEnable = env.DISCORD_ENABLE || "false";
            const discordWebhook = env.DISCORD_WEBHOOK_URL;
            const discordConfigured =
              discordEnable === "true" && !!discordWebhook;

            if (!discordConfigured && (inCorridor || enteredCorridor)) {
              console.log(
                `[DISCORD CONFIG] ${ticker}: Discord not configured`,
                {
                  DISCORD_ENABLE: discordEnable,
                  hasWebhook: !!discordWebhook,
                  inCorridor,
                  enteredCorridor,
                },
              );
            }

            const tradeSide = side || getTradeDirection(payload.state);
            
            // D1: Check for open position using D1 as single source of truth
            const d1OpenPosition = env?.DB ? await getPositionContext(env, ticker) : null;
            const hasOpenPosition = !!(d1OpenPosition && d1OpenPosition.status === "OPEN");
            
            // Fallback to KV trade lookup (will be deprecated)
            const openTrade = !hasOpenPosition ? (tradeSide
              ? await findOpenTradeForTicker(KV, ticker, tradeSide)
              : await findOpenTradeForTicker(KV, ticker, null)) : null;
            
            // Anti-churning check: limit trades per ticker per day
            const tradeFrequency = env?.DB ? await checkTradeFrequency(env, ticker) : { blocked: false };
            if (tradeFrequency.blocked) {
              console.log(
                `[ALERT SKIPPED] ${ticker}: Anti-churning block - ${tradeFrequency.reason} (${tradeFrequency.message})`,
              );
            } else if (hasOpenPosition || openTrade) {
              console.log(
                `[ALERT SKIPPED] ${ticker}: Trade already open (${
                  d1OpenPosition?.direction || openTrade?.direction || "UNKNOWN"
                }, source: ${hasOpenPosition ? "D1" : "KV"})`,
              );
            } else if (enhancedTrigger && rrOk && compOk && phaseOk) {
              // Smart dedupe: action + direction + UTC minute bucket (prevents duplicates but allows valid re-alerts)
              const action = "ENTRY";
              const alertEventTs = Number(
                payload.trigger_ts || payload.ts || Date.now(),
              );
              const dedupeInfo = buildAlertDedupeKey({
                ticker,
                action,
                side,
                ts: alertEventTs,
              });
              const akey = dedupeInfo.key;
              const today =
                dedupeInfo.day || new Date().toISOString().split("T")[0];
              const alreadyAlerted = akey ? await KV.get(akey) : null;

              console.log(`[ALERT CHECK] ${ticker}:`, {
                enhancedTrigger,
                rrOk,
                compOk,
                phaseOk,
                allConditionsMet: true,
                today,
                akey,
                dedupe_bucket: dedupeInfo.bucket,
                action,
                alreadyAlerted: !!alreadyAlerted,
                trigger_ts: payload.trigger_ts,
                ts: payload.ts,
              });

              if (!alreadyAlerted) {
                // Store deduplication key for 48 hours (covers edge cases around midnight)
                if (akey) {
                  await kvPutText(KV, akey, "1", 48 * 60 * 60);
                }

                console.log(`[DISCORD ALERT] Sending alert for ${ticker}`, {
                  akey,
                  today,
                  dedupe_bucket: dedupeInfo.bucket,
                  action,
                  side,
                  rank: payload.rank,
                  discordConfigured,
                  DISCORD_ENABLE: discordEnable,
                  hasWebhook: !!discordWebhook,
                });

                const alertTs = alertEventTs;
                const alertPayloadJson = (() => {
                  try {
                    return JSON.stringify(payload);
                  } catch {
                    return null;
                  }
                })();
                const alertMetaJson = (() => {
                  try {
                    return JSON.stringify({
                      akey,
                      today,
                      dedupe_bucket: dedupeInfo.bucket,
                      action,
                      alreadyAlerted: false,
                      side,
                      state: payload.state,
                      rank: payload.rank,
                      rr: rrToUse,
                      rrFromPayload: payload.rr,
                      calculatedAtCurrentPrice: currentRR,
                      thresholds: { minRR, maxComp, maxPhase },
                      checks: {
                        inCorridor,
                        enteredCorridor,
                        prevInCorridor,
                        corridorAlignedOK,
                        enteredAligned,
                        trigOk,
                        trigReason,
                        sqRel,
                        shouldConsiderAlert,
                        momentumEliteTrigger,
                        enhancedTrigger,
                        rrOk,
                        compOk,
                        phaseOk,
                      },
                      discordConfigured,
                    });
                  } catch {
                    return null;
                  }
                })();

                const why =
                  (side === "LONG"
                    ? "Entry corridor Q1→Q2"
                    : "Entry corridor Q4→Q3") +
                  (momentumElite ? " | 🚀 Momentum Elite" : "") +
                  (enteredAligned ? " | Entered aligned" : "") +
                  (trigReason
                    ? ` | ${trigReason}${
                        payload.trigger_dir
                          ? " (" + payload.trigger_dir + ")"
                          : ""
                      }`
                    : "") +
                  (sqRel ? " | ⚡ squeeze release" : "");

                const tv = `https://www.tradingview.com/chart/?symbol=${encodeURIComponent(
                  ticker,
                )}`;

                // Create Discord embed for trading opportunity
                // Calculate current R:R using current price (not trigger price)
                // This gives accurate R:R based on where price is now
                const currentRR = computeRR(payload);
                const rr = currentRR != null ? currentRR : payload.rr || 0;

                // Process TP levels with metadata
                const currentPrice = Number(payload.price) || 0;
                let tpLevels = [];
                let maxTP = Number(payload.tp);
                let minTP = Number(payload.tp);

                if (
                  payload.tp_levels &&
                  Array.isArray(payload.tp_levels) &&
                  payload.tp_levels.length > 0
                ) {
                  tpLevels = payload.tp_levels
                    .map((tpItem) => {
                      if (
                        typeof tpItem === "object" &&
                        tpItem !== null &&
                        tpItem.price != null
                      ) {
                        const price = Number(tpItem.price);
                        if (!Number.isFinite(price) || price <= 0) return null;
                        return {
                          price,
                          source: tpItem.source || "ATR Level",
                          type: tpItem.type || "ATR_FIB",
                          timeframe: tpItem.timeframe || "D",
                          confidence: Number(tpItem.confidence || 0.75),
                          multiplier: tpItem.multiplier
                            ? Number(tpItem.multiplier)
                            : null,
                          label: tpItem.label || "TP",
                        };
                      }
                      const price =
                        typeof tpItem === "number"
                          ? Number(tpItem)
                          : Number(tpItem);
                      if (!Number.isFinite(price) || price <= 0) return null;
                      return {
                        price,
                        source: "ATR Level",
                        type: "ATR_FIB",
                        timeframe: "D",
                        confidence: 0.75,
                        multiplier: null,
                        label: "TP",
                      };
                    })
                    .filter((tp) => tp !== null);

                  if (tpLevels.length > 0) {
                    const tpPrices = tpLevels.map((tp) => tp.price);
                    maxTP = Math.max(...tpPrices);
                    minTP = Math.min(...tpPrices);
                  }
                }

                // Add primary TP if not already in levels
                const primaryTP = Number(payload.tp);
                if (Number.isFinite(primaryTP) && primaryTP > 0) {
                  const exists = tpLevels.some(
                    (tp) => Math.abs(tp.price - primaryTP) < 0.01,
                  );
                  if (!exists) {
                    tpLevels.push({
                      price: primaryTP,
                      source: "Primary TP",
                      type: "ATR_FIB",
                      timeframe: "D",
                      confidence: 0.75,
                      multiplier: null,
                      label: "TP",
                    });
                  }
                }

                // Sort TP levels by price (ascending for LONG, descending for SHORT)
                const state = String(payload.state || "");
                const isLong = state.includes("BULL");
                tpLevels.sort((a, b) =>
                  isLong ? a.price - b.price : b.price - a.price,
                );

                const rrFormatted =
                  rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;

                // Calculate distance to TP and SL from current price
                const distanceToMaxTP =
                  maxTP > 0 ? Math.abs(maxTP - currentPrice) : 0;
                const distanceToSL =
                  Number(payload.sl) > 0
                    ? Math.abs(currentPrice - Number(payload.sl))
                    : 0;
                const maxTPDistancePct =
                  currentPrice > 0
                    ? ((distanceToMaxTP / currentPrice) * 100).toFixed(2)
                    : "0.00";
                const slDistancePct =
                  currentPrice > 0
                    ? ((distanceToSL / currentPrice) * 100).toFixed(2)
                    : "0.00";

                // Generate comprehensive trade opportunity interpretation
                const interpretation = generateTradeActionInterpretation(
                  "ENTRY",
                  payload,
                  {
                    direction: side,
                    rank: payload.rank,
                    rr: rr,
                  },
                );

                // Build comprehensive fields similar to Trade Entered card
                const fields = [];

                // Action & Reasoning (comprehensive explanation)
                if (interpretation) {
                  fields.push({
                    name: "📊 Why This Is A Trade Opportunity",
                    value: `${interpretation.action}\n\n${interpretation.reasons}`,
                    inline: false,
                  });
                } else {
                  // Fallback detailed explanation
                  const reasons = [];
                  if (inCorridor) reasons.push("✅ Price is in entry corridor");
                  if (corridorAlignedOK)
                    reasons.push("✅ Timeframes are aligned");
                  if (enhancedTrigger)
                    reasons.push("✅ Trigger conditions met");
                  if (momentumElite) reasons.push("⭐ Momentum Elite stock");
                  if (rr >= 1.5)
                    reasons.push(`💰 Excellent R:R (${rrFormatted})`);
                  if (payload.rank >= 75)
                    reasons.push(`⭐ High rank (${payload.rank})`);

                  fields.push({
                    name: "📊 Why This Is A Trade Opportunity",
                    value:
                      reasons.length > 0
                        ? reasons.join("\n")
                        : why || "Trade opportunity detected",
                    inline: false,
                  });
                }

                // Entry Details
                fields.push({
                  name: "💰 Entry Details",
                  value: `**Trigger Price:** $${fmt2(
                    payload.trigger_price,
                  )}\n**Current Price:** $${fmt2(
                    payload.price,
                  )}\n**Stop Loss:** $${fmt2(
                    payload.sl,
                  )} (${slDistancePct}% away)`,
                  inline: false,
                });

                // TP Levels with detailed breakdown
                if (tpLevels.length > 0) {
                  const tpLevelText = tpLevels
                    .map((tp) => {
                      const distance = Math.abs(tp.price - currentPrice);
                      const distancePct =
                        currentPrice > 0
                          ? ((distance / currentPrice) * 100).toFixed(2)
                          : "0.00";
                      const isMax = Math.abs(tp.price - maxTP) < 0.01;
                      const prefix = isMax ? "**⭐ MAX TP:**" : `**TP:**`;
                      const typeLabel =
                        tp.type === "STRUCTURE"
                          ? "Structure"
                          : tp.type === "ATR_FIB"
                            ? tp.multiplier
                              ? `ATR×${tp.multiplier}`
                              : "ATR Fib"
                            : tp.type;
                      const tfLabel =
                        tp.timeframe === "W"
                          ? "Weekly"
                          : tp.timeframe === "D"
                            ? "Daily"
                            : tp.timeframe === "240" || tp.timeframe === "4H"
                              ? "4H"
                              : tp.timeframe;
                      return `${prefix} $${tp.price.toFixed(
                        2,
                      )} (${distancePct}% away) - ${typeLabel} @ ${tfLabel} (${(
                        tp.confidence * 100
                      ).toFixed(0)}% conf)`;
                    })
                    .join("\n");

                  fields.push({
                    name: "🎯 Take Profit Levels",
                    value: tpLevelText,
                    inline: false,
                  });
                } else {
                  // Fallback if no TP levels
                  const distanceToTP =
                    primaryTP > 0 ? Math.abs(primaryTP - currentPrice) : 0;
                  const tpDistancePct =
                    currentPrice > 0
                      ? ((distanceToTP / currentPrice) * 100).toFixed(2)
                      : "0.00";
                  const tpVeryClose =
                    currentPrice > 0 && distanceToTP / currentPrice < 0.005;
                  const tpWarning = tpVeryClose ? " ⚠️ Very close!" : "";

                  fields.push({
                    name: "🎯 Take Profit",
                    value: `**Primary TP:** $${fmt2(
                      primaryTP,
                    )} (${tpDistancePct}% away)${tpWarning}`,
                    inline: false,
                  });
                }

                // Scores & Metrics
                const htfScore = Number(payload.htf_score || 0);
                const ltfScore = Number(payload.ltf_score || 0);
                const completion = Number(payload.completion || 0);
                const phase = Number(payload.phase_pct || 0);

                fields.push({
                  name: "📈 Scores & Metrics",
                  value: `**HTF Score:** ${htfScore.toFixed(
                    2,
                  )}\n**LTF Score:** ${ltfScore.toFixed(2)}\n**Completion:** ${(
                    completion * 100
                  ).toFixed(1)}%\n**Phase:** ${(phase * 100).toFixed(1)}%`,
                  inline: true,
                });

                // Quality Metrics
                fields.push({
                  name: "⭐ Quality Metrics",
                  value: `**Rank:** ${
                    payload.rank
                  }\n**Risk/Reward:** ${rrFormatted}${
                    currentRR != null && currentRR !== payload.rr ? " ⚠️" : ""
                  }\n**State:** ${payload.state || "N/A"}\n**ETA:** ${
                    payload.eta_days != null
                      ? `${Number(payload.eta_days).toFixed(1)}d`
                      : "—"
                  }`,
                  inline: true,
                });

                // Active Signals
                if (payload.flags) {
                  const flags = payload.flags;
                  const flagItems = [];
                  if (flags.sq30_release) flagItems.push("🚀 Squeeze Release");
                  if (flags.sq30_on && !flags.sq30_release)
                    flagItems.push("💥 In Squeeze");
                  if (flags.momentum_elite) flagItems.push("⭐ Momentum Elite");
                  if (flags.phase_dot) flagItems.push("⚫ Phase Dot");
                  if (flags.phase_zone_change)
                    flagItems.push("🔄 Phase Zone Change");

                  if (flagItems.length > 0) {
                    fields.push({
                      name: "🚩 Active Signals",
                      value: flagItems.join("\n"),
                      inline: false,
                    });
                  }
                }

                // TD Sequential if available
                if (payload.td_sequential) {
                  const tdSeq = payload.td_sequential;
                  const tdItems = [];
                  if (tdSeq.td9_bullish) tdItems.push("🔢 TD9 Bullish");
                  if (tdSeq.td9_bearish) tdItems.push("🔢 TD9 Bearish");
                  if (tdSeq.td13_bullish) tdItems.push("🔢 TD13 Bullish");
                  if (tdSeq.td13_bearish) tdItems.push("🔢 TD13 Bearish");

                  if (tdItems.length > 0) {
                    fields.push({
                      name: "🔢 TD Sequential",
                      value:
                        tdItems.join("\n") +
                        (tdSeq.boost
                          ? `\n**Boost:** ${Number(tdSeq.boost).toFixed(1)}`
                          : ""),
                      inline: false,
                    });
                  }
                }

                // RSI if available
                if (payload.rsi) {
                  const rsi = payload.rsi;
                  const rsiValue = Number(rsi.value || 0);
                  const rsiLevel = rsi.level || "neutral";
                  const divergence = rsi.divergence || {};

                  let rsiText = `**RSI:** ${rsiValue.toFixed(2)} (${rsiLevel})`;
                  if (divergence.type && divergence.type !== "none") {
                    rsiText += `\n**Divergence:** ${
                      divergence.type === "bullish"
                        ? "🔼 Bullish"
                        : "🔽 Bearish"
                    }`;
                    if (divergence.strength) {
                      rsiText += ` (Strength: ${Number(
                        divergence.strength,
                      ).toFixed(2)})`;
                    }
                  }

                  fields.push({
                    name: "📊 RSI",
                    value: rsiText,
                    inline: false,
                  });
                }

                // EMA Cloud positions if available
                if (
                  payload.daily_ema_cloud ||
                  payload.fourh_ema_cloud ||
                  payload.oneh_ema_cloud
                ) {
                  const cloudItems = [];
                  if (payload.daily_ema_cloud) {
                    const daily = payload.daily_ema_cloud;
                    cloudItems.push(
                      `**Daily (5-8 EMA):** ${daily.position.toUpperCase()}`,
                    );
                  }
                  if (payload.fourh_ema_cloud) {
                    const fourH = payload.fourh_ema_cloud;
                    cloudItems.push(
                      `**4H (8-13 EMA):** ${fourH.position.toUpperCase()}`,
                    );
                  }
                  if (payload.oneh_ema_cloud) {
                    const oneH = payload.oneh_ema_cloud;
                    cloudItems.push(
                      `**1H (13-21 EMA):** ${oneH.position.toUpperCase()}`,
                    );
                  }

                  if (cloudItems.length > 0) {
                    fields.push({
                      name: "☁️ EMA Cloud Positions",
                      value: cloudItems.join("\n"),
                      inline: false,
                    });
                  }
                }

                const allowDiscord = shouldSendDiscordAlert(
                  env,
                  "ALERT_ENTRY",
                  {
                    ticker,
                    side,
                    rank: payload.rank,
                    rr: rrToUse,
                    momentumElite,
                  },
                );

                const opportunityEmbed = {
                  title: `🎯 Trading Opportunity: ${ticker} ${side}`,
                  color: side === "LONG" ? 0x00ff00 : 0xff0000, // Green for LONG, Red for SHORT
                  fields: fields,
                  timestamp: new Date().toISOString(),
                  footer: {
                    text: "Timed Trading Alert",
                  },
                  url: tv, // Make the title clickable to open TradingView
                };

                const sendRes = allowDiscord
                  ? await notifyDiscord(env, opportunityEmbed)
                  : {
                      ok: false,
                      skipped: true,
                      reason: "suppressed_critical_only",
                    };

                // Persist alert ledger record to D1 (best-effort)
                d1UpsertAlert(env, {
                  ticker,
                  ts: alertTs,
                  side,
                  state: payload.state,
                  rank: payload.rank,
                  rr_at_alert: rrToUse,
                  trigger_reason: trigReason,
                  dedupe_day: today,
                  discord_sent: !!sendRes?.ok,
                  discord_status: sendRes?.status ?? null,
                  discord_error: sendRes?.ok
                    ? null
                    : sendRes?.reason ||
                      sendRes?.statusText ||
                      sendRes?.error ||
                      "discord_send_failed",
                  payload_json: alertPayloadJson,
                  meta_json: alertMetaJson,
                }).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to upsert alert ${ticker}:`,
                    e,
                  );
                });

                // Log Discord alert to activity feed
                if (sendRes?.ok) {
                  await appendActivity(KV, {
                    ticker,
                    type: "discord_alert",
                    direction: side,
                    action: "entry",
                    rank: payload.rank,
                    rr: payload.rr,
                    price: payload.price,
                    trigger_price: payload.trigger_price,
                    sl: payload.sl,
                    tp: payload.tp,
                    state: payload.state,
                    htf_score: payload.htf_score,
                    ltf_score: payload.ltf_score,
                    completion: payload.completion,
                    phase_pct: payload.phase_pct,
                    why: why,
                    momentum_elite: momentumElite,
                  });
                }
              } else {
                console.log(
                  `[DISCORD ALERT] Skipped ${ticker} - already alerted`,
                  {
                    akey,
                    today,
                    dedupe_bucket: dedupeInfo.bucket,
                    action,
                  },
                );

                // Persist deduped alert decision to D1 (best-effort)
                const alertTs = alertEventTs;
                const alertPayloadJson = (() => {
                  try {
                    return JSON.stringify(payload);
                  } catch {
                    return null;
                  }
                })();
                const alertMetaJson = (() => {
                  try {
                    return JSON.stringify({
                      akey,
                      today,
                      dedupe_bucket: dedupeInfo.bucket,
                      action,
                      alreadyAlerted: true,
                      side,
                      state: payload.state,
                      rank: payload.rank,
                      rr: rrToUse,
                      rrFromPayload: payload.rr,
                      calculatedAtCurrentPrice: currentRR,
                      thresholds: { minRR, maxComp, maxPhase },
                      checks: {
                        inCorridor,
                        enteredCorridor,
                        prevInCorridor,
                        corridorAlignedOK,
                        enteredAligned,
                        trigOk,
                        trigReason,
                        sqRel,
                        shouldConsiderAlert,
                        momentumEliteTrigger,
                        enhancedTrigger,
                        rrOk,
                        compOk,
                        phaseOk,
                      },
                      discordConfigured,
                    });
                  } catch {
                    return null;
                  }
                })();
                d1UpsertAlert(env, {
                  ticker,
                  ts: alertTs,
                  side,
                  state: payload.state,
                  rank: payload.rank,
                  rr_at_alert: rrToUse,
                  trigger_reason: trigReason,
                  dedupe_day: today,
                  discord_sent: false,
                  discord_status: null,
                  discord_error: "deduped_already_alerted",
                  payload_json: alertPayloadJson,
                  meta_json: alertMetaJson,
                }).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to upsert deduped alert ${ticker}:`,
                    e,
                  );
                });
              }
            } else if (inCorridor && corridorAlignedOK) {
              // Log why alert didn't fire
              const reasons = [];
              if (!enhancedTrigger) reasons.push("no trigger condition");
              if (!rrOk)
                reasons.push(
                  `RR ${rrToUse?.toFixed(2) || "null"} < ${minRR} (payload.rr=${
                    payload.rr?.toFixed(2) || "null"
                  })`,
                );
              if (!compOk)
                reasons.push(`Completion ${payload.completion} > ${maxComp}`);
              if (!phaseOk)
                reasons.push(`Phase ${payload.phase_pct} > ${maxPhase}`);
              console.log(`[ALERT SKIPPED] ${ticker}: ${reasons.join(", ")}`);
            }

            // Check for TD9 entry signals (potential reversal setups)
            // NOTE: td_sequential now preferably computed server-side from D/W/M candles
            // (via computeTDSequentialMultiTF in indicators.js). Webhook data serves as fallback.
            const tdSeq = payload.td_sequential || {};
            const td9Bullish =
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true";
            const td9Bearish =
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true";
            const td13Bullish =
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true";
            const td13Bearish =
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true";

            // TD9 entry signal: TD9/TD13 bullish suggests LONG, TD9/TD13 bearish suggests SHORT
            const hasTD9Signal =
              td9Bullish || td9Bearish || td13Bullish || td13Bearish;
            if (hasTD9Signal) {
              const suggestedDirection =
                td9Bullish || td13Bullish ? "LONG" : "SHORT";
              const signalType = td13Bullish || td13Bearish ? "TD13" : "TD9";

              // Check if TD9 signal aligns with corridor direction (potential entry)
              const td9AlignsWithCorridor =
                (suggestedDirection === "LONG" && side === "LONG") ||
                (suggestedDirection === "SHORT" && side === "SHORT");

              // Only alert if TD9 signal aligns with corridor and has reasonable RR
              if (td9AlignsWithCorridor && payload.rr >= 1.2) {
                const td9AlertKey = `timed:td9_alerted:${ticker}:${signalType}:${suggestedDirection}`;
                const alreadyTD9Alerted = await KV.get(td9AlertKey);

                if (!alreadyTD9Alerted) {
                  await kvPutText(KV, td9AlertKey, "1", 24 * 60 * 60); // 24h dedup

                  // Add activity feed event
                  await appendActivity(KV, {
                    ticker,
                    type: "td9_entry",
                    direction: suggestedDirection,
                    signalType,
                    price: payload.price,
                    sl: payload.sl,
                    tp: payload.tp,
                    rr: payload.rr,
                    rank: payload.rank,
                    td9_bullish: td9Bullish,
                    td9_bearish: td9Bearish,
                    td13_bullish: td13Bullish,
                    td13_bearish: td13Bearish,
                  });

                  // Send Discord alert (suppressed in critical-only mode)
                  // [DEPRECATED] TD9 entry notification removed — TD context now folded into KANBAN_ENTER embed
                  // The TD signal still contributes to entry qualification; if it triggers KANBAN_ENTER, that embed includes TD context

                  console.log(
                    `[TD9 ENTRY ALERT] ${ticker} ${suggestedDirection} - ${signalType} signal`,
                  );
                }
              }
            }
          } catch (alertErr) {
            console.error(
              `[ALERT ERROR] Failed to process alert evaluation for ${ticker}:`,
              {
                error: String(alertErr),
                message: alertErr.message,
                stack: alertErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if alert evaluation fails
          }

          // Store version-specific snapshot for historical access
          const version = payload.script_version || "unknown";
          if (version !== "unknown") {
            await kvPutJSON(KV, `timed:snapshot:${ticker}:${version}`, payload);
            // Also store timestamp of when this version was last seen
            await kvPutText(
              KV,
              `timed:version:${ticker}:${version}:last_seen`,
              String(payload.ts || Date.now()),
            );
          }

          await ensureTickerIndex(KV, ticker);
          await kvPutText(KV, "timed:last_ingest_ms", String(Date.now()));

          // Get current ticker count for logging
          const currentTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const wasNewTicker = !currentTickers.includes(ticker);
          console.log(
            `[INGEST COMPLETE] ${ticker} - ${
              wasNewTicker ? "NEW TICKER ADDED" : "updated existing"
            } - Total tickers in index: ${currentTickers.length} - Version: ${
              payload.script_version || "unknown"
            }`,
          );

          // Log all tickers in index if count is low (to debug missing tickers)
          if (currentTickers.length < 130) {
            console.log(
              `[INGEST INDEX DEBUG] Current tickers (${currentTickers.length}):`,
              currentTickers.slice(0, 30).join(", "),
              currentTickers.length > 30
                ? `... (showing first 30 of ${currentTickers.length})`
                : "",
            );
          }

          // Get final ticker count
          const finalTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          console.log(
            `[INGEST SUCCESS] ${ticker} - completed successfully. Total tickers: ${finalTickers.length}`,
          );
          return ackJSON(
            env,
            { ok: true, ticker, totalTickers: finalTickers.length },
            200,
            req,
          );
        } catch (error) {
          // Catch any unexpected errors during ingestion
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          const ticker = normTicker(body?.ticker) || "UNKNOWN";
          console.error(`[INGEST ERROR] ${ticker} - IP: ${ip}`, {
            error: String(error),
            stack: error.stack,
            message: error.message,
            body: body ? { ticker: body.ticker, ts: body.ts } : null,
          });
          // Return 500 instead of 429 to avoid confusion
          return ackJSON(
            env,
            {
              ok: false,
              error: "internal_error",
              message: "An error occurred during ingestion",
              ticker: ticker !== "UNKNOWN" ? ticker : null,
            },
            500,
            req,
          );
        }
      }

      // POST /timed/heartbeat (minimal KV + D1 fallback for new tickers)
      // Accepts ALL tickers. If ticker not in D1, creates minimal entry so it appears in UI.
      if (routeKey === "POST /timed/heartbeat") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const hbRate = await checkRateLimit(KV, ip, "/timed/heartbeat", 15000, 3600);
        if (!hbRate.allowed) {
          return sendJSON({ ok: false, error: "rate_limit_exceeded", retryAfter: 3600 }, 429, corsHeaders(env, req));
        }
        let body = null;
        try {
          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData;
          if (!body) {
            return ackJSON(env, { ok: false, error: "bad_json" }, 400, req);
          }
          const ticker = normTicker(body?.ticker);
          if (!ticker) {
            return ackJSON(env, { ok: false, error: "missing_ticker" }, 400, req);
          }
          const HEARTBEAT_TTL = 2 * 24 * 60 * 60; // 2 days
          const payload = {
            ticker,
            ts: body.ts ?? body.time_close ?? Date.now(),
            price: body.price,
            prev_close: body.prev_close ?? body.previous_close,
            day_change: body.day_change ?? body.change,
            day_change_pct: body.day_change_pct ?? body.change_pct,
            session: body.session,
            is_rth: body.is_rth,
            ingest_ts: Date.now(),
            ingest_kind: "heartbeat_minimal",
          };
          await kvPutJSON(KV, `timed:heartbeat:${ticker}`, payload, HEARTBEAT_TTL);
          // For new tickers: create minimal D1 entry so they appear in UI (accept all, no restrictions)
          try {
            if (env?.DB) {
              await d1EnsureLatestSchema(env);
              const existing = await env.DB.prepare(`SELECT 1 FROM ticker_latest WHERE ticker = ?1`).bind(ticker).first();
              if (!existing) {
                await d1UpsertTickerLatest(env, ticker, payload);
                await ensureTickerIndex(KV, ticker);
                await d1UpsertTickerIndex(env, ticker, payload.ts);
              }
            }
          } catch (e) {
            console.warn(`[HEARTBEAT] D1/index fallback failed for ${ticker}:`, String(e?.message || e));
          }
          return ackJSON(env, { ok: true, ticker }, 200, req);
        } catch (e) {
          console.error("[HEARTBEAT] Error:", e);
          return ackJSON(env, { ok: false, error: "internal_error" }, 500, req);
        }
      }

      // POST /timed/ingest-capture (capture-only heartbeat)
      if (routeKey === "POST /timed/ingest-capture") {
        let body = null;
        try {
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          console.log(
            `[CAPTURE INGEST RECEIVED] IP: ${ip}, User-Agent: ${
              req.headers.get("User-Agent") || "none"
            }`,
          );

          const authFail = requireKeyOr401(req, env);
          if (authFail) return authFail;

          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData;
          if (!body) {
            return ackJSON(
              env,
              {
                ok: false,
                error: "bad_json",
                sample: String(raw || "").slice(0, 200),
                parseError: String(err || ""),
              },
              400,
              req,
            );
          }

          const v = validateCapturePayload(body);
          if (!v.ok) return ackJSON(env, v, 400, req);

          const ticker = v.ticker;
          const payload = v.payload;
          const rawPayload =
            typeof raw === "string"
              ? raw
              : (() => {
                  try {
                    return JSON.stringify(body);
                  } catch {
                    return "";
                  }
                })();

          // Store raw capture payload separately for audit
          try {
            if (rawPayload) {
              await kvPutText(
                KV,
                `timed:capture:raw:${ticker}`,
                rawPayload,
                2 * 24 * 60 * 60,
              );
            }
          } catch (rawErr) {
            console.error(
              `[CAPTURE RAW] KV store failed for ${ticker}:`,
              rawErr,
            );
          }

          d1InsertIngestReceipt(env, ticker, payload, rawPayload).catch(
            (err) => {
              console.error(
                `[D1 CAPTURE] Receipt insert exception for ${ticker}:`,
                err,
              );
            },
          );

          const now = Date.now();
          payload.ingest_ts = now;
          payload.ingest_time = new Date(now).toISOString();

          // Compute Momentum Elite for capture payload too (display-only enrichment).
          // This lets the UI show 🚀 + criteria even if the ticker's scoring feed is separate.
          try {
            payload.flags =
              payload.flags && typeof payload.flags === "object"
                ? payload.flags
                : {};
            const m = await computeMomentumElite(KV, ticker, payload);
            if (m) {
              payload.flags.momentum_elite = !!m.momentum_elite;
              payload.momentum_elite_criteria = m.criteria;
            }
          } catch (e) {
            console.error(
              `[CAPTURE MOMENTUM] Failed for ${ticker}:`,
              String(e),
            );
          }

          // Persist context separately so it survives bars where context is omitted.
          // The capture heartbeat throttles context and otherwise sends a minimal payload;
          // without this, `timed:capture:latest:*` gets overwritten and context disappears.
          try {
            if (payload.context && typeof payload.context === "object") {
              // Avoid downgrading richer context (e.g. keep name/description if a later payload omits them).
              const incoming = sanitizeTickerContext(payload.context, payload);
              const saved = await kvGetJSON(KV, `timed:context:${ticker}`);
              const merged = mergeTickerContext(saved, incoming);
              await kvPutJSON(
                KV,
                `timed:context:${ticker}`,
                merged || incoming || payload.context,
                30 * 24 * 60 * 60,
              );
            }
          } catch (e) {
            console.error(
              `[CAPTURE CONTEXT] KV store failed for ${ticker}:`,
              String(e),
            );
          }

          await kvPutJSON(KV, `timed:capture:latest:${ticker}`, payload);
          // Best-effort: persist the heartbeat daily-change fields into D1 ticker_latest so /timed/all stays KV-free.
          try {
            ctx.waitUntil(
              d1PatchTickerLatestFields(env, ticker, {
                prev_close: payload.prev_close,
                day_change: payload.day_change,
                day_change_pct: payload.day_change_pct,
                change: payload.change,
                change_pct: payload.change_pct,
                session: payload.session,
                is_rth: payload.is_rth,
              }),
            );
          } catch {
            // ignore
          }
          await appendCaptureTrail(KV, ticker, {
            ts: payload.ts,
            price: payload.price,
            bar_index: payload.bar_index,
            time_close: payload.time_close,
          });
          await ensureCaptureIndex(KV, ticker);

          await kvPutText(KV, "timed:capture:last_ingest_ms", String(now));

          // If payload includes tf_candles, upsert them to D1 (heartbeat can now send both capture + candles).
          if (payload.tf_candles && typeof payload.tf_candles === "object") {
            try {
              await d1EnsureCandleSchema(env);
              for (const [tf, candle] of Object.entries(payload.tf_candles)) {
                if (candle && typeof candle === "object") {
                  ctx.waitUntil(d1UpsertCandle(env, ticker, tf, candle));
                }
              }
            } catch (candleErr) {
              console.error(
                `[CAPTURE CANDLES] Upsert failed for ${ticker}:`,
                String(candleErr),
              );
            }
          }

          // Promote capture payload into main latest/trail when it contains full score fields.
          // This fixes the “stale latest despite fresh receipts” issue when some alerts are wired to /ingest-capture.
          try {
            const hasScores =
              isNum(payload?.htf_score) &&
              isNum(payload?.ltf_score) &&
              isNum(payload?.ts);
            if (hasScores) {
              // Ensure RR is present (used widely by UI/alerts)
              if (!isNum(payload?.rr)) {
                try {
                  payload.rr = computeRR(payload);
                } catch {
                  // ignore
                }
              }

              // Store latest and trail (KV) and write to D1 trail, but do NOT run alert/discord logic here.
              // Ensure kanban_stage is always computed even on capture-promote path
              try {
                const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);
                // CRITICAL: Merge entry_ts/entry_price from existing so ACTIVE (not Watch) when move passed
                if (existing?.entry_ts != null || existing?.entry_price != null) {
                  if (payload.entry_ts == null && Number.isFinite(Number(existing?.entry_ts)))
                    payload.entry_ts = Number(existing.entry_ts);
                  if (payload.entry_price == null && Number.isFinite(Number(existing?.entry_price)))
                    payload.entry_price = Number(existing.entry_price);
                }
                if (existing?.kanban_cycle_enter_now_ts != null)
                  payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
                if (existing?.kanban_cycle_trigger_ts != null)
                  payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
                if (existing?.kanban_cycle_side != null)
                  payload.kanban_cycle_side = existing.kanban_cycle_side;
                  
                // D1 SINGLE SOURCE OF TRUTH: Get position context from D1 only
                const openPosition = env?.DB ? await getPositionContext(env, ticker) : null;
                const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
                if (hasOpenPosition) {
                  if (payload.entry_ts == null && openPosition.entry_ts) {
                    payload.entry_ts = openPosition.entry_ts;
                  }
                  if (payload.entry_price == null && openPosition.avg_entry_price > 0) {
                    payload.entry_price = openPosition.avg_entry_price;
                  }
                }
                payload.move_status = computeMoveStatus(payload);
                if (payload.flags) {
                  payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
                  payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
                  payload.flags.has_open_position = hasOpenPosition;
                }
                const stage = classifyKanbanStage(payload, openPosition);
                const prevStage = existing?.kanban_stage;
                let finalStage = stage;

                const tsNowCap = Number(payload?.ts) || Date.now();
                const dayKeyCap = nyTradingDayKey(tsNowCap);
                const marketOpenCap = dayKeyCap ? nyWallTimeToUtcMs(dayKeyCap, 9, 30, 0) : null;
                const existingTsCap = existing?.ts ?? existing?.ingest_ts;
                const firstBarAfterGapCap = isFirstBarOfDayAfterGap(existingTsCap, tsNowCap, marketOpenCap);

                // Lifecycle gate: Management stages require open position. Exception: first bar of day after AH/PM gap.
                try {
                  const mgmt =
                    finalStage === "active" ||
                    finalStage === "trim" ||
                    finalStage === "exit" ||
                    finalStage === "hold" ||        // legacy
                    finalStage === "just_entered";  // legacy
                    
                  // If management stage but no open position, force to watch
                  if (mgmt && !hasOpenPosition) {
                    finalStage = "watch";
                    if (!payload.flags) payload.flags = {};
                    payload.flags.forced_watch_no_position = true;
                  }
                  
                  if (mgmt && hasOpenPosition) {
                    const curTriggerTs = Number(payload?.trigger_ts);
                    const curSide = sideFromStateOrScores(payload);
                    const cycleEnterTs = Number(
                      existing?.kanban_cycle_enter_now_ts,
                    );
                    const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
                    const cycleSide =
                      existing?.kanban_cycle_side != null
                        ? String(existing.kanban_cycle_side)
                        : null;
                    const sameTrig =
                      Number.isFinite(curTriggerTs) &&
                      curTriggerTs > 0 &&
                      Number.isFinite(cycleTrig) &&
                      cycleTrig > 0 &&
                      cycleTrig === curTriggerTs;
                    const cycleOk =
                      Number.isFinite(cycleEnterTs) &&
                      cycleEnterTs > 0 &&
                      sameTrig &&
                      !!cycleSide &&
                      !!curSide &&
                      cycleSide === curSide;

                    if (firstBarAfterGapCap) {
                      if (!payload.flags) payload.flags = {};
                      payload.flags.first_bar_of_day_bridge = true;
                    } else {
                      if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                        finalStage = "watch";
                        payload.flags =
                          payload.flags && typeof payload.flags === "object"
                            ? payload.flags
                            : {};
                        payload.flags.forced_watch_missing_trigger = true;
                      } else if (!cycleOk) {
                        finalStage = "enter_now";
                        payload.flags =
                          payload.flags && typeof payload.flags === "object"
                            ? payload.flags
                            : {};
                        payload.flags.forced_enter_now_gate = true;
                      }
                    }
                  }

                  const tsNow = tsNowCap;
                  if (finalStage === "enter_now") {
                    const curTriggerTs = Number(payload?.trigger_ts);
                    const curSide = sideFromStateOrScores(payload);
                    payload.kanban_cycle_enter_now_ts = tsNow;
                    payload.kanban_cycle_trigger_ts =
                      Number.isFinite(curTriggerTs) && curTriggerTs > 0
                        ? curTriggerTs
                        : null;
                    payload.kanban_cycle_side =
                      curSide != null ? String(curSide) : null;
                  } else if (
                    finalStage === "hold" ||
                    finalStage === "just_entered" ||
                    finalStage === "trim" ||
                    finalStage === "exit"
                  ) {
                    if (firstBarAfterGapCap) {
                      payload.kanban_cycle_enter_now_ts = tsNow;
                      payload.kanban_cycle_trigger_ts =
                        Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : tsNow;
                      payload.kanban_cycle_side = sideFromStateOrScores(payload) != null ? String(sideFromStateOrScores(payload)) : null;
                      if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                      if (payload.entry_ts == null && Number.isFinite(tsNow)) payload.entry_ts = tsNow;
                    } else {
                      payload.kanban_cycle_enter_now_ts =
                        existing?.kanban_cycle_enter_now_ts || null;
                      payload.kanban_cycle_trigger_ts =
                        existing?.kanban_cycle_trigger_ts || null;
                      payload.kanban_cycle_side =
                        existing?.kanban_cycle_side || null;
                    }
                  } else {
                    payload.kanban_cycle_enter_now_ts = null;
                    payload.kanban_cycle_trigger_ts = null;
                    payload.kanban_cycle_side = null;
                  }
                } catch (e) {
                  console.error(
                    `[KANBAN] capture-promote lifecycle gate failed for ${ticker}:`,
                    String(e),
                  );
                }

                payload.kanban_stage = finalStage;
                if (
                  prevStage != null &&
                  stage != null &&
                  String(prevStage) !== String(stage)
                ) {
                  payload.prev_kanban_stage = String(prevStage);
                  payload.prev_kanban_stage_ts =
                    Number(payload?.ts) || Date.now();
                } else if (existing?.prev_kanban_stage != null) {
                  payload.prev_kanban_stage = String(
                    existing.prev_kanban_stage,
                  );
                  payload.prev_kanban_stage_ts = Number.isFinite(
                    Number(existing?.prev_kanban_stage_ts),
                  )
                    ? Number(existing.prev_kanban_stage_ts)
                    : null;
                } else {
                  payload.prev_kanban_stage = null;
                  payload.prev_kanban_stage_ts = null;
                }

                // Discord notification for kanban lane transitions (capture-promote path)
                const actionableStages = [
                  "enter",
                  "enter_now", // Legacy alias → treated as "enter"
                  "defend",
                  "trim",
                  "exit",
                ];
                if (
                  prevStage != null &&
                  finalStage != null &&
                  String(prevStage) !== String(finalStage) &&
                  actionableStages.includes(finalStage)
                ) {
                  const alertType = `KANBAN_${finalStage.toUpperCase()}`;
                  const tsMs = Number(payload?.ts) || Date.now();
                  const dedupeBucket = Math.floor(tsMs / 900000);
                  const dedupeKey = `timed:discord:kanban:${ticker}:${finalStage}:${dedupeBucket}`;
                  ctx.waitUntil(
                    (async () => {
                      try {
                        const already = await KV.get(dedupeKey);
                        if (already) return;
                        await kvPutText(KV, dedupeKey, "1", 60 * 60);
                        if (!shouldSendDiscordAlert(env, alertType, { ticker }))
                          return;
                        const embed = createKanbanStageEmbed(
                          ticker,
                          finalStage,
                          prevStage,
                          payload,
                        );
                        await notifyDiscord(env, embed).catch((err) => {
                          console.error(
                            `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                            err,
                          );
                        });
                      } catch (e) {
                        console.error(
                          `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                          e,
                        );
                      }
                    })(),
                  );
                }

                if (stage === "enter_now" && prevStage !== "enter_now") {
                  const price = Number(payload?.price);
                  if (Number.isFinite(price) && price > 0) {
                    payload.entry_price = price;
                    payload.entry_ts = payload.ts;
                  }
                }
                if (stage && existing?.entry_price) {
                  payload.entry_price = existing.entry_price;
                  payload.entry_ts = existing.entry_ts;
                }
                if (payload.entry_price) {
                  const entryPrice = Number(payload.entry_price);
                  const currentPrice = Number(payload.price);
                  if (
                    Number.isFinite(entryPrice) &&
                    Number.isFinite(currentPrice) &&
                    entryPrice > 0
                  ) {
                    payload.entry_change_pct =
                      ((currentPrice - entryPrice) / entryPrice) * 100;
                  }
                }
              } catch (e) {
                console.error(
                  `[KANBAN] capture-promote stage compute failed for ${ticker}:`,
                  String(e),
                );
              }

              // Attach ML score (v1) so UI can display model output immediately.
              try {
                await mlV1AttachToPayload(KV, payload);
              } catch (e) {
                console.warn(
                  `[ML_V1] attach failed (capture-promote) for ${ticker}:`,
                  String(e),
                );
              }

              await kvPutJSON(KV, `timed:latest:${ticker}`, payload);

              // Upsert latest snapshot to D1 for fast UI reads (best-effort)
              try {
                ctx.waitUntil(d1UpsertTickerLatest(env, ticker, payload));
                ctx.waitUntil(d1UpsertTickerIndex(env, ticker, payload?.ts));
              } catch {
                // ignore
              }
              await appendTrail(
                KV,
                ticker,
                {
                  ts: payload.ts,
                  price: payload.price,
                  htf_score: payload.htf_score,
                  ltf_score: payload.ltf_score,
                  completion: payload.completion,
                  phase_pct: payload.phase_pct,
                  state: payload.state,
                  rank: payload.rank,
                  flags: payload.flags,
                  trigger_reason: payload.trigger_reason,
                  trigger_dir: payload.trigger_dir,
                },
                20,
              );
              d1InsertTrailPoint(env, ticker, payload).catch((e) => {
                console.error(
                  `[D1 CAPTURE→TRAIL] Insert failed for ${ticker}:`,
                  String(e),
                );
              });
              await ensureTickerIndex(KV, ticker);
              await kvPutText(KV, "timed:last_ingest_ms", String(now));
            }
          } catch (promoteErr) {
            console.error(
              `[CAPTURE PROMOTE] Failed for ${ticker}:`,
              String(promoteErr),
            );
          }

          return ackJSON(env, { ok: true, ticker, capture: true }, 200, req);
        } catch (err) {
          console.error(`[CAPTURE INGEST ERROR]`, err);
          return ackJSON(
            env,
            { ok: false, error: String(err?.message || err) },
            500,
            req,
          );
        }
      }

      // POST /timed/ingest-candles (multi-timeframe OHLCV)
      if (routeKey === "POST /timed/ingest-candles") {
        let body = null;
        try {
          const authFail = requireKeyOr401(req, env);
          if (authFail) return authFail;

          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData;
          if (!body) {
            return ackJSON(
              env,
              {
                ok: false,
                error: "bad_json",
                sample: String(raw || "").slice(0, 200),
                parseError: String(err || ""),
              },
              400,
              req,
            );
          }

          const v = validateCandlesPayload(body);
          if (!v.ok) return ackJSON(env, v, 400, req);

          const ticker = v.ticker;
          const payload = v.payload;
          const tfCandles = payload?.tf_candles || {};

          // Check if bulk mode (tf_candles values are arrays of candles instead of single candles)
          const isBulk = Object.values(tfCandles).some((val) => Array.isArray(val));

          let okCount = 0;
          let errCount = 0;
          try {
            await d1EnsureCandleSchema(env);
          } catch {
            // ignore (d1UpsertCandle will surface errors)
          }

          if (isBulk) {
            // Bulk mode: each TF has an array of candles
            for (const [tf, candleArray] of Object.entries(tfCandles)) {
              if (!Array.isArray(candleArray)) continue;
              for (const candle of candleArray) {
                if (!candle || typeof candle !== "object") continue;
                const res = await d1UpsertCandle(env, ticker, tf, candle);
                if (res?.ok) okCount++;
                else errCount++;
              }
            }
          } else {
            // Single-candle mode: each TF has one candle object
            for (const [tf, candle] of Object.entries(tfCandles)) {
              const res = await d1UpsertCandle(env, ticker, tf, candle);
              if (res?.ok) okCount++;
              else errCount++;
            }
          }

          return ackJSON(
            env,
            {
              ok: true,
              ticker,
              ingested: okCount,
              rejected: errCount,
              tfs: Object.keys(tfCandles),
              bulk: isBulk,
            },
            200,
            req,
          );
        } catch (err) {
          console.error(`[CANDLES INGEST ERROR]`, err);
          return ackJSON(
            env,
            { ok: false, error: String(err?.message || err) },
            500,
            req,
          );
        }
      }

      // GET /timed/latest?ticker=
      if (routeKey === "GET /timed/latest") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/latest",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker)
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        // Prefer D1 for reads (single-row query)
        let data = null;
        let d1Stage = null;
        let d1PrevStage = null;
        let d1UpdatedAt = null;
        try {
          if (env?.DB) {
            await d1EnsureLatestSchema(env);
            const row = await env.DB.prepare(
              `SELECT payload_json, kanban_stage, prev_kanban_stage, updated_at
                 FROM ticker_latest
                 WHERE ticker = ?1`,
            )
              .bind(String(ticker || "").toUpperCase())
              .first();
            if (row) {
              d1Stage =
                row.kanban_stage != null ? String(row.kanban_stage) : null;
              d1PrevStage =
                row.prev_kanban_stage != null
                  ? String(row.prev_kanban_stage)
                  : null;
              d1UpdatedAt = Number(row.updated_at);
              if (!Number.isFinite(d1UpdatedAt)) d1UpdatedAt = null;
            }
            if (row && row.payload_json) {
              try {
                data = JSON.parse(String(row.payload_json));
              } catch {
                data = null;
              }
            }
          }
        } catch (e) {
          console.error(`[D1 LATEST] Read failed for ${ticker}:`, String(e));
        }

        // Fallback to KV if D1 misses (and best-effort backfill D1)
        if (!data) {
          data = await kvGetJSON(KV, `timed:latest:${ticker}`);
          if (data) {
            try {
              ctx.waitUntil(d1UpsertTickerLatest(env, ticker, data));
              ctx.waitUntil(d1UpsertTickerIndex(env, ticker, data?.ts));
            } catch {
              // ignore
            }
          }
        }
        const capture = await kvGetJSON(KV, `timed:capture:latest:${ticker}`);
        const heartbeat = await kvGetJSON(KV, `timed:heartbeat:${ticker}`);
        if (data) {
          // Overlay lightweight heartbeat (KV, 2d TTL) for fresh price/daily change
          if (heartbeat && typeof heartbeat === "object") {
            if (Number.isFinite(Number(heartbeat.price))) data.price = heartbeat.price;
            if (heartbeat.prev_close != null) data.prev_close = heartbeat.prev_close;
            if (heartbeat.day_change != null) {
              data.day_change = heartbeat.day_change;
              data.change = heartbeat.day_change;
            }
            if (heartbeat.day_change_pct != null) {
              data.day_change_pct = heartbeat.day_change_pct;
              data.change_pct = heartbeat.day_change_pct;
            }
            if (heartbeat.ingest_ts != null) data.ingest_ts = heartbeat.ingest_ts;
            if (heartbeat.session != null) data.session = heartbeat.session;
            if (heartbeat.is_rth != null) data.is_rth = heartbeat.is_rth;
          }
          // Ensure prev/current lane fields are present even if payload_json is older.
          if (data.kanban_stage == null && d1Stage != null)
            data.kanban_stage = d1Stage;
          if (data.prev_kanban_stage == null && d1PrevStage != null)
            data.prev_kanban_stage = d1PrevStage;
          if (
            data.prev_kanban_stage != null &&
            data.prev_kanban_stage_ts == null &&
            d1UpdatedAt != null
          ) {
            // Best-effort: when we only know "prev stage" from columns, approximate timestamp from row update.
            data.prev_kanban_stage_ts = d1UpdatedAt;
          }
          // Merge capture-only enrichment fields when present (non-destructive).
          // This helps after-hours analytics + Momentum Elite metadata even if heartbeat is wired to /ingest-capture.
          if (capture && typeof capture === "object") {
            // Prefer capture for daily-change fields (more reliable for UI/analysis).
            for (const k of ["prev_close", "day_change", "day_change_pct"]) {
              if (capture[k] != null) data[k] = capture[k];
            }
            for (const k of [
              "session",
              "is_rth",
              "avg_vol_30",
              "avg_vol_50",
              "adr_14",
              "momentum_pct",
              "momentum_elite_criteria",
            ]) {
              if (data[k] == null && capture[k] != null) data[k] = capture[k];
            }
            if (capture.flags && typeof capture.flags === "object") {
              data.flags =
                data.flags && typeof data.flags === "object" ? data.flags : {};
              // Override from capture: score payloads don't compute Momentum Elite reliably.
              if (capture.flags.momentum_elite != null)
                data.flags.momentum_elite = !!capture.flags.momentum_elite;
            }
          }

          // Context enrichment is now delivered via /timed/ingest-capture (throttled in Pine).
          // Merge it opportunistically when present (non-blocking).
          try {
            if (capture && typeof capture === "object") {
              const ctx =
                capture.context && typeof capture.context === "object"
                  ? capture.context
                  : null;
              if (ctx) {
                const cleaned = sanitizeTickerContext(ctx, data);
                data.context = mergeTickerContext(data.context, cleaned || ctx);
              }
            }
          } catch (e) {
            console.error(
              `[CONTEXT] /timed/latest capture merge failed for ${ticker}:`,
              String(e),
            );
          }

          // If capture doesn't include context on this bar, fall back to the persisted context blob.
          try {
            if (!data.context) {
              const saved = await kvGetJSON(KV, `timed:context:${ticker}`);
              if (saved && typeof saved === "object") {
                const cleaned = sanitizeTickerContext(saved, data);
                data.context = cleaned || saved;
              }
            }
          } catch (e) {
            console.error(
              `[CONTEXT] /timed/latest persisted context read failed for ${ticker}:`,
              String(e),
            );
          }

          // Final fallback: derive minimal context from fundamentals/profile fields.
          try {
            if (!data.context) {
              const derived = deriveTickerContext(data);
              if (derived) {
                const cleaned = sanitizeTickerContext(derived, data);
                data.context = cleaned || derived;
              }
            }
          } catch {
            // ignore
          }

          // Ensure Momentum Elite reflects the most recent computed status.
          // Score payloads often default flags.momentum_elite=false; use cached momentum computation when available.
          try {
            const m = await kvGetJSON(KV, `timed:momentum:${ticker}`);
            if (m && typeof m === "object" && m.momentum_elite != null) {
              data.flags =
                data.flags && typeof data.flags === "object" ? data.flags : {};
              data.flags.momentum_elite = !!m.momentum_elite;
              if (data.momentum_elite_criteria == null && m.criteria) {
                data.momentum_elite_criteria = m.criteria;
              }
            }
          } catch {
            // ignore
          }
          // Always recompute RR to ensure it uses the latest max TP from tp_levels
          data.rr = computeRR(data);

          // Ensure watchlist-style daily change is correct (prev trading day 4pm ET close).
          // This is used by the UI header/kanban and should not depend on ingest quirks.
          try {
            if (env?.DB) {
              const asOfTs = Number(data.ts ?? data.ingest_ts ?? Date.now());
              const rec = await computePrevCloseFromTrail(
                env.DB,
                ticker,
                asOfTs,
              );
              const price = Number(data.price);
              // Only backfill if daily-change fields are missing. Heartbeat capture is preferred when present.
              if (
                rec &&
                Number.isFinite(price) &&
                price > 0 &&
                !(
                  Number.isFinite(Number(data.day_change_pct)) &&
                  Number.isFinite(Number(data.day_change))
                )
              ) {
                data.prev_close = rec.close;
                data.day_change = price - rec.close;
                data.day_change_pct = ((price - rec.close) / rec.close) * 100;
              }
            }
          } catch (e) {
            console.warn(
              `[DAILY CHANGE] /timed/latest backfill failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          // Canonicalize daily change: if day_* disagrees with change_* (heartbeat), prefer change_*.
          try {
            const dayPct = Number(data.day_change_pct);
            const altPct = Number(data.change_pct);
            const dayChg = Number(data.day_change);
            const altChg = Number(data.change);
            const price = Number(data.price);
            const hasHeartbeatSession =
              data.session != null || data.is_rth != null;
            // If heartbeat fields are present, treat change/change_pct as authoritative watchlist daily change.
            if (hasHeartbeatSession && Number.isFinite(altPct)) {
              data.day_change_pct = altPct;
              if (Number.isFinite(altChg)) data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            }
            const disagree =
              Number.isFinite(dayPct) &&
              Number.isFinite(altPct) &&
              (dayPct >= 0 !== altPct >= 0 || Math.abs(dayPct - altPct) >= 1.5);
            const absurd = Number.isFinite(dayPct) && Math.abs(dayPct) > 5;
            const saneAlt = Number.isFinite(altPct) && Math.abs(altPct) <= 5;
            if ((disagree || (absurd && saneAlt)) && Number.isFinite(altPct)) {
              data.day_change_pct = altPct;
              if (Number.isFinite(altChg)) data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            } else if (!Number.isFinite(dayPct) && Number.isFinite(altPct)) {
              data.day_change_pct = altPct;
              if (Number.isFinite(altChg)) data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            } else if (!Number.isFinite(dayChg) && Number.isFinite(altChg)) {
              data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            }
          } catch {
            // ignore
          }

          // Back-compat: older KV entries may not have derived horizon/ETA v2 fields yet,
          // or may be missing the newer target TP fields. Compute on-the-fly.
          try {
            if (
              !data.horizon_bucket ||
              data.eta_days_v2 == null ||
              data.tp_target_price == null ||
              data.tp_target_pct == null
            ) {
              const derived = deriveHorizonAndMetrics(data);
              Object.assign(data, derived);
            }
          } catch (e) {
            console.error(
              `[DERIVED METRICS] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }
          // Back-compat: compute entry decision if missing
          try {
            if (!data.entry_decision) {
              data.entry_decision = buildEntryDecision(ticker, data, null);
            }
          } catch (e) {
            console.error(
              `[ENTRY DECISION] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }

          // Back-compat: attach ML v1 fields if missing (for older payloads).
          try {
            if (!data.ml_v1) {
              await mlV1AttachToPayload(KV, data);
            } else if (data.ml == null) {
              data.ml = data.ml_v1;
            }
          } catch (e) {
            console.error(
              `[ML V1] /timed/latest failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          // Back-compat: compute thesis features if missing (older KV entries)
          try {
            const hasThesisMatch =
              data?.flags &&
              typeof data.flags === "object" &&
              data.flags.thesis_match != null;
            const hasSeq = data?.seq && typeof data.seq === "object";
            const hasDeltas = data?.deltas && typeof data.deltas === "object";
            if (!hasThesisMatch || !hasSeq || !hasDeltas) {
              const trail =
                (await kvGetJSON(KV, `timed:trail:${ticker}`)) || null;
              if (trail && Array.isArray(trail) && trail.length >= 2) {
                const computed = computeLiveThesisFeaturesFromTrail(
                  trail,
                  data,
                );
                if (computed && typeof computed === "object") {
                  data.seq = computed.seq;
                  data.deltas = computed.deltas;
                  data.flags =
                    data.flags && typeof data.flags === "object"
                      ? data.flags
                      : {};
                  data.flags.htf_improving_4h =
                    !!computed.flags?.htf_improving_4h;
                  data.flags.htf_improving_1d =
                    !!computed.flags?.htf_improving_1d;
                  data.flags.htf_move_4h_ge_5 =
                    !!computed.flags?.htf_move_4h_ge_5;
                  data.flags.thesis_match = !!computed.flags?.thesis_match;

                  // Persist backfill so future reads don’t need to recompute.
                  await kvPutJSON(KV, `timed:latest:${ticker}`, data);
                }
              }
            }
          } catch (e) {
            console.error(
              `[THESIS FEATURES] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }

          // Back-compat: compute completeness + summaries if missing (older KV entries)
          try {
            if (!data.data_completeness) {
              data.data_completeness = computeDataCompleteness(data);
            }
            if (!data.tf_summary) {
              const tfSum = tfTechAlignmentSummary(data);
              if (tfSum) data.tf_summary = tfSum;
            }
            if (!data.trigger_summary) {
              data.trigger_summary = triggerSummaryAndScore(data);
            }
            if (!data.move_status) {
              data.move_status = computeMoveStatus(data);
            }
            data.flags =
              data.flags && typeof data.flags === "object" ? data.flags : {};
            data.flags.move_invalidated =
              data.move_status?.status === "INVALIDATED";
            data.flags.move_completed =
              data.move_status?.status === "COMPLETED";
          } catch (e) {
            console.error(
              `[ENRICH] /timed/latest failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          try {
            const corrData = await computeOpenTradesCorrelation(env, KV);
            const corr =
              corrData && corrData.avgCorrByTicker
                ? corrData.avgCorrByTicker[String(ticker).toUpperCase()]
                : null;
            if (corr) {
              data.avg_corr = corr.avg_corr;
              data.diversity_score = corr.diversity_score;
              data.corr_count = corr.corr_count;
            }
          } catch (e) {
            console.error(
              `[CORR] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }

          // Ensure kanban_stage reflects current logic for Action Center flow
          try {
            const cMax = computeCompletionToTpMax(data);
            if (Number.isFinite(cMax)) data.completion = cMax;
            const rr = computeRR(data);
            if (Number.isFinite(rr)) data.rr = rr;
            const rrTargets = computeRRTargets(data);
            if (rrTargets) Object.assign(data, rrTargets);
            data.move_status = computeMoveStatus(data);
          } catch {
            // ignore
          }
          try {
            data.flags =
              data.flags && typeof data.flags === "object" ? data.flags : {};
            data.flags.move_invalidated =
              data.move_status?.status === "INVALIDATED";
            data.flags.move_completed =
              data.move_status?.status === "COMPLETED";
          } catch {
            // ignore
          }
          try {
            const prevStage =
              data?.kanban_stage != null ? String(data.kanban_stage) : null;
            const stage = classifyKanbanStage(data);
            data.kanban_stage = stage;
            data.kanban_meta = deriveKanbanMeta(data, stage);
            // Track lane transitions even on read-time recompute (so UI can show prev lane + highlight).
            if (
              prevStage != null &&
              stage != null &&
              String(prevStage) !== String(stage)
            ) {
              data.prev_kanban_stage = String(prevStage);
              data.prev_kanban_stage_ts = Date.now();
              try {
                ctx.waitUntil(d1UpsertTickerLatest(env, ticker, data));
                ctx.waitUntil(d1UpsertTickerIndex(env, ticker, data?.ts));
              } catch {
                // ignore
              }
            }
          } catch {
            // ignore
          }

          return sendJSON(
            { ok: true, ticker, latestData: data, data },
            200,
            corsHeaders(env, req),
          );
        }
        return sendJSON(
          { ok: false, error: "ticker_not_found", ticker },
          404,
          corsHeaders(env, req),
        );
      }

      // GET /timed/tickers
      if (routeKey === "GET /timed/tickers") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/tickers",
          20000, // Increased: UI polling + multiple tabs
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        // Prefer D1 for reads (fast index table)
        let tickers = [];
        try {
          if (env?.DB) {
            await d1EnsureLatestSchema(env);
            const rows = await env.DB.prepare(
              `SELECT ticker FROM ticker_index ORDER BY ticker ASC`,
            ).all();
            const list = rows?.results || [];
            tickers = list
              .map((r) => String(r.ticker || "").toUpperCase())
              .filter(Boolean);
          }
        } catch (e) {
          console.error(`[D1 LATEST] /timed/tickers read failed:`, String(e));
        }
        // If D1 is still warming up, fall back to KV index to avoid hiding tickers.
        const kvTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        if (
          !Array.isArray(tickers) ||
          tickers.length === 0 ||
          (Array.isArray(kvTickers) && kvTickers.length > tickers.length)
        ) {
          tickers = Array.isArray(kvTickers) ? kvTickers : [];
          // Kick a background sync so D1 catches up without blocking the request.
          try {
            ctx.waitUntil(d1SyncLatestBatchFromKV(env, ctx, 50));
          } catch {
            // ignore
          }
        }
        return sendJSON(
          { ok: true, tickers, count: tickers.length },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/all?version=2.5.0 (optional version parameter)
      if (routeKey === "GET /timed/all") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/all",
          20000,
          3600,
        ); // Increased for single-user

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }
        // Read from D1 (single query) for UI performance
        try {
          if (!env?.DB) {
            return sendJSON(
              { ok: false, error: "no_db_binding" },
              500,
              corsHeaders(env, req),
            );
          }

          await d1EnsureLatestSchema(env);
          const rows = await env.DB.prepare(
            `SELECT ticker, payload_json, updated_at, kanban_stage, prev_kanban_stage FROM ticker_latest`,
          ).all();

          const results = rows?.results || [];
          const data = {};
          let maxUpdatedAt = 0;

          // POSITION-AWARE CLASSIFICATION: Load all open positions from D1
          // This ensures kanban lanes reflect management mode for open positions
          // Query includes fallback to lots table for entry price if cost_basis is missing
          const openPositionsMap = new Map();
          try {
            const positionsResult = await env.DB.prepare(
              `SELECT p.ticker, p.position_id, p.direction, p.status, p.stop_loss, p.take_profit,
                      p.cost_basis, p.total_qty, p.created_at,
                      CASE WHEN p.total_qty > 0 AND p.cost_basis > 0 
                           THEN p.cost_basis / p.total_qty 
                           ELSE (SELECT l.price FROM lots l WHERE l.position_id = p.position_id ORDER BY l.ts ASC LIMIT 1) 
                      END as avgEntry
               FROM positions p WHERE p.status = 'OPEN'`
            ).all();
            const openPositions = positionsResult?.results || [];
            for (const pos of openPositions) {
              const sym = String(pos.ticker).toUpperCase();
              if (sym) {
                // Dedupe: Keep only one position per ticker (most recent by created_at)
                const existing = openPositionsMap.get(sym);
                if (!existing || (pos.created_at > existing.created_at)) {
                  openPositionsMap.set(sym, {
                    ...pos,
                    entryPrice: pos.avgEntry,
                    entry_ts: pos.created_at,
                    sl: pos.stop_loss,
                    tp: pos.take_profit
                  });
                }
              }
            }
            if (openPositionsMap.size > 0) {
              console.log(`[/timed/all] Loaded ${openPositionsMap.size} open positions for position-aware classification`);
            }
          } catch (posErr) {
            console.warn("[/timed/all] Failed to load open positions:", String(posErr?.message || posErr));
          }

          // Pre-compute sector alignment for all sectors with data
          // This populates the cache so getSectorAlignmentCached() works in the loop below
          try {
            const sectorsToCompute = new Set();
            for (const r of results) {
              const sym = String(r?.ticker || "").toUpperCase();
              const sector = getSector(sym);
              if (sector) sectorsToCompute.add(sym);
            }
            // Compute for up to 10 unique sectors (dedupes via cache)
            const sectorTickers = [...sectorsToCompute].slice(0, 10);
            await Promise.all(sectorTickers.map(t => computeSectorAlignment(KV, t).catch(() => null)));
          } catch {
            // Sector alignment is a boost, never a gate
          }

          for (const r of results) {
            const sym = String(r?.ticker || "").toUpperCase();
            if (!sym) continue;
            if (Number(r?.updated_at) > maxUpdatedAt)
              maxUpdatedAt = Number(r.updated_at);
            const raw = r?.payload_json;
            if (!raw) continue;
            try {
              const obj = JSON.parse(String(raw));
              // Ensure price is available for UI (some sources use "close")
              if ((obj.price == null || !Number.isFinite(Number(obj.price))) && obj.close != null && Number.isFinite(Number(obj.close)))
                obj.price = obj.close;
              // Ensure lane fields are present even if payload_json is older than the D1 columns.
              if (obj.kanban_stage == null && r?.kanban_stage != null)
                obj.kanban_stage = String(r.kanban_stage);
              if (obj.prev_kanban_stage == null && r?.prev_kanban_stage != null)
                obj.prev_kanban_stage = String(r.prev_kanban_stage);
              if (
                obj.prev_kanban_stage != null &&
                obj.prev_kanban_stage_ts == null &&
                Number.isFinite(Number(r?.updated_at))
              ) {
                obj.prev_kanban_stage_ts = Number(r.updated_at);
              }
              // Canonicalize daily change fields: prefer heartbeat capture semantics (change/change_pct)
              // when stored day_change_pct is poisoned by a bad prev_close anchor.
              try {
                const dayPct = Number(obj.day_change_pct);
                const altPct = Number(obj.change_pct);
                const altChg = Number(obj.change);
                const price = Number(obj.price);
                const hasHeartbeatSession =
                  obj.session != null || obj.is_rth != null;
                if (hasHeartbeatSession && Number.isFinite(altPct)) {
                  obj.day_change_pct = altPct;
                  if (Number.isFinite(altChg)) obj.day_change = altChg;
                  if (Number.isFinite(price) && Number.isFinite(altChg))
                    obj.prev_close = price - altChg;
                }
                const disagree =
                  Number.isFinite(dayPct) &&
                  Number.isFinite(altPct) &&
                  (dayPct >= 0 !== altPct >= 0 ||
                    Math.abs(dayPct - altPct) >= 1.5);
                const absurd = Number.isFinite(dayPct) && Math.abs(dayPct) > 5;
                const saneAlt =
                  Number.isFinite(altPct) && Math.abs(altPct) <= 5;
                if (
                  (disagree || (absurd && saneAlt)) &&
                  Number.isFinite(altPct)
                ) {
                  obj.day_change_pct = altPct;
                  if (Number.isFinite(altChg)) obj.day_change = altChg;
                  if (Number.isFinite(price) && Number.isFinite(altChg))
                    obj.prev_close = price - altChg;
                } else if (
                  !Number.isFinite(dayPct) &&
                  Number.isFinite(altPct)
                ) {
                  obj.day_change_pct = altPct;
                  if (Number.isFinite(altChg)) obj.day_change = altChg;
                  if (Number.isFinite(price) && Number.isFinite(altChg))
                    obj.prev_close = price - altChg;
                }
              } catch {
                // ignore
              }
              // Ensure stage/status reflect current logic even if no new ingests
              try {
                const cMax = computeCompletionToTpMax(obj);
                if (Number.isFinite(cMax)) obj.completion = cMax;
                const rr = computeRR(obj);
                if (Number.isFinite(rr)) obj.rr = rr;
                const rrTargets = computeRRTargets(obj);
                if (rrTargets) Object.assign(obj, rrTargets);
                obj.move_status = computeMoveStatus(obj);
              } catch {
                // ignore
              }
              try {
                obj.flags =
                  obj.flags && typeof obj.flags === "object" ? obj.flags : {};
                obj.flags.move_invalidated =
                  obj.move_status?.status === "INVALIDATED";
                obj.flags.move_completed =
                  obj.move_status?.status === "COMPLETED";
              } catch {
                // ignore
              }
              try {
                const prevStage =
                  obj?.kanban_stage != null ? String(obj.kanban_stage) : null;
                // POSITION-AWARE: Pass open position to enable management mode classification
                const openPosition = openPositionsMap.get(sym) || null;
                const stage = classifyKanbanStage(obj, openPosition);
                obj.kanban_stage = stage;
                // Attach sector alignment data for UI display
                const sectorInfo = getSectorAlignmentCached(sym);
                if (sectorInfo) {
                  obj.sector_alignment = {
                    sector: sectorInfo.sector,
                    aligned: sectorInfo.aligned,
                    direction: sectorInfo.direction,
                    strength: sectorInfo.strength,
                    consensus: `${sectorInfo.bullCount}B/${sectorInfo.bearCount}S of ${sectorInfo.totalWithData}`,
                  };
                }
                // Track if this ticker has an open position for UI display
                if (openPosition) {
                  obj.has_open_position = true;
                  obj.position_direction = openPosition.direction;
                  obj.position_entry = openPosition.entryPrice;
                  obj.position_sl = openPosition.sl;
                  obj.position_tp = openPosition.tp;
                }
                obj.kanban_meta = deriveKanbanMeta(obj, stage);
                // Track lane transitions even if no new ingests (persist back into D1 so UI can highlight).
                if (
                  prevStage != null &&
                  stage != null &&
                  String(prevStage) !== String(stage)
                ) {
                  obj.prev_kanban_stage = String(prevStage);
                  obj.prev_kanban_stage_ts = Date.now();
                  try {
                    ctx.waitUntil(d1UpsertTickerLatest(env, sym, obj));
                    ctx.waitUntil(d1UpsertTickerIndex(env, sym, obj?.ts));
                  } catch {
                    // ignore
                  }
                }
              } catch {
                // ignore
              }

              // Context fallback for D1 /timed/all path (payload_json may omit capture.context).
              try {
                if (obj.context && typeof obj.context === "object") {
                  const cleaned = sanitizeTickerContext(obj.context, obj);
                  if (cleaned) obj.context = cleaned;
                } else if (!obj.context) {
                  const derived = deriveTickerContext(obj);
                  if (derived) {
                    const cleaned = sanitizeTickerContext(derived, obj);
                    obj.context = cleaned || derived;
                  }
                }
              } catch {
                // ignore
              }

              data[sym] = obj;
            } catch {
              // skip bad rows
            }
          }

          // POSITION RECONCILIATION: Ensure ALL tickers with open positions appear in data
          // Even if they're missing from ticker_latest, we need them visible in kanban
          try {
            for (const [sym, pos] of openPositionsMap.entries()) {
              if (!data[sym]) {
                // Try to get latest data from KV
                let latestData = await kvGetJSON(KV, `timed:latest:${sym}`);
                
                if (latestData && typeof latestData === "object") {
                  // Apply position-aware classification
                  const stage = classifyKanbanStage(latestData, pos);
                  latestData.kanban_stage = stage;
                  latestData.kanban_meta = deriveKanbanMeta(latestData, stage);
                  latestData.has_open_position = true;
                  latestData.position_direction = pos.direction;
                  latestData.position_entry = pos.entryPrice;
                  latestData.position_sl = pos.sl;
                  latestData.position_tp = pos.tp;
                  data[sym] = latestData;
                  console.log(`[/timed/all] Injected missing position ticker ${sym} from KV (stage: ${stage})`);
                } else {
                  // Minimal placeholder for UI visibility
                  data[sym] = {
                    ticker: sym,
                    kanban_stage: "just_entered",
                    has_open_position: true,
                    position_direction: pos.direction,
                    position_entry: pos.entryPrice,
                    position_sl: pos.sl,
                    position_tp: pos.tp,
                    _synthetic: true,
                    _reason: "open_position_missing_data"
                  };
                  console.warn(`[/timed/all] Created synthetic entry for position ticker ${sym} (no data in KV or D1)`);
                }
              }
            }
          } catch (reconcileErr) {
            console.warn("[/timed/all] Position reconciliation failed:", String(reconcileErr?.message || reconcileErr));
          }

          // Overlay lightweight heartbeat (KV, 2d TTL) for fresh price/daily change
          try {
            const syms = Object.keys(data);
            const heartbeats = await Promise.all(
              syms.map((s) => kvGetJSON(KV, `timed:heartbeat:${s}`)),
            );
            const tickersWithPriceUpdate = new Set();
            for (let i = 0; i < syms.length; i++) {
              const hb = heartbeats[i];
              if (hb && typeof hb === "object") {
                const obj = data[syms[i]];
                if (!obj) continue;
                if (Number.isFinite(Number(hb.price))) {
                  obj.price = hb.price;
                  tickersWithPriceUpdate.add(syms[i]);
                }
                if (hb.prev_close != null) obj.prev_close = hb.prev_close;
                if (hb.day_change != null) {
                  obj.day_change = hb.day_change;
                  obj.change = hb.day_change;
                }
                if (hb.day_change_pct != null) {
                  obj.day_change_pct = hb.day_change_pct;
                  obj.change_pct = hb.day_change_pct;
                }
                if (hb.ingest_ts != null) obj.ingest_ts = hb.ingest_ts;
                if (hb.session != null) obj.session = hb.session;
                if (hb.is_rth != null) obj.is_rth = hb.is_rth;
              }
            }
            
            // RE-CLASSIFY KANBAN STAGE with updated prices
            // This is critical for detecting stale signals where price has moved below SL
            if (tickersWithPriceUpdate.size > 0) {
              for (const sym of tickersWithPriceUpdate) {
                const obj = data[sym];
                if (!obj) continue;
                try {
                  const openPosition = openPositionsMap.get(sym) || null;
                  const prevStage = obj.kanban_stage;
                  const newStage = classifyKanbanStage(obj, openPosition);
                  if (newStage !== prevStage) {
                    obj.kanban_stage = newStage;
                    obj.kanban_meta = deriveKanbanMeta(obj, newStage);
                    // Clear stale entry metadata if no longer qualifying for enter
                    if (prevStage === "enter" && newStage !== "enter") {
                      delete obj.__entry_path;
                      delete obj.__entry_confidence;
                      delete obj.__entry_reason;
                    }
                  }
                } catch (reClassifyErr) {
                  console.warn(`[HEARTBEAT] Re-classification failed for ${sym}:`, String(reClassifyErr?.message || reClassifyErr));
                }
              }
            }
          } catch (e) {
            console.warn("[HEARTBEAT] Merge failed:", String(e?.message || e));
          }

          // If D1 is warming up, report total index from KV for transparency
          let totalIndex = Object.keys(data).length;
          try {
            const kvTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
            if (Array.isArray(kvTickers) && kvTickers.length > totalIndex) {
              totalIndex = kvTickers.length;
              // Background sync to accelerate warm-up
              try {
                ctx.waitUntil(d1SyncLatestBatchFromKV(env, ctx, 75));
              } catch {
                // ignore
              }
            }
          } catch {
            // ignore
          }

          // Compute rank positions and add score/position (canonical) alongside rank/rank_position
          const ranked = Object.entries(data)
            .map(([ticker, value]) => {
              const sc = Number(value?.dynamicScore ?? value?.rank);
              const safeScore = Number.isFinite(sc)
                ? sc
                : (value && computeDynamicScore(value)) || Number(value?.rank) || 0;
              return { ticker, score: safeScore };
            })
            .sort((a, b) => b.score - a.score);
          const rankTotal = ranked.length;
          ranked.forEach((item, idx) => {
            const entry = data[item.ticker];
            if (!entry) return;
            const pos = idx + 1;
            entry.rank_position = pos;
            entry.position = pos;
            entry.rank_total = rankTotal;
            entry.rank_score = item.score;
            entry.score = Number(entry?.rank ?? item.score);
          });

          const socialAdditions = (await kvGetJSON(KV, "timed:social:additions")) || [];

          return sendJSON(
            {
              ok: true,
              count: Object.keys(data).length,
              totalIndex,
              data,
              socialAdditions: Array.isArray(socialAdditions) ? socialAdditions : [],
              d1_max_updated_at: maxUpdatedAt || null,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (e) {
          console.error(`[D1 LATEST] /timed/all failed:`, String(e));
          return sendJSON(
            {
              ok: false,
              error: "d1_all_failed",
              message: String(e?.message || e),
            },
            500,
            corsHeaders(env, req),
          );
        }

        /* REMOVED: On-demand computation (KV-based) - replaced by D1 reads
        const useLightweightMode = true;
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const storedVersion =
          (await getStoredVersion(KV)) || CURRENT_DATA_VERSION;

        // Debug: Check if BMNR is in the ticker index
        if (tickers.includes("BMNR") || tickers.includes("BABA")) {
          console.log(`[ALL ENDPOINT] BMNR/BABA in index:`, {
            BMNR: tickers.includes("BMNR"),
            BABA: tickers.includes("BABA"),
            totalTickers: tickers.length,
            indexSample: tickers.slice(0, 10),
          });
        } else {
          console.log(
            `[ALL ENDPOINT] BMNR/BABA NOT in index. Total tickers: ${tickers.length}`
          );
        }

        // Check if version parameter is provided
        const requestedVersion = url.searchParams.get("version");
        const useVersionSnapshots =
          requestedVersion && requestedVersion !== "latest";

        // Use Promise.all for parallel KV reads instead of sequential
        const dataPromises = tickers.map(async (t) => {
          let value;
          if (useVersionSnapshots) {
            // Try to get version-specific snapshot first
            value = await kvGetJSON(
              KV,
              `timed:snapshot:${t}:${requestedVersion}`
            );
            // If no snapshot found, fall back to latest
            if (!value) {
              value = await kvGetJSON(KV, `timed:latest:${t}`);
              // Only include if version matches
              if (value && value.script_version !== requestedVersion) {
                value = null; // Don't include mismatched versions
              }
            }
          } else if (useLightweightMode) {
            // LIGHTWEIGHT MODE: Only get latest data, skip capture/context/momentum merges
            value = await kvGetJSON(KV, `timed:latest:${t}`);
          } else {
            // Default: get latest data
            value = await kvGetJSON(KV, `timed:latest:${t}`);

            // Merge capture-only enrichment fields when present (non-destructive).
            // This helps after-hours analytics + Momentum Elite metadata even if heartbeat is wired to /ingest-capture.
            if (!useLightweightMode) {
              try {
                const capture = await kvGetJSON(KV, `timed:capture:latest:${t}`);
                if (value && capture && typeof capture === "object") {
                // Prefer capture for daily-change fields (more reliable for UI/analysis).
                for (const k of ["prev_close", "day_change", "day_change_pct"]) {
                  if (capture[k] != null) value[k] = capture[k];
                }
                for (const k of [
                  "session",
                  "is_rth",
                  "avg_vol_30",
                  "avg_vol_50",
                  "adr_14",
                  "momentum_pct",
                  "momentum_elite_criteria",
                ]) {
                  if (value[k] == null && capture[k] != null) value[k] = capture[k];
                }
                if (capture.flags && typeof capture.flags === "object") {
                  value.flags = value.flags && typeof value.flags === "object" ? value.flags : {};
                  // Override from capture: score payloads don't compute Momentum Elite reliably.
                  if (capture.flags.momentum_elite != null) value.flags.momentum_elite = !!capture.flags.momentum_elite;
                }

                // Context enrichment rides along on capture payload (throttled in Pine).
                if (capture.context && typeof capture.context === "object") {
                  value.context = capture.context;
                }
              }
            } catch (e) {
              // ignore merge failures
            }

            // If capture doesn't include context on this bar, fall back to persisted context.
            try {
              if (value && !value.context) {
                const saved = await kvGetJSON(KV, `timed:context:${t}`);
                if (saved && typeof saved === "object") value.context = saved;
              }
            } catch {
              // ignore
            }

            // Ensure Momentum Elite reflects the most recent computed status.
            try {
              if (value) {
                const m = await kvGetJSON(KV, `timed:momentum:${t}`);
                if (m && typeof m === "object" && m.momentum_elite != null) {
                  value.flags = value.flags && typeof value.flags === "object" ? value.flags : {};
                  value.flags.momentum_elite = !!m.momentum_elite;
                  if (value.momentum_elite_criteria == null && m.criteria) {
                    value.momentum_elite_criteria = m.criteria;
                  }
                }
              }
              } catch {
                // ignore
              }
            } // End lightweight mode skip

            // Debug: Check if BMNR data exists in KV
            if (t === "BMNR" || t === "BABA") {
              console.log(`[ALL ENDPOINT] Fetched ${t} from KV:`, {
                hasValue: !!value,
                valueKeys: value ? Object.keys(value) : [],
                htf_score: value?.htf_score,
                ltf_score: value?.ltf_score,
                script_version: value?.script_version,
              });
            }
          }
          return { ticker: t, value };
        });
        const results = await Promise.all(dataPromises);

        // Find all versions in the data
        const versionsSeen = new Set();
        for (const { value } of results) {
          if (value && value.script_version) {
            versionsSeen.add(value.script_version);
          }
        }

        // Accept ANY version that exists in the data, plus "unknown" for legacy data
        // This prevents filtering out data during version transitions
        const acceptedVersions = new Set([
          storedVersion,
          CURRENT_DATA_VERSION,
          "unknown", // Legacy data without script_version
          ...Array.from(versionsSeen), // All versions seen in current data
        ]);

        const data = {};
        let corrData = null;
        if (!useLightweightMode) {
          try {
            corrData = await computeOpenTradesCorrelation(env, KV);
          } catch (e) {
            console.error(`[CORR] /timed/all compute failed:`, String(e));
          }
        }
        let versionFilteredCount = 0;
        const versionBreakdown = {}; // Track which versions are being filtered

        for (const { ticker, value } of results) {
          // Debug specific tickers that aren't showing
          if (ticker === "BMNR" || ticker === "BABA") {
            console.log(`[ALL ENDPOINT DEBUG] ${ticker}:`, {
              inIndex: tickers.includes(ticker),
              hasValue: !!value,
              valueKeys: value ? Object.keys(value) : [],
              htf_score: value?.htf_score,
              ltf_score: value?.ltf_score,
              script_version: value?.script_version,
              price: value?.price,
              state: value?.state,
            });
          }

          if (value) {
            // Accept ALL data - don't filter by version unless explicitly requested
            // This ensures all historical data is accessible
            const tickerVersion = value.script_version || "unknown";

            // Only filter if a specific version was requested AND it doesn't match
            if (useVersionSnapshots && tickerVersion !== requestedVersion) {
              versionFilteredCount++;
              // Track which versions are being filtered
              if (!versionBreakdown[tickerVersion]) {
                versionBreakdown[tickerVersion] = 0;
              }
              versionBreakdown[tickerVersion]++;
              console.log(
                `[FILTER] Ticker ${ticker} filtered: version=${tickerVersion}, requested=${requestedVersion}`
              );
            } else {
              // LIGHTWEIGHT MODE: Skip heavy enrichment, just return raw data
              if (!useLightweightMode) {
                // Always recompute RR to ensure it uses the latest max TP from tp_levels
                value.rr = computeRR(value);
              }

              // Back-compat: compute completeness + summaries if missing (older KV entries)
              if (!useLightweightMode) {
                try {
                if (!value.data_completeness) {
                  value.data_completeness = computeDataCompleteness(value);
                }
                if (!value.tf_summary) {
                  const tfSum = tfTechAlignmentSummary(value);
                  if (tfSum) value.tf_summary = tfSum;
                }
                if (!value.trigger_summary) {
                  value.trigger_summary = triggerSummaryAndScore(value);
                }
                if (!value.move_status) {
                  value.move_status = computeMoveStatus(value);
                }
                value.flags = value.flags && typeof value.flags === "object" ? value.flags : {};
                value.flags.move_invalidated = value.move_status?.status === "INVALIDATED";
                value.flags.move_completed = value.move_status?.status === "COMPLETED";
              } catch (e) {
                console.error(
                  `[ENRICH] /timed/all failed for ${ticker}:`,
                  String(e?.message || e)
                );
                }
              } // End lightweight mode skip

              // Calculate dynamicScore (for ranking) - backend calculation
              if (!useLightweightMode) {
                value.dynamicScore = computeDynamicScore(value);
              }

              // Back-compat: compute derived horizon/ETA v2 + target TP fields if missing
              if (!useLightweightMode) {
              try {
                if (
                  !value.horizon_bucket ||
                  value.eta_days_v2 == null ||
                  value.tp_target_price == null ||
                  value.tp_target_pct == null
                ) {
                  const derived = deriveHorizonAndMetrics(value);
                  Object.assign(value, derived);
                }
              } catch (e) {
                console.error(
                  `[DERIVED METRICS] /timed/all failed for ${ticker}:`,
                  String(e)
                );
              }
              // Back-compat: compute entry decision if missing
              try {
                if (!value.entry_decision) {
                  value.entry_decision = buildEntryDecision(
                    ticker,
                    value,
                    null
                  );
                }
              } catch (e) {
                console.error(
                  `[ENTRY DECISION] /timed/all failed for ${ticker}:`,
                  String(e)
                );
                }
              } // End lightweight mode skip

              if (!useLightweightMode) {
                if (corrData && corrData.avgCorrByTicker) {
                  const corr =
                    corrData.avgCorrByTicker[String(ticker).toUpperCase()];
                  if (corr) {
                    value.avg_corr = corr.avg_corr;
                    value.diversity_score = corr.diversity_score;
                    value.corr_count = corr.corr_count;
                  }
                }
              }

              // Enrich with sector from SECTOR_MAP if not present in data
              if (!value.sector && !value.fundamentals?.sector) {
                const sectorFromMap = getSector(ticker);
                if (sectorFromMap) {
                  // Add sector to both top-level and fundamentals for consistency
                  value.sector = sectorFromMap;
                  if (!value.fundamentals) {
                    value.fundamentals = {};
                  }
                  value.fundamentals.sector = sectorFromMap;
                }
              }

              data[ticker] = value;
            }
          } else {
            // Log tickers in index but without data
            if (ticker === "BMNR" || ticker === "BABA") {
              console.log(
                `[ALL ENDPOINT DEBUG] ${ticker}: In index but no data found in KV`
              );
            }
          }
        }

        // Backfill daily change fields (watchlist-style) if missing.
        // Many tickers do not include prev close / session change from TradingView,
        // so we derive prev_close from D1 timed_trail and cache it in KV.
        //
        // IMPORTANT: We anchor "current day" to each ticker's own last timestamp.
        // This makes weekends behave like a trading platform watchlist:
        // - Sat/Sun: compare Friday close vs Thursday close (since ticker ts is Friday)
        // - Mon: compare current vs Friday close
        // - Tue: compare current vs Monday close, etc.
        try {
          const db = env?.DB;
          if (db) {
            const needs = [];
            const byDay = new Map(); // dayKey -> Set(ticker)

            for (const [sym, v] of Object.entries(data)) {
              if (!v || typeof v !== "object") continue;
              const price = Number(v.price);
              if (!Number.isFinite(price) || price <= 0) continue;
              if (
                v.prev_close != null ||
                v.day_change != null ||
                v.day_change_pct != null
              ) {
                continue;
              }
              const ts = Number(v.ts ?? v.ingest_ts);
              const dayKey = nyTradingDayKey(ts);
              if (!dayKey) continue;
              needs.push(sym);
              if (!byDay.has(dayKey)) byDay.set(dayKey, new Set());
              byDay.get(dayKey).add(String(sym).toUpperCase());
            }

            if (needs.length > 0 && byDay.size > 0) {
              const cachePromises = [];

              for (const [dayKey, tickSet] of byDay.entries()) {
                const prevKey = prevTradingDayKey(dayKey);
                if (!prevKey) continue;
                const closeCutoff = nyWallTimeToUtcMs(prevKey, 16, 0, 0);
                if (!Number.isFinite(closeCutoff)) continue;
                const lookbackStart = closeCutoff - 14 * 24 * 60 * 60 * 1000;

                // Watchlist semantics: prev_close = prior trading day regular close (4pm ET).
                const rows = await db
                  .prepare(
                    `SELECT t1.ticker AS ticker, t1.price AS price, t1.ts AS ts
                     FROM timed_trail t1
                     JOIN (
                       SELECT ticker, MAX(ts) AS tsMax
                       FROM timed_trail
                       WHERE ts >= ?1 AND ts <= ?2 AND price IS NOT NULL
                       GROUP BY ticker
                     ) t2
                     ON t1.ticker = t2.ticker AND t1.ts = t2.tsMax`
                  )
                  .bind(lookbackStart, closeCutoff + 1000)
                  .all();

                const closeMap = new Map();
                for (const r of rows?.results || []) {
                  const sym = String(r.ticker || "").toUpperCase();
                  const p = Number(r.price);
                  if (sym && Number.isFinite(p) && p > 0 && !closeMap.has(sym)) {
                    closeMap.set(sym, { close: p, ts: Number(r.ts) });
                  }
                }

                for (const sym of tickSet.values()) {
                  const v = data[sym];
                  if (!v) continue;
                  const price = Number(v.price);
                  const rec = closeMap.get(sym);
                  const prevClose = Number(rec?.close);
                  if (!Number.isFinite(price) || price <= 0) continue;
                  if (!Number.isFinite(prevClose) || prevClose <= 0) continue;

                  v.prev_close = prevClose;
                  v.day_change = price - prevClose;
                  v.day_change_pct = ((price - prevClose) / prevClose) * 100;

                  const prevDayKey = prevKey;
                  if (prevDayKey) {
                    cachePromises.push(
                      kvPutJSON(
                        KV,
                        `timed:prev_close:${sym}`,
                        { day: prevDayKey, close: prevClose },
                        14 * 24 * 60 * 60
                      )
                    );
                  }
                }
              }

              if (cachePromises.length > 0) {
                await Promise.allSettled(cachePromises);
              }
            }
          }
        } catch (e) {
          console.warn(`[DAILY CHANGE] /timed/all backfill failed:`, String(e?.message || e));
        }

        // Log summary if any data was filtered
        if (versionFilteredCount > 0) {
          console.log(
            `[FILTER] Filtered ${versionFilteredCount} tickers by version. Breakdown:`,
            versionBreakdown
          );
        }

        // Compute rank positions once (server-authoritative)
        const ranked = Object.entries(data)
          .map(([ticker, value]) => {
            const score = Number(value?.dynamicScore);
            const safeScore = Number.isFinite(score)
              ? score
              : computeDynamicScore(value || {});
            return { ticker, score: safeScore };
          })
          .sort((a, b) => b.score - a.score);
        const rankTotal = ranked.length;
        ranked.forEach((item, idx) => {
          const entry = data[item.ticker];
          if (!entry) return;
          entry.rank_position = idx + 1;
          entry.rank_total = rankTotal;
          entry.rank_score = item.score;
        });

        const responseData = {
          ok: true,
          count: Object.keys(data).length,
          totalIndex: tickers.length,
          versionFiltered: versionFilteredCount,
          versionBreakdown: versionBreakdown,
          dataVersion: storedVersion,
          requestedVersion: requestedVersion || "latest",
          versionsSeen: Array.from(versionsSeen),
          acceptedVersions: Array.from(acceptedVersions),
          currentDataVersion: CURRENT_DATA_VERSION,
          data,
          cached_at: Date.now(),
        };
        
        // Cache the response for future requests (background write, don't await)
        ctx.waitUntil(kvPutJSON(KV, "timed:all:cache", responseData));
        
        return sendJSON(responseData, 200, corsHeaders(env, req));
        */
        // END OF REMOVED ON-DEMAND COMPUTATION CODE
      }

      // GET /timed/candles?ticker=&tf=&limit=
      if (routeKey === "GET /timed/candles") {
        try {
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          const rateLimit = await checkRateLimitFixedWindow(
            KV,
            ip,
            "/timed/candles",
            20000,
            3600,
          );
          if (!rateLimit.allowed) {
            const retryAfter = Math.max(
              1,
              Math.ceil((rateLimit.resetAt - Date.now()) / 1000),
            );
            return sendJSON(
              { ok: false, error: "rate_limit_exceeded", retryAfter },
              429,
              {
                ...corsHeaders(env, req),
                "Retry-After": String(retryAfter),
                "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
                "X-RateLimit-Remaining": "0",
                "X-RateLimit-Reset": String(rateLimit.resetAt),
              },
            );
          }

          const ticker = normTicker(url.searchParams.get("ticker"));
          const tf = url.searchParams.get("tf");
          const limitRaw = url.searchParams.get("limit");
          const limit =
            limitRaw != null && limitRaw !== "" ? Number(limitRaw) : 200;
          if (!ticker || !tf) {
            return sendJSON(
              { ok: false, error: "missing ticker/tf" },
              400,
              corsHeaders(env, req),
            );
          }

          const res = await d1GetCandles(env, ticker, tf, limit);
          if (!res?.ok) {
            return sendJSON(
              { ok: false, error: res?.error || "candles_read_failed" },
              500,
              corsHeaders(env, req),
            );
          }
          return sendJSON(res, 200, corsHeaders(env, req));
        } catch (e) {
          console.error(`[CANDLES] /timed/candles failed:`, String(e));
          return sendJSON(
            { ok: false, error: "internal_error" },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/trail/performance?ticker=XYZ
      // Lightweight endpoint: returns daily close prices at key lookback dates
      // for 5D/15D/30D/90D performance calculations using actual daily candles.
      if (routeKey === "GET /timed/trail/performance") {
        try {
          const ticker = normTicker(url.searchParams.get("ticker"));
          if (!ticker) {
            return sendJSON({ ok: false, error: "missing ticker" }, 400, corsHeaders(env, req));
          }

          const db = env?.DB;
          if (!db) {
            return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          }

          const t = String(ticker).toUpperCase();

          // Fetch daily candles for the past ~400 trading days (covers 90D+ easily)
          // Sorted descending so most recent is first
          const rows = await db
            .prepare(
              `SELECT ts, c AS close FROM ticker_candles
               WHERE ticker = ?1 AND tf = 'D' AND c IS NOT NULL
               ORDER BY ts DESC
               LIMIT 400`,
            )
            .bind(t)
            .all();

          const candles = Array.isArray(rows?.results) ? rows.results : [];

          if (candles.length === 0) {
            return sendJSON(
              { ok: true, ticker, performance: {}, latestClose: null },
              200,
              corsHeaders(env, req),
            );
          }

          // Most recent candle close = reference price
          const latestClose = Number(candles[0].close);
          const latestTs = Number(candles[0].ts);

          // Build performance for each period
          const periods = [
            { key: "1D", days: 1 },
            { key: "5D", days: 5 },
            { key: "15D", days: 15 },
            { key: "30D", days: 30 },
            { key: "90D", days: 90 },
          ];

          const now = Date.now();
          const performance = {};

          for (const { key, days } of periods) {
            const cutoff = now - days * 24 * 60 * 60 * 1000;
            // Find the closest candle at or before the cutoff
            let closest = null;
            for (const c of candles) {
              if (Number(c.ts) <= cutoff) {
                closest = c;
                break; // candles are DESC sorted, first match is closest
              }
            }
            if (closest) {
              const oldPrice = Number(closest.close);
              const changePct = ((latestClose - oldPrice) / oldPrice) * 100;
              const changePoints = latestClose - oldPrice;
              const actualDays = Math.round((latestTs - Number(closest.ts)) / (24 * 60 * 60 * 1000));
              performance[key] = {
                oldPrice,
                oldTs: Number(closest.ts),
                changePct: Math.round(changePct * 100) / 100,
                changePoints: Math.round(changePoints * 100) / 100,
                actualDays,
                isUp: changePct >= 0,
              };
            }
          }

          return sendJSON(
            { ok: true, ticker, latestClose, latestTs, performance },
            200,
            corsHeaders(env, req),
          );
        } catch (e) {
          return sendJSON(
            { ok: false, error: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/trail?ticker=
      if (routeKey === "GET /timed/trail") {
        try {
          // Rate limiting
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          const rateLimit = await checkRateLimitFixedWindow(
            KV,
            ip,
            "/timed/trail",
            20000, // Higher limit: UI may fetch many tickers' trails
            3600,
          );

          if (!rateLimit.allowed) {
            const retryAfter = Math.max(
              1,
              Math.ceil((rateLimit.resetAt - Date.now()) / 1000),
            );
            return sendJSON(
              { ok: false, error: "rate_limit_exceeded", retryAfter },
              429,
              {
                ...corsHeaders(env, req),
                "Retry-After": String(retryAfter),
                "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
                "X-RateLimit-Remaining": "0",
                "X-RateLimit-Reset": String(rateLimit.resetAt),
              },
            );
          }

          const ticker = normTicker(url.searchParams.get("ticker"));
          if (!ticker) {
            return sendJSON(
              { ok: false, error: "missing ticker" },
              400,
              corsHeaders(env, req),
            );
          }

          const sinceRaw = url.searchParams.get("since");
          const limitRaw = url.searchParams.get("limit");
          const includeKanbanRaw = url.searchParams.get("include_kanban");
          const since =
            sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
          const limit =
            limitRaw != null && limitRaw !== "" ? Number(limitRaw) : 5000;
          // include_kanban=1 or include_kanban=true to get kanban_stage, entry_ts, move_status in trail points
          // Useful for Time Travel replay feature
          const includeKanban = includeKanbanRaw === "1" || includeKanbanRaw === "true";

          // Prefer D1 for longer history, but fall back to KV if D1 is empty/sparse.
          const d1Result = await d1GetTrailRange(env, ticker, since, limit, includeKanban);
          const d1Trail =
            d1Result && Array.isArray(d1Result.trail) ? d1Result.trail : [];

          // KV (rolling window) — also used as fallback when D1 is sparse.
          let kvTrail = [];
          try {
            kvTrail = (await kvGetJSON(KV, `timed:trail:${ticker}`)) || [];
            if (!Array.isArray(kvTrail)) kvTrail = [];
          } catch (kvError) {
            console.error(`[TRAIL] KV read error for ${ticker}:`, kvError);
            kvTrail = [];
          }

          if (since != null && Number.isFinite(since)) {
            kvTrail = kvTrail.filter((p) => Number(p?.ts) >= since);
          }

          // IMPORTANT:
          // D1 can be "ok" but still return very few rows (e.g. not backfilled / intermittent writes),
          // while KV may still have a healthy recent window. If D1 is sparse and KV is richer,
          // return KV so the UI can render a usable trail.
          if (d1Result.ok && d1Trail.length > 0) {
            const d1IsSparse = d1Trail.length < 2;
            const kvIsRicher = kvTrail.length > d1Trail.length;
            if (!d1IsSparse || !kvIsRicher) {
              return sendJSON(
                {
                  ok: true,
                  ticker,
                  trail: d1Trail,
                  count: d1Trail.length,
                  source: d1Result.source,
                },
                200,
                {
                  ...corsHeaders(env, req),
                  "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
                  "X-RateLimit-Remaining": String(rateLimit.remaining ?? 0),
                  "X-RateLimit-Reset": String(rateLimit.resetAt ?? Date.now()),
                },
              );
            }
          }

          // KV response (either fallback, or D1 is sparse/unavailable)
          const trail = kvTrail;

          return sendJSON(
            {
              ok: true,
              ticker,
              trail,
              count: trail.length,
              source: "kv",
              note: d1Result.ok
                ? d1Trail.length > 0
                  ? `D1 returned sparse rows (${d1Trail.length}) — using KV recent window`
                  : "D1 returned 0 rows (falling back to KV)"
                : d1Result.skipped
                  ? `D1 unavailable (${d1Result.reason || "unknown"})`
                  : d1Result.error
                    ? `D1 error (${d1Result.error})`
                    : "D1 unavailable",
            },
            200,
            {
              ...corsHeaders(env, req),
              "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
              "X-RateLimit-Remaining": String(rateLimit.remaining ?? 0),
              "X-RateLimit-Reset": String(rateLimit.resetAt ?? Date.now()),
            },
          );
        } catch (error) {
          console.error(`[TRAIL] Unexpected error:`, error);
          // Return empty trail instead of 500 error
          const ticker =
            normTicker(url.searchParams.get("ticker")) || "UNKNOWN";
          return sendJSON(
            { ok: true, ticker, trail: [], count: 0, source: "error" },
            200,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/top?bucket=long|short|setup&n=10
      if (routeKey === "GET /timed/top") {
        const n = Math.max(
          1,
          Math.min(50, Number(url.searchParams.get("n") || "10")),
        );
        const bucket = String(
          url.searchParams.get("bucket") || "long",
        ).toLowerCase();
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];

        const items = [];
        for (const t of tickers) {
          const d = await kvGetJSON(KV, `timed:latest:${t}`);
          if (d) items.push(d);
        }

        // IMPORTANT: Top lists should favor corridor relevance for "long/short" tabs.
        // long bucket shows Q2 (bull aligned), short shows Q3 (bear aligned), setup shows Q1/Q4.
        const isLongAligned = (d) => d.state === "HTF_BULL_LTF_BULL";
        const isShortAligned = (d) => d.state === "HTF_BEAR_LTF_BEAR";
        const isSetup = (d) =>
          d.state === "HTF_BULL_LTF_PULLBACK" ||
          d.state === "HTF_BEAR_LTF_PULLBACK";

        let filtered =
          bucket === "long"
            ? items.filter(isLongAligned)
            : bucket === "short"
              ? items.filter(isShortAligned)
              : items.filter(isSetup);

        filtered.sort((a, b) => Number(b.rank || 0) - Number(a.rank || 0));
        filtered = filtered.slice(0, n);

        return sendJSON(
          { ok: true, bucket, n: filtered.length, data: filtered },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/momentum?ticker=XYZ
      if (routeKey === "GET /timed/momentum") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/momentum",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker)
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        let data = await kvGetJSON(KV, `timed:momentum:${ticker}`);
        if (!data) {
          // On-demand compute using latest + capture enrichment (avoids waiting for next cache fill).
          try {
            const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
            const capture = await kvGetJSON(
              KV,
              `timed:capture:latest:${ticker}`,
            );
            const base =
              latest && typeof latest === "object" ? { ...latest } : {};
            if (capture && typeof capture === "object") {
              for (const k of [
                "avg_vol_30",
                "avg_vol_50",
                "adr_14",
                "momentum_pct",
                "price",
              ]) {
                if (base[k] == null && capture[k] != null) base[k] = capture[k];
              }
            }
            if (base && Object.keys(base).length > 0) {
              data = await computeMomentumElite(KV, ticker, base);
            }
          } catch {
            // ignore
          }
        }
        return sendJSON({ ok: true, ticker, data }, 200, corsHeaders(env, req));
      }

      // GET /timed/momentum/history?ticker=XYZ
      if (routeKey === "GET /timed/momentum/history") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/momentum/history",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker)
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        const history =
          (await kvGetJSON(KV, `timed:momentum:history:${ticker}`)) || [];
        return sendJSON(
          { ok: true, ticker, history },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/momentum/all
      if (routeKey === "GET /timed/momentum/all") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/momentum/all",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const eliteTickers = [];
        for (const t of tickers) {
          const momentumData = await kvGetJSON(KV, `timed:momentum:${t}`);
          if (momentumData && momentumData.momentum_elite) {
            eliteTickers.push({ ticker: t, ...momentumData });
          }
        }
        return sendJSON(
          { ok: true, count: eliteTickers.length, tickers: eliteTickers },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/sectors - Get all sectors and their ratings
      if (routeKey === "GET /timed/sectors") {
        const sectors = getAllSectors().map((sector) => ({
          sector,
          ...getSectorRating(sector),
          tickerCount: getTickersInSector(sector).length,
        }));

        return sendJSON({ ok: true, sectors }, 200, corsHeaders(env, req));
      }

      // GET /timed/sectors/:sector/tickers?limit=10 - Get top tickers in a sector
      if (routeKey === "GET /timed/sectors/:sector/tickers") {
        const sectorPath = url.pathname
          .replace("/timed/sectors/", "")
          .replace("/tickers", "");
        const sector = decodeURIComponent(sectorPath);
        const limit = Math.max(
          1,
          Math.min(50, Number(url.searchParams.get("limit") || "10")),
        );

        if (!getAllSectors().includes(sector)) {
          return sendJSON(
            { ok: false, error: `Invalid sector: ${sector}` },
            400,
            corsHeaders(env, req),
          );
        }

        const topTickers = await rankTickersInSector(KV, sector, limit);

        return sendJSON(
          {
            ok: true,
            sector,
            rating: getSectorRating(sector),
            limit: topTickers.length,
            tickers: topTickers,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/sectors/recommendations?limit=10 - Get top tickers across all overweight sectors
      if (routeKey === "GET /timed/sectors/recommendations") {
        const limitPerSector = Math.max(
          1,
          Math.min(20, Number(url.searchParams.get("limit") || "10")),
        );
        const totalLimit = Math.max(
          1,
          Math.min(100, Number(url.searchParams.get("totalLimit") || "50")),
        );

        const overweightSectors = getAllSectors().filter(
          (sector) => getSectorRating(sector).rating === "overweight",
        );

        const allRecommendations = [];

        for (const sector of overweightSectors) {
          const topTickers = await rankTickersInSector(
            KV,
            sector,
            limitPerSector,
          );
          allRecommendations.push(
            ...topTickers.map((t) => ({
              ...t,
              sector,
            })),
          );
        }

        // Sort by boosted rank and take top N
        allRecommendations.sort((a, b) => b.boostedRank - a.boostedRank);
        const topRecommendations = allRecommendations.slice(0, totalLimit);

        return sendJSON(
          {
            ok: true,
            sectors: overweightSectors,
            limitPerSector,
            totalLimit: topRecommendations.length,
            recommendations: topRecommendations,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/debug/migrate-brk?key=... - Migrate BRK.B to BRK-B
      if (routeKey === "POST /timed/debug/migrate-brk") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const oldData = await kvGetJSON(KV, `timed:latest:BRK.B`);
          const newData = await kvGetJSON(KV, `timed:latest:BRK-B`);

          if (!oldData && !newData) {
            return sendJSON(
              { ok: false, error: "No BRK data found" },
              404,
              corsHeaders(env, req),
            );
          }

          // Use newer data if both exist
          const dataToUse =
            oldData && newData && newData.ts > oldData.ts
              ? newData
              : oldData || newData;
          const migrated = !!oldData && oldData !== dataToUse;

          await kvPutJSON(KV, `timed:latest:BRK-B`, dataToUse);

          // Migrate trail data
          const oldTrail = await kvGetJSON(KV, `timed:trail:BRK.B`);
          const newTrail = await kvGetJSON(KV, `timed:trail:BRK-B`);
          if (oldTrail || newTrail) {
            await kvPutJSON(KV, `timed:trail:BRK-B`, oldTrail || newTrail);
          }

          // Ensure BRK-B is in index
          await ensureTickerIndex(KV, "BRK-B");

          // Remove BRK.B from index if it exists
          let tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          if (tickers.includes("BRK.B")) {
            tickers = tickers.filter((t) => t !== "BRK.B");
            await kvPutJSON(KV, "timed:tickers", tickers);
          }

          // Delete old BRK.B data if we migrated
          if (migrated) {
            await KV.delete(`timed:latest:BRK.B`);
            await KV.delete(`timed:trail:BRK.B`);
          }

          return sendJSON(
            {
              ok: true,
              message: "BRK migration completed",
              hadOldData: !!oldData,
              hadNewData: !!newData,
              migrated,
              finalTicker: "BRK-B",
              ts: dataToUse?.ts,
              htf_score: dataToUse?.htf_score,
              ltf_score: dataToUse?.ltf_score,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          console.error(`[MIGRATE BRK ERROR]`, {
            error: String(err),
            message: err.message,
            stack: err.stack,
          });
          return sendJSON(
            { ok: false, error: "internal_error", message: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/cleanup-duplicates?key=... - Remove duplicate/empty tickers from index
      if (routeKey === "POST /timed/debug/cleanup-duplicates") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const duplicatesToRemove = [
            "BTC", // Duplicate of BTCUSD (BTCUSD has data)
            "ES", // Duplicate of ES1! (ES1! has data)
            "ETH", // Duplicate of ETHUSD (ETHUSD has data)
            "NQ", // Duplicate of NQ1! (NQ1! has data)
            "MES1!", // Not sending data
            "MNQ1!", // Not sending data
            "RTY1!", // Not sending data
            "YM1!", // Not sending data
          ];

          const removed = [];
          const notFound = [];
          const hasData = [];

          for (const ticker of duplicatesToRemove) {
            if (!tickers.includes(ticker)) {
              notFound.push(ticker);
              continue;
            }

            // Check if ticker has data
            const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
            if (
              data &&
              (data.htf_score !== undefined || data.ltf_score !== undefined)
            ) {
              hasData.push(ticker);
              continue; // Don't remove if it has data
            }

            // Remove from index
            removed.push(ticker);

            // Also delete the data if it exists (even without scores)
            await KV.delete(`timed:latest:${ticker}`);
            await KV.delete(`timed:trail:${ticker}`);
          }

          // Update index once after processing all removals
          if (removed.length > 0) {
            const updatedTickers = tickers.filter((t) => !removed.includes(t));
            updatedTickers.sort();
            await kvPutJSON(KV, "timed:tickers", updatedTickers);
          }

          const finalTickers = (await kvGetJSON(KV, "timed:tickers")) || [];

          return sendJSON(
            {
              ok: true,
              message: "Cleanup completed",
              removed,
              notFound,
              hasData,
              beforeCount: tickers.length,
              afterCount: finalTickers.length,
              removedCount: removed.length,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/fix-index?key=...&ticker=BMNR - Manually add ticker to index if data exists
      if (routeKey === "POST /timed/debug/fix-index") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        // Allow requests without origin for debug endpoints (curl, direct API calls)
        const cors = corsHeaders(env, req, true);

        try {
          const ticker = normTicker(url.searchParams.get("ticker"));
          if (!ticker) {
            return sendJSON(
              { ok: false, error: "ticker parameter required" },
              400,
              cors,
            );
          }

          // Check if data exists in KV
          const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
          const inIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const alreadyInIndex = inIndex.includes(ticker);

          if (!data) {
            return sendJSON(
              {
                ok: false,
                error: "ticker data not found in KV",
                ticker,
                inIndex: alreadyInIndex,
              },
              404,
              cors,
            );
          }

          // Add to index if not already there
          if (!alreadyInIndex) {
            await ensureTickerIndex(KV, ticker);
            const updatedIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
            const nowInIndex = updatedIndex.includes(ticker);

            return sendJSON(
              {
                ok: true,
                message: `Ticker ${ticker} ${
                  nowInIndex ? "added to" : "failed to add to"
                } index`,
                ticker,
                hadData: true,
                wasInIndex: false,
                nowInIndex,
                indexSize: updatedIndex.length,
              },
              200,
              cors,
            );
          } else {
            return sendJSON(
              {
                ok: true,
                message: `Ticker ${ticker} already in index`,
                ticker,
                hadData: true,
                inIndex: true,
                indexSize: inIndex.length,
              },
              200,
              cors,
            );
          }
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, cors);
        }
      }

      // POST /timed/watchlist/add?key=... - Add tickers to watchlist
      if (routeKey === "POST /timed/watchlist/add") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const { obj: body } = await readBodyAsJSON(req);
          const tickersToAdd = body.tickers || [];

          if (!Array.isArray(tickersToAdd) || tickersToAdd.length === 0) {
            return sendJSON(
              { ok: false, error: "tickers array required" },
              400,
              corsHeaders(env, req),
            );
          }

          const currentTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const added = [];
          const alreadyExists = [];

          for (const ticker of tickersToAdd) {
            const tickerUpper = String(ticker).toUpperCase().trim();
            if (!tickerUpper) continue;

            if (!currentTickers.includes(tickerUpper)) {
              currentTickers.push(tickerUpper);
              added.push(tickerUpper);
              await ensureTickerIndex(KV, tickerUpper);
            } else {
              alreadyExists.push(tickerUpper);
            }
          }

          // Sort and save
          currentTickers.sort();
          await kvPutJSON(KV, "timed:tickers", currentTickers);

          return sendJSON(
            {
              ok: true,
              added: added.length,
              alreadyExists: alreadyExists.length,
              addedTickers: added,
              alreadyExistsTickers: alreadyExists,
              totalTickers: currentTickers.length,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/activity
      if (routeKey === "GET /timed/activity") {
        const feed = (await kvGetJSON(KV, "timed:activity:feed")) || [];

        const now = Date.now();
        const oneWeekAgo = now - 7 * 24 * 60 * 60 * 1000;
        const currentEvents = [];

        // Merge feed events with current events, deduplicate by ticker+type
        const allEvents = [...feed, ...currentEvents];
        const seen = new Set();
        const uniqueEvents = allEvents.filter((e) => {
          const key = `${e.ticker}-${e.type}-${Math.floor(
            e.ts / (60 * 60 * 1000),
          )}`; // Group by hour
          if (seen.has(key)) return false;
          seen.add(key);
          return e.ts > oneWeekAgo; // Only keep events from last week
        });

        // Sort by timestamp descending
        uniqueEvents.sort((a, b) => b.ts - a.ts);

        const limit = Math.min(
          100,
          Number(url.searchParams.get("limit") || "100"),
        );
        const filtered = uniqueEvents.slice(0, limit);

        return sendJSON(
          {
            ok: true,
            count: filtered.length,
            events: filtered,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/check-ticker?ticker=AAPL
      if (routeKey === "GET /timed/check-ticker") {
        const ticker = url.searchParams.get("ticker");
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "ticker parameter required" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickerUpper = ticker.toUpperCase();
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const inIndex = tickers.includes(tickerUpper);
        const latest = await kvGetJSON(KV, `timed:latest:${tickerUpper}`);
        const trail = await kvGetJSON(KV, `timed:trail:${tickerUpper}`);

        // Capture-only channel (some TV alerts may be wired to /timed/ingest-capture)
        const captureTickers =
          (await kvGetJSON(KV, "timed:capture:tickers")) || [];
        const inCaptureIndex = Array.isArray(captureTickers)
          ? captureTickers.includes(tickerUpper)
          : false;
        const captureLatest = await kvGetJSON(
          KV,
          `timed:capture:latest:${tickerUpper}`,
        );
        const captureTrail = await kvGetJSON(
          KV,
          `timed:capture:trail:${tickerUpper}`,
        );

        // Raw payload breadcrumbs (last seen) to identify which endpoint is receiving data.
        // NOTE: truncated for safety/size.
        const ingestRawKey = `timed:ingest:raw:${tickerUpper}`;
        const captureRawKey = `timed:capture:raw:${tickerUpper}`;
        const ingestRaw = await KV.get(ingestRawKey);
        const captureRaw = await KV.get(captureRawKey);
        const ingestRawSample = ingestRaw
          ? String(ingestRaw).slice(0, 500)
          : null;
        const captureRawSample = captureRaw
          ? String(captureRaw).slice(0, 500)
          : null;

        const latestTs =
          latest?.ingest_ts ?? latest?.ingest_time ?? latest?.ts ?? null;
        const captureTs =
          captureLatest?.ingest_ts ??
          captureLatest?.ingest_time ??
          captureLatest?.ts ??
          null;
        const likelyCaptureOnly = !!captureLatest && !latest && inCaptureIndex;

        return sendJSON(
          {
            ok: true,
            ticker: tickerUpper,
            inIndex,
            hasLatest: !!latest,
            hasTrail: !!trail,
            latestData: latest || null,
            trailLength: trail ? trail.length : 0,
            inCaptureIndex,
            hasCaptureLatest: !!captureLatest,
            hasCaptureTrail: !!captureTrail,
            captureLatestData: captureLatest || null,
            captureTrailLength: captureTrail ? captureTrail.length : 0,
            debug: {
              latestTs,
              captureTs,
              likelyCaptureOnly,
              raw: {
                ingestRawPresent: !!ingestRaw,
                captureRawPresent: !!captureRaw,
                ingestRawSample,
                captureRawSample,
              },
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ingest-status
      if (routeKey === "GET /timed/ingest-status") {
        try {
          const now = new Date();
          const result = await checkIngestCoverage(KV, now);
          return sendJSON(
            {
              ok: true,
              marketHoursET: isMarketHoursET(now),
              checked: result.checked || 0,
              missing: result.missing || [],
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: String(err?.message || err) },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/ingestion/stats?since&until&bucketMin
      // Coverage = distinct(ticker,bucket) / (watchlist_count * bucket_count)
      if (routeKey === "GET /timed/ingestion/stats") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const now = Date.now();
        const since = numParam(url, "since", now - 6 * 60 * 60 * 1000);
        const until = numParam(url, "until", now);
        const bucketMin = Math.max(
          1,
          Math.floor(numParam(url, "bucketMin", 5)),
        );
        const bucketMs = bucketMin * 60 * 1000;
        const threshold = Math.max(
          0,
          Math.min(1, numParam(url, "threshold", 0.9)),
        );
        const basis = String(url.searchParams.get("basis") || "payload")
          .trim()
          .toLowerCase(); // payload|received

        if (
          !Number.isFinite(since) ||
          !Number.isFinite(until) ||
          until <= since
        ) {
          return sendJSON(
            { ok: false, error: "invalid_since_until" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const watchlistCount = Array.isArray(tickers) ? tickers.length : 0;

        const bucketStart = Math.floor(since / bucketMs) * bucketMs;
        const bucketEnd = Math.floor(until / bucketMs) * bucketMs;
        const bucketCount =
          bucketEnd >= bucketStart
            ? Math.floor((bucketEnd - bucketStart) / bucketMs) + 1
            : 0;
        const expectedPairs = watchlistCount * bucketCount;

        const receiptsTotalRow = await db
          .prepare(
            `SELECT COUNT(*) AS n
             FROM ingest_receipts
             WHERE received_ts >= ?1 AND received_ts <= ?2`,
          )
          .bind(since, until)
          .first();

        const distinctPairsRow = await db
          .prepare(
            basis === "received"
              ? `SELECT COUNT(DISTINCT ticker || ':' || (CAST(received_ts / ?1 AS INTEGER) * ?1)) AS n
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3`
              : `SELECT COUNT(DISTINCT ticker || ':' || (CAST(ts / ?1 AS INTEGER) * ?1)) AS n
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3`,
          )
          .bind(bucketMs, since, until)
          .first();

        const receiptsTotal = Number(receiptsTotalRow?.n) || 0;
        const distinctPairs = Number(distinctPairsRow?.n) || 0;
        const coverage =
          expectedPairs > 0 ? distinctPairs / expectedPairs : null;

        return sendJSON(
          {
            ok: true,
            window: {
              since,
              until,
              bucketMin,
              bucketMs,
              bucketStart,
              bucketEnd,
              bucketCount,
            },
            basis,
            watchlistCount,
            expectedPairs,
            receiptsTotal,
            distinctPairs,
            coveragePct:
              coverage == null ? null : Math.round(coverage * 10000) / 100,
            meetsThreshold: coverage == null ? null : coverage >= threshold,
            thresholdPct: Math.round(threshold * 10000) / 100,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/watchlist/coverage?since&until&bucketMin&threshold
      // Per-ticker coverage across expected buckets (uses ingest_receipts)
      if (routeKey === "GET /timed/watchlist/coverage") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const now = Date.now();
        const since = numParam(url, "since", now - 6 * 60 * 60 * 1000);
        const until = numParam(url, "until", now);
        const bucketMin = Math.max(
          1,
          Math.floor(numParam(url, "bucketMin", 5)),
        );
        const bucketMs = bucketMin * 60 * 1000;
        const threshold = Math.max(
          0,
          Math.min(1, numParam(url, "threshold", 0.9)),
        );
        const basis = String(url.searchParams.get("basis") || "payload")
          .trim()
          .toLowerCase(); // payload|received

        if (
          !Number.isFinite(since) ||
          !Number.isFinite(until) ||
          until <= since
        ) {
          return sendJSON(
            { ok: false, error: "invalid_since_until" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const list = Array.isArray(tickers)
          ? tickers
              .map((t) =>
                String(t || "")
                  .trim()
                  .toUpperCase(),
              )
              .filter(Boolean)
          : [];

        const bucketStart = Math.floor(since / bucketMs) * bucketMs;
        const bucketEnd = Math.floor(until / bucketMs) * bucketMs;
        const bucketCount =
          bucketEnd >= bucketStart
            ? Math.floor((bucketEnd - bucketStart) / bucketMs) + 1
            : 0;

        const rows = await db
          .prepare(
            basis === "received"
              ? `SELECT
                  ticker,
                  COUNT(DISTINCT (CAST(received_ts / ?1 AS INTEGER) * ?1)) AS seen_buckets
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3
                 GROUP BY ticker`
              : `SELECT
                  ticker,
                  COUNT(DISTINCT (CAST(ts / ?1 AS INTEGER) * ?1)) AS seen_buckets
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3
                 GROUP BY ticker`,
          )
          .bind(bucketMs, since, until)
          .all();

        const seenByTicker = new Map();
        for (const r of rows?.results || []) {
          const t = String(r.ticker || "").toUpperCase();
          const n = Number(r.seen_buckets) || 0;
          if (t) seenByTicker.set(t, n);
        }

        const perTicker = list.map((t) => {
          const seen = seenByTicker.get(t) || 0;
          const pct = bucketCount > 0 ? seen / bucketCount : 0;
          return {
            ticker: t,
            seenBuckets: seen,
            expectedBuckets: bucketCount,
            coveragePct: bucketCount > 0 ? Math.round(pct * 10000) / 100 : null,
            meetsThreshold: bucketCount > 0 ? pct >= threshold : null,
          };
        });

        const tickersTotal = perTicker.length;
        const tickersAny = perTicker.filter(
          (t) => (t.seenBuckets || 0) > 0,
        ).length;
        const tickersMeet = perTicker.filter(
          (t) => t.meetsThreshold === true,
        ).length;

        // Sort “worst first” to make it easy to spot dropouts
        perTicker.sort((a, b) => (a.coveragePct ?? 0) - (b.coveragePct ?? 0));

        return sendJSON(
          {
            ok: true,
            window: {
              since,
              until,
              bucketMin,
              bucketMs,
              bucketStart,
              bucketEnd,
              bucketCount,
            },
            basis,
            thresholdPct: Math.round(threshold * 10000) / 100,
            summary: {
              tickersTotal,
              tickersAny,
              pctTickersAny:
                tickersTotal > 0
                  ? Math.round((tickersAny / tickersTotal) * 10000) / 100
                  : null,
              tickersMeet,
              pctTickersMeet:
                tickersTotal > 0
                  ? Math.round((tickersMeet / tickersTotal) * 10000) / 100
                  : null,
            },
            worst: perTicker.slice(0, 25),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ingest-audit?since&until&bucket&ticker&includeKv&scriptVersion
      if (routeKey === "GET /timed/ingest-audit") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const bucketRaw = url.searchParams.get("bucket");
        const tickerParam = normTicker(url.searchParams.get("ticker"));
        const includeKv = url.searchParams.get("includeKv") === "1";
        const scriptVersion = url.searchParams.get("scriptVersion");

        const now = Date.now();
        const since =
          sinceRaw != null && sinceRaw !== ""
            ? Number(sinceRaw)
            : now - 6 * 60 * 60 * 1000;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : now;
        const bucketMin = Math.max(1, Number(bucketRaw) || 5);
        const bucketMs = bucketMin * 60 * 1000;

        if (
          !Number.isFinite(since) ||
          !Number.isFinite(until) ||
          until <= since
        ) {
          return sendJSON(
            { ok: false, error: "invalid_since_until" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickers = tickerParam
          ? [tickerParam]
          : (await kvGetJSON(KV, "timed:tickers")) || [];

        const expectedBuckets = [];
        for (let t = since; t <= until; t += bucketMs) {
          expectedBuckets.push(Math.floor(t / bucketMs) * bucketMs);
        }

        const receiptRows = await db
          .prepare(
            `SELECT
              ticker,
              (ts / ?1) * ?1 AS bucket,
              COUNT(*) AS cnt
             FROM ingest_receipts
             WHERE ts >= ?2 AND ts <= ?3
             ${scriptVersion ? "AND script_version = ?4" : ""}
             ${tickerParam ? `AND ticker = ?${scriptVersion ? 5 : 4}` : ""}
             GROUP BY ticker, bucket`,
          )
          .bind(
            bucketMs,
            since,
            until,
            ...(scriptVersion ? [scriptVersion] : []),
            ...(tickerParam ? [tickerParam] : []),
          )
          .all();

        const trailRows = await db
          .prepare(
            `SELECT
              ticker,
              (ts / ?1) * ?1 AS bucket,
              COUNT(*) AS cnt
             FROM timed_trail
             WHERE ts >= ?2 AND ts <= ?3
             ${tickerParam ? "AND ticker = ?4" : ""}
             GROUP BY ticker, bucket`,
          )
          .bind(bucketMs, since, until, ...(tickerParam ? [tickerParam] : []))
          .all();

        const receiptMap = new Map();
        for (const row of receiptRows?.results || []) {
          const t = String(row.ticker || "").toUpperCase();
          if (!receiptMap.has(t)) receiptMap.set(t, new Set());
          receiptMap.get(t).add(Number(row.bucket));
        }

        const trailMap = new Map();
        for (const row of trailRows?.results || []) {
          const t = String(row.ticker || "").toUpperCase();
          if (!trailMap.has(t)) trailMap.set(t, new Set());
          trailMap.get(t).add(Number(row.bucket));
        }

        const kvMap = new Map();
        if (includeKv && tickerParam) {
          try {
            let kvTrail =
              (await kvGetJSON(KV, `timed:trail:${tickerParam}`)) || [];
            if (!Array.isArray(kvTrail)) kvTrail = [];
            const buckets = new Set();
            for (const point of kvTrail) {
              const ts = Number(point?.ts);
              if (!Number.isFinite(ts)) continue;
              if (ts < since || ts > until) continue;
              buckets.add(Math.floor(ts / bucketMs) * bucketMs);
            }
            kvMap.set(tickerParam, buckets);
          } catch (err) {
            console.error(`[INGEST AUDIT] KV trail read failed:`, err);
          }
        }

        const perTicker = tickers.map((t) => {
          const ticker = String(t || "").toUpperCase();
          const receiptBuckets = receiptMap.get(ticker) || new Set();
          const trailBuckets = trailMap.get(ticker) || new Set();
          const kvBuckets = kvMap.get(ticker) || null;

          const missingReceipts = expectedBuckets.filter(
            (b) => !receiptBuckets.has(b),
          );
          const missingTrail = expectedBuckets.filter(
            (b) => !trailBuckets.has(b),
          );
          const missingKv = kvBuckets
            ? expectedBuckets.filter((b) => !kvBuckets.has(b))
            : null;

          return {
            ticker,
            expectedBuckets: expectedBuckets.length,
            receiptBuckets: receiptBuckets.size,
            trailBucketsD1: trailBuckets.size,
            trailBucketsKV: kvBuckets ? kvBuckets.size : null,
            missingReceipts: missingReceipts.length,
            missingTrailD1: missingTrail.length,
            missingTrailKV: missingKv ? missingKv.length : null,
            missingReceiptSamples: missingReceipts.slice(0, 20),
            missingTrailSamples: missingTrail.slice(0, 20),
            missingTrailKvSamples: missingKv ? missingKv.slice(0, 20) : null,
          };
        });

        return sendJSON(
          {
            ok: true,
            since,
            until,
            bucketMinutes: bucketMin,
            tickers: tickers.length,
            includeKv: includeKv && !!tickerParam,
            scriptVersion: scriptVersion || null,
            perTicker,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/health
      if (routeKey === "GET /timed/health") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/health",
          500,
          3600,
        ); // Increased for single-user

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const last = Number(await KV.get("timed:last_ingest_ms")) || 0;
        const captureLast =
          Number(await KV.get("timed:capture:last_ingest_ms")) || 0;
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const captureTickers =
          (await kvGetJSON(KV, "timed:capture:tickers")) || [];
        const storedVersion = await getStoredVersion(KV);
        return sendJSON(
          {
            ok: true,
            now: Date.now(),
            lastIngestMs: last,
            minutesSinceLast: last ? (Date.now() - last) / 60000 : null,
            captureLastIngestMs: captureLast,
            captureMinutesSinceLast: captureLast
              ? (Date.now() - captureLast) / 60000
              : null,
            tickers: tickers.length,
            captureTickers: Array.isArray(captureTickers)
              ? captureTickers.length
              : 0,
            dataVersion: storedVersion || "none",
            expectedVersion: CURRENT_DATA_VERSION,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/purge?key=... (Manual purge endpoint)
      if (routeKey === "POST /timed/purge") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const result = await purgeOldData(KV);
        await setStoredVersion(KV, CURRENT_DATA_VERSION);

        return sendJSON(
          {
            ok: true,
            message: "Data purged successfully",
            purged: result.purged,
            tickerCount: result.tickerCount,
            version: CURRENT_DATA_VERSION,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/cleanup-no-scores?key=... (Remove tickers without score data from index)
      if (routeKey === "POST /timed/cleanup-no-scores") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const tickersToKeep = [];
        const tickersRemoved = [];

        for (const ticker of tickers) {
          const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
          const hasScores =
            data &&
            (data.htf_score !== undefined || data.ltf_score !== undefined);

          if (hasScores) {
            tickersToKeep.push(ticker);
          } else {
            tickersRemoved.push(ticker);
            // Also clean up the latest data entry if it exists but has no scores
            await KV.delete(`timed:latest:${ticker}`);
          }
        }

        await kvPutJSON(KV, "timed:tickers", tickersToKeep);

        return sendJSON(
          {
            ok: true,
            message: `Cleaned up ${tickersRemoved.length} tickers without scores`,
            removed: tickersRemoved,
            kept: tickersToKeep.length,
            totalBefore: tickers.length,
            totalAfter: tickersToKeep.length,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/rebuild-index?key=... (Rebuild ticker index from watchlist)
      if (routeKey === "POST /timed/rebuild-index") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        // Known ticker list from watchlists (Q1 2026 + Sectors)
        // This should match your TradingView watchlists
        const knownTickers = [
          "TSLA",
          "STX",
          "AU",
          "CCJ",
          "CLS",
          "CRS",
          "VST",
          "FSLR",
          "JCI",
          "ORCL",
          "AMZN",
          "BRK-B",
          "BABA",
          "WMT",
          "PH",
          "GEV",
          "HII",
          "ULTA",
          "SHOP",
          "CSX",
          "PWR",
          "HOOD",
          "SPGI",
          "APP",
          "PANW",
          "RDDT",
          "TT",
          "GLXY",
          "ETHA",
          "META",
          "NVDA",
          "AMD",
          "ANET",
          "GS",
          "TJX",
          "SOFI",
          "PNC",
          "PLTR",
          "NFLX",
          "MSTR",
          "MSFT",
          "MNST",
          "LRCX",
          "KLAC",
          "JPM",
          "GOOGL",
          "GE",
          "EXPE",
          "ETN",
          "EMR",
          "DE",
          "CRWD",
          "COST",
          "CDNS",
          "CAT",
          "BK",
          "AXP",
          "AXON",
          "AVGO",
          "AAPL",
          "RKLB",
          "LITE",
          "SN",
          "ALB",
          "RGLD",
          "MTZ",
          "ON",
          "ALLY",
          "DY",
          "EWBC",
          "PATH",
          "WFRD",
          "WAL",
          "IESC",
          "ENS",
          "TWLO",
          "MLI",
          "KTOS",
          "MDB",
          "TLN",
          "EME",
          "AWI",
          "IBP",
          "DCI",
          "WTS",
          "FIX",
          "UTHR",
          "NBIS",
          "SGI",
          "AYI",
          "RIOT",
          "NXT",
          "SANM",
          "BWXT",
          "PEGA",
          "JOBY",
          "IONQ",
          "ITT",
          "STRL",
          "QLYS",
          "MP",
          "HIMS",
          "IOT",
          "BE",
          "NEU",
          "AVAV",
          "PSTG",
          "RBLX",
          "CSCO",
          "BA",
          "NKE",
          "PI",
          "APLD",
          "MU",
          // ETFs
          "XLK",
          "XLF",
          "XLY",
          "XLP",
          "XLC",
          "XLB",
          "XLE",
          "XLU",
          "XLV",
          // Futures & Crypto
          "ES",
          "NQ",
          "BTC",
          "ETH",
          "BTCUSD",
          "ETHUSD",
          // Futures contracts
          "ES1!",
          "NQ1!",
          "MES1!",
          "MNQ1!",
          "YM1!",
          "RTY1!",
        ]
          .map((t) => t.toUpperCase())
          .filter((v, i, a) => a.indexOf(v) === i); // Deduplicate

        const currentIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
        const addedTickers = [];
        const existingTickers = new Set(currentIndex);

        for (const ticker of knownTickers) {
          if (!existingTickers.has(ticker)) {
            currentIndex.push(ticker);
            addedTickers.push(ticker);
          }
        }

        // Sort and save
        currentIndex.sort();
        await kvPutJSON(KV, "timed:tickers", currentIndex);

        return sendJSON(
          {
            ok: true,
            message: `Index rebuilt. Added ${addedTickers.length} tickers.`,
            beforeCount: currentIndex.length - addedTickers.length,
            afterCount: currentIndex.length,
            addedTickers: addedTickers.slice(0, 20), // Show first 20
            totalAdded: addedTickers.length,
            note: "Index will continue to grow as TradingView sends alerts for these tickers.",
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/purge-trades-by-version?key=...&version=2.6.0 (Purge trades by version)
      if (routeKey === "POST /timed/purge-trades-by-version") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const targetVersion = url.searchParams.get("version");
        if (!targetVersion) {
          return sendJSON(
            { ok: false, error: "version parameter required" },
            400,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

        const beforeCount = allTrades.length;
        const filteredTrades = allTrades.filter((trade) => {
          const tradeVersion =
            trade.scriptVersion || trade.script_version || "unknown";
          return tradeVersion !== targetVersion;
        });
        const purgedCount = beforeCount - filteredTrades.length;

        await kvPutJSON(KV, tradesKey, filteredTrades);

        return sendJSON(
          {
            ok: true,
            message: `Purged ${purgedCount} trades with version ${targetVersion}`,
            beforeCount,
            afterCount: filteredTrades.length,
            purgedCount,
            targetVersion,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/cleanup-tickers?key=... (Remove unapproved tickers, keep only approved list, normalize Gold/Silver)
      // POST /timed/clear-rate-limit?key=...&all=true (Reset all) or &ip=...&endpoint=... (Clear specific)
      if (routeKey === "POST /timed/clear-rate-limit") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const ip = url.searchParams.get("ip") || null;
        const endpoint = url.searchParams.get("endpoint") || null;
        const clearAll = url.searchParams.get("all") === "true";

        // List of all known endpoints that use rate limiting
        const allEndpoints = [
          "/timed/all",
          "/timed/latest",
          "/timed/activity",
          "/timed/trail",
          "/timed/top",
          "/timed/momentum",
          "/timed/momentum/history",
          "/timed/momentum/all",
          "/timed/trades",
          "/timed/health",
          "/timed/version",
          "/timed/alert-debug",
          "/timed/check-ticker",
        ];

        let cleared = 0;
        const clearedKeys = [];

        if (clearAll) {
          // Clear ALL rate limits - note: KV doesn't support listing all keys
          // So we return a message that rate limits will expire naturally
          // For immediate clearing, users should specify IP
          return sendJSON(
            {
              ok: true,
              message:
                "Rate limit reset acknowledged. Note: Cloudflare KV doesn't support listing all keys, so active rate limits will expire naturally after 1 hour. For immediate clearing, use ?ip=IP_ADDRESS to clear all endpoints for a specific IP.",
              note: "To clear all rate limits for your IP immediately, use: ?ip=YOUR_IP",
              endpoints: allEndpoints,
            },
            200,
            corsHeaders(env, req),
          );
        } else if (ip && endpoint) {
          // Clear specific IP + endpoint combination
          const legacyKey = `ratelimit:${ip}:${endpoint}`;
          await KV.delete(legacyKey);
          clearedKeys.push(legacyKey);
          cleared++;

          // Also clear fixed-window buckets (current + previous bucket)
          const window = 3600;
          const bucket = Math.floor(Date.now() / (window * 1000));
          const fixedKeyNow = `ratelimit:${ip}:${endpoint}:${bucket}`;
          const fixedKeyPrev = `ratelimit:${ip}:${endpoint}:${bucket - 1}`;
          await KV.delete(fixedKeyNow);
          await KV.delete(fixedKeyPrev);
          clearedKeys.push(fixedKeyNow, fixedKeyPrev);
          cleared++;
        } else if (ip) {
          // Clear all rate limits for a specific IP (all endpoints)
          for (const ep of allEndpoints) {
            const legacyKey = `ratelimit:${ip}:${ep}`;
            await KV.delete(legacyKey);
            cleared++;
            clearedKeys.push(legacyKey);

            // Also clear fixed-window buckets (current + previous bucket)
            const window = 3600;
            const bucket = Math.floor(Date.now() / (window * 1000));
            const fixedKeyNow = `ratelimit:${ip}:${ep}:${bucket}`;
            const fixedKeyPrev = `ratelimit:${ip}:${ep}:${bucket - 1}`;
            await KV.delete(fixedKeyNow);
            await KV.delete(fixedKeyPrev);
            cleared += 2;
            clearedKeys.push(fixedKeyNow, fixedKeyPrev);
          }
        } else if (endpoint) {
          // Clear all rate limits for a specific endpoint (all IPs)
          // Note: This is not directly possible without listing all IPs
          // For now, return an error suggesting to specify IP
          return sendJSON(
            {
              ok: false,
              error:
                "Cannot clear endpoint without IP. Please specify both 'ip' and 'endpoint', or just 'ip' to clear all endpoints for that IP.",
            },
            400,
            corsHeaders(env, req),
          );
        } else {
          // No parameters - return usage info
          return sendJSON(
            {
              ok: false,
              error: "Missing parameters",
              usage: {
                clearAll: "POST /timed/clear-rate-limit?key=YOUR_KEY&all=true",
                clearSpecific:
                  "POST /timed/clear-rate-limit?key=YOUR_KEY&ip=IP_ADDRESS&endpoint=/timed/activity",
                clearAllForIP:
                  "POST /timed/clear-rate-limit?key=YOUR_KEY&ip=IP_ADDRESS",
              },
            },
            400,
            corsHeaders(env, req),
          );
        }

        return sendJSON(
          {
            ok: true,
            message: `Cleared ${cleared} rate limit(s)`,
            cleared,
            keys: clearedKeys,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/cleanup-tickers?key=...&strict=1 (strict=1: purge-only, no social-additions)
      if (routeKey === "POST /timed/cleanup-tickers") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const url = new URL(req.url || `https://x/${req.url}`);
        const strictPurge = url.searchParams.get("strict") === "1";

        // Approved ticker list — WATCHLIST_Q1_2026
        const approvedTickers = new Set([
          "AAPL", "AEHR", "AGQ", "ALB", "ALLY", "AMD", "AMGN", "AMZN", "ANET", "APLD", "APP", "ASTS",
          "AU", "AVAV", "AVGO", "AWI", "AXON", "AXP", "AYI", "B", "BA", "BABA", "BE", "BK", "BMNR",
          "BRK-B", "BRK.B", "BTCUSD", "BWXT", "CAT", "CCJ", "CDNS", "CLS", "COIN", "COST", "CRS", "CRVS",
          "CRWD", "CRWV", "CSCO", "CSX", "CVNA", "CVX", "DCI", "DE", "DY", "EME", "EMR", "ENS", "ES1!", "ETHA",
          "ETHT", "ETHUSD", "ETN", "EWBC", "EXPE", "FIX", "FSLR", "GDXJ", "GE", "GEV", "GILD",
          "GLXY", "GOLD", "GOOGL", "GS", "HII", "HIMS", "HL", "HOOD", "IAU", "IBP", "IBRX", "IESC",
          "INTC", "INTU", "IONQ", "IOT", "IREN", "ITT", "IWM", "JCI", "JOBY", "JPM", "KLAC", "KO",
          "KTOS", "LLY", "LITE", "LRCX", "LULU", "MCD", "MDB", "META", "MLI", "MNST", "MP", "MSFT", "MSTR", "MTB", "MTZ",
          "MU", "NBIS", "NEU", "NFLX", "NKE", "NQ1!", "NVDA", "NXT", "ON", "ONDS", "ORCL", "PANW",
          "PATH", "PEGA", "PH", "PI", "PLTR", "PNC", "PSTG", "PWR", "QLYS", "QQQ", "RBLX", "RDDT",
          "RGLD", "RIOT", "RKLB", "SANM", "SGI", "SHOP", "SILVER", "SLV", "SN", "SNDK", "SOFI",
          "SOXL", "SPGI", "SPY", "STRL", "STX", "SWK", "TJX", "TLN", "TSM", "TSLA", "TT", "TWLO", "ULTA",
          "UTHR", "UUUU", "US500", "VIX", "VST", "WAL", "WDC", "WFRD", "WM", "WMT", "WTS",
          "XLB", "XLC", "XLE", "XLF", "XLI", "XLK", "XLP", "XLRE", "XLU", "XLV", "XLY", "XOM",
          "ES", "NQ", "BTC", "ETH",
        ]);

        const tickerMap = {
          "BRK.B": "BRK-B",
          ES: "ES1!",
          NQ: "NQ1!",
          BTC: "BTCUSD",
          ETH: "ETHUSD",
        };

        let approvedSet = new Set(approvedTickers);
        if (!strictPurge) {
          const socialAdditions = (await kvGetJSON(KV, "timed:social:additions")) || [];
          for (const t of socialAdditions) {
            if (t && typeof t === "string") approvedSet.add(String(t).toUpperCase());
          }
        }

        const currentTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const toRemove = [];
        const toKeep = [];
        const renamed = [];
        const addedToSocial = [];

        for (const ticker of currentTickers) {
          const upperTicker = ticker.toUpperCase();
          const normalized = tickerMap[upperTicker] || upperTicker;

          if (approvedSet.has(upperTicker) || approvedSet.has(normalized)) {
            if (normalized !== upperTicker && tickerMap[upperTicker]) {
              renamed.push({ from: ticker, to: normalized });
              toKeep.push(normalized);
            } else {
              toKeep.push(ticker);
            }
          } else {
            if (!strictPurge) {
              // Accept new ticker: add to Social and keep
              const additions = (await kvGetJSON(KV, "timed:social:additions")) || [];
              const upper = upperTicker;
              if (!additions.includes(upper)) {
                additions.push(upper);
                additions.sort();
                await kvPutJSON(KV, "timed:social:additions", additions);
                addedToSocial.push(upper);
              }
              approvedSet.add(upper);
              toKeep.push(ticker);
            } else {
              toRemove.push(ticker);
            }
          }
        }

        let removedCount = 0;
        for (const ticker of toRemove) {
          await KV.delete(`timed:latest:${ticker}`);
          await KV.delete(`timed:trail:${ticker}`);
          await KV.delete(`timed:heartbeat:${ticker}`);
          if (env?.DB) {
            try {
              await env.DB.prepare(`DELETE FROM ticker_latest WHERE ticker = ?1`).bind(ticker).run();
            } catch (_) {}
          }
          removedCount++;
        }

        // Purge trades/positions for tickers not in watchlist (strict mode only)
        let tradesPurged = 0;
        if (strictPurge && env?.DB && toRemove.length > 0) {
          try {
            for (const ticker of toRemove) {
              const posRows = await env.DB.prepare(`SELECT position_id FROM positions WHERE ticker = ?1`).bind(ticker).all();
              const posIds = (posRows?.results || []).map((r) => r.position_id);
              for (const pid of posIds) {
                await env.DB.prepare(`DELETE FROM execution_actions WHERE position_id = ?1`).bind(pid).run();
                await env.DB.prepare(`DELETE FROM lots WHERE position_id = ?1`).bind(pid).run();
              }
              const posDel = await env.DB.prepare(`DELETE FROM positions WHERE ticker = ?1`).bind(ticker).run();
              const tradeIds = (await env.DB.prepare(`SELECT trade_id FROM trades WHERE ticker = ?1`).bind(ticker).all())?.results || [];
              for (const row of tradeIds) {
                await env.DB.prepare(`DELETE FROM trade_events WHERE trade_id = ?1`).bind(row.trade_id).run();
              }
              const tradeDel = await env.DB.prepare(`DELETE FROM trades WHERE ticker = ?1`).bind(ticker).run();
              tradesPurged += (tradeDel?.meta?.changes || 0) + (posDel?.meta?.changes || 0);
            }
          } catch (e) {
            console.warn("[cleanup-tickers] D1 trade purge error:", String(e?.message || e));
          }
        }

        // Also purge trades for tickers in D1 that aren't in approvedSet (covers already-removed tickers like BTBT)
        if (strictPurge && env?.DB) {
          try {
            const allTradeTickers = (await env.DB.prepare(`SELECT DISTINCT ticker FROM trades`).all())?.results || [];
            const allPosTickers = (await env.DB.prepare(`SELECT DISTINCT ticker FROM positions`).all())?.results || [];
            const tickersToPurge = new Set();
            for (const r of allTradeTickers) {
              const t = String(r?.ticker || "").toUpperCase();
              const norm = tickerMap[t] || t;
              if (!approvedSet.has(t) && !approvedSet.has(norm)) tickersToPurge.add(r.ticker);
            }
            for (const r of allPosTickers) {
              const t = String(r?.ticker || "").toUpperCase();
              const norm = tickerMap[t] || t;
              if (!approvedSet.has(t) && !approvedSet.has(norm)) tickersToPurge.add(r.ticker);
            }
            for (const ticker of tickersToPurge) {
              if (toRemove.includes(ticker)) continue;
              const posRows = await env.DB.prepare(`SELECT position_id FROM positions WHERE ticker = ?1`).bind(ticker).all();
              const posIds = (posRows?.results || []).map((r) => r.position_id);
              for (const pid of posIds) {
                await env.DB.prepare(`DELETE FROM execution_actions WHERE position_id = ?1`).bind(pid).run();
                await env.DB.prepare(`DELETE FROM lots WHERE position_id = ?1`).bind(pid).run();
              }
              await env.DB.prepare(`DELETE FROM positions WHERE ticker = ?1`).bind(ticker).run();
              const tradeIds = (await env.DB.prepare(`SELECT trade_id FROM trades WHERE ticker = ?1`).bind(ticker).all())?.results || [];
              for (const row of tradeIds) {
                await env.DB.prepare(`DELETE FROM trade_events WHERE trade_id = ?1`).bind(row.trade_id).run();
              }
              await env.DB.prepare(`DELETE FROM trades WHERE ticker = ?1`).bind(ticker).run();
              tradesPurged++;
            }
          } catch (e) {
            console.warn("[cleanup-tickers] D1 orphan trade purge error:", String(e?.message || e));
          }
        }

        let renamedCount = 0;
        for (const { from, to } of renamed) {
          const latestData = await kvGetJSON(KV, `timed:latest:${from}`);
          const trailData = await kvGetJSON(KV, `timed:trail:${from}`);
          if (latestData) {
            await kvPutJSON(KV, `timed:latest:${to}`, latestData);
            await KV.delete(`timed:latest:${from}`);
          }
          if (trailData) {
            await kvPutJSON(KV, `timed:trail:${to}`, trailData);
            await KV.delete(`timed:trail:${from}`);
          }
          if (env?.DB) {
            try {
              await env.DB.prepare(`UPDATE ticker_latest SET ticker = ?1 WHERE ticker = ?2`).bind(to, from).run();
            } catch (_) {}
          }
          renamedCount++;
        }

        await kvPutJSON(KV, "timed:tickers", toKeep.sort());

        return sendJSON(
          {
            ok: true,
            message: strictPurge ? "One-time purge completed (strict mode)" : "Cleanup completed (new tickers added to Social)",
            removed: removedCount,
            renamed: renamedCount,
            addedToSocial: addedToSocial.length,
            kept: toKeep.length,
            tradesPurged: tradesPurged,
            removedTickers: toRemove.sort(),
            addedToSocialTickers: addedToSocial,
            renamedTickers: renamed,
            finalTickers: toKeep.sort(),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/social-additions — tickers accepted into Social group (not in watchlist)
      if (routeKey === "GET /timed/social-additions") {
        const additions = (await kvGetJSON(KV, "timed:social:additions")) || [];
        return sendJSON(
          { ok: true, additions: Array.isArray(additions) ? additions : [] },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/cors-debug (Debug CORS configuration)
      if (routeKey === "GET /timed/cors-debug") {
        const corsConfig = env.CORS_ALLOW_ORIGIN || "";
        const allowedOrigins = corsConfig
          .split(",")
          .map((o) => o.trim())
          .filter(Boolean);
        const origin = req?.headers?.get("Origin") || "";

        return sendJSON(
          {
            ok: true,
            cors: {
              config: corsConfig,
              allowedOrigins: allowedOrigins,
              requestedOrigin: origin,
              isAllowed: allowedOrigins.includes(origin),
              willReturn:
                allowedOrigins.length === 0
                  ? "*"
                  : allowedOrigins.includes(origin)
                    ? origin
                    : "null",
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/version (Check current version)
      if (routeKey === "GET /timed/version") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/version",
          500, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const storedVersion = await getStoredVersion(KV);
        return sendJSON(
          {
            ok: true,
            storedVersion: storedVersion || "none",
            expectedVersion: CURRENT_DATA_VERSION,
            match: storedVersion === CURRENT_DATA_VERSION,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/alert-debug?ticker=XYZ (Debug why alerts aren't firing)
      if (routeKey === "GET /timed/alert-debug") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/alert-debug",
          500, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        }

        const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
        if (!data) {
          return sendJSON(
            { ok: false, error: "no data for ticker", ticker },
            404,
            corsHeaders(env, req),
          );
        }

        // Replicate alert logic
        const state = String(data.state || "");
        const alignedLong = state === "HTF_BULL_LTF_BULL";
        const alignedShort = state === "HTF_BEAR_LTF_BEAR";
        const aligned = alignedLong || alignedShort;

        const prevKey = `timed:prevstate:${ticker}`;
        const prevState = await KV.get(prevKey);
        const enteredAligned = aligned && prevState !== state;

        const trigReason = String(data.trigger_reason || "");
        const trigOk =
          trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
          trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");

        const flags = data.flags || {};
        const sqRel = !!flags.sq30_release;

        const side = corridorSide(data);
        const inCorridor = !!side;
        const corridorAlignedOK =
          (side === "LONG" && alignedLong) ||
          (side === "SHORT" && alignedShort);

        const shouldConsiderAlert =
          inCorridor &&
          corridorAlignedOK &&
          (enteredAligned || trigOk || sqRel);

        // Threshold gates (with Momentum Elite adjustments)
        const momentumElite = !!flags.momentum_elite;

        // Momentum Elite gets relaxed thresholds (higher quality stocks)
        const baseMinRR = Number(env.ALERT_MIN_RR || "1.5");
        const baseMaxComp = Number(env.ALERT_MAX_COMPLETION || "0.4");
        const baseMaxPhase = Number(env.ALERT_MAX_PHASE || "0.6");
        // Adjust thresholds for Momentum Elite (more lenient for quality stocks)
        const minRR = momentumElite
          ? Math.max(1.2, baseMinRR * 0.9)
          : baseMinRR; // Lower RR requirement
        const maxComp = momentumElite
          ? Math.min(0.5, baseMaxComp * 1.25)
          : baseMaxComp; // Allow higher completion
        const maxPhase = momentumElite
          ? Math.min(0.7, baseMaxPhase * 1.17)
          : baseMaxPhase; // Allow higher phase

        // Use current price for dynamic RR calculation (matches actual alert logic)
        const currentRR = computeRR(data);
        const rrToUse =
          currentRR != null ? currentRR : data.rr != null ? Number(data.rr) : 0;
        const rrOk = rrToUse >= minRR;
        const compToMax = computeCompletionToTpMax(data);
        const compRaw = data.completion == null ? null : Number(data.completion);
        const compVal = Number.isFinite(compToMax) ? compToMax : compRaw;
        const compOk = compVal == null ? true : compVal <= maxComp;
        const phaseOk =
          data.phase_pct == null ? true : Number(data.phase_pct) <= maxPhase;

        // Also consider Momentum Elite as a trigger condition (quality signal)
        const momentumEliteTrigger =
          momentumElite && inCorridor && corridorAlignedOK;

        // Enhanced trigger: original conditions OR Momentum Elite in good setup
        const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

        const discordEnabled = (env.DISCORD_ENABLE || "false") === "true";
        const discordUrlSet = !!env.DISCORD_WEBHOOK_URL;

        const wouldAlert =
          enhancedTrigger &&
          rrOk &&
          compOk &&
          phaseOk &&
          discordEnabled &&
          discordUrlSet;

        return sendJSON(
          {
            ok: true,
            ticker,
            wouldAlert,
            discord: {
              enabled: discordEnabled,
              urlSet: discordUrlSet,
              configured: discordEnabled && discordUrlSet,
            },
            conditions: {
              inCorridor,
              side: side || "none",
              corridorAlignedOK,
              enteredAligned,
              trigOk,
              sqRel,
              momentumElite,
              shouldConsiderAlert,
              momentumEliteTrigger,
              enhancedTrigger,
              rrOk: {
                value: rrToUse,
                valueFromPayload: data.rr,
                calculatedAtCurrentPrice: currentRR,
                baseRequired: baseMinRR,
                adjustedRequired: minRR,
                ok: rrOk,
              },
              compOk: {
                value: data.completion,
                baseRequired: baseMaxComp,
                adjustedRequired: maxComp,
                ok: compOk,
              },
              phaseOk: {
                value: data.phase_pct,
                baseRequired: baseMaxPhase,
                adjustedRequired: maxPhase,
                ok: phaseOk,
              },
            },
            thresholds: {
              base: {
                minRR: baseMinRR,
                maxComp: baseMaxComp,
                maxPhase: baseMaxPhase,
              },
              adjusted: { minRR, maxComp, maxPhase },
              momentumEliteAdjustments: momentumElite,
            },
            data: {
              state,
              htf_score: data.htf_score,
              ltf_score: data.ltf_score,
              rr: data.rr,
              completion: data.completion,
              phase_pct: data.phase_pct,
              trigger_reason: data.trigger_reason,
              flags: data.flags,
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/alert-replay?ticker=XYZ&since=<ms>&until=<ms>&limit=<n>
      // Replays alert eligibility across historical ingest payloads (D1-backed).
      if (routeKey === "GET /timed/alert-replay") {
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/alert-replay",
          200, // conservative; this endpoint can be heavy
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        }

        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const limitRaw = url.searchParams.get("limit");

        const now = Date.now();
        const since =
          sinceRaw != null && sinceRaw !== ""
            ? Number(sinceRaw)
            : now - 8 * 24 * 60 * 60 * 1000; // default: last ~week
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;
        const limit =
          limitRaw != null && limitRaw !== "" ? Number(limitRaw) : 5000;

        const history = await d1GetTrailPayloadRange(
          env,
          ticker,
          since,
          until,
          limit,
        );
        if (!history.ok) {
          return sendJSON(
            {
              ok: false,
              error: history.skipped
                ? `d1_unavailable:${history.reason || "unknown"}`
                : "d1_query_failed",
              details: history.error || null,
              ticker,
            },
            503,
            corsHeaders(env, req),
          );
        }

        const payloads = Array.isArray(history.payloads)
          ? history.payloads
          : [];
        if (payloads.length === 0) {
          return sendJSON(
            {
              ok: true,
              ticker,
              source: history.source,
              since,
              until,
              count: 0,
              results: [],
              note: "No historical payloads found in D1 for requested range.",
            },
            200,
            corsHeaders(env, req),
          );
        }

        const discordEnabled = (env.DISCORD_ENABLE || "false") === "true";
        const discordUrlSet = !!env.DISCORD_WEBHOOK_URL;

        const baseMinRR = Number(env.ALERT_MIN_RR || "1.5");
        const baseMaxComp = Number(env.ALERT_MAX_COMPLETION || "0.4");
        const baseMaxPhase = Number(env.ALERT_MAX_PHASE || "0.6");

        let prevState = null;
        const results = [];
        const wouldDays = new Set();

        for (const data of payloads) {
          const state = String(data.state || "");
          const alignedLong = state === "HTF_BULL_LTF_BULL";
          const alignedShort = state === "HTF_BEAR_LTF_BEAR";
          const aligned = alignedLong || alignedShort;

          const enteredAligned =
            aligned && prevState != null && prevState !== state;

          const trigReason = String(data.trigger_reason || "");
          const trigOk =
            trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
            trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");

          const flags = data.flags || {};
          const sqRel = !!flags.sq30_release;

          const side = corridorSide(data);
          const inCorridor = !!side;
          const corridorAlignedOK =
            (side === "LONG" && alignedLong) ||
            (side === "SHORT" && alignedShort);

          const shouldConsiderAlert =
            inCorridor &&
            corridorAlignedOK &&
            (enteredAligned || trigOk || sqRel);

          const momentumElite = !!flags.momentum_elite;

          const minRR = momentumElite
            ? Math.max(1.2, baseMinRR * 0.9)
            : baseMinRR;
          const maxComp = momentumElite
            ? Math.min(0.5, baseMaxComp * 1.25)
            : baseMaxComp;
          const maxPhase = momentumElite
            ? Math.min(0.7, baseMaxPhase * 1.17)
            : baseMaxPhase;

          const currentRR = computeRR(data);
          const rrToUse =
            currentRR != null
              ? currentRR
              : data.rr != null
                ? Number(data.rr)
                : 0;
          const rrOk = rrToUse >= minRR;
          const compOk =
            data.completion == null ? true : Number(data.completion) <= maxComp;
          const phaseOk =
            data.phase_pct == null ? true : Number(data.phase_pct) <= maxPhase;

          const momentumEliteTrigger =
            momentumElite && inCorridor && corridorAlignedOK;
          const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

          const wouldAlertLogic = enhancedTrigger && rrOk && compOk && phaseOk;
          const wouldAlert = wouldAlertLogic && discordEnabled && discordUrlSet;

          const action = "ENTRY";
          const ts = Number(data.trigger_ts || data.ts);
          const dedupeInfo = buildAlertDedupeKey({
            ticker,
            action,
            side,
            ts,
          });
          if (wouldAlert && dedupeInfo.key) wouldDays.add(dedupeInfo.key);

          if (wouldAlertLogic) {
            results.push({
              ts,
              day: dedupeInfo.day,
              dedupe_key: dedupeInfo.key,
              dedupe_bucket: dedupeInfo.bucket,
              action,
              state,
              side: side || "none",
              inCorridor,
              corridorAlignedOK,
              enteredAligned,
              trigOk,
              trigger_reason: trigReason || null,
              sqRel,
              momentumElite,
              rr: rrToUse,
              rrOk,
              completion: data.completion,
              compOk,
              phase_pct: data.phase_pct,
              phaseOk,
              rank: data.rank,
              enhancedTrigger,
              wouldAlertLogic,
              wouldAlert, // includes discord configured
            });
          }

          prevState = state;
        }

        // Check KV dedupe keys for alert buckets (so replay can explain "blocked by dedupe")
        const dedupe = {};
        const days = Array.from(wouldDays);
        await Promise.all(
          days.map(async (day) => {
            const v = await KV.get(day);
            dedupe[day] = { key: day, alreadyAlerted: !!v };
          }),
        );

        // Compute "wouldSendIfFirstBucket" as a deterministic simulation of dedupe behavior
        const firstOfDaySeen = new Set();
        const enriched = results.map((r) => {
          if (!r.wouldAlert)
            return {
              ...r,
              dedupe: dedupe[r.dedupe_key] || null,
              wouldSend: false,
            };
          const already =
            (dedupe[r.dedupe_key] && dedupe[r.dedupe_key].alreadyAlerted) ||
            false;
          const first = r.dedupe_key && !firstOfDaySeen.has(r.dedupe_key);
          if (r.dedupe_key && first) firstOfDaySeen.add(r.dedupe_key);
          return {
            ...r,
            dedupe: dedupe[r.dedupe_key] || null,
            wouldSend: !already && first,
          };
        });

        return sendJSON(
          {
            ok: true,
            ticker,
            source: history.source,
            since,
            until,
            pointsFetched: payloads.length,
            eligiblePoints: enriched.length, // only those passing logic
            wouldSendCount: enriched.filter((x) => x.wouldSend).length,
            discord: { enabled: discordEnabled, urlSet: discordUrlSet },
            thresholds: {
              base: {
                minRR: baseMinRR,
                maxComp: baseMaxComp,
                maxPhase: baseMaxPhase,
              },
            },
            results: enriched,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/trades?since&until&ticker&status&limit&cursor
      if (routeKey === "GET /timed/ledger/trades") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/ledger/trades",
          600,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker")) || null;
        const statusRaw = url.searchParams.get("status");
        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const limitRaw = url.searchParams.get("limit");
        const cursorRaw = url.searchParams.get("cursor");

        const since =
          sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;
        const limit = Math.max(1, Math.min(1000, Number(limitRaw) || 200));
        const cursor = decodeCursor(cursorRaw);

        let where = "WHERE 1=1";
        const binds = [];
        if (ticker) {
          where += " AND ticker = ?";
          binds.push(String(ticker).toUpperCase());
        }
        const statusNorm =
          statusRaw != null ? String(statusRaw).trim().toLowerCase() : "";
        if (statusNorm && statusNorm !== "all") {
          // UX-friendly filters used by the ledger UI
          if (statusNorm === "closed") {
            where += " AND status IN ('WIN','LOSS')";
          } else if (statusNorm === "open") {
            // Includes OPEN + TRIMMED-style intermediate statuses + nulls
            where += " AND (status IS NULL OR status NOT IN ('WIN','LOSS'))";
          } else {
            // Exact match fallback (stored statuses are uppercase)
            where += " AND status = ?";
            binds.push(String(statusRaw).toUpperCase());
          }
        }
        if (since != null && Number.isFinite(since)) {
          where += " AND entry_ts >= ?";
          binds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          where += " AND entry_ts <= ?";
          binds.push(Number(until));
        }
        if (
          cursor &&
          Number.isFinite(Number(cursor.entry_ts)) &&
          cursor.trade_id
        ) {
          where += " AND (entry_ts < ? OR (entry_ts = ? AND trade_id < ?))";
          binds.push(
            Number(cursor.entry_ts),
            Number(cursor.entry_ts),
            String(cursor.trade_id),
          );
        }

        const sqlFull = `SELECT
            trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at, trim_ts, trim_price
          FROM trades
          ${where}
          ORDER BY entry_ts DESC, trade_id DESC
          LIMIT ?`;
        const sqlWithoutTrimPrice = `SELECT
            trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at, trim_ts
          FROM trades
          ${where}
          ORDER BY entry_ts DESC, trade_id DESC
          LIMIT ?`;
        const sqlWithoutTrimTs = `SELECT
            trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at
          FROM trades
          ${where}
          ORDER BY entry_ts DESC, trade_id DESC
          LIMIT ?`;

        let rows;
        try {
          rows = await db
            .prepare(sqlFull)
            .bind(...binds, limit + 1)
            .all();
        } catch (e) {
          const msg = (e && (e.message || String(e))) || "";
          if (msg.includes("trim_price") || msg.includes("no such column")) {
            try {
              rows = await db
                .prepare(sqlWithoutTrimPrice)
                .bind(...binds, limit + 1)
                .all();
              if (Array.isArray(rows?.results)) {
                rows.results = rows.results.map((r) => ({ ...r, trim_price: null }));
              }
            } catch (e2) {
              const msg2 = (e2 && (e2.message || String(e2))) || "";
              if (msg2.includes("trim_ts") || msg2.includes("no such column")) {
                rows = await db
                  .prepare(sqlWithoutTrimTs)
                  .bind(...binds, limit + 1)
                  .all();
                if (Array.isArray(rows?.results)) {
                  rows.results = rows.results.map((r) => ({ ...r, trim_ts: null, trim_price: null }));
                }
              } else {
                throw e2;
              }
            }
          } else if (msg.includes("trim_ts") || msg.includes("no such column")) {
            rows = await db
              .prepare(sqlWithoutTrimTs)
              .bind(...binds, limit + 1)
              .all();
            if (Array.isArray(rows?.results)) {
              rows.results = rows.results.map((r) => ({ ...r, trim_ts: null, trim_price: null }));
            }
          } else {
            throw e;
          }
        }
        const results = Array.isArray(rows?.results) ? rows.results : [];
        const page = results.slice(0, limit);
        const hasMore = results.length > limit;
        const last = page.length > 0 ? page[page.length - 1] : null;
        const nextCursor =
          hasMore && last
            ? encodeCursor({ entry_ts: last.entry_ts, trade_id: last.trade_id })
            : null;

        // Enrich with quantity from positions (remaining qty) for Holdings display
        try {
          const ids = page.map((r) => r.trade_id).filter(Boolean);
          if (ids.length > 0) {
            const placeholders = ids.map(() => "?").join(",");
            const posRows = await db
              .prepare(
                `SELECT position_id, total_qty FROM positions WHERE position_id IN (${placeholders})`,
              )
              .bind(...ids)
              .all();
            const qtyByTrade = new Map();
            for (const r of posRows?.results || []) {
              qtyByTrade.set(String(r.position_id), Number(r.total_qty) || 0);
            }
            for (const t of page) {
              const qty = qtyByTrade.get(String(t.trade_id));
              if (qty != null) {
                t.quantity = qty;
                t.shares = qty;
              } else if (Number(t.trimmed_pct ?? 0) >= 0.9999) {
                t.quantity = 0;
                t.shares = 0;
              }
            }
          }
        } catch {
          for (const t of page) {
            t.quantity = null;
            t.shares = null;
          }
        }

        return sendJSON(
          { ok: true, count: page.length, hasMore, nextCursor, trades: page },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/trades/:tradeId
      // GET /timed/ledger/trades/:tradeId/decision-card?type=ENTRY|TRIM|EXIT&ts=...
      // Returns a Discord-style "Action & Reasoning" card using the nearest trail snapshot.
      if (routeKey === "GET /timed/ledger/trades/:id/decision-card") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const raw = url.pathname.split("/timed/ledger/trades/")[1] || "";
        const tradeId = decodeURIComponent(
          raw.replace(/\/decision-card$/, ""),
        ).trim();
        if (!tradeId) {
          return sendJSON(
            { ok: false, error: "missing trade_id" },
            400,
            corsHeaders(env, req),
          );
        }

        const typeRaw = String(
          url.searchParams.get("type") || url.searchParams.get("event") || "",
        )
          .trim()
          .toUpperCase();
        const type =
          typeRaw === "CLOSE"
            ? "EXIT"
            : typeRaw === "ENTRY" || typeRaw === "TRIM" || typeRaw === "EXIT"
              ? typeRaw
              : null;
        if (!type) {
          return sendJSON(
            {
              ok: false,
              error: "missing_or_invalid_type",
              allowed: ["ENTRY", "TRIM", "EXIT"],
            },
            400,
            corsHeaders(env, req),
          );
        }

        const tsParam = url.searchParams.get("ts");
        const ts = tsParam != null && tsParam !== "" ? Number(tsParam) : null;

        const tradeRow = await db
          .prepare(
            `SELECT
              trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
              exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
              script_version, created_at, updated_at
             FROM trades WHERE trade_id = ?1 LIMIT 1`,
          )
          .bind(tradeId)
          .first();

        if (!tradeRow) {
          return sendJSON(
            { ok: false, error: "not_found", trade_id: tradeId },
            404,
            corsHeaders(env, req),
          );
        }

        const ticker = String(tradeRow.ticker || "").toUpperCase();
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing_ticker", trade_id: tradeId },
            400,
            corsHeaders(env, req),
          );
        }

        const evRowFromDb = await (async () => {
          if (Number.isFinite(ts)) {
            // Find closest event in time (best for "By Day Activity" clicks)
            const r = await db
              .prepare(
                `SELECT
                  event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
                 FROM trade_events
                 WHERE trade_id = ?1 AND type = ?2
                 ORDER BY ABS(ts - ?3) ASC
                 LIMIT 1`,
              )
              .bind(tradeId, type, Number(ts))
              .first();
            return r || null;
          }
          // Default: entry -> earliest; others -> latest
          const order = type === "ENTRY" ? "ASC" : "DESC";
          const r = await db
            .prepare(
              `SELECT
                event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
               FROM trade_events
               WHERE trade_id = ?1 AND type = ?2
               ORDER BY ts ${order}
               LIMIT 1`,
            )
            .bind(tradeId, type)
            .first();
          return r || null;
        })();

        // Resilience: some environments may not have trade_events populated.
        // In that case, fall back to the timestamp passed by the client (preferred),
        // or use the trade's own lifecycle timestamps.
        const fallbackTs = (() => {
          if (Number.isFinite(ts)) return Number(ts);
          if (type === "ENTRY") return Number(tradeRow.entry_ts);
          if (type === "EXIT") return Number(tradeRow.exit_ts);
          // TRIM: best available fallback is updated_at when trim status is present
          const trimmed = Number(tradeRow.trimmed_pct || 0);
          if (type === "TRIM" && trimmed > 0)
            return Number(tradeRow.updated_at);
          return null;
        })();

        const evRow = evRowFromDb
          ? evRowFromDb
          : Number.isFinite(Number(fallbackTs))
            ? {
                event_id: null,
                trade_id: String(tradeId),
                ts: Number(fallbackTs),
                type,
                price: null,
                qty_pct_delta: null,
                qty_pct_total:
                  type === "TRIM"
                    ? Number(tradeRow.trimmed_pct || 0) || null
                    : null,
                pnl_realized: null,
                reason: null,
                meta_json: null,
              }
            : null;

        if (!evRow || !Number.isFinite(Number(evRow.ts))) {
          return sendJSON(
            { ok: false, error: "event_not_found", trade_id: tradeId, type },
            404,
            corsHeaders(env, req),
          );
        }

        const evTs = Number(evRow.ts);
        const snapWindowMs =
          type === "ENTRY" ? 3 * 60 * 60 * 1000 : 2 * 60 * 60 * 1000;
        const snap = await d1GetNearestTrailPayload(
          db,
          ticker,
          evTs,
          snapWindowMs,
        );

        const tickerData = snap && snap.payload ? snap.payload : null;
        if (!tickerData) {
          return sendJSON(
            {
              ok: false,
              error: "missing_snapshot",
              trade_id: tradeId,
              type,
              ts: evTs,
            },
            404,
            corsHeaders(env, req),
          );
        }

        const tradeLite = {
          direction: tradeRow.direction,
          rank: Number(tradeRow.rank) || 0,
          rr: Number(tradeRow.rr) || 0,
          status: tradeRow.status,
          exitReason: tradeRow.exit_reason || null,
          pnl: Number(tradeRow.pnl) || 0,
          pnlPct: Number(tradeRow.pnl_pct) || 0,
        };

        const trimPct = (() => {
          const v =
            evRow.qty_pct_total != null ? Number(evRow.qty_pct_total) : null;
          if (Number.isFinite(v)) return v;
          const fromMeta = parseTrimPctFromText(evRow.meta_json);
          return Number.isFinite(fromMeta) ? fromMeta : null;
        })();

        const actionKey = type === "EXIT" ? "CLOSE" : type;
        const interpretation = generateTradeActionInterpretation(
          actionKey,
          tickerData,
          tradeLite,
          trimPct,
        );

        return sendJSON(
          {
            ok: true,
            trade: tradeRow,
            event: evRow,
            snapshot: { ts: Number(snap.ts), payload: tickerData },
            card: {
              title:
                `${ticker} ${String(tradeLite.direction || "").toUpperCase()}`.trim(),
              action: interpretation?.action || null,
              reasons: interpretation?.reasons || null,
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      if (routeKey === "GET /timed/ledger/trades/:id") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const tradeId = decodeURIComponent(
          url.pathname.split("/timed/ledger/trades/")[1] || "",
        ).trim();
        if (!tradeId) {
          return sendJSON(
            { ok: false, error: "missing trade_id" },
            400,
            corsHeaders(env, req),
          );
        }

        const includeEvidence =
          (url.searchParams.get("includeEvidence") || "") === "1";

        const tradeRow = await db
          .prepare(
            `SELECT
              trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
              exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
              script_version, created_at, updated_at
             FROM trades WHERE trade_id = ?1 LIMIT 1`,
          )
          .bind(tradeId)
          .first();

        if (!tradeRow) {
          return sendJSON(
            { ok: false, error: "not_found", trade_id: tradeId },
            404,
            corsHeaders(env, req),
          );
        }

        const eventsRows = await db
          .prepare(
            `SELECT
              event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
             FROM trade_events
             WHERE trade_id = ?1
             ORDER BY ts ASC`,
          )
          .bind(tradeId)
          .all();

        const events = Array.isArray(eventsRows?.results)
          ? eventsRows.results
          : [];

        let evidence = null;
        let entry_evidence = null;
        if (includeEvidence) {
          const ticker = String(tradeRow.ticker || "").toUpperCase();
          // Always try to attach a "best" entry snapshot (bubble-style detail)
          entry_evidence = await d1GetNearestTrailPayload(
            db,
            ticker,
            tradeRow.entry_ts,
            3 * 60 * 60 * 1000,
          );

          evidence = [];
          for (const ev of events) {
            const ts = Number(ev.ts);
            if (!ticker || !Number.isFinite(ts)) continue;
            const snap = await d1GetNearestTrailPayload(
              db,
              ticker,
              ts,
              2 * 60 * 60 * 1000,
            );
            if (snap && snap.payload) {
              evidence.push({
                event_id: ev.event_id,
                ts: ts,
                snapshot_ts: Number(snap.ts),
                payload: snap.payload,
              });
            }
          }
        }

        return sendJSON(
          { ok: true, trade: tradeRow, events, evidence, entry_evidence },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/alerts?since&until&ticker&dedupe_day&limit&cursor
      if (routeKey === "GET /timed/ledger/alerts") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/ledger/alerts",
          600,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker")) || null;
        const dedupeDay = url.searchParams.get("dedupe_day");
        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const limitRaw = url.searchParams.get("limit");
        const cursorRaw = url.searchParams.get("cursor");

        const since =
          sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;
        const limit = Math.max(1, Math.min(1000, Number(limitRaw) || 200));
        const cursor = decodeCursor(cursorRaw);

        let where = "WHERE 1=1";
        const binds = [];
        if (ticker) {
          where += " AND ticker = ?";
          binds.push(String(ticker).toUpperCase());
        }
        if (dedupeDay && dedupeDay !== "all") {
          where += " AND dedupe_day = ?";
          binds.push(String(dedupeDay));
        }
        if (since != null && Number.isFinite(since)) {
          where += " AND ts >= ?";
          binds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          where += " AND ts <= ?";
          binds.push(Number(until));
        }
        if (cursor && Number.isFinite(Number(cursor.ts)) && cursor.alert_id) {
          where += " AND (ts < ? OR (ts = ? AND alert_id < ?))";
          binds.push(
            Number(cursor.ts),
            Number(cursor.ts),
            String(cursor.alert_id),
          );
        }

        const sql = `SELECT
            alert_id, ticker, ts, side, state, rank, rr_at_alert, trigger_reason, dedupe_day,
            discord_sent, discord_status, discord_error
          FROM alerts
          ${where}
          ORDER BY ts DESC, alert_id DESC
          LIMIT ?`;

        const rows = await db
          .prepare(sql)
          .bind(...binds, limit + 1)
          .all();
        const results = Array.isArray(rows?.results) ? rows.results : [];
        const page = results.slice(0, limit);
        const hasMore = results.length > limit;
        const last = page.length > 0 ? page[page.length - 1] : null;
        const nextCursor =
          hasMore && last
            ? encodeCursor({ ts: last.ts, alert_id: last.alert_id })
            : null;

        return sendJSON(
          { ok: true, count: page.length, hasMore, nextCursor, alerts: page },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/summary?since&until
      if (routeKey === "GET /timed/ledger/summary") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/ledger/summary",
          300,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const since =
          sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;

        let where = "WHERE 1=1";
        const binds = [];
        if (since != null && Number.isFinite(since)) {
          where += " AND entry_ts >= ?";
          binds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          where += " AND entry_ts <= ?";
          binds.push(Number(until));
        }

        const overall = await db
          .prepare(
            `SELECT
              COUNT(*) AS total,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN 1 ELSE 0 END) AS closed,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS closed_pnl,
              SUM(CASE WHEN status = 'WIN' THEN pnl ELSE 0 END) AS gross_win,
              SUM(CASE WHEN status = 'LOSS' THEN -pnl ELSE 0 END) AS gross_loss,
              AVG(CASE WHEN status = 'WIN' THEN pnl ELSE NULL END) AS avg_win,
              AVG(CASE WHEN status = 'LOSS' THEN -pnl ELSE NULL END) AS avg_loss_abs
            FROM trades
            ${where}`,
          )
          .bind(...binds)
          .first();

        const closed = Number(overall?.closed || 0);
        const openTrades = Math.max(0, Number(overall?.total || 0) - closed);
        const wins = Number(overall?.wins || 0);
        const losses = Number(overall?.losses || 0);
        const winRate = closed > 0 ? (wins / closed) * 100 : 0;
        const grossWin = Number(overall?.gross_win || 0);
        const grossLoss = Number(overall?.gross_loss || 0);
        const profitFactor =
          grossLoss > 0 ? grossWin / grossLoss : grossWin > 0 ? Infinity : 0;
        const avgWin = Number(overall?.avg_win || 0);
        const avgLossAbs = Number(overall?.avg_loss_abs || 0);
        const expectancy =
          closed > 0 ? Number(overall?.closed_pnl || 0) / closed : 0;

        const rankBuckets = await db
          .prepare(
            `SELECT
              CASE
                WHEN rank >= 80 THEN '80+'
                WHEN rank >= 70 THEN '70-79'
                WHEN rank >= 60 THEN '60-69'
                WHEN rank IS NULL THEN 'unknown'
                ELSE '<60'
              END AS bucket,
              COUNT(*) AS n,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS pnl
            FROM trades
            ${where}
            GROUP BY bucket
            ORDER BY bucket`,
          )
          .bind(...binds)
          .all();

        const rrBuckets = await db
          .prepare(
            `SELECT
              CASE
                WHEN rr >= 2.0 THEN '2.0+'
                WHEN rr >= 1.5 THEN '1.5-1.99'
                WHEN rr >= 1.0 THEN '1.0-1.49'
                WHEN rr IS NULL THEN 'unknown'
                ELSE '<1.0'
              END AS bucket,
              COUNT(*) AS n,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS pnl
            FROM trades
            ${where}
            GROUP BY bucket
            ORDER BY bucket`,
          )
          .bind(...binds)
          .all();

        const exitReasons = await db
          .prepare(
            `SELECT
              COALESCE(exit_reason, 'unknown') AS reason,
              COUNT(*) AS n,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS pnl
            FROM trades
            ${where}
            GROUP BY reason
            ORDER BY n DESC`,
          )
          .bind(...binds)
          .all();

        // Trigger reasons from alerts (sent + skipped) in same time window (best-effort)
        let alertWhere = "WHERE 1=1";
        const alertBinds = [];
        if (since != null && Number.isFinite(since)) {
          alertWhere += " AND ts >= ?";
          alertBinds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          alertWhere += " AND ts <= ?";
          alertBinds.push(Number(until));
        }

        const triggerReasons = await db
          .prepare(
            `SELECT
              COALESCE(trigger_reason, 'unknown') AS reason,
              COUNT(*) AS n,
              SUM(CASE WHEN discord_sent = 1 THEN 1 ELSE 0 END) AS sent,
              SUM(CASE WHEN discord_sent = 0 THEN 1 ELSE 0 END) AS not_sent
            FROM alerts
            ${alertWhere}
            GROUP BY reason
            ORDER BY n DESC`,
          )
          .bind(...alertBinds)
          .all();

        return sendJSON(
          {
            ok: true,
            since,
            until,
            totals: {
              totalTrades: Number(overall?.total || 0),
              openTrades,
              closedTrades: closed,
              wins,
              losses,
              winRate,
              closedPnl: Number(overall?.closed_pnl || 0),
              profitFactor,
              avgWin,
              avgLoss: avgLossAbs,
              expectancy,
              grossWin,
              grossLoss,
            },
            breakdown: {
              byRank: rankBuckets?.results || [],
              byRR: rrBuckets?.results || [],
              byExitReason: exitReasons?.results || [],
              byTriggerReason: triggerReasons?.results || [],
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-trades?key=...&limit=...&offset=...&ticker=...
      // Backfill KV trades/history into D1 ledger tables (idempotent via upserts + INSERT OR IGNORE).
      if (routeKey === "POST /timed/admin/backfill-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
        const filtered = Array.isArray(allTrades)
          ? allTrades.filter((t) => {
              if (!t || !t.id) return false;
              if (tickerFilter)
                return String(t.ticker || "").toUpperCase() === tickerFilter;
              return true;
            })
          : [];

        const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
        const limit =
          qLimit > 0 ? Math.max(1, Math.min(5000, qLimit)) : filtered.length;
        const slice = filtered.slice(offset, offset + limit);

        let tradesUpserted = 0;
        let eventsInserted = 0;
        const errors = [];

        const batchSize = 50;
        for (let i = 0; i < slice.length; i += batchSize) {
          const batch = slice.slice(i, i + batchSize);
          await Promise.all(
            batch.map(async (t) => {
              try {
                // Enrich legacy history (trim percentages + inferred exit reason/price)
                const tradeCopy = { ...t };
                if (Array.isArray(tradeCopy.history)) {
                  let prevTrimTotal = 0;
                  for (let idx = 0; idx < tradeCopy.history.length; idx++) {
                    const ev = tradeCopy.history[idx];
                    if (!ev || !ev.type) continue;
                    if (String(ev.type).toUpperCase() === "TRIM") {
                      const inferredTotal =
                        ev.trimPct != null
                          ? Number(ev.trimPct)
                          : (parseTrimPctFromText(ev.note) ??
                            parseTrimPctFromText(ev.meta_json));
                      if (
                        inferredTotal != null &&
                        Number.isFinite(inferredTotal)
                      ) {
                        ev.trimPct = inferredTotal;
                        if (ev.trimDeltaPct == null && prevTrimTotal != null) {
                          ev.trimDeltaPct = Math.max(
                            0,
                            inferredTotal - prevTrimTotal,
                          );
                        }
                        prevTrimTotal = inferredTotal;
                      }
                    }
                    if (String(ev.type).toUpperCase() === "EXIT") {
                      // Add explicit reason for better bucketing
                      ev.reason =
                        ev.reason ||
                        inferExitReasonForLegacyTrade(tradeCopy, ev);
                      // Ensure price is a number if present
                      if (ev.price != null) ev.price = Number(ev.price);
                    }
                  }
                }

                // Ensure trade-level exit fields exist for legacy trades
                if (
                  (String(tradeCopy.status || "").toUpperCase() === "WIN" ||
                    String(tradeCopy.status || "").toUpperCase() === "LOSS") &&
                  Array.isArray(tradeCopy.history)
                ) {
                  const exitEv =
                    [...tradeCopy.history]
                      .reverse()
                      .find((e) => e && e.type === "EXIT") || null;
                  if (exitEv) {
                    if (tradeCopy.exitPrice == null && exitEv.price != null)
                      tradeCopy.exitPrice = Number(exitEv.price);
                    if (!tradeCopy.exitReason)
                      tradeCopy.exitReason = inferExitReasonForLegacyTrade(
                        tradeCopy,
                        exitEv,
                      );
                  }
                }

                const r = await d1UpsertTrade(env, tradeCopy);
                if (r.ok) tradesUpserted += 1;

                if (Array.isArray(tradeCopy.history)) {
                  for (const ev of tradeCopy.history) {
                    const er = await d1InsertTradeEvent(
                      env,
                      String(tradeCopy.id),
                      ev,
                    );
                    if (er.ok) eventsInserted += 1;
                  }
                }
              } catch (e) {
                errors.push({ trade_id: t?.id || null, error: String(e) });
              }
            }),
          );
        }

        return sendJSON(
          {
            ok: true,
            ticker: tickerFilter || null,
            totalInKV: Array.isArray(allTrades) ? allTrades.length : 0,
            filtered: filtered.length,
            offset,
            limit: slice.length,
            tradesUpserted,
            eventsInserted,
            errorsCount: errors.length,
            errors: errors.slice(0, 25),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-positions?key=...&limit=...&offset=...
      // Backfill positions/lots/execution_actions from existing D1 trades + trade_events (idempotent).
      if (routeKey === "POST /timed/admin/backfill-positions") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));

        let tradeRows = [];
        try {
          let sql = `SELECT trade_id, ticker, direction, entry_ts, entry_price, status, trimmed_pct, pnl, script_version, created_at, updated_at, exit_ts
            FROM trades WHERE 1=1`;
          const binds = [];
          if (tickerFilter) {
            sql += " AND ticker = ?";
            binds.push(tickerFilter);
          }
          sql += " ORDER BY entry_ts ASC";
          if (qLimit > 0) {
            sql += " LIMIT ? OFFSET ?";
            binds.push(qLimit, qOffset);
          }
          const res = await db.prepare(sql).bind(...binds).all();
          tradeRows = Array.isArray(res?.results) ? res.results : [];
        } catch (e) {
          return sendJSON(
            { ok: false, error: "trades_query_failed", message: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }

        let positionsInserted = 0;
        let lotsInserted = 0;
        let actionsInserted = 0;
        const errors = [];

        for (const row of tradeRows) {
          try {
            const tradeId = row.trade_id;
            const ticker = String(row.ticker || "").toUpperCase();
            const direction = String(row.direction || "LONG").toUpperCase();
            let entryTs = Number(row.entry_ts) || Number(row.created_at) || 0;
            if (entryTs < 1e12) entryTs *= 1000;
            const status = row.status && (row.status === "WIN" || row.status === "LOSS") ? "CLOSED" : "OPEN";
            const closedAt = status === "CLOSED" ? (Number(row.exit_ts) || Number(row.updated_at) || null) : null; // trades has exit_ts, not closed_at

            const eventsRes = await db.prepare(
              `SELECT event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
               FROM trade_events WHERE trade_id = ? ORDER BY ts ASC`
            ).bind(tradeId).all();
            const events = Array.isArray(eventsRes?.results) ? eventsRes.results : [];

            const entryPrice = Number(row.entry_price) || 0;
            let totalQty = 0;
            let costBasis = 0;
            const parseShares = (ev) => {
              if (ev.meta_json) {
                try {
                  const m = JSON.parse(ev.meta_json);
                  if (Number.isFinite(m.shares)) return m.shares;
                } catch {}
              }
              if (ev.price != null && ev.price > 0 && Number.isFinite(ev.value)) return ev.value / ev.price;
              return null;
            };

            const r1 = await d1InsertPosition(env, {
              position_id: tradeId,
              ticker,
              direction,
              status,
              total_qty: 0,
              cost_basis: 0,
              created_at: entryTs,
              updated_at: Number(row.updated_at) || Date.now(),
              closed_at: closedAt,
              script_version: row.script_version || null,
            });
            if (r1.ok) positionsInserted++;

            for (const ev of events) {
              const ts = Number(ev.ts) || 0;
              const tsMs = ts < 1e12 ? ts * 1000 : ts;
              const type = String(ev.type || "").toUpperCase();
              const price = ev.price != null ? Number(ev.price) : 0;
              let qty = parseShares(ev);
              if (qty == null && type === "ENTRY" && entryPrice > 0) {
                qty = 1000 / entryPrice;
              }
              if (qty == null || qty <= 0) continue;
              const value = price * qty;

              if (type === "ENTRY" || type === "SCALE_IN") {
                const lotId = `${tradeId}-lot-${tsMs}`;
                const actionType = type === "SCALE_IN" ? "ADD_ENTRY" : "ENTRY";
                const actionId = `${tradeId}-${actionType}-${tsMs}`;
                const r2 = await d1InsertLot(env, {
                  lot_id: lotId,
                  position_id: tradeId,
                  ts: tsMs,
                  qty,
                  price,
                  value,
                  remaining_qty: type === "ENTRY" ? qty : qty,
                });
                if (r2.ok) lotsInserted++;
                totalQty += qty;
                costBasis += value;
                const r3 = await d1InsertExecutionAction(env, {
                  action_id: actionId,
                  position_id: tradeId,
                  ts: tsMs,
                  action_type: actionType,
                  qty,
                  price,
                  value,
                  pnl_realized: null,
                  reason: ev.reason || actionType,
                });
                if (r3.ok) actionsInserted++;
              } else if (type === "TRIM" || type === "EXIT") {
                const actionId = `${tradeId}-${type}-${tsMs}`;
                const pnl = ev.pnl_realized != null ? Number(ev.pnl_realized) : null;
                const r3 = await d1InsertExecutionAction(env, {
                  action_id: actionId,
                  position_id: tradeId,
                  ts: tsMs,
                  action_type: type,
                  qty,
                  price,
                  value: price * qty,
                  pnl_realized: pnl,
                  reason: ev.reason || type,
                });
                if (r3.ok) actionsInserted++;
                if (type === "EXIT") {
                  totalQty = 0;
                  costBasis = 0;
                }
              }
            }

            if (totalQty > 0 || costBasis > 0) {
              await d1UpdatePosition(env, tradeId, {
                total_qty: totalQty,
                cost_basis: costBasis,
                updated_at: Number(row.updated_at) || Date.now(),
                ...(status === "CLOSED" ? { status: "CLOSED", closed_at: closedAt } : {}),
              });
            }
          } catch (e) {
            errors.push({ trade_id: row?.trade_id, error: String(e?.message || e) });
          }
        }

        return sendJSON(
          {
            ok: true,
            tradesProcessed: tradeRows.length,
            positionsInserted,
            lotsInserted,
            actionsInserted,
            errorsCount: errors.length,
            errors: errors.slice(0, 20),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-alerts?key=...&limit=...&offset=...&ticker=...&source=trades|activity|all
      // Backfill KV activity + trades into D1 alerts ledger (idempotent via upserts).
      if (routeKey === "POST /timed/admin/backfill-alerts") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const source = String(
          url.searchParams.get("source") || "all",
        ).toLowerCase();
        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));

        let alertsUpserted = 0;
        const errors = [];

        const upsertAlertSafe = async (payload) => {
          try {
            const r = await d1UpsertAlert(env, payload);
            if (r.ok) alertsUpserted += 1;
          } catch (err) {
            errors.push(String(err));
          }
        };

        if (source === "activity" || source === "all") {
          try {
            const feed = (await kvGetJSON(KV, "timed:activity:feed")) || [];
            const activityAlerts = feed.filter((e) => {
              if (!e || !e.ticker) return false;
              if (
                tickerFilter &&
                String(e.ticker).toUpperCase() !== tickerFilter
              )
                return false;
              return (
                e.type === "discord_alert" ||
                e.type === "trade_entry" ||
                e.type === "td9_exit"
              );
            });
            for (const ev of activityAlerts) {
              const ts = Number(ev.ts) || Date.now();
              const side =
                ev.direction || ev.side || ev.trigger_dir || ev.action || null;
              const alertType =
                ev.type === "discord_alert"
                  ? "ALERT_ENTRY"
                  : ev.type === "trade_entry"
                    ? "TRADE_ENTRY"
                    : "TD9_EXIT";
              const payloadJson = (() => {
                try {
                  return JSON.stringify(ev);
                } catch {
                  return null;
                }
              })();
              const metaJson = (() => {
                try {
                  return JSON.stringify({ source: "activity", type: ev.type });
                } catch {
                  return null;
                }
              })();
              await upsertAlertSafe({
                alert_id: buildAlertId(ev.ticker, ts, alertType),
                ticker: ev.ticker,
                ts,
                side,
                state: ev.state,
                rank: ev.rank,
                rr_at_alert: ev.rr,
                trigger_reason: ev.trigger_reason || ev.action || alertType,
                dedupe_day: formatDedupDay(ts),
                discord_sent: true,
                discord_status: 200,
                discord_error: null,
                payload_json: payloadJson,
                meta_json: metaJson,
              });
            }
          } catch (err) {
            errors.push(String(err));
          }
        }

        if (source === "trades" || source === "all") {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const filtered = Array.isArray(allTrades)
            ? allTrades.filter((t) => {
                if (!t || !t.id) return false;
                if (tickerFilter)
                  return String(t.ticker || "").toUpperCase() === tickerFilter;
                return true;
              })
            : [];

          const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
          const limit =
            qLimit > 0 ? Math.max(1, Math.min(5000, qLimit)) : filtered.length;
          const slice = filtered.slice(offset, offset + limit);

          for (const trade of slice) {
            if (!Array.isArray(trade.history)) continue;
            for (const ev of trade.history) {
              if (!ev || !ev.type) continue;
              const ts = isoToMs(ev.timestamp) || Number(ev.ts) || Date.now();
              const type = String(ev.type).toUpperCase();
              const reason =
                ev.reason ||
                (type === "EXIT"
                  ? trade.exitReason || trade.exit_reason
                  : type);
              const payloadJson = (() => {
                try {
                  return JSON.stringify({
                    trade_id: trade.id,
                    trade,
                    event: ev,
                  });
                } catch {
                  return null;
                }
              })();
              const metaJson = (() => {
                try {
                  return JSON.stringify({ source: "trade_history", type });
                } catch {
                  return null;
                }
              })();
              await upsertAlertSafe({
                alert_id: buildAlertId(trade.ticker, ts, type),
                ticker: trade.ticker,
                ts,
                side: trade.direction,
                state: trade.state,
                rank: trade.rank,
                rr_at_alert: trade.rr,
                trigger_reason: reason,
                dedupe_day: formatDedupDay(ts),
                discord_sent: false,
                discord_status: null,
                discord_error: null,
                payload_json: payloadJson,
                meta_json: metaJson,
              });
            }
          }
        }

        return sendJSON(
          { ok: true, alertsUpserted, errors },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-derived?key=...&limit=...&offset=...&ticker=...&includeTrades=1
      // Recompute derived horizon/ETA/TP fields for latest tickers (and optionally trades) and persist to KV.
      if (routeKey === "POST /timed/admin/backfill-derived") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));
        const includeTrades =
          String(url.searchParams.get("includeTrades") || "") === "1";

        const tickersList = (await kvGetJSON(KV, "timed:tickers")) || [];
        const filteredTickers = Array.isArray(tickersList)
          ? tickersList.filter((t) => {
              if (!t) return false;
              if (tickerFilter)
                return String(t).toUpperCase() === String(tickerFilter);
              return true;
            })
          : [];

        const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
        const limit =
          qLimit > 0
            ? Math.max(1, Math.min(2000, qLimit))
            : filteredTickers.length;
        const slice = filteredTickers.slice(offset, offset + limit);

        let tickersUpdated = 0;
        let tradesUpdated = 0;
        const errors = [];

        for (const t of slice) {
          try {
            const ticker = String(t || "").toUpperCase();
            if (!ticker) continue;
            const latestKey = `timed:latest:${ticker}`;
            const latest = await kvGetJSON(KV, latestKey);
            if (!latest || typeof latest !== "object") continue;
            const derived = deriveHorizonAndMetrics(latest);
            Object.assign(latest, derived);
            await kvPutJSON(KV, latestKey, latest);
            tickersUpdated += 1;
          } catch (e) {
            errors.push({ ticker: t || null, error: String(e) });
          }
        }

        if (includeTrades) {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          if (Array.isArray(allTrades) && allTrades.length > 0) {
            for (const trade of allTrades) {
              if (!trade || !trade.ticker) continue;
              const tradeTicker = String(trade.ticker || "").toUpperCase();
              if (tickerFilter && tradeTicker !== tickerFilter) continue;
              try {
                const latest = await kvGetJSON(
                  KV,
                  `timed:latest:${tradeTicker}`,
                );
                const base =
                  latest && typeof latest === "object" ? latest : trade;
                const source = {
                  ...base,
                  entry_ref:
                    base.entry_ref != null
                      ? base.entry_ref
                      : (trade.entryPrice ?? base.trigger_price ?? base.price),
                  trigger_price: base.trigger_price ?? trade.entryPrice,
                  price: base.price ?? trade.currentPrice ?? trade.entryPrice,
                  sl: base.sl ?? trade.sl,
                  tp: base.tp ?? trade.tp,
                };
                const derived = deriveHorizonAndMetrics(source);
                trade.horizon_bucket = derived.horizon_bucket;
                trade.eta_days_v2 = derived.eta_days_v2;
                trade.expected_return_pct = derived.expected_return_pct;
                trade.risk_pct = derived.risk_pct;
                trade.tp_target_price = derived.tp_target_price;
                trade.tp_target_pct = derived.tp_target_pct;
                trade.tp_max_price = derived.tp_max_price;
                trade.tp_max_pct = derived.tp_max_pct;
                trade.entry_ref = derived.entry_ref ?? trade.entry_ref;
                tradesUpdated += 1;
              } catch (e) {
                errors.push({ trade_id: trade?.id || null, error: String(e) });
              }
            }
            await kvPutJSON(KV, tradesKey, allTrades);
          }
        }

        return sendJSON(
          {
            ok: true,
            ticker: tickerFilter || null,
            totalTickers: Array.isArray(tickersList) ? tickersList.length : 0,
            filtered: filteredTickers.length,
            offset,
            limit: slice.length,
            tickersUpdated,
            tradesUpdated: includeTrades ? tradesUpdated : 0,
            errorsCount: errors.length,
            errors: errors.slice(0, 25),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // ═══════════════════════════════════════════════════════════════════════
      // ALPACA INTEGRATION ENDPOINTS
      // ═══════════════════════════════════════════════════════════════════════

      // POST /timed/admin/alpaca-backfill?key=...&tf=all|D|W|...
      // One-time backfill of historical bars from Alpaca for EMA200 warm-up.
      if (routeKey === "POST /timed/admin/alpaca-backfill") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        if (!env.ALPACA_API_KEY_ID || !env.ALPACA_API_SECRET_KEY) {
          return sendJSON(
            { ok: false, error: "alpaca_not_configured", hint: "Set ALPACA_API_KEY_ID and ALPACA_API_SECRET_KEY via wrangler secret put" },
            400, corsHeaders(env, req),
          );
        }

        const tfParam = url.searchParams.get("tf") || "all";
        const batchOffset = Math.max(0, Number(url.searchParams.get("offset")) || 0);
        const batchLimit = Math.max(1, Math.min(100, Number(url.searchParams.get("limit")) || 0));
        let allTickers = Object.keys(SECTOR_MAP);
        if (batchLimit > 0) {
          allTickers = allTickers.slice(batchOffset, batchOffset + batchLimit);
        }

        // Run backfill in background (will take a while)
        ctx.waitUntil(
          alpacaBackfill(env, allTickers, d1UpsertCandle, tfParam)
            .then(res => console.log(`[ALPACA BACKFILL] Done:`, JSON.stringify(res)))
            .catch(err => console.error(`[ALPACA BACKFILL] Error:`, err))
        );

        return sendJSON(
          {
            ok: true,
            message: "Alpaca backfill started in background",
            tickers: allTickers.length,
            tf: tfParam,
          },
          200, corsHeaders(env, req),
        );
      }

      // POST /timed/admin/alpaca-compute?key=...&ticker=AAPL (compute scores for one ticker)
      if (routeKey === "POST /timed/admin/alpaca-compute") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const tickerParam = normTicker(url.searchParams.get("ticker"));
        if (!tickerParam) {
          return sendJSON({ ok: false, error: "missing ticker param" }, 400, corsHeaders(env, req));
        }

        const existingData = await kvGetJSON(KV, `timed:latest:${tickerParam}`);
        const result = await computeServerSideScores(tickerParam, d1GetCandles, env, existingData);

        if (!result) {
          return sendJSON(
            { ok: false, error: "insufficient_candle_data", ticker: tickerParam, hint: "Run alpaca-backfill first" },
            200, corsHeaders(env, req),
          );
        }

        // Save to KV
        await kvPutJSON(KV, `timed:latest:${tickerParam}`, result);

        return sendJSON(
          {
            ok: true,
            ticker: tickerParam,
            htf_score: result.htf_score,
            ltf_score: result.ltf_score,
            state: result.state,
            price: result.price,
            data_source: result.data_source,
            flags: result.flags,
            td_sequential: result.td_sequential || null,
          },
          200, corsHeaders(env, req),
        );
      }

      // GET /timed/admin/alpaca-status?key=...
      if (routeKey === "GET /timed/admin/alpaca-status") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const allTickers = Object.keys(SECTOR_MAP);
        const tfs = ["M", "W", "D", "240", "60", "30", "10", "3"];
        const coverage = {};
        let totalCandles = 0;

        // Sample a few tickers for coverage stats
        const sampleTickers = allTickers.slice(0, 10);
        for (const t of sampleTickers) {
          coverage[t] = {};
          for (const tf of tfs) {
            try {
              const res = await d1GetCandles(env, t, tf, 5);
              const count = res?.candles?.length || 0;
              coverage[t][tf] = count;
              totalCandles += count;
            } catch { coverage[t][tf] = 0; }
          }
        }

        // Count alpaca-sourced tickers in KV
        let alpacaSourced = 0;
        let tvSourced = 0;
        for (const t of allTickers.slice(0, 50)) {
          const data = await kvGetJSON(KV, `timed:latest:${t}`);
          if (data?.data_source === "alpaca") alpacaSourced++;
          else if (data?.script_version && data.script_version.startsWith("score_engine")) tvSourced++;
        }

        return sendJSON(
          {
            ok: true,
            alpaca_configured: !!(env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY),
            alpaca_enabled: env.ALPACA_ENABLED === "true",
            total_tickers: allTickers.length,
            sample_coverage: coverage,
            sample_total_candles: totalCandles,
            kv_data_sources: { alpaca: alpacaSourced, tradingview: tvSourced, sampled: 50 },
          },
          200, corsHeaders(env, req),
        );
      }

      // ═══════════════════════════════════════════════════════════════════════════
      // POST /timed/admin/candle-replay
      // Pure candle-based replay: generates scoring snapshots from Alpaca historical
      // candle data (no trail/webhook dependency). Pre-loads candles into memory,
      // then slides through 5-min intervals computing scores + running trade sim.
      //
      // Params:
      //   date=YYYY-MM-DD       (required) trading day to replay
      //   tickerOffset=0        batch start index into SECTOR_MAP
      //   tickerBatch=15        tickers per invocation
      //   intervalMinutes=5     interval between scoring snapshots
      //   cleanSlate=1          purge all trades first (only on first batch of first day)
      // ═══════════════════════════════════════════════════════════════════════════
      if (routeKey === "POST /timed/admin/candle-replay") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));

        const dateParam = url.searchParams.get("date");
        if (!dateParam || !/^\d{4}-\d{2}-\d{2}$/.test(dateParam)) {
          return sendJSON({ ok: false, error: "date param required (YYYY-MM-DD)" }, 400, corsHeaders(env, req));
        }

        const tickerOffset = Math.max(0, Number(url.searchParams.get("tickerOffset")) || 0);
        const tickerBatch = Math.max(1, Math.min(30, Number(url.searchParams.get("tickerBatch")) || 15));
        const intervalMinutes = Math.max(1, Math.min(30, Number(url.searchParams.get("intervalMinutes")) || 5));
        const cleanSlate = url.searchParams.get("cleanSlate") === "1";
        const trailOnly = url.searchParams.get("trailOnly") === "1";

        const allTickers = Object.keys(SECTOR_MAP);
        const batchTickers = allTickers.slice(tickerOffset, tickerOffset + tickerBatch);
        const hasMore = tickerOffset + tickerBatch < allTickers.length;

        if (batchTickers.length === 0) {
          return sendJSON({ ok: true, processed: 0, hasMore: false, message: "no_tickers_in_batch" }, 200, corsHeaders(env, req));
        }

        // Market hours: 9:30 AM to 4:00 PM ET
        const marketOpenMs = nyWallTimeToUtcMs(dateParam, 9, 30, 0);
        const marketCloseMs = nyWallTimeToUtcMs(dateParam, 16, 0, 0);
        if (!marketOpenMs || !marketCloseMs) {
          return sendJSON({ ok: false, error: "failed_to_compute_market_hours" }, 500, corsHeaders(env, req));
        }

        const intervalMs = intervalMinutes * 60 * 1000;
        const intervals = [];
        for (let ts = marketOpenMs; ts <= marketCloseMs; ts += intervalMs) {
          intervals.push(ts);
        }

        // Clean slate: purge ALL trades on first batch of a day
        if (cleanSlate && tickerOffset === 0) {
          await kvPutJSON(KV, "timed:trades:all", []);
          await kvPutJSON(KV, "timed:portfolio:v1", null);
          await kvPutJSON(KV, "timed:activity:feed", null);
        }

        // Pre-load all candles for batch tickers (all 7 TFs) in parallel
        const REPLAY_TFS = ["W", "D", "240", "60", "30", "10", "3"];
        const candleCache = {}; // { TICKER: { TF: [candles sorted asc by ts] } }

        await Promise.all(
          batchTickers.map(async (ticker) => {
            candleCache[ticker] = {};
            await Promise.all(
              REPLAY_TFS.map(async (tf) => {
                try {
                  const res = await d1GetCandles(env, ticker, tf, 1500);
                  candleCache[ticker][tf] = (res?.ok && Array.isArray(res.candles)) ? res.candles : [];
                } catch {
                  candleCache[ticker][tf] = [];
                }
              })
            );
          })
        );

        // Load existing trades for trade simulation
        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        const replayCtx = { allTrades };

        // State map: track evolving ticker state across intervals
        const stateMap = {};
        for (const ticker of batchTickers) {
          stateMap[ticker] = (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
        }

        let processed = 0;
        let tradesCreated = 0;
        let scored = 0;
        let skipped = 0;
        const errors = [];
        const timeline = [];
        const stageCounts = {}; // Track stage distribution

        for (const intervalTs of intervals) {
          for (const ticker of batchTickers) {
            try {
              // Slice candles to only include bars at or before this interval
              const bundles = {};
              let hasData = false;
              for (const tf of REPLAY_TFS) {
                const allCandles = candleCache[ticker][tf] || [];
                const sliced = allCandles.filter(c => c.ts <= intervalTs);
                if (sliced.length >= 50) {
                  const bundle = computeTfBundle(sliced);
                  if (bundle) {
                    bundles[tf] = bundle;
                    hasData = true;
                  }
                }
              }

              if (!hasData) { skipped++; continue; }

              const bundleMap = {
                W: bundles.W || null,
                D: bundles.D || null,
                "240": bundles["240"] || null,
                "60": bundles["60"] || null,
                "30": bundles["30"] || null,
                "10": bundles["10"] || null,
                "3": bundles["3"] || null,
              };

              const existing = stateMap[ticker] || {};
              const result = assembleTickerData(ticker, bundleMap, existing);
              if (!result) { skipped++; continue; }

              // Enrich with timestamp and derived fields
              result.ts = intervalTs;
              result.ingest_ts = intervalTs;
              result.data_source = "candle_replay";
              result.data_source_ts = intervalTs;

              // Compute RR, rank, move status
              if (result.rr == null || !Number.isFinite(Number(result.rr))) {
                result.rr = computeRR(result);
                if (result.rr != null && Number(result.rr) > 25) result.rr = 25;
              }
              if (result.score == null && result.rank == null) {
                result.score = computeRank(result);
              }
              if (result.rr_warning == null && Number.isFinite(result.rr)) {
                result.rr_warning = computeRRWarning(result.rr);
              }
              result.move_status = computeMoveStatus(result);
              if (result.flags) {
                result.flags.move_invalidated = result.move_status?.status === "INVALIDATED";
                result.flags.move_completed = result.move_status?.status === "COMPLETED";
              }

              // Carry forward entry state from previous interval
              if (existing?.entry_ts != null && result.entry_ts == null) result.entry_ts = existing.entry_ts;
              if (existing?.entry_price != null && result.entry_price == null) result.entry_price = existing.entry_price;
              if (existing?.kanban_cycle_enter_now_ts != null) result.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
              if (existing?.kanban_cycle_trigger_ts != null) result.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
              if (existing?.kanban_cycle_side != null) result.kanban_cycle_side = existing.kanban_cycle_side;

              // Synthesize trigger_ts for candle-based replay (MUST happen BEFORE classifyKanbanStage):
              // When state transitions to an aligned/actionable state, mark as fresh trigger.
              // Carry forward trigger_ts from previous interval if state hasn't changed.
              const prevState = existing?.state;
              const curState = result.state;
              const isActionable = curState && (
                curState.includes("BULL_BULL") || curState.includes("BEAR_BEAR") ||
                curState.includes("PULLBACK")
              );
              if (isActionable && curState !== prevState) {
                result.trigger_ts = intervalTs;
              } else if (existing?.trigger_ts) {
                result.trigger_ts = existing.trigger_ts;
              }

              // Classify kanban stage
              const openTrade = replayCtx.allTrades.find(
                t => String(t?.ticker || "").toUpperCase() === ticker && isOpenTradeStatus(t?.status)
              ) || null;
              const prevStage = existing?.kanban_stage;
              const stage = classifyKanbanStage(result, openTrade, intervalTs);
              let finalStage = stage;

              // Enter gate: set cycle tracking
              if (finalStage === "enter_now" || finalStage === "enter") {
                result.kanban_cycle_enter_now_ts = intervalTs;
                result.kanban_cycle_trigger_ts = Number.isFinite(Number(result?.trigger_ts)) ? result.trigger_ts : intervalTs;
                result.kanban_cycle_side = sideFromStateOrScores(result);
              } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
                result.kanban_cycle_enter_now_ts = existing?.kanban_cycle_enter_now_ts ?? null;
                result.kanban_cycle_trigger_ts = existing?.kanban_cycle_trigger_ts ?? null;
                result.kanban_cycle_side = existing?.kanban_cycle_side ?? null;
              } else {
                result.kanban_cycle_enter_now_ts = null;
                result.kanban_cycle_trigger_ts = null;
                result.kanban_cycle_side = null;
              }

              // Track entry price on stage transitions
              if ((finalStage === "enter_now" || finalStage === "enter") && prevStage !== "enter_now" && prevStage !== "enter") {
                const price = Number(result?.price);
                if (Number.isFinite(price) && price > 0) {
                  result.entry_price = price;
                  result.entry_ts = intervalTs;
                }
              }
              if (finalStage && existing?.entry_price) {
                result.entry_price = existing.entry_price;
                result.entry_ts = existing.entry_ts;
              }

              // Set stage transitions
              if (prevStage && finalStage && String(prevStage) !== String(finalStage)) {
                result.prev_kanban_stage = String(prevStage);
                result.prev_kanban_stage_ts = intervalTs;
              }

              result.kanban_stage = finalStage;
              result.kanban_meta = deriveKanbanMeta(result, finalStage);

              // Track stage distribution
              stageCounts[finalStage || "null"] = (stageCounts[finalStage || "null"] || 0) + 1;

              // Write trail point to D1 for historical backfill (always, regardless of trailOnly)
              try {
                await d1InsertTrailPoint(env, ticker, result);
              } catch (e) { /* non-critical */ }

              if (!trailOnly) {
                // Run trade simulation (with Discord disabled and no D1 writes)
                const replayEnv = { ...env, DISCORD_ENABLE: "false", DISCORD_WEBHOOK_URL: null };
                const countBefore = replayCtx.allTrades.filter(x => String(x?.ticker).toUpperCase() === ticker).length;
                await processTradeSimulation(KV, ticker, result, existing, replayEnv, {
                  forceUseIngestTs: true,
                  replayBatchContext: replayCtx,
                  asOfTs: intervalTs,
                });
                const countAfter = replayCtx.allTrades.filter(x => String(x?.ticker).toUpperCase() === ticker).length;
                if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
              }

              stateMap[ticker] = result;
              scored++;
              processed++;
            } catch (e) {
              errors.push({ ticker, ts: intervalTs, error: String(e?.message || e) });
            }
          }
        }

        // Write final state for each ticker to KV (skip when trailOnly to preserve current state)
        if (!trailOnly) {
          for (const ticker of batchTickers) {
            if (stateMap[ticker] && Object.keys(stateMap[ticker]).length > 0) {
              try {
                await kvPutJSON(KV, `timed:latest:${ticker}`, stateMap[ticker]);
              } catch { /* non-critical */ }
            }
          }

          // Persist trades
          try {
            await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
          } catch (e) {
            errors.push({ ticker: "TRADES_SAVE", error: String(e?.message || e) });
          }
        }

        return sendJSON({
          ok: true,
          date: dateParam,
          tickerOffset,
          tickerBatch,
          tickersProcessed: batchTickers.length,
          intervals: intervals.length,
          intervalMinutes,
          scored,
          skipped,
          tradesCreated,
          totalTrades: replayCtx.allTrades.length,
          hasMore,
          nextTickerOffset: hasMore ? tickerOffset + tickerBatch : null,
          errorsCount: errors.length,
          errors: errors.slice(0, 10),
          stageCounts,
        }, 200, corsHeaders(env, req));
      }

      // POST /timed/admin/run-lifecycle?key=...
      // Manually trigger data lifecycle: aggregate timed_trail → trail_5m_facts, purge old data.
      if (routeKey === "POST /timed/admin/run-lifecycle") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          // Optional: ?cutoff_hours=N to override the 48h window (e.g., cutoff_hours=0 forces all)
          const cutoffHoursRaw = url.searchParams.get("cutoff_hours");
          const opts = {};
          if (cutoffHoursRaw != null && cutoffHoursRaw !== "") {
            const h = Number(cutoffHoursRaw);
            if (Number.isFinite(h) && h >= 0) {
              opts.cutoffMs = Date.now() - h * 60 * 60 * 1000;
            }
          }
          await runDataLifecycle(env, opts);
          return sendJSON({ ok: true, message: "data_lifecycle_complete" }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // MODEL ENDPOINTS (Phase 2 — Self-Learning Model)
      // ═══════════════════════════════════════════════════════════════════════

      // POST /timed/admin/model-retro?key=...
      // Manually trigger the weekly retrospective.
      if (routeKey === "POST /timed/admin/model-retro") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const result = await runWeeklyRetrospective(DB);
          return sendJSON({ ok: true, ...result }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/model-approve?key=...&change_id=...&action=approve|reject
      // Approve or reject a model_changelog proposal. Approved changes are applied.
      if (routeKey === "POST /timed/admin/model-approve") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));

          const changeId = url.searchParams.get("change_id");
          const action = url.searchParams.get("action") || "approve"; // approve | reject

          if (!changeId) return sendJSON({ ok: false, error: "change_id required" }, 400, corsHeaders(env, req));
          if (!["approve", "reject"].includes(action)) return sendJSON({ ok: false, error: "action must be approve or reject" }, 400, corsHeaders(env, req));

          const now = Date.now();
          const { results: rows } = await DB.prepare(
            `SELECT * FROM model_changelog WHERE change_id = ? AND status = 'proposed'`
          ).bind(changeId).all();

          if (!rows || rows.length === 0) {
            return sendJSON({ ok: false, error: "proposal not found or already processed" }, 404, corsHeaders(env, req));
          }

          const change = rows[0];

          if (action === "reject") {
            await DB.prepare(
              `UPDATE model_changelog SET status = 'rejected', approved_at = ?, approved_by = 'human' WHERE change_id = ?`
            ).bind(now, changeId).run();
            return sendJSON({ ok: true, action: "rejected", change_id: changeId }, 200, corsHeaders(env, req));
          }

          // Apply the approved change
          if (change.change_type === "degrade_pattern" && change.pattern_id) {
            await DB.prepare(
              `UPDATE pattern_library SET status = 'degraded', last_updated = ? WHERE pattern_id = ?`
            ).bind(now, change.pattern_id).run();
          } else if (change.change_type === "promote_pattern" && change.pattern_id) {
            await DB.prepare(
              `UPDATE pattern_library SET status = 'active', last_updated = ? WHERE pattern_id = ?`
            ).bind(now, change.pattern_id).run();
          } else if (change.change_type === "retire_pattern" && change.pattern_id) {
            await DB.prepare(
              `UPDATE pattern_library SET status = 'retired', last_updated = ? WHERE pattern_id = ?`
            ).bind(now, change.pattern_id).run();
          }
          // add_pattern and other types would require additional data — handled by seed script

          await DB.prepare(
            `UPDATE model_changelog SET status = 'approved', approved_at = ?, approved_by = 'human' WHERE change_id = ?`
          ).bind(now, changeId).run();

          return sendJSON({ ok: true, action: "approved", change_id: changeId, change_type: change.change_type, pattern_id: change.pattern_id }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/model-resolve?key=...
      // Resolve expired predictions against actual price data.
      if (routeKey === "POST /timed/admin/model-resolve") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const result = await resolveExpiredPredictions(DB, Date.now());
          return sendJSON({ ok: true, ...result }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/health
      // Model health summary: prediction counts, hit rates, pattern status.
      if (routeKey === "GET /timed/model/health") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const health = await getModelHealth(DB);
          return sendJSON({ ok: true, ...health }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/predictions?ticker=XYZ&resolved=0&limit=50
      // Query model predictions.
      if (routeKey === "GET /timed/model/predictions") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const ticker = url.searchParams.get("ticker");
          const resolved = url.searchParams.get("resolved");
          const limit = Math.min(Number(url.searchParams.get("limit")) || 50, 200);

          let sql = "SELECT * FROM model_predictions WHERE 1=1";
          const binds = [];
          if (ticker) { sql += " AND ticker = ?"; binds.push(normTicker(ticker)); }
          if (resolved != null) { sql += " AND resolved = ?"; binds.push(Number(resolved)); }
          sql += " ORDER BY ts DESC LIMIT ?";
          binds.push(limit);

          const stmt = DB.prepare(sql);
          const { results } = await (binds.length ? stmt.bind(...binds) : stmt).all();
          return sendJSON({ ok: true, predictions: results || [] }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/signals?level=ticker|sector|market
      // Multi-level predictions: ticker, sector, and market regime signals.
      if (routeKey === "GET /timed/model/signals") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const level = url.searchParams.get("level"); // ticker, sector, market, or null (all)
          const predictions = await computeMultiLevelPredictions(DB, SECTOR_MAP);

          if (level === "ticker") return sendJSON({ ok: true, ticker: predictions.ticker }, 200, corsHeaders(env, req));
          if (level === "sector") return sendJSON({ ok: true, sector: predictions.sector }, 200, corsHeaders(env, req));
          if (level === "market") return sendJSON({ ok: true, market: predictions.market }, 200, corsHeaders(env, req));
          return sendJSON({ ok: true, ...predictions }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/changelog?status=proposed&limit=50
      // View model change proposals and history.
      if (routeKey === "GET /timed/model/changelog") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const status = url.searchParams.get("status"); // proposed, approved, rejected, auto_applied
          const limit = Math.min(Number(url.searchParams.get("limit")) || 50, 200);

          let sql = "SELECT * FROM model_changelog";
          const binds = [];
          if (status) { sql += " WHERE status = ?"; binds.push(status); }
          sql += " ORDER BY proposed_at DESC LIMIT ?";
          binds.push(limit);

          const stmt = DB.prepare(sql);
          const { results } = await (binds.length ? stmt.bind(...binds) : stmt).all();
          return sendJSON({ ok: true, changes: results || [] }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/patterns?status=active
      // Query the pattern library.
      if (routeKey === "GET /timed/model/patterns") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const status = url.searchParams.get("status") || "active";

          const { results } = await DB.prepare(
            `SELECT * FROM pattern_library WHERE status = ? ORDER BY expected_value DESC`
          ).bind(status).all();
          return sendJSON({ ok: true, patterns: results || [] }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/trades?version=2.1.0 (Get all trades, optional version filter)
      if (routeKey === "GET /timed/trades") {
        // Rate limiting - increased limits for UI polling (100 requests per minute)
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/trades",
          100, // 100 requests
          60, // per minute (instead of per hour)
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 60 },
            429,
            corsHeaders(env, req),
          );
        }
        const versionFilter = url.searchParams.get("version");
        const source = url.searchParams.get("source");
        const useD1 = source !== "kv" && env?.DB; // Default to D1; ?source=kv to force KV

        // Read from D1: positions (?source=positions) or trades+events (?source=d1 or default)
        let d1Trades = null;
        if (useD1) {
          if (source === "positions") {
            d1Trades = await d1GetAllPositionsAsTrades(env);
          } else {
            d1Trades = await d1GetAllTradesWithEvents(env);
          }
        }
        if (d1Trades) {
          let filtered = d1Trades;
          if (versionFilter && versionFilter !== "all") {
            filtered = d1Trades.filter(
              (t) => (t.scriptVersion || t.script_version || "unknown") === versionFilter,
            );
          }
          const versions = [
            ...new Set(d1Trades.map((t) => t.scriptVersion || t.script_version || "unknown")),
          ].sort().reverse();
          return sendJSON(
            {
              ok: true,
              count: filtered.length,
              totalCount: d1Trades.length,
              version: versionFilter || "all",
              versions,
              trades: filtered,
              source: source || "d1",
            },
            200,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        let allTrades = (await kvGetJSON(KV, tradesKey)) || [];

        // Correct any trades with incorrect WIN/LOSS status based on P&L
        let corrected = false;
        for (let i = 0; i < allTrades.length; i++) {
          const trade = allTrades[i];
          if (
            (trade.status === "WIN" || trade.status === "LOSS") &&
            trade.pnl !== undefined &&
            trade.pnl !== null
          ) {
            // Check if status matches P&L
            if (trade.status === "WIN" && trade.pnl < 0) {
              console.log(
                `[TRADE CORRECTION] Correcting ${trade.ticker} ${
                  trade.direction
                }: WIN with negative P&L (${trade.pnl.toFixed(2)}) -> LOSS`,
              );
              allTrades[i] = { ...trade, status: "LOSS" };
              corrected = true;
            } else if (trade.status === "LOSS" && trade.pnl > 0) {
              console.log(
                `[TRADE CORRECTION] Correcting ${trade.ticker} ${
                  trade.direction
                }: LOSS with positive P&L (${trade.pnl.toFixed(2)}) -> WIN`,
              );
              allTrades[i] = { ...trade, status: "WIN" };
              corrected = true;
            }
          }
        }

        // Save corrected trades back to KV if any corrections were made
        if (corrected) {
          await kvPutJSON(KV, tradesKey, allTrades);
          console.log(
            `[TRADE CORRECTION] Saved ${allTrades.length} trades with corrections`,
          );
        }

        // Dedupe by (ticker, direction, entry_ts) — replay can create duplicates
        const entryTsForTrade = (t) => {
          const et = Number(t?.entry_ts ?? t?.entryTs);
          if (Number.isFinite(et)) return et;
          const iso = t?.entryTime;
          if (iso) return isoToMs(iso) || null;
          const hist = Array.isArray(t?.history) ? t.history : [];
          const ent = hist.find((e) => String(e?.type || "").toUpperCase() === "ENTRY");
          return ent ? isoToMs(ent.timestamp ?? ent.ts) || null : null;
        };
        const seen = new Set();
        const deduped = [];
        for (const t of allTrades) {
          const ticker = String(t?.ticker || "").toUpperCase();
          const dir = String(t?.direction || "").toUpperCase();
          const et = entryTsForTrade(t);
          const key = `${ticker}:${dir}:${et != null ? et : t?.id || ""}`;
          if (seen.has(key)) continue;
          seen.add(key);
          deduped.push(t);
        }
        if (deduped.length < allTrades.length) {
          await kvPutJSON(KV, tradesKey, deduped);
          allTrades = deduped;
        }

        let filteredTrades = allTrades;
        if (versionFilter && versionFilter !== "all") {
          filteredTrades = allTrades.filter(
            (t) => (t.scriptVersion || "unknown") === versionFilter,
          );
        }

        // Get unique versions for reference
        const versions = [
          ...new Set(allTrades.map((t) => t.scriptVersion || "unknown")),
        ]
          .sort()
          .reverse();

        return sendJSON(
          {
            ok: true,
            count: filteredTrades.length,
            totalCount: allTrades.length,
            version: versionFilter || "all",
            versions: versions,
            trades: filteredTrades,
            corrected: corrected, // Indicate if corrections were made
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/portfolio (paper portfolio + executions, derived from D1 positions)
      // D1 is the SINGLE SOURCE OF TRUTH for positions
      if (routeKey === "GET /timed/portfolio") {
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/portfolio",
          2000,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        // ═══════════════════════════════════════════════════════════════════════
        // D1 SINGLE SOURCE OF TRUTH: Get positions and executions from D1
        // ═══════════════════════════════════════════════════════════════════════
        const startCash = PORTFOLIO_START_CASH;
        let useD1 = !!env?.DB;
        let d1Positions = [];
        let d1Actions = [];
        
        if (useD1) {
          try {
            // Get all positions (open and closed)
            const posRes = await env.DB.prepare(`
              SELECT position_id, ticker, direction, status, total_qty, cost_basis, 
                     created_at, updated_at, closed_at, script_version
              FROM positions 
              ORDER BY created_at DESC
            `).all();
            d1Positions = posRes?.results || [];
            
            // Get all execution actions
            const actRes = await env.DB.prepare(`
              SELECT action_id, position_id, ts, action_type, qty, price, value, pnl_realized, reason
              FROM execution_actions
              ORDER BY ts ASC
            `).all();
            d1Actions = actRes?.results || [];
          } catch (err) {
            console.warn("[PORTFOLIO] D1 query failed, falling back to KV:", err);
            useD1 = false;
          }
        }

        // Fallback to KV trades if D1 not available
        const tradesKey = "timed:trades:all";
        const trades = useD1 ? [] : ((await kvGetJSON(KV, tradesKey)) || []);

        const tpTargetPrice = (src) => {
          const directTarget = Number(src?.tp_target_price ?? src?.tp_target);
          if (Number.isFinite(directTarget) && directTarget > 0)
            return directTarget;
          const tp = Number(src?.tp);
          if (Number.isFinite(tp) && tp > 0) return tp;
          return null;
        };

        const toMs = (tsLike) => {
          const n =
            typeof tsLike === "string" ? isoToMs(tsLike) : Number(tsLike);
          if (!Number.isFinite(n) || n <= 0) return null;
          return n < 1e12 ? n * 1000 : n;
        };
        const dayKey = (ms) => {
          try {
            const d = new Date(ms);
            const y = d.getUTCFullYear();
            const m = String(d.getUTCMonth() + 1).padStart(2, "0");
            const da = String(d.getUTCDate()).padStart(2, "0");
            return `${y}-${m}-${da}`;
          } catch {
            return "unknown";
          }
        };

        const events = [];
        
        // ═══════════════════════════════════════════════════════════════════════
        // D1 SOURCE: Build events from D1 execution_actions
        // ═══════════════════════════════════════════════════════════════════════
        if (useD1 && d1Actions.length > 0) {
          // Build position lookup for direction
          const posById = new Map();
          for (const p of d1Positions) {
            posById.set(p.position_id, p);
          }
          
          for (const a of d1Actions) {
            const pos = posById.get(a.position_id);
            const ticker = pos?.ticker || "UNKNOWN";
            const dir = pos?.direction || "LONG";
            const ts = Number(a.ts);
            if (!Number.isFinite(ts) || ts <= 0) continue;
            
            const type = String(a.action_type || "").toUpperCase();
            if (!type) continue;
            
            events.push({
              ts,
              day: dayKey(ts),
              ticker,
              direction: dir,
              type,
              price: Number(a.price) || null,
              shares: Number(a.qty) || null,
              value: Number(a.value) || null,
              reason: a.reason || null,
              notional: Number(a.value) || null,
              trade_id: a.position_id,
              pnl_realized: Number(a.pnl_realized) || 0,
            });
          }
        }

        // ═══════════════════════════════════════════════════════════════════════
        // KV FALLBACK: Build events from KV trades (legacy)
        // ═══════════════════════════════════════════════════════════════════════
        for (const tr of trades) {
          const ticker = String(tr?.ticker || "").toUpperCase();
          const dir = String(tr?.direction || "").toUpperCase();
          const notional = Number(tr?.notional);
          const hist = Array.isArray(tr?.history) ? tr.history : [];
          for (const ev of hist) {
            const ts = toMs(ev?.timestamp ?? ev?.ts);
            if (!Number.isFinite(ts) || ts <= 0 || ts < 946684800000) continue; // skip zero or pre-2000 (bogus epoch)
            const type = String(ev?.type || "").toUpperCase();
            if (!type) continue;
            const price = Number(ev?.price);
            const shares = Number(ev?.shares);
            const value = Number.isFinite(Number(ev?.value))
              ? Number(ev.value)
              : Number.isFinite(price) && Number.isFinite(shares)
                ? price * shares
                : null;
            events.push({
              ts,
              day: dayKey(ts),
              ticker,
              direction: dir,
              type,
              price: Number.isFinite(price) ? price : null,
              shares: Number.isFinite(shares) ? shares : null,
              value: Number.isFinite(value) ? value : null,
              reason: ev?.reason != null ? String(ev.reason) : null,
              notional: Number.isFinite(notional) ? notional : null,
              trade_id: tr?.id || null,
            });
          }
        }

        // Dedupe events (same ticker+direction+type+ts) — prevents duplicate tape entries
        const eventKey = (e) => `${e.ticker}:${e.direction}:${e.type}:${e.ts}`;
        const seenEvents = new Set();
        const dedupedEvents = [];
        for (const e of events) {
          const k = eventKey(e);
          if (seenEvents.has(k)) continue;
          seenEvents.add(k);
          dedupedEvents.push(e);
        }
        events.length = 0;
        events.push(...dedupedEvents);

        events.sort((a, b) => a.ts - b.ts);

        // Best-effort latest snapshots for tickers referenced by the portfolio/tape.
        const latestByTicker = {};
        try {
          const tickSet = new Set();
          for (const e of events)
            if (e?.ticker) tickSet.add(String(e.ticker).toUpperCase());
          for (const tr of trades)
            if (tr?.ticker) tickSet.add(String(tr.ticker).toUpperCase());
          const tickers = Array.from(tickSet).filter(Boolean).slice(0, 500);

          // Prefer D1 for reads (batch query), fallback to KV.
          if (env?.DB && tickers.length > 0) {
            await d1EnsureLatestSchema(env);
            const placeholders = tickers.map((_, i) => `?${i + 1}`).join(", ");
            const rows = await env.DB.prepare(
              `SELECT ticker, payload_json FROM ticker_latest WHERE ticker IN (${placeholders})`,
            )
              .bind(...tickers)
              .all();
            for (const r of rows?.results || []) {
              const sym = String(r?.ticker || "").toUpperCase();
              if (!sym) continue;
              const raw = r?.payload_json;
              if (!raw) continue;
              try {
                latestByTicker[sym] = JSON.parse(String(raw));
              } catch {
                // ignore
              }
            }
          }

          // Backfill from KV when D1 misses.
          const missing = tickers.filter((t) => !latestByTicker[t]);
          if (missing.length > 0) {
            for (const t of missing) {
              const v = await kvGetJSON(KV, `timed:latest:${t}`);
              if (v && typeof v === "object") {
                latestByTicker[t] = v;
                try {
                  ctx.waitUntil(d1UpsertTickerLatest(env, t, v));
                  ctx.waitUntil(d1UpsertTickerIndex(env, t, v?.ts));
                } catch {
                  // ignore
                }
              }
            }
          }
        } catch (e) {
          console.warn(
            `[PORTFOLIO] latest snapshot join failed:`,
            String(e?.message || e),
          );
        }

        // Replay portfolio from executions (simple cash + positions model)
        let cash = startCash;
        const positions = {}; // ticker -> {direction, shares, avgEntry, cost}

        const ensurePos = (tkr, dir) => {
          if (!positions[tkr])
            positions[tkr] = {
              ticker: tkr,
              direction: dir,
              shares: 0,
              avgEntry: null,
              cost: 0,
            };
          return positions[tkr];
        };

        for (const e of events) {
          if (!e.ticker || !e.type) continue;
          const tkr = e.ticker;
          const dir = e.direction || null;
          const shares = Number(e.shares);
          const value = Number(e.value);
          if (!Number.isFinite(shares) || shares <= 0) continue;
          if (!Number.isFinite(value) || value <= 0) continue;

          if (e.type === "ENTRY") {
            cash -= value;
            const p = ensurePos(tkr, dir);
            // simple avg entry calc
            const newShares = p.shares + shares;
            const entryPx = Number(e.price);
            const newCost = p.cost + value;
            p.shares = newShares;
            p.cost = newCost;
            p.avgEntry =
              Number.isFinite(entryPx) && newShares > 0
                ? newCost / newShares
                : p.avgEntry;
            p.direction = dir || p.direction;
          } else if (e.type === "TRIM" || e.type === "EXIT") {
            cash += value;
            const p = ensurePos(tkr, dir);
            p.shares = Math.max(0, p.shares - shares);
            if (p.shares <= 1e-9) {
              delete positions[tkr];
            }
          }
        }

        // Mark-to-market open positions using last known price (best-effort)
        let positionsValue = 0;
        const openPositions = [];
        
        // ═══════════════════════════════════════════════════════════════════════
        // D1 SOURCE: Build open positions from D1 positions table
        // ═══════════════════════════════════════════════════════════════════════
        if (useD1 && d1Positions.length > 0) {
          for (const p of d1Positions) {
            if (p.status !== "OPEN") continue;
            const tkr = String(p.ticker || "").toUpperCase();
            const latest = latestByTicker[tkr];
            const shares = Number(p.total_qty) || 0;
            const costBasis = Number(p.cost_basis) || 0;
            const avgEntry = shares > 0 ? costBasis / shares : null;
            const px = Number(
              latest?.price ??
                latest?.last ??
                latest?.close
            );
            const val = Number.isFinite(px) && shares > 0 ? px * shares : null;
            if (Number.isFinite(val)) positionsValue += val;
            
            // Calculate realized P&L from actions
            const posActions = d1Actions.filter(a => a.position_id === p.position_id);
            const realizedPnl = posActions.reduce((sum, a) => sum + (Number(a.pnl_realized) || 0), 0);
            
            openPositions.push({
              ticker: tkr,
              direction: p.direction,
              shares,
              avgEntry,
              mark: Number.isFinite(px) ? px : null,
              value: Number.isFinite(val) ? val : null,
              phase_pct: latest?.phase_pct != null ? Number(latest.phase_pct) : null,
              completion: latest?.completion != null ? Number(latest.completion) : null,
              tp: tpTargetPrice(latest),
              kanban_stage: latest?.kanban_stage || null,
              position_id: p.position_id,
              entry_ts: p.created_at,
              realized_pnl: realizedPnl,
              source: "d1",
            });
          }
        } else {
          // KV FALLBACK: Build from replayed positions
          for (const [tkr, p] of Object.entries(positions)) {
            const trade = trades.find(
              (x) =>
                String(x?.ticker || "").toUpperCase() === tkr &&
                isOpenTradeStatus(x?.status),
            );
            const latest = latestByTicker[String(tkr).toUpperCase()];
            const px = Number(
              latest?.price ??
                latest?.last ??
                latest?.close ??
                trade?.currentPrice ??
                trade?.price,
            );
            const val = Number.isFinite(px) ? px * Number(p.shares) : null;
            if (Number.isFinite(val)) positionsValue += val;
            openPositions.push({
              ticker: tkr,
              direction: p.direction,
              shares: p.shares,
              avgEntry: p.avgEntry,
              mark: Number.isFinite(px) ? px : null,
              value: Number.isFinite(val) ? val : null,
              phase_pct: latest?.phase_pct != null ? Number(latest.phase_pct) : null,
              completion: latest?.completion != null ? Number(latest.completion) : null,
              tp: tpTargetPrice(latest),
              source: "kv",
            });
          }
        }

        const equity = cash + positionsValue;

        // Group executions by day and ticker
        const byDay = {};
        const byTicker = {};
        for (const e of events) {
          if (!byDay[e.day]) byDay[e.day] = [];
          byDay[e.day].push(e);
          if (!byTicker[e.ticker]) byTicker[e.ticker] = [];
          byTicker[e.ticker].push(e);
        }

        // Proof snapshot (server-side join): per-day rows with trade details.
        const proofByDay = {};
        try {
          const entryByTradeId = new Map(); // trade_id -> { entryPrice, entryShares, entryTs, direction }
          for (const e of events) {
            if (
              e?.type === "ENTRY" &&
              e?.trade_id &&
              Number.isFinite(Number(e?.price))
            ) {
              entryByTradeId.set(String(e.trade_id), {
                entryPrice: Number(e.price),
                entryShares: Number.isFinite(Number(e?.shares))
                  ? Number(e.shares)
                  : null,
                entryTs: Number.isFinite(Number(e?.ts)) ? Number(e.ts) : null,
                direction: e?.direction || null,
              });
            }
          }

          // Index open positions for remaining qty and avgEntry/mark.
          const posByTickerDir = new Map(); // `${tkr}:${dir}` -> pos
          for (const p of openPositions) {
            const key = `${String(p.ticker).toUpperCase()}:${String(p.direction || "").toUpperCase()}`;
            posByTickerDir.set(key, p);
          }

          const getPos = (tkr, dir) => {
            const key = `${String(tkr).toUpperCase()}:${String(dir || "").toUpperCase()}`;
            return posByTickerDir.get(key) || null;
          };

          for (const [day, dayEvents] of Object.entries(byDay)) {
            const arr = Array.isArray(dayEvents) ? dayEvents : [];
            const tradesById = new Map();
            let entries = 0,
              trims = 0,
              exits = 0;
            let realizedPnl = 0;
            const closedById = new Map(); // trade_id -> pnl

            for (const e of arr) {
              const tradeId = e?.trade_id ? String(e.trade_id) : null;
              const tkr = String(e?.ticker || "").toUpperCase();
              const type = String(e?.type || "").toUpperCase();
              if (type === "ENTRY") entries += 1;
              if (type === "TRIM") trims += 1;
              if (type === "EXIT") exits += 1;

              if (!tradeId || !tkr) continue;
              if (!tradesById.has(tradeId)) {
                const meta = entryByTradeId.get(tradeId) || {};
                const latest = latestByTicker[tkr] || null;
                const pos = getPos(tkr, meta.direction || e?.direction || "");
                const currentPx = Number(
                  pos?.mark ??
                    latest?.price ??
                    latest?.last ??
                    latest?.close ??
                    null,
                );
                const entryPx = Number.isFinite(Number(pos?.avgEntry))
                  ? Number(pos.avgEntry)
                  : Number(meta?.entryPrice);
                tradesById.set(tradeId, {
                  trade_id: tradeId,
                  ticker: tkr,
                  direction:
                    String(
                      meta.direction || e?.direction || "",
                    ).toUpperCase() || null,
                  entry: {
                    ts: meta?.entryTs ?? null,
                    price: Number.isFinite(entryPx) ? entryPx : null,
                    shares: meta?.entryShares ?? null,
                  },
                  current: {
                    price: Number.isFinite(currentPx) ? currentPx : null,
                    phase_pct:
                      latest?.phase_pct != null
                        ? Number(latest.phase_pct)
                        : null,
                    completion:
                      latest?.completion != null
                        ? Number(latest.completion)
                        : null,
                    tp: tpTargetPrice(latest),
                    ts: latest?.ts != null ? toMs(latest.ts) : null,
                  },
                  last_action_type: null,
                  last_action_ts: null,
                  trim_ts: null,
                  exit_ts: null,
                  trim_price: null,
                  exit_price: null,
                  exit_reason: null,
                  remaining_qty:
                    pos?.shares != null ? Number(pos.shares) : null,
                  realized_pnl: 0,
                });
              }

              const t = tradesById.get(tradeId);
              const px = Number(e?.price);
              const sh = Number(e?.shares);
              const eventTs = Number.isFinite(Number(e?.ts)) ? Number(e.ts) : null;
              if (eventTs != null) t.last_action_ts = eventTs;
              t.last_action_type = type || t.last_action_type;
              if (type === "TRIM") {
                if (Number.isFinite(px)) t.trim_price = px;
                if (eventTs != null) t.trim_ts = eventTs;
              }
              if (type === "EXIT") {
                if (Number.isFinite(px)) t.exit_price = px;
                if (eventTs != null) t.exit_ts = eventTs;
                if (e?.reason) t.exit_reason = String(e.reason);
              }

              // realized pnl for trim/exit if entry is known
              const entryPx = Number(t?.entry?.price);
              const dir = String(t?.direction || "").toUpperCase();
              const sign = dir === "SHORT" ? -1 : 1;
              if (
                (type === "TRIM" || type === "EXIT") &&
                Number.isFinite(entryPx) &&
                Number.isFinite(px) &&
                Number.isFinite(sh)
              ) {
                const pnl = (px - entryPx) * sh * sign;
                t.realized_pnl += pnl;
                realizedPnl += pnl;
                if (type === "EXIT") closedById.set(tradeId, pnl);
              }
            }

            let wins = 0,
              losses = 0;
            for (const pnl of closedById.values()) {
              if (!Number.isFinite(pnl) || pnl === 0) continue;
              if (pnl > 0) wins += 1;
              if (pnl < 0) losses += 1;
            }

            proofByDay[day] = {
              day,
              stats: {
                entries,
                trims,
                exits,
                wins,
                losses,
                realizedPnl,
              },
              trades: Array.from(tradesById.values()).sort((a, b) => {
                const tickerA = String(a.ticker || "").toUpperCase();
                const tickerB = String(b.ticker || "").toUpperCase();
                if (tickerA !== tickerB) return tickerA.localeCompare(tickerB);
                const entryA = Number(a.entry?.ts ?? a.entry_ts ?? 0);
                const entryB = Number(b.entry?.ts ?? b.entry_ts ?? 0);
                return entryA - entryB;
              }),
            };
          }
        } catch (e) {
          console.warn(
            `[PORTFOLIO] proof build failed:`,
            String(e?.message || e),
          );
        }

        return sendJSON(
          {
            ok: true,
            portfolio: {
              startCash,
              cash,
              equity,
              positionsValue,
              openPositions,
              updated_at: Date.now(),
            },
            executions: {
              count: events.length,
              byDay,
              byTicker,
            },
            proof: {
              generated_at: Date.now(),
              byDay: proofByDay,
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/trades?key=... (Create or update trade)
      if (routeKey === "POST /timed/trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const { obj: body, err } = await readBodyAsJSON(req);
        if (!body || !body.id) {
          return sendJSON(
            { ok: false, error: "missing trade id" },
            400,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

        // Find existing trade or add new one
        const existingIndex = allTrades.findIndex((t) => t.id === body.id);

        if (existingIndex >= 0) {
          // Update existing trade
          allTrades[existingIndex] = { ...allTrades[existingIndex], ...body };
        } else {
          // Add new trade
          allTrades.push(body);
        }

        // Sort by entry time (newest first)
        allTrades.sort((a, b) => {
          const timeA = new Date(a.entryTime || 0).getTime();
          const timeB = new Date(b.entryTime || 0).getTime();
          return timeB - timeA;
        });

        await kvPutJSON(KV, tradesKey, allTrades);

        return sendJSON(
          {
            ok: true,
            trade: existingIndex >= 0 ? allTrades[existingIndex] : body,
            action: existingIndex >= 0 ? "updated" : "created",
          },
          200,
          corsHeaders(env, req),
        );
      }

      // DELETE /timed/trades/:id?key=... (Delete trade)
      if (routeKey === "DELETE /timed/trades/:id") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const tradeId = url.pathname.split("/timed/trades/")[1];
        if (!tradeId) {
          return sendJSON(
            { ok: false, error: "missing trade id" },
            400,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
        const filteredTrades = allTrades.filter((t) => t.id !== tradeId);

        await kvPutJSON(KV, tradesKey, filteredTrades);

        return sendJSON(
          {
            ok: true,
            deleted: allTrades.length - filteredTrades.length === 1,
            remainingCount: filteredTrades.length,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // OPTIONS /timed/ai/chat (CORS preflight)
      if (routeKey === "OPTIONS /timed/ai/chat") {
        const origin = req?.headers?.get("Origin") || "";
        // Always allow timedtrading.pages.dev origin, otherwise use "*"
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          "Access-Control-Max-Age": "86400",
          Vary: "Origin",
        };
        return new Response(null, {
          status: 204,
          headers: aiChatCorsHeaders,
        });
      }

      // POST /timed/ai/chat (AI Chat Assistant)
      if (routeKey === "POST /timed/ai/chat") {
        // Get CORS headers early - always allow timedtrading.pages.dev for AI chat
        const origin = req?.headers?.get("Origin") || "";
        // Always allow timedtrading.pages.dev origin, otherwise use "*"
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        // Wrap entire handler in try-catch to ensure CORS headers are always returned
        try {
          // Handle JSON parsing errors with CORS headers
          let body;
          try {
            const result = await readBodyAsJSON(req);
            if (result.err) {
              return sendJSON(
                { ok: false, error: "Invalid JSON in request body" },
                400,
                aiChatCorsHeaders,
              );
            }
            body = result.obj;
          } catch (e) {
            return sendJSON(
              { ok: false, error: "Failed to parse request body" },
              400,
              aiChatCorsHeaders,
            );
          }

          if (!body || !body.message) {
            return sendJSON(
              { ok: false, error: "missing message" },
              400,
              aiChatCorsHeaders,
            );
          }

          try {
            const openaiApiKey = env.OPENAI_API_KEY;
            if (!openaiApiKey) {
              return sendJSON(
                {
                  ok: false,
                  error:
                    "AI service not configured. Please set OPENAI_API_KEY secret.",
                },
                503,
                aiChatCorsHeaders,
              );
            }

            // Fetch full ticker data for context
            const tickerSymbols = body.tickerData || [];
            const tickerContext = [];

            // Handle ticker data fetching with error handling
            try {
              const tickerDataPromises = tickerSymbols
                .slice(0, 20)
                .map(async (ticker) => {
                  try {
                    const latestData = await kvGetJSON(
                      KV,
                      `timed:latest:${ticker}`,
                    );
                    if (latestData) {
                      return {
                        ticker: ticker,
                        rank: latestData.rank || 0,
                        rr: latestData.rr || 0,
                        price: latestData.price || 0,
                        state: latestData.state || "",
                        phase_pct: latestData.phase_pct || 0,
                        completion: latestData.completion || 0,
                        flags: latestData.flags || {},
                      };
                    }
                    return null;
                  } catch (err) {
                    console.error(
                      `[AI CHAT] Error fetching ticker ${ticker}:`,
                      err,
                    );
                    return null;
                  }
                });

              const tickerDataResults = await Promise.all(tickerDataPromises);
              tickerDataResults
                .filter(Boolean)
                .forEach((t) => tickerContext.push(t));
            } catch (err) {
              console.error("[AI CHAT] Error fetching ticker data:", err);
              // Continue with empty ticker context - not critical
            }

            // Format activity feed context with safe handling
            const activityContext = [];
            try {
              const rawActivityData = body.activityData || [];
              if (Array.isArray(rawActivityData)) {
                rawActivityData.slice(0, 10).forEach((event) => {
                  try {
                    if (event && typeof event === "object") {
                      const ts = event.ts ? Number(event.ts) : Date.now();
                      const price = Number(event.price) || 0;
                      activityContext.push({
                        ticker: String(event.ticker || "UNKNOWN"),
                        type: String(event.type || "event"),
                        time:
                          ts > 0
                            ? new Date(ts).toLocaleTimeString()
                            : "Unknown time",
                        price: price,
                        rank: Number(event.rank) || 0,
                      });
                    }
                  } catch (e) {
                    console.error(
                      "[AI CHAT] Error formatting activity event:",
                      e,
                    );
                    // Skip this event
                  }
                });
              }
            } catch (err) {
              console.error("[AI CHAT] Error processing activity data:", err);
              // Continue with empty activity context - not critical
            }

            // Build system prompt with context
            const systemPrompt = `You are an expert trading analyst assistant and active monitor for the Timed Trading platform. 
Your role is to continuously observe market conditions, identify opportunities, warn about risks, and help traders make informed decisions.

## YOUR CAPABILITIES
- **Real-time Monitoring**: Continuously observe ticker data, activity feeds, and market conditions
- **Proactive Alerts**: Identify good trades to watch, warnings about risks, trim/exit signals
- **Pattern Recognition**: Learn from trade history and identify profitable patterns
- **Data Analysis**: Analyze ticker data (ranks, RR, phase, completion, states)
- **Signal Interpretation**: Interpret trading signals and setups
- **System Education**: Explain the quadrant-based trading system
- **Risk Management**: Provide risk assessments and actionable insights
- **Research Capabilities**: Answer questions about setups, signals, and market research (note: external research APIs can be added later)

## AVAILABLE DATA
- **${
              tickerContext.length
            } tickers** with real-time data (rank, RR, price, phase, completion, state)
- **${
              activityContext.length
            } recent activity events** (corridor entries, squeeze releases, alignments)

### Sample Ticker Data (Top 10):
${
  tickerContext.length > 0
    ? tickerContext
        .slice(0, 10)
        .map((t) => {
          try {
            const rr = Number(t.rr) || 0;
            const price = Number(t.price) || 0;
            const phasePct = Number(t.phase_pct) || 0;
            const completion = Number(t.completion) || 0;
            return `- **${String(t.ticker || "UNKNOWN")}**: Rank ${
              Number(t.rank) || 0
            }, RR ${rr.toFixed(2)}:1, Price $${price.toFixed(
              2,
            )}, State: ${String(t.state || "UNKNOWN")}, Phase: ${(
              phasePct * 100
            ).toFixed(0)}%, Completion: ${(completion * 100).toFixed(0)}%`;
          } catch (e) {
            console.error("[AI CHAT] Error formatting ticker:", t, e);
            return `- **${String(t.ticker || "UNKNOWN")}**: Data unavailable`;
          }
        })
        .filter(Boolean)
        .join("\n")
    : "No ticker data available"
}

### Recent Activity:
${
  activityContext.length > 0
    ? activityContext
        .map((a) => {
          try {
            const price = Number(a.price) || 0;
            return `- ${String(a.time || "Unknown time")}: **${String(
              a.ticker || "UNKNOWN",
            )}** ${String(a.type || "event")} at $${price.toFixed(2)}`;
          } catch (e) {
            console.error("[AI CHAT] Error formatting activity:", a, e);
            return null;
          }
        })
        .filter(Boolean)
        .join("\n")
    : "No recent activity"
}

## TRADING SYSTEM OVERVIEW

### Quadrant System:
The platform uses a quadrant-based approach combining Higher Timeframe (HTF) and Lower Timeframe (LTF) signals:

- **Q1 (HTF_BULL_LTF_PULLBACK)**: Bull Setup - High timeframe bullish, short-term pullback. Waiting for entry confirmation.
- **Q2 (HTF_BULL_LTF_BULL)**: Bull Momentum - Both timeframes bullish. Active long trend, momentum phase.
- **Q3 (HTF_BEAR_LTF_BEAR)**: Bear Momentum - Both timeframes bearish. Active short trend, momentum phase.
- **Q4 (HTF_BEAR_LTF_PULLBACK)**: Bear Setup - High timeframe bearish, short-term pullback. Waiting for entry confirmation.

### Setup Quality Indicators:
- **Prime Setup**: High rank (≥75), excellent RR (≥1.5), low completion (<40%), favorable phase (<60%). Highest quality setups.
- **Momentum Elite**: High-quality momentum stock with strong fundamentals (volume, ADR, momentum metrics).
- **In Corridor**: Price is in the optimal entry zone for the directional setup (LTF score between -8 to +12 for LONG, -12 to +8 for SHORT).
- **Squeeze Release**: Momentum indicator suggesting a directional move is beginning (pent-up energy releasing).

### Key Metrics:
- **Rank**: Composite score (0-100) based on multiple factors. Higher = better setup quality.
- **RR (Risk/Reward)**: Ratio of potential profit to potential loss. ≥1.5 is considered good.
- **Phase %**: Position in the market cycle (0-100%). Lower (<40%) = early, higher (>60%) = late.
- **Completion %**: How far price has moved toward target (0-100%). Lower = more upside potential.

## MONITORING & PROACTIVE ALERTS

As an active monitor, you should:

1. **Identify Opportunities**:
   - Prime setups (Rank ≥75, RR ≥1.5, Completion <40%, Phase <60%)
   - Momentum Elite stocks entering good setups
   - New corridor entries with strong signals
   - Squeeze releases indicating potential moves

2. **Flag Warnings**:
   - High completion (>70%) - consider trimming or exiting
   - Late phase (>80%) - risk of reversal
   - Positions approaching stop loss
   - Setups losing quality (rank dropping, RR deteriorating)

3. **Pattern Recognition**:
   - Identify which setups/types perform best
   - Recognize when similar patterns led to wins/losses
   - Suggest improvements based on historical performance

4. **Continuous Learning**:
   - Reference trade history when relevant
   - Learn from what worked and what didn't
   - Adapt recommendations based on patterns

## RESPONSE GUIDELINES

1. **Be concise but thorough**: 
   - Simple queries: 2-4 sentences
   - Analysis questions: More detailed but organized
   - Monitoring queries: Structured with Opportunities, Warnings, Insights, Recommendations
   - Use bullet points for multiple items

2. **Always reference data**: 
   - Cite specific ranks, RR values, prices, states
   - Reference activity feed events when relevant
   - Mention trade history patterns when applicable
   - If ticker data isn't available, say so clearly

3. **Provide actionable insights**:
   - Not just data, but interpretation
   - Highlight risks and opportunities proactively
   - Suggest next steps (watch, enter, trim, exit)
   - Be specific: "Consider trimming 50% of POSITION at $PRICE"

4. **Risk awareness**:
   - Always mention risks for high-completion setups
   - Caution about late-phase positions
   - Note when setups lack confirmation
   - Warn about approaching stop losses

5. **Formatting**:
   - Use **bold** for tickers and key terms
   - Use \`code\` for technical terms
   - Use bullet points for lists
   - Use emojis for quick scanning: 🎯 Opportunities, ⚠️ Warnings, 📊 Insights, 💡 Recommendations
   - Keep paragraphs short (2-3 sentences max)

6. **Educational approach**:
   - Explain concepts if user seems unfamiliar
   - Define abbreviations on first use
   - Provide context for recommendations
   - Reference the trading system when explaining decisions

## EXAMPLE RESPONSES

**Good response for "What's the status of AAPL?"**:
"**AAPL** is currently ranked #X with an RR of X:1. It's in Q2 (Bull Momentum) with phase at X% and completion at X%. [Specific insight based on data]. [Risk assessment if relevant]."

**Good response for "Show me prime setups"**:
"Based on current data, here are the prime setups: [List with ranks and RR]. These setups have high rank (≥75), good RR (≥1.5), and are in early stages. [Overall market context]."

Remember: You're a helpful assistant. Be professional, accurate, and prioritize user safety by emphasizing risk management.`;

            // Format conversation history
            const messages = [
              { role: "system", content: systemPrompt },
              ...(body.conversationHistory || []).slice(-8).map((msg) => ({
                role: msg.role,
                content: msg.content,
              })),
              { role: "user", content: body.message },
            ];

            // Call OpenAI API with timeout
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout

            let aiResponse;
            try {
              aiResponse = await fetch(
                "https://api.openai.com/v1/chat/completions",
                {
                  method: "POST",
                  headers: {
                    Authorization: `Bearer ${openaiApiKey}`,
                    "Content-Type": "application/json",
                  },
                  body: JSON.stringify({
                    model:
                      env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                        ? env.OPENAI_MODEL
                        : "gpt-3.5-turbo",
                    messages: messages,
                    temperature: 0.7,
                    max_tokens: 800,
                  }),
                  signal: controller.signal,
                },
              );
            } catch (fetchError) {
              clearTimeout(timeoutId);
              if (fetchError.name === "AbortError") {
                throw new Error(
                  "Request timeout - OpenAI API took too long to respond",
                );
              }
              throw new Error(`Network error: ${fetchError.message}`);
            }

            clearTimeout(timeoutId);

            if (!aiResponse.ok) {
              let errorData = {};
              try {
                errorData = await aiResponse.json();
              } catch (e) {
                // If response isn't JSON, use status text
                errorData = { error: { message: aiResponse.statusText } };
              }
              console.error(
                "[AI CHAT] OpenAI API error:",
                aiResponse.status,
                errorData,
              );
              // Provide user-friendly error messages for common OpenAI errors
              let errorMessage =
                errorData.error?.message ||
                `OpenAI API error: ${aiResponse.status}`;
              if (aiResponse.status === 429) {
                if (errorData.error?.code === "insufficient_quota") {
                  errorMessage =
                    "OpenAI API quota exceeded. Please check your billing and plan details.";
                } else {
                  errorMessage =
                    "OpenAI API rate limit exceeded. Please try again later.";
                }
              }
              throw new Error(errorMessage);
            }

            let aiData;
            try {
              aiData = await aiResponse.json();
            } catch (e) {
              throw new Error("Invalid JSON response from OpenAI API");
            }

            const aiMessage =
              aiData.choices?.[0]?.message?.content ||
              "Sorry, I couldn't process that request.";

            // Extract sources if any tickers were mentioned
            const mentionedTickers = [];
            const tickerRegex = /\b([A-Z]{1,5})\b/g;
            const matches = body.message.toUpperCase().match(tickerRegex);
            if (matches) {
              matches.forEach((ticker) => {
                if (tickerContext.some((t) => t.ticker === ticker)) {
                  mentionedTickers.push(ticker);
                }
              });
            }

            return sendJSON(
              {
                ok: true,
                response: aiMessage,
                sources:
                  mentionedTickers.length > 0
                    ? [`Data from: ${mentionedTickers.join(", ")}`]
                    : [],
                timestamp: Date.now(),
              },
              200,
              aiChatCorsHeaders,
            );
          } catch (error) {
            // Catch any errors (including errors in error handling)
            console.error("[AI CHAT ERROR]", error);
            console.error("[AI CHAT ERROR] Stack:", error.stack);
            console.error("[AI CHAT ERROR] Message:", error.message);
            console.error("[AI CHAT ERROR] Name:", error.name);
            // Always return CORS headers even on error
            try {
              return sendJSON(
                {
                  ok: false,
                  error: error.message || "AI service error",
                  details: error.stack,
                },
                500,
                aiChatCorsHeaders,
              );
            } catch (sendError) {
              // If even sendJSON fails, return a basic response with CORS headers
              console.error(
                "[AI CHAT FATAL ERROR] Failed to send error response:",
                sendError,
              );
              return new Response(
                JSON.stringify({ ok: false, error: "Internal server error" }),
                {
                  status: 500,
                  headers: {
                    "Content-Type": "application/json",
                    ...aiChatCorsHeaders,
                  },
                },
              );
            }
          } // End of inner try-catch for OpenAI API
        } catch (fatalError) {
          // Catch any unhandled errors that might crash the worker
          console.error("[AI CHAT FATAL ERROR]", fatalError);
          console.error("[AI CHAT FATAL ERROR] Stack:", fatalError?.stack);
          console.error("[AI CHAT FATAL ERROR] Message:", fatalError?.message);
          console.error("[AI CHAT FATAL ERROR] Name:", fatalError?.name);
          console.error("[AI CHAT FATAL ERROR] Type:", typeof fatalError);
          // Always return CORS headers even on fatal errors
          // Re-create CORS headers in case they're out of scope
          const origin = req?.headers?.get("Origin") || "";
          const allowedOrigin = origin.includes("timedtrading.pages.dev")
            ? origin
            : "*";
          const fatalCorsHeaders = {
            "Access-Control-Allow-Origin": allowedOrigin,
            "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type",
            Vary: "Origin",
          };
          try {
            return sendJSON(
              {
                ok: false,
                error: "Internal server error",
                details: fatalError?.message || "Unknown error",
              },
              500,
              fatalCorsHeaders,
            );
          } catch (sendError) {
            // Last resort - return basic response
            console.error("[AI CHAT] Even sendJSON failed:", sendError);
            return new Response(
              JSON.stringify({ ok: false, error: "Internal server error" }),
              {
                status: 500,
                headers: {
                  "Content-Type": "application/json",
                  ...fatalCorsHeaders,
                },
              },
            );
          }
        }
      } // End of POST /timed/ai/chat handler

      // GET /timed/ai/updates (Get periodic AI updates)
      if (routeKey === "GET /timed/ai/updates") {
        const origin = req?.headers?.get("Origin") || "";
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        try {
          const limit = parseInt(url.searchParams.get("limit") || "10", 10);

          // Get list of updates
          const updatesListKey = `timed:ai:updates:list`;
          const updatesList = (await kvGetJSON(KV, updatesListKey)) || [];

          // Fetch actual update data
          const updatesPromises = updatesList
            .slice(0, limit)
            .map(async (item) => {
              try {
                const updateData = await kvGetJSON(KV, item.key);
                return updateData;
              } catch (err) {
                return null;
              }
            });

          const updates = (await Promise.all(updatesPromises))
            .filter(Boolean)
            .sort((a, b) => {
              const timeA = a.timestamp ? new Date(a.timestamp).getTime() : 0;
              const timeB = b.timestamp ? new Date(b.timestamp).getTime() : 0;
              return timeB - timeA;
            });

          return sendJSON(
            {
              ok: true,
              updates,
              count: updates.length,
            },
            200,
            aiChatCorsHeaders,
          );
        } catch (error) {
          console.error("[AI UPDATES ERROR]", error);
          return sendJSON(
            {
              ok: false,
              error: error.message || "Failed to fetch updates",
            },
            500,
            aiChatCorsHeaders,
          );
        }
      }

      // GET /timed/ai/daily-summary (Daily Summary of Simulation Dashboard Performance)
      if (routeKey === "GET /timed/ai/daily-summary") {
        const origin = req?.headers?.get("Origin") || "";
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        try {
          const openaiApiKey = env.OPENAI_API_KEY;
          if (!openaiApiKey) {
            return sendJSON(
              {
                ok: false,
                error:
                  "AI service not configured. Please set OPENAI_API_KEY secret.",
              },
              503,
              aiChatCorsHeaders,
            );
          }

          // Get date filter (default: today)
          const dateParam = url.searchParams.get("date");
          const targetDate = dateParam ? new Date(dateParam) : new Date();
          const todayStart = new Date(targetDate);
          todayStart.setHours(0, 0, 0, 0);
          const todayEnd = new Date(targetDate);
          todayEnd.setHours(23, 59, 59, 999);

          // Fetch all trades from unified storage
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

          // Filter trades by date
          const todayTrades = allTrades.filter((trade) => {
            if (!trade.entryTime) return false;
            const entryDate = new Date(trade.entryTime);
            return entryDate >= todayStart && entryDate <= todayEnd;
          });

          // Categorize trades
          const newTrades = todayTrades.filter(
            (t) => t.status === "OPEN" || !t.status,
          );
          const closedTrades = todayTrades.filter(
            (t) => t.status === "WIN" || t.status === "LOSS",
          );
          const trimmedTrades = todayTrades.filter(
            (t) => t.status === "TP_HIT_TRIM",
          );

          // Calculate P&L
          const closedPnl = closedTrades.reduce(
            (sum, t) => sum + (Number(t.pnl) || 0),
            0,
          );
          const openPnl = newTrades.reduce(
            (sum, t) => sum + (Number(t.pnl) || 0),
            0,
          );
          const trimmedPnl = trimmedTrades.reduce(
            (sum, t) => sum + (Number(t.pnl) || 0),
            0,
          );

          // Calculate win rate
          const wins = closedTrades.filter((t) => t.status === "WIN").length;
          const losses = closedTrades.filter((t) => t.status === "LOSS").length;
          const winRate =
            closedTrades.length > 0 ? (wins / closedTrades.length) * 100 : 0;

          // Analyze patterns for learning
          const winningTrades = closedTrades.filter((t) => t.status === "WIN");
          const losingTrades = closedTrades.filter((t) => t.status === "LOSS");

          // Analyze by signal types (trigger reasons and flags)
          const signalAnalysis = {};
          const allTradesForSignals = [...todayTrades];
          allTradesForSignals.forEach((trade) => {
            const signals = [];

            // Trigger reasons
            if (trade.state) {
              const state = String(trade.state || "");
              if (state.includes("BULL")) signals.push("HTF_BULL");
              if (state.includes("BEAR")) signals.push("HTF_BEAR");
              if (state.includes("PULLBACK")) signals.push("LTF_PULLBACK");
              if (state.includes("LTF_BULL")) signals.push("LTF_BULL");
              if (state.includes("LTF_BEAR")) signals.push("LTF_BEAR");
            }

            // Flags
            const flags = trade.flags || {};
            if (flags.sq30_release) signals.push("SQUEEZE_RELEASE");
            if (flags.sq30_on) signals.push("SQUEEZE_ON");
            if (flags.phase_zone_change) signals.push("PHASE_ZONE_CHANGE");
            if (flags.momentum_elite) signals.push("MOMENTUM_ELITE");

            // Trigger reason
            if (trade.trigger_reason) {
              const triggerReason = String(trade.trigger_reason || "");
              if (triggerReason === "EMA_CROSS")
                signals.push("EMA_CROSS_DAILY");
              if (triggerReason === "SQUEEZE_RELEASE")
                signals.push("SQUEEZE_RELEASE_TRIGGER");
            }

            const signalKey =
              signals.length > 0 ? signals.sort().join("+") : "NO_SIGNALS";

            if (!signalAnalysis[signalKey]) {
              signalAnalysis[signalKey] = {
                total: 0,
                wins: 0,
                losses: 0,
                totalPnl: 0,
                trades: [],
              };
            }

            signalAnalysis[signalKey].total++;
            if (trade.status === "WIN") signalAnalysis[signalKey].wins++;
            if (trade.status === "LOSS") signalAnalysis[signalKey].losses++;
            signalAnalysis[signalKey].totalPnl += Number(trade.pnl) || 0;
            signalAnalysis[signalKey].trades.push({
              ticker: trade.ticker,
              status: trade.status,
              pnl: Number(trade.pnl) || 0,
              rank: Number(trade.rank) || 0,
              rr: Number(trade.rr) || 0,
            });
          });

          // Analyze by rank ranges
          const rankAnalysis = {};
          closedTrades.forEach((trade) => {
            const rank = Number(trade.rank) || 0;
            let range = "Unknown";
            if (rank >= 80) range = "Rank ≥ 80";
            else if (rank >= 70) range = "Rank 70-80";
            else if (rank >= 60) range = "Rank 60-70";
            else if (rank > 0) range = "Rank < 60";

            if (!rankAnalysis[range]) {
              rankAnalysis[range] = { wins: 0, losses: 0, totalPnl: 0 };
            }
            if (trade.status === "WIN") rankAnalysis[range].wins++;
            if (trade.status === "LOSS") rankAnalysis[range].losses++;
            rankAnalysis[range].totalPnl += Number(trade.pnl) || 0;
          });

          // Analyze by RR ranges
          const rrAnalysis = {};
          closedTrades.forEach((trade) => {
            const rr = Number(trade.rr) || 0;
            let range = "Unknown";
            if (rr >= 2.0) range = "RR ≥ 2.0";
            else if (rr >= 1.5) range = "RR 1.5-2.0";
            else if (rr >= 1.0) range = "RR 1.0-1.5";
            else if (rr > 0) range = "RR < 1.0";

            if (!rrAnalysis[range]) {
              rrAnalysis[range] = { wins: 0, losses: 0, totalPnl: 0 };
            }
            if (trade.status === "WIN") rrAnalysis[range].wins++;
            if (trade.status === "LOSS") rrAnalysis[range].losses++;
            rrAnalysis[range].totalPnl += Number(trade.pnl) || 0;
          });

          // Find most common signals
          const topSignals = Object.entries(signalAnalysis)
            .filter(([_, stats]) => stats.total >= 2)
            .sort((a, b) => {
              const aRate = a[1].wins / (a[1].wins + a[1].losses || 1);
              const bRate = b[1].wins / (b[1].wins + b[1].losses || 1);
              return bRate - aRate;
            })
            .slice(0, 5);

          // Build summary prompt
          const summaryPrompt = `You are a senior trading analyst providing a comprehensive daily market thesis. Write as if someone asked you: "How did the market do today? What interesting developments were there?"

Your response should be thesis-driven, narrative, and detailed - like a professional market commentary.

## TODAY'S PERFORMANCE SUMMARY

**Date:** ${targetDate.toLocaleDateString()}

### Trade Activity:
- **New Trades:** ${newTrades.length}
- **Closed Trades:** ${closedTrades.length} (${wins} wins, ${losses} losses)
- **Trimmed Trades:** ${trimmedTrades.length}

### P&L Summary:
- **Closed P&L:** $${closedPnl.toFixed(2)}
- **Open P&L:** $${openPnl.toFixed(2)}
- **Trimmed P&L:** $${trimmedPnl.toFixed(2)}
- **Total P&L:** $${(closedPnl + openPnl + trimmedPnl).toFixed(2)}
- **Win Rate:** ${winRate.toFixed(1)}%

### Signal Breakdown - What Drove Today's Trades:

**Most Common Signal Combinations:**
${
  topSignals.length > 0
    ? topSignals
        .map(
          ([signals, stats]) =>
            `- **${signals}**: ${stats.total} trades | ${stats.wins}W/${
              stats.losses
            }L (${(
              (stats.wins / (stats.wins + stats.losses || 1)) *
              100
            ).toFixed(1)}% win rate) | P&L: $${stats.totalPnl.toFixed(2)}`,
        )
        .join("\n")
    : "No significant signal patterns"
}

**Signal Details:**
- **EMA Crossovers (Daily)**: ${
            allTradesForSignals.filter((t) => t.trigger_reason === "EMA_CROSS")
              .length
          } trades
- **Squeeze Releases**: ${
            allTradesForSignals.filter((t) => t.flags?.sq30_release).length
          } trades
- **Momentum Elite**: ${
            allTradesForSignals.filter((t) => t.flags?.momentum_elite).length
          } trades
- **Phase Zone Changes**: ${
            allTradesForSignals.filter((t) => t.flags?.phase_zone_change).length
          } trades

---

### Performance by Rank:
${
  Object.entries(rankAnalysis)
    .map(
      ([range, stats]) =>
        `- **${range}**: ${stats.wins}W/${
          stats.losses
        }L | P&L: $${stats.totalPnl.toFixed(2)}`,
    )
    .join("\n") || "No data"
}

---

### Performance by RR:
${
  Object.entries(rrAnalysis)
    .map(
      ([range, stats]) =>
        `- **${range}**: ${stats.wins}W/${
          stats.losses
        }L | P&L: $${stats.totalPnl.toFixed(2)}`,
    )
    .join("\n") || "No data"
}

---

### Top Performers:
${
  winningTrades
    .sort((a, b) => (Number(b.pnl) || 0) - (Number(a.pnl) || 0))
    .slice(0, 5)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: +$${(Number(t.pnl) || 0).toFixed(2)} | Rank ${
        t.rank || 0
      } | RR ${rrFormatted}`;
    })
    .join("\n") || "None"
}

### Worst Performers:
${
  losingTrades
    .sort((a, b) => (Number(a.pnl) || 0) - (Number(b.pnl) || 0))
    .slice(0, 5)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: $${(Number(t.pnl) || 0).toFixed(2)} | Rank ${
        t.rank || 0
      } | RR ${rrFormatted}`;
    })
    .join("\n") || "None"
}

### Current Open Positions (For Actionable Recommendations):
${
  newTrades.length > 0
    ? newTrades
        .slice(0, 10)
        .map((t) => {
          const entryPrice = Number(t.entryPrice) || 0;
          const currentPrice = Number(t.currentPrice) || entryPrice;
          const sl = Number(t.sl) || 0;
          const tp = Number(t.tp) || 0;
          const rr = Number(t.rr) || 0;
          const rrFormatted =
            rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
          const direction = String(t.direction || "LONG");
          const riskPerShare =
            direction === "LONG" ? entryPrice - sl : sl - entryPrice;
          const rewardPerShare =
            direction === "LONG" ? tp - entryPrice : entryPrice - tp;
          const distanceToTP =
            direction === "LONG" ? tp - currentPrice : currentPrice - tp;
          const distanceToSL =
            direction === "LONG" ? currentPrice - sl : sl - currentPrice;
          const pctToTP =
            entryPrice > 0
              ? ((distanceToTP / rewardPerShare) * 100).toFixed(0)
              : "0";
          const trimLevel = tp; // Trim at first TP

          return `- **${t.ticker}** (${direction}): Entry $${entryPrice.toFixed(
            2,
          )} | Current $${currentPrice.toFixed(2)} | SL $${sl.toFixed(
            2,
          )} | TP $${tp.toFixed(2)} | RR ${rrFormatted} | Rank ${
            t.rank || 0
          } | ${pctToTP}% to TP`;
        })
        .join("\n")
    : "No open positions"
}

## YOUR TASK

Write a comprehensive, thesis-driven daily market summary. Structure it as follows:

### 1. **Market Thesis** (2-3 paragraphs)
Start with a clear thesis statement: "Today's market was characterized by [X]..." 
- What was the overall market character? (Bullish momentum, choppy consolidation, bearish pressure, etc.)
- What drove the day's activity? (EMA crossovers, squeeze releases, specific setups)
- Were there any notable patterns or themes?

### 2. **Signal-Driven Analysis** (Detailed breakdown)
For each major signal type, explain:
- **EMA Crossovers**: How many occurred? Were they on the daily timeframe? Did they lead to successful trades? What was the typical setup?
- **Squeeze Releases**: How many squeeze releases triggered trades? Were they bullish or bearish? How did they perform?
- **Momentum Elite**: Did Momentum Elite stocks outperform? What was their win rate?
- **Phase Zone Changes**: Did phase transitions lead to good entries? Were they early or late in the cycle?

Break down what specifically drove the scores and signals. For example:
- "The majority of winning trades today were driven by EMA crossovers on the daily timeframe, particularly when combined with squeeze releases. These setups showed an average rank of 78 and RR of 2.1:1..."
- "Squeeze releases were the dominant signal, accounting for X% of new entries. However, they showed mixed results - bullish squeezes in Q2 (HTF_BULL_LTF_BULL) performed well with a Y% win rate, while bearish squeezes struggled..."

### 3. **Interesting Developments** (What stood out)
- Were there any unusual patterns? (e.g., "Rank ≥80 trades significantly outperformed today")
- Did certain sectors or setups surprise? (e.g., "Short setups unexpectedly outperformed longs")
- Any notable failures or successes? (e.g., "High RR trades (>2.0) had perfect win rate but low volume")

### 4. **Performance Breakdown by Signals**
Reference the signal analysis data above. Explain which signal combinations worked best and why.

### 5. **Actionable Trade Recommendations** (Walk-through with actual details)
For each open position, provide specific guidance:

**Format for each recommendation:**
\`\`\`
**[TICKER]** - [DIRECTION] Setup
- **Current Price**: $X.XX
- **Entry Price**: $X.XX (if different from current)
- **Stop Loss**: $X.XX (risk: $X.XX per share, X.X% risk)
- **Take Profit**: $X.XX (reward: $X.XX per share, X.X% reward)
- **Risk/Reward**: X.X:1
- **Current Status**: X% to TP / X% above SL
- **When to Trim**: Trim 50% at $X.XX (first TP level)
- **Action Plan**: [Specific guidance - e.g., "Hold until TP at $X.XX, then trim 50%. Move SL to breakeven if price reaches $X.XX"]
- **Risk Assessment**: [Any concerns - e.g., "Approaching SL, consider tightening stop if price breaks below $X.XX"]
\`\`\`

Provide 3-5 most important open positions with full walk-through details. Be specific about price levels, percentages, and exact actions.

### 6. **Recommendations for Scoring/Capturing** (System improvements)
Based on today's data:
- Should we adjust minimum rank thresholds? (e.g., "Rank ≥80 showed 85% win rate vs 60% for Rank 70-80")
- Should we adjust RR requirements? (e.g., "RR ≥2.0 trades had perfect win rate")
- Are certain signal combinations performing better? (e.g., "EMA_CROSS+SQUEEZE_RELEASE+MOMENTUM_ELITE had 90% win rate")
- What patterns should we focus on? (e.g., "Focus on Momentum Elite stocks with squeeze releases")

### 7. **What to Watch Tomorrow**
- What setups are forming?
- What signals are developing?
- Any warnings or opportunities?

**Writing Style:**
- Write in a narrative, conversational tone (like explaining to a colleague)
- Use specific data points and examples
- Be detailed about signal mechanics (e.g., "EMA crossovers on the daily timeframe when price was above the 21 EMA")
- Reference actual tickers when relevant
- Make it insightful, not just data-dumping

**Length:** Aim for 800-1200 words. Be thorough but focused.`;

          // Call OpenAI API
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), 30000);

          let aiResponse;
          try {
            aiResponse = await fetch(
              "https://api.openai.com/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  Authorization: `Bearer ${openaiApiKey}`,
                  "Content-Type": "application/json",
                },
                body: JSON.stringify({
                  model:
                    env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                      ? env.OPENAI_MODEL
                      : "gpt-3.5-turbo",
                  messages: [{ role: "system", content: summaryPrompt }],
                  temperature: 0.7,
                  max_tokens: 2000,
                }),
                signal: controller.signal,
              },
            );
          } catch (fetchError) {
            clearTimeout(timeoutId);
            if (fetchError.name === "AbortError") {
              throw new Error("Request timeout");
            }
            throw new Error(`Network error: ${fetchError.message}`);
          }

          clearTimeout(timeoutId);

          if (!aiResponse.ok) {
            throw new Error(`OpenAI API error: ${aiResponse.status}`);
          }

          const aiData = await aiResponse.json();
          const summary =
            aiData.choices?.[0]?.message?.content ||
            "Daily summary unavailable.";

          return sendJSON(
            {
              ok: true,
              summary,
              stats: {
                date: targetDate.toISOString().split("T")[0],
                newTrades: newTrades.length,
                closedTrades: closedTrades.length,
                trimmedTrades: trimmedTrades.length,
                wins,
                losses,
                winRate: winRate.toFixed(1),
                closedPnl: closedPnl.toFixed(2),
                openPnl: openPnl.toFixed(2),
                trimmedPnl: trimmedPnl.toFixed(2),
                totalPnl: (closedPnl + openPnl + trimmedPnl).toFixed(2),
                rankAnalysis,
                rrAnalysis,
                signalAnalysis,
                topSignals: topSignals.map(([signals, stats]) => ({
                  signals,
                  ...stats,
                })),
              },
              timestamp: Date.now(),
            },
            200,
            aiChatCorsHeaders,
          );
        } catch (error) {
          console.error("[DAILY SUMMARY ERROR]", error);
          return sendJSON(
            {
              ok: false,
              error: error.message || "Daily summary service error",
            },
            500,
            aiChatCorsHeaders,
          );
        }
      }

      // GET /timed/ai/monitor (Real-time Monitoring & Proactive Alerts)
      if (routeKey === "GET /timed/ai/monitor") {
        const origin = req?.headers?.get("Origin") || "";
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        try {
          const openaiApiKey = env.OPENAI_API_KEY;
          if (!openaiApiKey) {
            return sendJSON(
              {
                ok: false,
                error:
                  "AI service not configured. Please set OPENAI_API_KEY secret.",
              },
              503,
              aiChatCorsHeaders,
            );
          }

          // Fetch all ticker data
          const allKeys = await KV.list({ prefix: "timed:latest:" });
          const tickerDataPromises = allKeys.keys
            .slice(0, 50)
            .map(async (key) => {
              try {
                const data = await kvGetJSON(KV, key.name);
                if (data) {
                  const ticker = key.name.replace("timed:latest:", "");
                  return {
                    ticker,
                    rank: Number(data.rank) || 0,
                    rr: Number(data.rr) || 0,
                    price: Number(data.price) || 0,
                    state: String(data.state || ""),
                    phase_pct: Number(data.phase_pct) || 0,
                    completion: Number(data.completion) || 0,
                    flags: data.flags || {},
                    htf_score: Number(data.htf_score) || 0,
                    ltf_score: Number(data.ltf_score) || 0,
                    sl: Number(data.sl) || 0,
                    tp: Number(data.tp) || 0,
                  };
                }
                return null;
              } catch (err) {
                console.error(`[AI MONITOR] Error fetching ${key.name}:`, err);
                return null;
              }
            });

          const allTickers = (await Promise.all(tickerDataPromises))
            .filter(Boolean)
            .sort((a, b) => (b.rank || 0) - (a.rank || 0));

          // Fetch recent activity feed (last 20 events)
          const activityKeys = await KV.list({ prefix: "timed:activity:" });
          const recentActivity = [];
          const activityPromises = activityKeys.keys
            .slice(-20)
            .map(async (key) => {
              try {
                const data = await kvGetJSON(KV, key.name);
                if (data) {
                  return {
                    ticker: String(data.ticker || "UNKNOWN"),
                    type: String(data.type || "event"),
                    ts: Number(data.ts) || Date.now(),
                    price: Number(data.price) || 0,
                    rank: Number(data.rank) || 0,
                  };
                }
                return null;
              } catch (err) {
                return null;
              }
            });

          const activityEvents = (await Promise.all(activityPromises))
            .filter(Boolean)
            .sort((a, b) => b.ts - a.ts)
            .slice(0, 20);

          // Fetch trade history for pattern recognition
          const tradesKey = "timed:trades:all";
          const allTradesForHistory = (await kvGetJSON(KV, tradesKey)) || [];
          const tradeHistory = allTradesForHistory
            .filter((t) => t.status === "WIN" || t.status === "LOSS")
            .slice(-50) // Increased to 50 for better pattern recognition
            .map((t) => ({
              ticker: String(t.ticker || ""),
              direction: String(t.direction || ""),
              status: String(t.status || ""),
              pnl: Number(t.pnl) || 0,
              rank: Number(t.rank) || 0,
              rr: Number(t.rr) || 0,
              entryTime: String(t.entryTime || ""),
              state: String(t.state || ""),
              flags: t.flags || {},
            }));

          // Pattern Recognition: Analyze winning patterns
          const winningPatterns = analyzeWinningPatterns(
            tradeHistory,
            allTickers,
          );

          // Proactive Alerts: Detect conditions that need attention
          const proactiveAlerts = generateProactiveAlerts(
            allTickers,
            allTradesForHistory,
          );

          // Analyze for proactive alerts
          const primeSetups = allTickers.filter(
            (t) =>
              t.rank >= 75 &&
              t.rr >= 1.5 &&
              t.completion < 0.4 &&
              t.phase_pct < 0.6,
          );

          const highRiskPositions = allTickers.filter(
            (t) => t.completion > 0.7 || t.phase_pct > 0.8,
          );

          const momentumEliteSetups = allTickers.filter(
            (t) => t.flags?.momentum_elite && t.rank >= 70,
          );

          // Build monitoring prompt
          const monitoringPrompt = `You are an AI trading monitor for the Timed Trading platform. Your role is to continuously observe market conditions, identify opportunities, warn about risks, and provide actionable insights.

## YOUR MONITORING CAPABILITIES
- **Real-time Market Analysis**: Monitor all tickers and activity feeds
- **Proactive Alerts**: Identify good trades, warnings, trim/exit signals
- **Pattern Recognition**: Learn from trade history and identify patterns
- **Risk Management**: Flag high-risk positions and suggest exits
- **Opportunity Detection**: Surface prime setups and momentum elite stocks

## CURRENT MARKET DATA
- **${allTickers.length} total tickers** being monitored
- **${
            primeSetups.length
          } prime setups** (Rank ≥75, RR ≥1.5, Completion <40%, Phase <60%)
- **${
            highRiskPositions.length
          } high-risk positions** (Completion >70% or Phase >80%)
- **${momentumEliteSetups.length} Momentum Elite setups**
- **${activityEvents.length} recent activity events**
- **${tradeHistory.length} closed trades** for pattern analysis

### Top Prime Setups (${primeSetups.slice(0, 10).length}):
${
  primeSetups
    .slice(0, 10)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: Rank ${
        t.rank
      } | RR ${rrFormatted} | Price $${t.price.toFixed(2)} | Phase ${(
        t.phase_pct * 100
      ).toFixed(0)}% | Completion ${(t.completion * 100).toFixed(0)}%`;
    })
    .join("\n") || "None"
}

### High-Risk Positions (${highRiskPositions.slice(0, 10).length}):
${
  highRiskPositions
    .slice(0, 10)
    .map(
      (t) =>
        `- **${t.ticker}**: Rank ${t.rank}, Completion ${(
          t.completion * 100
        ).toFixed(0)}%, Phase ${(t.phase_pct * 100).toFixed(
          0,
        )}%, Price $${t.price.toFixed(2)}`,
    )
    .join("\n") || "None"
}

### Recent Activity (Last ${activityEvents.slice(0, 10).length}):
${
  activityEvents
    .slice(0, 10)
    .map(
      (a) =>
        `- ${new Date(a.ts).toLocaleTimeString()}: **${a.ticker}** ${
          a.type
        } at $${a.price.toFixed(2)}`,
    )
    .join("\n") || "None"
}

### Trade History Patterns (Last ${tradeHistory.length}):
${
  tradeHistory.length > 0
    ? `Win Rate: ${(
        (tradeHistory.filter((t) => t.status === "WIN").length /
          tradeHistory.length) *
        100
      ).toFixed(1)}%\n` +
      `Avg P&L: $${(
        tradeHistory.reduce((sum, t) => sum + (t.pnl || 0), 0) /
        tradeHistory.length
      ).toFixed(2)}\n` +
      `Best Performers: ${tradeHistory
        .filter((t) => t.pnl > 0)
        .sort((a, b) => b.pnl - a.pnl)
        .slice(0, 5)
        .map((t) => `${t.ticker} (+$${t.pnl.toFixed(2)})`)
        .join(", ")}`
    : "No trade history available"
}

### Pattern Recognition Insights:
${winningPatterns.summary || "Analyzing patterns..."}

### Proactive Alerts (${proactiveAlerts.length}):
${
  proactiveAlerts.length > 0
    ? proactiveAlerts
        .slice(0, 10)
        .map((a) => `- **${a.type}**: ${a.message}`)
        .join("\n")
    : "No alerts at this time"
}

## MONITORING RESPONSE FORMAT

Provide a well-structured, easy-to-read analysis with clear spacing and formatting:

### 🎯 Opportunities

List prime setups worth watching and pattern matches. For each opportunity:
- Use bullet points with ticker symbol in **bold**
- Include: Rank, RR, Price, Phase %, Completion %
- Add a brief reason why it's worth watching
- Leave a blank line between each opportunity

Example format:
\`\`\`
- **AWI**: Rank 89 | RR 2.00:1 | Price $189.56 | Phase 34% | Completion 15%
  Prime setup with excellent risk/reward and early stage positioning.
\`\`\`

### ⚠️ Warnings

List high-risk positions and positions approaching TP/SL. Group by type:
- **High-Risk Positions**: (Completion >70% or Phase >80%)
- **Approaching TP**: (Within 5% of Take Profit - consider trimming)
- **Approaching SL**: (Within 5% of Stop Loss - monitor closely)

For each warning:
- Use bullet points with ticker symbol in **bold**
- Include relevant metrics (Completion %, Phase %, distance to TP/SL)
- Add specific action recommendation
- Leave a blank line between each warning

Example format:
\`\`\`
**High-Risk Positions:**
- **ALB**: Rank 90 | Completion 19% | Phase 83% | Price $162.05
  Late phase position - consider trimming or tightening stops.

**Approaching TP:**
- **GS**: Within 2.3% of TP at $940.68
  Consider trimming 50% at TP to lock in profits.
\`\`\`

### 📊 Market Insights

Provide overall market conditions and pattern recognition findings:
- Start with a brief summary sentence
- Reference pattern recognition insights from above
- Mention any notable trends or patterns
- Use bullet points for key insights
- Leave blank lines between major points

### 💡 Recommendations

Provide 3-5 actionable next steps:
- Number each recommendation (1., 2., 3.)
- Be specific and actionable
- Reference specific tickers when relevant
- Include price levels or percentages when applicable
- Leave blank lines between each recommendation

**FORMATTING GUIDELINES:**
- Use **bold** for ticker symbols and key terms
- Use blank lines (double newlines) to separate major sections
- Use bullet points (-) for lists within sections
- Use numbered lists (1., 2., 3.) for recommendations
- Keep paragraphs short (2-3 sentences max)
- Use code formatting for specific values like prices or percentages

**IMPORTANT**: Reference the proactive alerts above and pattern recognition insights. Prioritize alerts marked as "high" priority. Be concise but thorough. Focus on actionable insights, not just data.`;

          // Call OpenAI API
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), 30000);

          let aiResponse;
          try {
            aiResponse = await fetch(
              "https://api.openai.com/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  Authorization: `Bearer ${openaiApiKey}`,
                  "Content-Type": "application/json",
                },
                body: JSON.stringify({
                  model:
                    env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                      ? env.OPENAI_MODEL
                      : "gpt-3.5-turbo",
                  messages: [{ role: "system", content: monitoringPrompt }],
                  temperature: 0.7,
                  max_tokens: 1000,
                }),
                signal: controller.signal,
              },
            );
          } catch (fetchError) {
            clearTimeout(timeoutId);
            if (fetchError.name === "AbortError") {
              throw new Error("Request timeout");
            }
            throw new Error(`Network error: ${fetchError.message}`);
          }

          clearTimeout(timeoutId);

          if (!aiResponse.ok) {
            let errorData = {};
            try {
              errorData = await aiResponse.json();
            } catch (e) {
              errorData = { error: { message: aiResponse.statusText } };
            }
            throw new Error(
              errorData.error?.message ||
                `OpenAI API error: ${aiResponse.status}`,
            );
          }

          const aiData = await aiResponse.json();
          const aiMessage =
            aiData.choices?.[0]?.message?.content ||
            "Monitoring analysis unavailable.";

          return sendJSON(
            {
              ok: true,
              analysis: aiMessage,
              stats: {
                totalTickers: allTickers.length,
                primeSetups: primeSetups.length,
                highRiskPositions: highRiskPositions.length,
                momentumElite: momentumEliteSetups.length,
                recentActivity: activityEvents.length,
                tradeHistory: tradeHistory.length,
              },
              timestamp: Date.now(),
            },
            200,
            aiChatCorsHeaders,
          );
        } catch (error) {
          console.error("[AI MONITOR ERROR]", error);
          return sendJSON(
            {
              ok: false,
              error: error.message || "Monitoring service error",
            },
            500,
            aiChatCorsHeaders,
          );
        }
      }

      // ─────────────────────────────────────────────────────────────
      // Debug Endpoints
      // ─────────────────────────────────────────────────────────────

      // GET /timed/debug/trades?ticker=RIOT - Get all trades with details, optionally filtered by ticker
      if (routeKey === "GET /timed/debug/trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

          // Optional ticker filter
          const tickerFilter = url.searchParams.get("ticker");
          let filteredTrades = allTrades;
          if (tickerFilter) {
            const tickerUpper = String(tickerFilter).toUpperCase();
            filteredTrades = allTrades.filter(
              (t) => String(t.ticker || "").toUpperCase() === tickerUpper,
            );
          }

          const openTrades = filteredTrades.filter(
            (t) =>
              t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
          );
          const closedTrades = filteredTrades.filter(
            (t) => t.status === "WIN" || t.status === "LOSS",
          );

          return sendJSON(
            {
              ok: true,
              ticker: tickerFilter || null,
              total: filteredTrades.length,
              open: openTrades.length,
              closed: closedTrades.length,
              trades: filteredTrades,
              summary: {
                byVersion: filteredTrades.reduce((acc, t) => {
                  const v = t.scriptVersion || "unknown";
                  acc[v] = (acc[v] || 0) + 1;
                  return acc;
                }, {}),
                byStatus: filteredTrades.reduce((acc, t) => {
                  const s = t.status || "OPEN";
                  acc[s] = (acc[s] || 0) + 1;
                  return acc;
                }, {}),
              },
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/debug/score-analysis - Analyze score distribution
      if (routeKey === "GET /timed/debug/score-analysis") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const tickerDataPromises = tickerIndex.map(async (ticker) => {
            const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
            return data;
          });

          const allData = (await Promise.all(tickerDataPromises)).filter(
            Boolean,
          );

          // Score distribution
          const scoreRanges = {
            "90-100": 0,
            "80-89": 0,
            "70-79": 0,
            "60-69": 0,
            "50-59": 0,
            "40-49": 0,
            "30-39": 0,
            "20-29": 0,
            "10-19": 0,
            "0-9": 0,
          };

          const scoreBreakdown = [];
          const componentStats = {
            aligned: { count: 0, avgScore: 0 },
            setup: { count: 0, avgScore: 0 },
            squeezeRelease: { count: 0, avgScore: 0 },
            squeezeOn: { count: 0, avgScore: 0 },
            momentumElite: { count: 0, avgScore: 0 },
            phaseZoneChange: { count: 0, avgScore: 0 },
          };

          allData.forEach((d) => {
            const rank = Number(d.rank) || 0;
            const scoreRange =
              rank >= 90
                ? "90-100"
                : rank >= 80
                  ? "80-89"
                  : rank >= 70
                    ? "70-79"
                    : rank >= 60
                      ? "60-69"
                      : rank >= 50
                        ? "50-59"
                        : rank >= 40
                          ? "40-49"
                          : rank >= 30
                            ? "30-39"
                            : rank >= 20
                              ? "20-29"
                              : rank >= 10
                                ? "10-19"
                                : "0-9";
            scoreRanges[scoreRange]++;

            // Component analysis
            const state = String(d.state || "");
            const aligned =
              state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
            const setup =
              state === "HTF_BULL_LTF_PULLBACK" ||
              state === "HTF_BEAR_LTF_PULLBACK";
            const flags = d.flags || {};
            const sqRel = !!flags.sq30_release;
            const sqOn = !!flags.sq30_on;
            const momentumElite = !!flags.momentum_elite;
            const phaseZoneChange = !!flags.phase_zone_change;

            if (aligned) {
              componentStats.aligned.count++;
              componentStats.aligned.avgScore += rank;
            }
            if (setup) {
              componentStats.setup.count++;
              componentStats.setup.avgScore += rank;
            }
            if (sqRel) {
              componentStats.squeezeRelease.count++;
              componentStats.squeezeRelease.avgScore += rank;
            }
            if (sqOn && !sqRel) {
              componentStats.squeezeOn.count++;
              componentStats.squeezeOn.avgScore += rank;
            }
            if (momentumElite) {
              componentStats.momentumElite.count++;
              componentStats.momentumElite.avgScore += rank;
            }
            if (phaseZoneChange) {
              componentStats.phaseZoneChange.count++;
              componentStats.phaseZoneChange.avgScore += rank;
            }

            // Detailed breakdown for high scores
            if (rank >= 85) {
              const htf = Number(d.htf_score) || 0;
              const ltf = Number(d.ltf_score) || 0;
              const comp = Number(d.completion) || 0;
              const phase = Number(d.phase_pct) || 0;
              const rr = Number(d.rr) || 0;

              scoreBreakdown.push({
                ticker: d.ticker,
                rank,
                state,
                aligned,
                setup,
                htf_score: htf,
                ltf_score: ltf,
                completion: comp,
                phase_pct: phase,
                rr,
                flags: {
                  sq30_release: sqRel,
                  sq30_on: sqOn,
                  momentum_elite: momentumElite,
                  phase_zone_change: phaseZoneChange,
                },
              });
            }
          });

          // Calculate averages
          Object.keys(componentStats).forEach((key) => {
            if (componentStats[key].count > 0) {
              componentStats[key].avgScore =
                componentStats[key].avgScore / componentStats[key].count;
            }
          });

          // Overall stats
          const ranks = allData
            .map((d) => Number(d.rank) || 0)
            .filter((r) => r > 0);
          const avgRank =
            ranks.length > 0
              ? ranks.reduce((a, b) => a + b, 0) / ranks.length
              : 0;
          const medianRank =
            ranks.length > 0
              ? ranks.sort((a, b) => a - b)[Math.floor(ranks.length / 2)]
              : 0;
          const maxRank = ranks.length > 0 ? Math.max(...ranks) : 0;
          const minRank = ranks.length > 0 ? Math.min(...ranks) : 0;

          return sendJSON(
            {
              ok: true,
              summary: {
                totalTickers: allData.length,
                avgRank: Math.round(avgRank * 100) / 100,
                medianRank,
                maxRank,
                minRank,
              },
              distribution: scoreRanges,
              componentStats,
              highScoreBreakdown: scoreBreakdown.slice(0, 50), // Top 50 high scores
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/debug/tickers - Get all tickers with latest data
      if (routeKey === "GET /timed/debug/tickers") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const tickerDataPromises = tickerIndex
            .slice(0, 100)
            .map(async (ticker) => {
              const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
              return {
                ticker,
                hasData: !!data,
                data: data
                  ? {
                      price: data.price,
                      state: data.state,
                      rank: data.rank,
                      rr: data.rr,
                      completion: data.completion,
                      phase_pct: data.phase_pct,
                      sl: data.sl,
                      tp: data.tp,
                      script_version: data.script_version,
                      ingest_time: data.ingest_time,
                    }
                  : null,
              };
            });

          const tickerData = await Promise.all(tickerDataPromises);

          return sendJSON(
            {
              ok: true,
              totalTickers: tickerIndex.length,
              tickersWithData: tickerData.filter((t) => t.hasData).length,
              tickers: tickerData,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/debug/config - Check Discord and other configuration
      if (routeKey === "GET /timed/debug/config") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        return sendJSON(
          {
            ok: true,
            config: {
              discordEnabled: (env.DISCORD_ENABLE || "false") === "true",
              discordWebhookSet: !!env.DISCORD_WEBHOOK_URL,
              discordWebhookUrl: env.DISCORD_WEBHOOK_URL
                ? "***SET***"
                : "NOT SET",
              openaiApiKeySet: !!env.OPENAI_API_KEY,
              openaiModel: env.OPENAI_MODEL || "gpt-3.5-turbo",
              alertMinRR: env.ALERT_MIN_RR || "1.5",
              alertMaxCompletion: env.ALERT_MAX_COMPLETION || "0.4",
              alertMaxPhase: env.ALERT_MAX_PHASE || "0.6",
              alertMinRank: env.ALERT_MIN_RANK || "70",
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/debug/daily?ticker=AMD
      // Debug endpoint to inspect daily change inputs/sources (latest vs capture vs worker-derived).
      if (routeKey === "GET /timed/debug/daily") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        }

        const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
        const capture = await kvGetJSON(KV, `timed:capture:latest:${ticker}`);

        const pick = (obj, keys) => {
          for (const k of keys) {
            if (!obj || typeof obj !== "object") continue;
            if (obj[k] != null) return obj[k];
          }
          return null;
        };
        const num = (v) => {
          const n = Number(v);
          return Number.isFinite(n) ? n : null;
        };

        const latestTs = num(pick(latest, ["ts", "ingest_ts"])) || null;
        const captureTs = num(pick(capture, ["ts", "ingest_ts"])) || null;
        const asOfTs = latestTs || captureTs || Date.now();

        let derived = null;
        try {
          if (env?.DB) {
            const rec = await computePrevCloseFromTrail(env.DB, ticker, asOfTs);
            const price =
              num(pick(latest, ["price"])) ?? num(pick(capture, ["price"]));
            if (rec && Number.isFinite(price) && price > 0) {
              derived = {
                prev_close: rec.close,
                prev_close_day: rec.dayKey,
                prev_close_ts: rec.ts,
                day_change: price - rec.close,
                day_change_pct: ((price - rec.close) / rec.close) * 100,
              };
            } else {
              derived = {
                prev_close: null,
                reason: rec ? "bad_price" : "no_prev_close_row",
              };
            }
          }
        } catch (e) {
          derived = { prev_close: null, error: String(e?.message || e) };
        }

        const fields = [
          "price",
          "prev_close",
          "day_change",
          "day_change_pct",
          "change",
          "change_pct",
          "session",
          "is_rth",
          "ts",
          "ingest_ts",
        ];
        const subset = (obj) => {
          const out = {};
          for (const k of fields)
            if (obj && typeof obj === "object" && obj[k] != null)
              out[k] = obj[k];
          return out;
        };

        return sendJSON(
          {
            ok: true,
            ticker,
            latest: subset(latest),
            capture: subset(capture),
            derived,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/debug/cleanup-duplicates?key=...&ticker=RIOT - Remove duplicate trades for a ticker
      if (routeKey === "POST /timed/debug/cleanup-duplicates") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const tickerFilter = url.searchParams.get("ticker");

          if (!tickerFilter) {
            return sendJSON(
              { ok: false, error: "ticker parameter required" },
              400,
              corsHeaders(env, req),
            );
          }

          const tickerUpper = String(tickerFilter).toUpperCase();
          const tickerTrades = allTrades.filter(
            (t) => String(t.ticker || "").toUpperCase() === tickerUpper,
          );

          if (tickerTrades.length === 0) {
            return sendJSON(
              {
                ok: true,
                message: `No trades found for ${tickerUpper}`,
                removed: 0,
                kept: 0,
              },
              200,
              corsHeaders(env, req),
            );
          }

          // Group by direction and find duplicates
          const byDirection = {};
          tickerTrades.forEach((trade) => {
            const dir = trade.direction || "UNKNOWN";
            if (!byDirection[dir]) {
              byDirection[dir] = [];
            }
            byDirection[dir].push(trade);
          });

          const tradesToKeep = [];
          const tradesToRemove = [];

          Object.keys(byDirection).forEach((direction) => {
            const dirTrades = byDirection[direction];

            // Keep the most recent open trade, or if all closed, keep the most recent one
            const openTrades = dirTrades.filter(
              (t) =>
                t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
            );

            if (openTrades.length > 0) {
              // Keep the most recent open trade
              const sortedOpen = openTrades.sort((a, b) => {
                const timeA = new Date(a.entryTime || 0).getTime();
                const timeB = new Date(b.entryTime || 0).getTime();
                return timeB - timeA;
              });
              tradesToKeep.push(sortedOpen[0]);
              tradesToRemove.push(...sortedOpen.slice(1));
              tradesToRemove.push(
                ...dirTrades.filter((t) => !openTrades.includes(t)),
              );
            } else {
              // All closed - keep the most recent one
              const sortedClosed = dirTrades.sort((a, b) => {
                const timeA = new Date(a.entryTime || 0).getTime();
                const timeB = new Date(b.entryTime || 0).getTime();
                return timeB - timeA;
              });
              tradesToKeep.push(sortedClosed[0]);
              tradesToRemove.push(...sortedClosed.slice(1));
            }
          });

          // Remove duplicates from allTrades
          const tradeIdsToRemove = new Set(tradesToRemove.map((t) => t.id));
          const cleanedTrades = allTrades.filter(
            (t) => !tradeIdsToRemove.has(t.id),
          );

          await kvPutJSON(KV, tradesKey, cleanedTrades);

          return sendJSON(
            {
              ok: true,
              ticker: tickerUpper,
              total: tickerTrades.length,
              kept: tradesToKeep.length,
              removed: tradesToRemove.length,
              keptTrades: tradesToKeep.map((t) => ({
                id: t.id,
                entryTime: t.entryTime,
                entryPrice: t.entryPrice,
                status: t.status,
              })),
              removedTrades: tradesToRemove.map((t) => ({
                id: t.id,
                entryTime: t.entryTime,
                entryPrice: t.entryPrice,
                status: t.status,
              })),
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/purge-ticker?key=...&ticker=RIOT - Delete ALL trades for a specific ticker
      if (routeKey === "POST /timed/debug/purge-ticker") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const tickerFilter = url.searchParams.get("ticker");

          if (!tickerFilter) {
            return sendJSON(
              { ok: false, error: "ticker parameter required" },
              400,
              corsHeaders(env, req),
            );
          }

          const tickerUpper = String(tickerFilter).toUpperCase();
          const beforeCount = allTrades.length;

          // Filter out all trades for this ticker
          const filteredTrades = allTrades.filter(
            (t) => String(t.ticker || "").toUpperCase() !== tickerUpper,
          );

          const removedCount = beforeCount - filteredTrades.length;

          // Save the cleaned trades (even if 0 removed from KV, we still clear D1)
          if (removedCount > 0) {
            await kvPutJSON(KV, tradesKey, filteredTrades);
          }

          // Also clear D1 positions, lots, execution_actions, trades, trade_events for this ticker
          let d1Cleared = { positions: 0, lots: 0, actions: 0, trades: 0, events: 0 };
          if (env?.DB) {
            try {
              // Get position IDs first (for FK cleanup)
              const posRows = await env.DB.prepare(
                `SELECT position_id FROM positions WHERE ticker = ?1`
              ).bind(tickerUpper).all();
              const posIds = (posRows?.results || []).map((r) => r.position_id);
              
              // Clear execution_actions and lots for each position
              for (const pid of posIds) {
                const actRes = await env.DB.prepare(
                  `DELETE FROM execution_actions WHERE position_id = ?1`
                ).bind(pid).run();
                d1Cleared.actions += actRes?.meta?.changes || 0;
                
                const lotRes = await env.DB.prepare(
                  `DELETE FROM lots WHERE position_id = ?1`
                ).bind(pid).run();
                d1Cleared.lots += lotRes?.meta?.changes || 0;
              }
              
              // Clear positions
              const posRes = await env.DB.prepare(
                `DELETE FROM positions WHERE ticker = ?1`
              ).bind(tickerUpper).run();
              d1Cleared.positions = posRes?.meta?.changes || 0;
              
              // Clear trade_events for trades of this ticker
              const tradeRows = await env.DB.prepare(
                `SELECT trade_id FROM trades WHERE ticker = ?1`
              ).bind(tickerUpper).all();
              for (const row of tradeRows?.results || []) {
                const evtRes = await env.DB.prepare(
                  `DELETE FROM trade_events WHERE trade_id = ?1`
                ).bind(row.trade_id).run();
                d1Cleared.events += evtRes?.meta?.changes || 0;
              }
              
              // Clear trades
              const trdRes = await env.DB.prepare(
                `DELETE FROM trades WHERE ticker = ?1`
              ).bind(tickerUpper).run();
              d1Cleared.trades = trdRes?.meta?.changes || 0;
            } catch (d1Err) {
              console.warn(`[purge-ticker] D1 cleanup error for ${tickerUpper}:`, d1Err?.message || d1Err);
            }
          }

          // Also clear the ticker's latest KV record to reset kanban state
          try {
            await KV.delete(`timed:latest:${tickerUpper}`);
          } catch (_) {}

          const totalD1 = d1Cleared.positions + d1Cleared.lots + d1Cleared.actions + d1Cleared.trades + d1Cleared.events;

          return sendJSON(
            {
              ok: true,
              ticker: tickerUpper,
              kv: { removed: removedCount, remaining: filteredTrades.length, beforeCount },
              d1: d1Cleared,
              message: `Purged ${removedCount} KV trades and ${totalD1} D1 records for ${tickerUpper}`,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/cleanup-all-duplicates?key=... - Remove all duplicate trades (keeps most recent per ticker+direction)
      if (routeKey === "POST /timed/debug/cleanup-all-duplicates") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

          const beforeCount = allTrades.length;

          // Group trades by ticker+direction, keep most recent
          const tradeMap = new Map();
          const duplicates = [];

          allTrades.forEach((trade) => {
            const key = `${String(trade.ticker || "").toUpperCase()}_${
              trade.direction || "UNKNOWN"
            }`;
            const existing = tradeMap.get(key);

            if (!existing) {
              tradeMap.set(key, trade);
            } else {
              // Compare entry times to keep the most recent
              const existingTime = existing.entryTime
                ? new Date(existing.entryTime).getTime()
                : 0;
              const currentTime = trade.entryTime
                ? new Date(trade.entryTime).getTime()
                : 0;

              if (currentTime > existingTime) {
                duplicates.push(existing);
                tradeMap.set(key, trade);
              } else {
                duplicates.push(trade);
              }
            }
          });

          const cleanedTrades = Array.from(tradeMap.values());
          const removedCount = beforeCount - cleanedTrades.length;

          if (removedCount === 0) {
            return sendJSON(
              {
                ok: true,
                message: "No duplicates found",
                beforeCount,
                afterCount: cleanedTrades.length,
                removed: 0,
              },
              200,
              corsHeaders(env, req),
            );
          }

          // Save cleaned trades
          await kvPutJSON(KV, tradesKey, cleanedTrades);

          // Group duplicates by ticker for summary
          const duplicatesByTicker = {};
          duplicates.forEach((d) => {
            const ticker = String(d.ticker || "UNKNOWN").toUpperCase();
            if (!duplicatesByTicker[ticker]) {
              duplicatesByTicker[ticker] = [];
            }
            duplicatesByTicker[ticker].push({
              id: d.id,
              entryTime: d.entryTime,
              entryPrice: d.entryPrice,
              status: d.status,
            });
          });

          return sendJSON(
            {
              ok: true,
              message: `Successfully removed ${removedCount} duplicate trades`,
              beforeCount,
              afterCount: cleanedTrades.length,
              removed: removedCount,
              duplicatesByTicker,
              summary: Object.keys(duplicatesByTicker).map((ticker) => ({
                ticker,
                count: duplicatesByTicker[ticker].length,
              })),
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/recalculate-ranks?key=... - Recalculate ranks for all tickers using new formula
      if (routeKey === "POST /timed/debug/recalculate-ranks") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const results = {
            processed: 0,
            updated: 0,
            errors: [],
          };

          // Process all tickers
          for (const ticker of tickerIndex) {
            try {
              const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
              if (!data) {
                results.errors.push({ ticker, error: "No data found" });
                continue;
              }

              // Recalculate rank using new formula
              const newRank = computeRank(data);
              const oldRank = Number(data.rank) || 0;

              // Only update if rank changed
              if (newRank !== oldRank) {
                data.rank = newRank;
                await kvPutJSON(KV, `timed:latest:${ticker}`, data);
                results.updated++;
              }

              results.processed++;
            } catch (err) {
              results.errors.push({ ticker, error: err.message });
            }
          }

          return sendJSON(
            {
              ok: true,
              message: `Recalculated ranks for ${results.processed} tickers`,
              results,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/fix-entry-prices?key=... - Fix entry prices for trades that used trigger_price instead of current price
      if (routeKey === "POST /timed/debug/fix-entry-prices") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          let fixed = 0;
          const fixedTrades = [];

          for (let i = 0; i < allTrades.length; i++) {
            const trade = allTrades[i];

            // Only fix OPEN trades (closed trades should keep their original entry price)
            if (trade.status !== "OPEN" && trade.status !== "TP_HIT_TRIM") {
              continue;
            }

            // Get latest ticker data
            const tickerData = await kvGetJSON(
              KV,
              `timed:latest:${trade.ticker}`,
            );
            if (!tickerData || !tickerData.price) {
              console.log(
                `[FIX ENTRY PRICES] Skipping ${trade.ticker} - no current price data`,
              );
              continue;
            }

            const currentPrice = Number(tickerData.price);
            const entryPrice = Number(trade.entryPrice);

            if (
              !Number.isFinite(currentPrice) ||
              !Number.isFinite(entryPrice)
            ) {
              continue;
            }

            // Check if entry price differs significantly from current price (>1%)
            const priceDiffPct =
              Math.abs(currentPrice - entryPrice) / entryPrice;
            if (priceDiffPct <= 0.01) {
              // Entry price is close to current price - likely correct
              continue;
            }

            // Check if this looks like it was created from trigger_price
            // (entry price matches trigger_price or is significantly different from current)
            const triggerPrice = tickerData.trigger_price
              ? Number(tickerData.trigger_price)
              : null;
            const entryMatchesTrigger =
              triggerPrice &&
              Math.abs(entryPrice - triggerPrice) / triggerPrice < 0.001;

            // Also check if trade is old (more than 1 hour)
            const entryTime = trade.entryTime
              ? new Date(trade.entryTime).getTime()
              : null;
            const now = Date.now();
            const isOldTrade = entryTime && now - entryTime > 60 * 60 * 1000;

            if (entryMatchesTrigger || isOldTrade || priceDiffPct > 0.05) {
              // Fix entry price to current price
              const correctedEntryPrice = currentPrice;

              // Recalculate shares based on new entry price
              const tickerUpper = String(trade.ticker || "").toUpperCase();
              const isFutures =
                FUTURES_SPECS[tickerUpper] || tickerUpper.endsWith("1!");
              const correctedShares =
                isFutures && FUTURES_SPECS[tickerUpper]
                  ? 1
                  : TRADE_SIZE / correctedEntryPrice;

              // Recalculate P&L with corrected entry price
              const tradeCalc = calculateTradePnl(
                tickerData,
                correctedEntryPrice,
                trade,
              );

              if (!tradeCalc) {
                console.log(
                  `[FIX ENTRY PRICES] Skipping ${trade.ticker} - cannot recalculate P&L`,
                );
                continue;
              }

              // Update trade
              const updatedTrade = {
                ...trade,
                entryPrice: correctedEntryPrice,
                shares: correctedShares,
                entryPriceCorrected: true,
                ...tradeCalc,
                history: [
                  ...(trade.history || []),
                  {
                    type: "ENTRY_PRICE_CORRECTION",
                    timestamp: new Date().toISOString(),
                    price: correctedEntryPrice,
                    shares: correctedShares,
                    value: correctedEntryPrice * correctedShares,
                    note: `Entry price corrected from $${entryPrice.toFixed(
                      2,
                    )} to $${correctedEntryPrice.toFixed(
                      2,
                    )} (was using trigger_price or outdated price)`,
                  },
                ],
                lastUpdate: new Date().toISOString(),
              };

              allTrades[i] = updatedTrade;
              fixed++;
              fixedTrades.push({
                ticker: trade.ticker,
                direction: trade.direction,
                oldEntryPrice: entryPrice.toFixed(2),
                newEntryPrice: correctedEntryPrice.toFixed(2),
                oldPnl: trade.pnl?.toFixed(2) || "0.00",
                newPnl: tradeCalc.pnl?.toFixed(2) || "0.00",
              });

              console.log(
                `[FIX ENTRY PRICES] Fixed ${trade.ticker} ${
                  trade.direction
                }: $${entryPrice.toFixed(2)} -> $${correctedEntryPrice.toFixed(
                  2,
                )} (P&L: $${(trade.pnl || 0).toFixed(
                  2,
                )} -> $${tradeCalc.pnl.toFixed(2)})`,
              );
            }
          }

          if (fixed > 0) {
            await kvPutJSON(KV, tradesKey, allTrades);
            console.log(
              `[FIX ENTRY PRICES] Fixed ${fixed} trades with incorrect entry prices`,
            );
          }

          return sendJSON(
            {
              ok: true,
              message: `Fixed ${fixed} trades with incorrect entry prices`,
              fixed,
              fixedTrades,
            },
            200,
            corsHeaders(env, req, true),
          );
        } catch (err) {
          console.error(`[FIX ENTRY PRICES ERROR]`, {
            error: String(err),
            message: err.message,
            stack: err.stack,
          });
          return sendJSON(
            { ok: false, error: "internal_error", message: err.message },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/debug/fix-backfill-trades?key=... - Fix entryTime for backfilled trades
      if (routeKey === "POST /timed/debug/fix-backfill-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const now = Date.now();
          let fixed = 0;
          const fixedTrades = [];

          const threeDaysAgo = now - 3 * 24 * 60 * 60 * 1000; // 3 days ago

          for (const trade of allTrades) {
            let updated = false;
            const updatedTrade = { ...trade };
            let bestMatchTimestamp = null;
            let bestMatchPrice = null;
            let matchMethod = null;

            // Method 1: Check if trade has triggerTimestamp that's significantly older than entryTime
            if (trade.triggerTimestamp && trade.entryTime) {
              const triggerTime = new Date(trade.triggerTimestamp).getTime();
              const entryTime = new Date(trade.entryTime).getTime();
              const isBackfill =
                triggerTime && now - triggerTime > 60 * 60 * 1000; // More than 1 hour old

              if (isBackfill && triggerTime < entryTime) {
                bestMatchTimestamp = trade.triggerTimestamp;
                bestMatchPrice = trade.entryPrice;
                matchMethod = "triggerTimestamp";
              }
            }

            // Method 2: Search trail data for when entry price was actually touched (last 3 days)
            if (!bestMatchTimestamp && trade.ticker && trade.entryPrice) {
              try {
                const trail =
                  (await kvGetJSON(KV, `timed:trail:${trade.ticker}`)) || [];
                const entryPrice = Number(trade.entryPrice);
                const priceTolerance = entryPrice * 0.005; // 0.5% tolerance

                // Search through trail points in reverse (most recent first)
                // Find the point where price matches entryPrice within tolerance
                for (let i = trail.length - 1; i >= 0; i--) {
                  const point = trail[i];
                  if (!point.ts || !point.price) continue;

                  const pointTime = Number(point.ts);
                  const pointPrice = Number(point.price);

                  // Only consider points from last 3 days
                  if (pointTime < threeDaysAgo) continue;

                  // Check if price matches entry price (within tolerance)
                  const priceDiff = Math.abs(pointPrice - entryPrice);
                  if (priceDiff <= priceTolerance) {
                    // Found a match - use this timestamp
                    bestMatchTimestamp = new Date(pointTime).toISOString();
                    bestMatchPrice = pointPrice;
                    matchMethod = "trail_price_match";
                    break; // Use first match (most recent)
                  }
                }

                // If no exact match, find closest price match in last 3 days
                if (!bestMatchTimestamp) {
                  let closestDiff = Infinity;
                  let closestPoint = null;
                  for (const point of trail) {
                    if (!point.ts || !point.price) continue;
                    const pointTime = Number(point.ts);
                    const pointPrice = Number(point.price);
                    if (pointTime < threeDaysAgo) continue;

                    const priceDiff = Math.abs(pointPrice - entryPrice);
                    if (priceDiff < closestDiff) {
                      closestDiff = priceDiff;
                      closestPoint = point;
                    }
                  }

                  // Use closest match if it's within 2% of entry price
                  if (closestPoint && closestDiff <= entryPrice * 0.02) {
                    bestMatchTimestamp = new Date(
                      Number(closestPoint.ts),
                    ).toISOString();
                    bestMatchPrice = Number(closestPoint.price);
                    matchMethod = "trail_closest_match";
                  }
                }
              } catch (err) {
                // Ignore errors - trail data might not exist
              }
            }

            // Method 3: Try to get triggerTimestamp from ticker's latest data
            if (!bestMatchTimestamp && trade.ticker) {
              try {
                const tickerData = await kvGetJSON(
                  KV,
                  `timed:latest:${trade.ticker}`,
                );
                if (tickerData && tickerData.trigger_ts) {
                  const triggerTime = Number(tickerData.trigger_ts);
                  // Only use if it's from last 3 days and older than current entryTime
                  if (triggerTime >= threeDaysAgo) {
                    const entryTime = trade.entryTime
                      ? new Date(trade.entryTime).getTime()
                      : now;
                    if (triggerTime < entryTime) {
                      bestMatchTimestamp = new Date(triggerTime).toISOString();
                      bestMatchPrice =
                        tickerData.trigger_price || trade.entryPrice;
                      matchMethod = "ticker_trigger_ts";
                      // Store it in the trade for future reference
                      updatedTrade.triggerTimestamp = bestMatchTimestamp;
                    }
                  }
                }
              } catch (err) {
                // Ignore errors
              }
            }

            // Update entryTime if we found a better match
            if (bestMatchTimestamp && trade.entryTime) {
              const currentEntryTime = new Date(trade.entryTime).getTime();
              const newEntryTime = new Date(bestMatchTimestamp).getTime();

              // Only update if new time is significantly different (more than 5 minutes) and older
              if (
                Math.abs(newEntryTime - currentEntryTime) > 5 * 60 * 1000 &&
                newEntryTime < currentEntryTime
              ) {
                updatedTrade.entryTime = bestMatchTimestamp;
                updated = true;

                // Also update entry price if we found a better match from trail
                if (
                  bestMatchPrice &&
                  matchMethod.includes("trail") &&
                  Math.abs(bestMatchPrice - trade.entryPrice) >
                    trade.entryPrice * 0.01
                ) {
                  updatedTrade.entryPrice = bestMatchPrice;
                }
              }
            }

            // Update history entry timestamp if it matches the old entryTime
            if (
              updated &&
              updatedTrade.history &&
              Array.isArray(updatedTrade.history)
            ) {
              updatedTrade.history = updatedTrade.history.map((event) => {
                if (
                  event.type === "ENTRY" &&
                  event.timestamp === trade.entryTime
                ) {
                  return {
                    ...event,
                    timestamp: updatedTrade.entryTime,
                    price: updatedTrade.entryPrice || event.price,
                  };
                }
                return event;
              });
            }

            if (updated) {
              fixed++;
              fixedTrades.push({
                id: trade.id,
                ticker: trade.ticker,
                oldEntryTime: trade.entryTime,
                newEntryTime: updatedTrade.entryTime,
                oldEntryPrice: trade.entryPrice,
                newEntryPrice: updatedTrade.entryPrice,
                matchMethod: matchMethod,
              });
              const index = allTrades.findIndex((t) => t.id === trade.id);
              if (index >= 0) {
                allTrades[index] = updatedTrade;
              }
            }
          }

          if (fixed > 0) {
            await kvPutJSON(KV, tradesKey, allTrades);
          }

          return sendJSON(
            {
              ok: true,
              fixed,
              totalTrades: allTrades.length,
              fixedTrades: fixedTrades.slice(0, 50), // Show first 50
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/clear-all-trades?key=... - Clear all trades and start fresh
      if (routeKey === "POST /timed/debug/clear-all-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const tradeCount = allTrades.length;

          // Clear all trades
          await KV.delete(tradesKey);

          return sendJSON(
            {
              ok: true,
              message: "All trades cleared successfully",
              clearedCount: tradeCount,
              note: "New trades will be created automatically as TradingView alerts come in",
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/simulate-trades?key=... - Manually simulate trades for all tickers
      if (routeKey === "POST /timed/debug/simulate-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const results = {
            processed: 0,
            created: 0,
            updated: 0,
            skipped: 0,
            errors: [],
          };

          // Process first 50 tickers to avoid timeout
          for (const ticker of tickerIndex.slice(0, 50)) {
            try {
              const latestData = await kvGetJSON(KV, `timed:latest:${ticker}`);
              if (latestData) {
                const prevLatest = null; // No previous data for manual simulation
                await processTradeSimulation(
                  KV,
                  ticker,
                  latestData,
                  prevLatest,
                  env,
                );
                results.processed++;
              } else {
                results.skipped++;
              }
            } catch (err) {
              results.errors.push({ ticker, error: err.message });
            }
          }

          // Get final trade count
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const openTrades = allTrades.filter(
            (t) =>
              t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
          );

          return sendJSON(
            {
              ok: true,
              message: `Processed ${results.processed} tickers`,
              results,
              currentTrades: {
                total: allTrades.length,
                open: openTrades.length,
              },
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/ml/train?key=... - Trigger ML model training from labeled queue
      if (routeKey === "POST /timed/ml/train") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const limit = Number(url.searchParams.get("limit")) || 75;
          const force = url.searchParams.get("force") === "1";
          const result = await mlV1TrainFromQueue(env, KV, limit, force);
          return sendJSON(result, 200, corsHeaders(env, req, true));
        } catch (error) {
          return sendJSON(
            { ok: false, error: String(error) },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/ml/backfill-queue?key=... - Backfill ML queue from timed_trail
      if (routeKey === "POST /timed/ml/backfill-queue") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const db = env?.DB;
          if (!db) {
            return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req, true));
          }

          await d1EnsureMlV1Schema(env);
          
          const daysBack = Number(url.searchParams.get("days")) || 7;
          const cutoff = Date.now() - (daysBack * 24 * 60 * 60 * 1000);
          
          // Get recent trail data
          const rows = await db.prepare(
            `SELECT ticker, ts, payload_json FROM timed_trail 
             WHERE ts >= ?1 
             ORDER BY ts DESC 
             LIMIT 1000`
          ).bind(cutoff).all();

          let queued = 0;
          const horizons = [4 * 60 * 60 * 1000, 24 * 60 * 60 * 1000]; // 4h, 1d

          for (const row of (rows?.results || [])) {
            try {
              const payload = JSON.parse(row.payload_json);
              await d1EnqueueMlV1(env, row.ticker, payload, horizons);
              queued++;
            } catch (e) {
              // Skip invalid entries
            }
          }

          return sendJSON(
            { ok: true, queued, daysBack, processed: rows?.results?.length || 0 },
            200,
            corsHeaders(env, req, true),
          );
        } catch (error) {
          return sendJSON(
            { ok: false, error: String(error) },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/admin/reprocess-kanban?key=...&limit=...&offset=...&ticker=...&resetTrades=1&from=YYYY-MM-DD&to=YYYY-MM-DD
      // Re-run Kanban classification + trade sim for all tickers. Batched to avoid subrequest limits.
      // Default limit=15 per call; use offset to process remaining (e.g. offset=15, offset=30).
      // resetTrades=1: purge open trades for batch tickers (optionally in from/to range) and clear entry state before reprocess.
      if (routeKey === "POST /timed/admin/reprocess-kanban") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const qLimit = Number(url.searchParams.get("limit") || "15");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));
        const resetTrades = url.searchParams.get("resetTrades") === "1" || url.searchParams.get("resetTrades") === "true";
        const fromDay = url.searchParams.get("from") || null; // YYYY-MM-DD
        const toDay = url.searchParams.get("to") || null;
        const DEFAULT_BATCH = 15;

        const tickersList = (await kvGetJSON(KV, "timed:tickers")) || [];
        const filtered = Array.isArray(tickersList)
          ? tickersList.filter((t) => {
              if (!t) return false;
              if (tickerFilter)
                return String(t).toUpperCase() === String(tickerFilter);
              return true;
            })
          : [];
        const limit = Math.min(
          qLimit > 0 ? qLimit : DEFAULT_BATCH,
          filtered.length,
          25,
        );
        const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
        const slice = filtered.slice(offset, offset + limit);

        // resetTrades: purge ALL trades (open + closed) for batch tickers in from/to window for clean slate
        let tradesPurged = 0;
        if (resetTrades && slice.length > 0) {
          const allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
          const sliceSet = new Set(slice.map((t) => String(t || "").toUpperCase()));
          let tsMin = null;
          let tsMax = null;
          if (fromDay && /^\d{4}-\d{2}-\d{2}$/.test(fromDay)) {
            tsMin = nyWallMidnightToUtcMs(fromDay) ?? null;
          }
          if (toDay && /^\d{4}-\d{2}-\d{2}$/.test(toDay)) {
            const endOfDay = nyWallTimeToUtcMs(toDay, 23, 59, 59);
            tsMax = endOfDay != null ? endOfDay + 999 : null;
          }
          const kept = allTrades.filter((t) => {
            const ticker = String(t?.ticker || "").toUpperCase();
            if (!sliceSet.has(ticker)) return true;
            const entryTs = Number(t?.entry_ts ?? t?.entryTime);
            if (!Number.isFinite(entryTs)) return true;
            if (tsMin != null && entryTs < tsMin) return true;
            if (tsMax != null && entryTs > tsMax) return true;
            tradesPurged += 1;
            return false;
          });
          await kvPutJSON(KV, "timed:trades:all", kept);
        }

        let updated = 0;
        let tradesCreated = 0;
        const laneCounts = {};
        const errors = [];

        for (const t of slice) {
          try {
            const ticker = String(t || "").toUpperCase();
            if (!ticker) continue;
            const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
            if (!latest || typeof latest !== "object") continue;

            const existing = latest;
            const payload = { ...latest };

            // resetTrades: clear entry state so we reprocess from scratch (no phantom Enter Now -> Exit)
            if (resetTrades) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              // Merge entry_ts/entry_price from existing + D1 position
              if (existing?.entry_ts != null || existing?.entry_price != null) {
                if (payload.entry_ts == null && Number.isFinite(Number(existing?.entry_ts)))
                  payload.entry_ts = Number(existing.entry_ts);
                if (payload.entry_price == null && Number.isFinite(Number(existing?.entry_price)))
                  payload.entry_price = Number(existing.entry_price);
              }
              // D1 SINGLE SOURCE OF TRUTH
              const openPosition = env?.DB ? await getPositionContext(env, ticker) : null;
              const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
              if (hasOpenPosition) {
                if (payload.entry_ts == null && openPosition.entry_ts) {
                  payload.entry_ts = openPosition.entry_ts;
                }
                if (payload.entry_price == null && openPosition.avg_entry_price > 0) {
                  payload.entry_price = openPosition.avg_entry_price;
                }
              }
              payload.__position_context = openPosition;
            }

            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) {
              payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
              payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
            }

            // D1 position context for Kanban classification
            const openPosition = payload.__position_context || (env?.DB ? await getPositionContext(env, ticker) : null);
            const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
            
            const prevStage = existing?.kanban_stage;
            // Pass payload.ts as asOfTs for consistent trigger freshness check
            const payloadTs = Number(payload?.ts) || Date.now();
            const stage = classifyKanbanStage(payload, openPosition, payloadTs);
            let finalStage = stage;

            // Recycle rule: position always wins
            const prevStageLegacy = prevStage === "archive" || prevStage === "closed";
            const isManagementStage = ["active", "trim", "exit", "hold", "just_entered"].includes(stage);
            if (prevStageLegacy && isManagementStage && !hasOpenPosition) {
              finalStage = "watch";
              if (!payload.flags) payload.flags = {};
              payload.flags.recycled_from_archive = true;
            }

            const tsNow = Number(payload?.ts) || Date.now();
            const dayKeyLive = nyTradingDayKey(tsNow);
            const marketOpenLive = dayKeyLive ? nyWallTimeToUtcMs(dayKeyLive, 9, 30, 0) : null;
            const existingTsLive = existing?.ts ?? existing?.ingest_ts;
            const firstBarAfterGapLive = isFirstBarOfDayAfterGap(existingTsLive, tsNow, marketOpenLive);

            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existing?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
              const cycleSide = existing?.kanban_cycle_side != null ? String(existing.kanban_cycle_side) : null;
              const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 &&
                Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
              const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig &&
                !!cycleSide && !!curSide && cycleSide === curSide;
              if (firstBarAfterGapLive) {
                if (!payload.flags) payload.flags = {};
                payload.flags.first_bar_of_day_bridge = true;
              } else {
                if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                  finalStage = "watch";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_watch_missing_trigger = true;
                } else if (!cycleOk) {
                  finalStage = "enter";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_enter_gate = true;
                }
              }
            }

            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = tsNow;
              payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              if (firstBarAfterGapLive) {
                payload.kanban_cycle_enter_now_ts = tsNow;
                payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : tsNow;
                payload.kanban_cycle_side = sideFromStateOrScores(payload) != null ? String(sideFromStateOrScores(payload)) : null;
                if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                if (payload.entry_ts == null && Number.isFinite(tsNow)) payload.entry_ts = tsNow;
              } else {
                payload.kanban_cycle_enter_now_ts = existing?.kanban_cycle_enter_now_ts || null;
                payload.kanban_cycle_trigger_ts = existing?.kanban_cycle_trigger_ts || null;
                payload.kanban_cycle_side = existing?.kanban_cycle_side || null;
              }
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }

            if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = tsNow;
            }

            if (finalStage === "enter_now" && prevStage !== "enter_now") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) {
                payload.entry_price = price;
                payload.entry_ts = payload.ts;
              }
            }
            if (finalStage && existing?.entry_price) {
              payload.entry_price = existing.entry_price;
              payload.entry_ts = existing.entry_ts;
            }

            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);

            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;

            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
            updated += 1;

            const tradesBefore = (await kvGetJSON(KV, "timed:trades:all")) || [];
            const countBefore = tradesBefore.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            await processTradeSimulation(KV, ticker, payload, existing, env, { forceUseIngestTs: true });
            const tradesAfter = (await kvGetJSON(KV, "timed:trades:all")) || [];
            const countAfter = tradesAfter.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
          } catch (e) {
            errors.push({ ticker: t || null, error: String(e?.message || e) });
          }
        }

        try {
          await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50);
        } catch (syncErr) {
          errors.push({ sync: String(syncErr?.message || syncErr) });
        }

        const nextOffset = offset + slice.length;
        const hasMore = nextOffset < filtered.length;

        return sendJSON(
          {
            ok: true,
            tickersProcessed: updated,
            tradesCreated,
            tradesPurged: resetTrades ? tradesPurged : undefined,
            laneCounts,
            offset,
            nextOffset: hasMore ? nextOffset : null,
            hasMore,
            total: filtered.length,
            errorsCount: errors.length,
            errors: errors.slice(0, 10),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/replay-ticker?key=...&ticker=BE&date=YYYY-MM-DD
      // Single-ticker replay: fetches trail via d1GetTrailRange (no payload_json), processes chronologically.
      // Use this for ticker-by-ticker replay; avoids D1 large-result limits.
      if (routeKey === "POST /timed/admin/replay-ticker") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        if (!tickerParam) {
          return sendJSON({ ok: false, error: "missing ticker" }, 400, corsHeaders(env, req));
        }
        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";

        const trailRes = await d1GetTrailRange(env, tickerParam, Math.floor(tsStart), 500);
        if (!trailRes?.ok) {
          return sendJSON(
            { ok: false, error: "trail_fetch_failed", detail: trailRes?.error || "unknown" },
            500,
            corsHeaders(env, req),
          );
        }
        const trail = (trailRes?.trail || []).filter(
          (p) => { const ts = Number(p?.ts); return Number.isFinite(ts) && ts >= tsStart && ts <= tsEnd; },
        );
        let rows;
        let replaySource = "timed_trail";

        if (trail.length > 0) {
          rows = trail.map((p) => {
            const ts = Number(p?.ts);
            const obj = { ticker: tickerParam, ts, price: p?.price, htf_score: p?.htf_score, ltf_score: p?.ltf_score, completion: p?.completion, phase_pct: p?.phase_pct, state: p?.state, rank: p?.rank, flags: p?.flags || {}, trigger_reason: p?.trigger_reason, trigger_dir: p?.trigger_dir, trigger_ts: p?.trigger_ts ?? ts, sl: p?.sl, tp: p?.tp, tp_levels: p?.tp_levels, kanban_stage: p?.kanban_stage };
            return { ticker: tickerParam, ts: obj.ts, payload_json: JSON.stringify(obj) };
          });
        } else {
          // Fallback: reconstruct from trail_5m_facts (for data older than 48h)
          replaySource = "trail_5m_facts";
          const db = env?.DB;
          let factsRows = [];
          if (db) {
            try {
              const factsRes = await db
                .prepare(
                  `SELECT bucket_ts, price_open, price_high, price_low, price_close,
                          htf_score_avg, ltf_score_avg, state, rank, completion, phase_pct,
                          kanban_stage_start, kanban_stage_end,
                          had_squeeze_release, had_ema_cross, had_st_flip, had_momentum_elite
                   FROM trail_5m_facts
                   WHERE ticker = ?1 AND bucket_ts >= ?2 AND bucket_ts <= ?3
                   ORDER BY bucket_ts ASC`,
                )
                .bind(tickerParam, tsStart, tsEnd)
                .all();
              factsRows = factsRes?.results || [];
            } catch (e) {
              console.error(`[REPLAY-TICKER] Facts fallback error:`, e);
            }
          }
          rows = factsRows.map((f) => {
            const ts = Number(f.bucket_ts);
            const obj = {
              ticker: tickerParam, ts,
              price: f.price_close ?? f.price_open,
              htf_score: f.htf_score_avg, ltf_score: f.ltf_score_avg,
              state: f.state, rank: f.rank,
              completion: f.completion, phase_pct: f.phase_pct,
              trigger_ts: ts, trigger_reason: null, trigger_dir: null,
              kanban_stage: f.kanban_stage_end || f.kanban_stage_start || null,
              flags: {
                squeeze_release: !!f.had_squeeze_release,
                ema_cross: !!f.had_ema_cross,
                st_flip: !!f.had_st_flip,
                momentum_elite: !!f.had_momentum_elite,
              },
            };
            return { ticker: tickerParam, ts, payload_json: JSON.stringify(obj) };
          });
        }

        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        let tradesPurged = 0;
        if (cleanSlate && rows.length > 0) {
          const kept = allTrades.filter((t) => {
            if (String(t?.ticker || "").toUpperCase() !== tickerParam) return true;
            const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
            if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
            if (entryTs < tsStart || entryTs > tsEnd) return true;
            tradesPurged += 1;
            return false;
          });
          allTrades = kept;
          await kvPutJSON(KV, "timed:trades:all", kept);
        }

        const existing = (await kvGetJSON(KV, `timed:latest:${tickerParam}`)) || {};
        const stateMap = { [tickerParam]: cleanSlate ? { ...existing, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null } : { ...existing } };
        const findOpenInArray = (trades, sym) => trades.find((x) => String(x?.ticker || "").toUpperCase() === sym && isOpenTradeStatus(x?.status)) || null;
        const replayCtx = { allTrades, debugEntries: [], processDebug: [] };
        let processed = 0, tradesCreated = 0;
        const laneCounts = {};
        const replayTimeline = []; // Per-snapshot timeline for time-travel

        for (const row of rows) {
          try {
            const ticker = tickerParam;
            let payload;
            try { payload = row.payload_json ? JSON.parse(row.payload_json) : null; } catch { continue; }
            if (!payload || typeof payload !== "object") continue;
            const rowTs = Number(row?.ts);
            if (!Number.isFinite(rowTs)) continue;
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            const existingState = stateMap[ticker] || {};
            const existingTs = Number(existingState?.ts ?? existingState?.ingest_ts);
            const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;
            if (isEarlierThanStored) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              if (existingState?.entry_ts != null && payload.entry_ts == null) payload.entry_ts = Number(existingState.entry_ts);
              if (existingState?.entry_price != null && payload.entry_price == null) payload.entry_price = Number(existingState.entry_price);
              if (existingState?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existingState.kanban_cycle_enter_now_ts;
              if (existingState?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existingState.kanban_cycle_trigger_ts;
              if (existingState?.kanban_cycle_side != null) payload.kanban_cycle_side = existingState.kanban_cycle_side;
            }
            const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
            if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
              const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
              const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
              if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
              if (payload.entry_price == null && Number.isFinite(ep) && ep > 0) payload.entry_price = ep;
            }
            // Compute derived fields (rr, score) - not stored in ingest_receipts/trail
            if (payload.rr == null || !Number.isFinite(Number(payload.rr))) {
              payload.rr = computeRR(payload);
              if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
            }
            if (payload.score == null && payload.rank == null) {
              payload.score = computeRank(payload);
            }
            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) { payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED"; payload.flags.move_completed = payload.move_status?.status === "COMPLETED"; }
            const prevStage = existingState?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            let finalStage = stage;
            if (prevStage === "archive" && ["hold", "just_entered", "trim", "exit"].includes(stage)) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.recycled_from_archive = true; }
            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existingState?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existingState?.kanban_cycle_trigger_ts);
              const cycleSide = existingState?.kanban_cycle_side != null ? String(existingState.kanban_cycle_side) : null;
              const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 && Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
              const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig && !!cycleSide && !!curSide && cycleSide === curSide;
              if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.forced_watch_missing_trigger = true; }
              else if (!cycleOk) { finalStage = "enter"; if (!payload.flags) payload.flags = {}; payload.flags.forced_enter_gate = true; }
            }
            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = rowTs;
              payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              payload.kanban_cycle_enter_now_ts = existingState?.kanban_cycle_enter_now_ts ?? null;
              payload.kanban_cycle_trigger_ts = existingState?.kanban_cycle_trigger_ts ?? null;
              payload.kanban_cycle_side = existingState?.kanban_cycle_side ?? null;
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }
            if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }
            if (finalStage === "enter_now" && prevStage !== "enter_now") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) { payload.entry_price = price; payload.entry_ts = rowTs; }
            }
            if (finalStage && existingState?.entry_price) { payload.entry_price = existingState.entry_price; payload.entry_ts = existingState.entry_ts; }
            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;
            // Capture per-snapshot timeline point
            replayTimeline.push({
              ts: rowTs,
              ticker,
              price: payload.price != null ? Number(payload.price) : null,
              htf_score: payload.htf_score != null ? Number(payload.htf_score) : null,
              ltf_score: payload.ltf_score != null ? Number(payload.ltf_score) : null,
              state: payload.state || null,
              kanban_stage: finalStage,
              prev_stage: prevStage || null,
            });
            stateMap[ticker] = payload;
            const countBefore = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            // Capture debug for first few "enter" rows
            const openTradeCheck = replayCtx.allTrades.find((t) => String(t?.ticker || "").toUpperCase() === ticker && (String(t?.status || "").toUpperCase() === "OPEN" || String(t?.status || "").toUpperCase() === "TP_HIT_TRIM"));
            if ((finalStage === "enter" || finalStage === "enter_now") && replayCtx.debugEntries.length < 3) {
              replayCtx.debugEntries.push({
                ts: rowTs,
                stage: finalStage,
                entryPath: payload.__entry_path,
                state: payload.state,
                htf: payload.htf_score,
                ltf: payload.ltf_score,
                price: payload.price,
                sl: payload.sl,
                tp: payload.tp,
                atr: payload.atr,
                tradeCountBefore: countBefore,
                openTradeExists: !!openTradeCheck,
                openTradeStatus: openTradeCheck?.status || null,
              });
            }
            await processTradeSimulation(KV, ticker, payload, existingState, env, { forceUseIngestTs: true, replayBatchContext: replayCtx, asOfTs: rowTs });
            const countAfter = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
            if ((finalStage === "enter" || finalStage === "enter_now") && replayCtx.debugEntries.length > 0 && replayCtx.debugEntries[replayCtx.debugEntries.length - 1].ts === rowTs) {
              replayCtx.debugEntries[replayCtx.debugEntries.length - 1].tradeCountAfter = countAfter;
              replayCtx.debugEntries[replayCtx.debugEntries.length - 1].tradeCreated = countAfter > countBefore;
            }
            processed += 1;
          } catch (e) {
            console.error(`[REPLAY-TICKER] ${tickerParam} row error:`, e);
          }
        }

        await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
        await kvPutJSON(KV, `timed:latest:${tickerParam}`, stateMap[tickerParam] || {});
        try { await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50); } catch {}
        return sendJSON({
          ok: true,
          ticker: tickerParam,
          day: dayKey,
          source: replaySource,
          rowsProcessed: processed,
          tradesCreated,
          tradesPurged,
          laneCounts,
          timeline: replayTimeline,
          debugEntries: replayCtx.debugEntries || [],
          processDebug: replayCtx.processDebug || [],
        }, 200, corsHeaders(env, req));
      }

      // POST /timed/admin/replay-ticker-d1?key=...&ticker=AAPL&date=YYYY-MM-DD&cleanSlate=1
      // Single-ticker replay from D1 timed_trail (payload_json). Processes all rows in one request, writes KV only at end (avoids 429).
      if (routeKey === "POST /timed/admin/replay-ticker-d1") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }
        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        if (!tickerParam) {
          return sendJSON({ ok: false, error: "missing ticker" }, 400, corsHeaders(env, req));
        }
        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";
        const debug = url.searchParams.get("debug") === "1" || url.searchParams.get("debug") === "true";
        const limit = Math.min(2000, Math.max(1, parseInt(url.searchParams.get("limit") || "1000", 10)));

        let rows = [];
        try {
          const res = await db.prepare(
            `SELECT ts, payload_json FROM timed_trail
             WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3 AND payload_json IS NOT NULL
             ORDER BY ts ASC LIMIT ?4`,
          ).bind(tickerParam, Math.floor(tsStart), Math.floor(tsEnd), limit).all();
          const results = res?.results || [];
          rows = results.map((r) => ({
            ticker: tickerParam,
            ts: Number(r?.ts),
            payload_json: r?.payload_json ?? null,
          })).filter((r) => r.ts != null && Number.isFinite(r.ts));
        } catch (e) {
          return sendJSON({ ok: false, error: "d1_query_failed", detail: String(e?.message || e) }, 500, corsHeaders(env, req));
        }

        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        let tradesPurged = 0;
        if (cleanSlate && rows.length > 0) {
          const kept = allTrades.filter((t) => {
            if (String(t?.ticker || "").toUpperCase() !== tickerParam) return true;
            const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
            if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
            if (entryTs < tsStart || entryTs > tsEnd) return true;
            tradesPurged += 1;
            return false;
          });
          allTrades = kept;
          await kvPutJSON(KV, "timed:trades:all", kept);
        }

        const existing = (await kvGetJSON(KV, `timed:latest:${tickerParam}`)) || {};
        let stateMap = { [tickerParam]: cleanSlate ? { ...existing, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null } : { ...existing } };

        // Bridge 4pm–9:30am: seed with last known state before tsStart so first row can detect justEnteredCorridor / enteredAligned
        const includePrevPeriod = url.searchParams.get("includePrevPeriod") !== "0" && url.searchParams.get("includePrevPeriod") !== "false";
        let prevPeriodSeeded = false;
        if (includePrevPeriod && rows.length > 0) {
          try {
            const prevRow = await db.prepare(
              `SELECT ts, payload_json FROM timed_trail
               WHERE ticker = ?1 AND ts < ?2 AND payload_json IS NOT NULL
               ORDER BY ts DESC LIMIT 1`,
            ).bind(tickerParam, Math.floor(tsStart)).first();
            if (prevRow?.payload_json) {
              let prevPayload = null;
              try { prevPayload = JSON.parse(prevRow.payload_json); } catch {}
              if (prevPayload && typeof prevPayload === "object") {
                const prevTs = Number(prevRow?.ts);
                prevPayload.ts = prevTs;
                prevPayload.ingest_ts = prevTs;
                if ((prevPayload.trigger_ts == null || !Number.isFinite(Number(prevPayload.trigger_ts))) && Number.isFinite(prevTs)) prevPayload.trigger_ts = prevTs < 1e12 ? prevTs * 1000 : prevTs;
                if ((prevPayload.sl == null || !Number.isFinite(Number(prevPayload.sl))) && prevPayload.sl_price != null) prevPayload.sl = prevPayload.sl_price;
                const tpVal = prevPayload.tp ?? prevPayload.tp_max_price ?? prevPayload.tp_target_price ?? prevPayload.tp_target;
                if ((prevPayload.tp == null || !Number.isFinite(Number(prevPayload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) prevPayload.tp = Number(tpVal);
                prevPayload.move_status = computeMoveStatus(prevPayload);
                if (prevPayload.flags) { prevPayload.flags.move_invalidated = prevPayload.move_status?.status === "INVALIDATED"; prevPayload.flags.move_completed = prevPayload.move_status?.status === "COMPLETED"; }
                prevPayload.kanban_stage = classifyKanbanStage(prevPayload);
                prevPayload.kanban_meta = deriveKanbanMeta(prevPayload, prevPayload.kanban_stage);
                stateMap = { [tickerParam]: prevPayload };
                prevPeriodSeeded = true;
              }
            }
          } catch (e) {
            console.error("[REPLAY-TICKER-D1] prev-period seed failed:", e?.message || e);
          }
        }

        const findOpenInArray = (trades, sym) => trades.find((x) => String(x?.ticker || "").toUpperCase() === sym && isOpenTradeStatus(x?.status)) || null;
        const replayCtx = { allTrades };
        let processed = 0, tradesCreated = 0;
        const laneCounts = {};

        for (const row of rows) {
          try {
            const ticker = tickerParam;
            let payload;
            try { payload = row.payload_json ? JSON.parse(row.payload_json) : null; } catch { continue; }
            if (!payload || typeof payload !== "object") continue;
            const rowTs = Number(row?.ts);
            if (!Number.isFinite(rowTs)) continue;
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
              payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
            }
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
            const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
            if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);

            const existingState = stateMap[ticker] || {};
            const existingTs = Number(existingState?.ts ?? existingState?.ingest_ts);
            const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;
            if (isEarlierThanStored) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              if (existingState?.entry_ts != null && payload.entry_ts == null) payload.entry_ts = Number(existingState.entry_ts);
              if (existingState?.entry_price != null && payload.entry_price == null) payload.entry_price = Number(existingState.entry_price);
              if (existingState?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existingState.kanban_cycle_enter_now_ts;
              if (existingState?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existingState.kanban_cycle_trigger_ts;
              if (existingState?.kanban_cycle_side != null) payload.kanban_cycle_side = existingState.kanban_cycle_side;
            }
            const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
            if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
              const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
              const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
              if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
              if (payload.entry_price == null && Number.isFinite(ep) && ep > 0) payload.entry_price = ep;
            }
            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) { payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED"; payload.flags.move_completed = payload.move_status?.status === "COMPLETED"; }
            const prevStage = existingState?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            let finalStage = stage;
            if (prevStage === "archive" && ["hold", "just_entered", "trim", "exit"].includes(stage)) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.recycled_from_archive = true; }
            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            const firstBarAfterGap = isFirstBarOfDayAfterGap(existingTs, rowTs, tsStart);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existingState?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existingState?.kanban_cycle_trigger_ts);
              const cycleSide = existingState?.kanban_cycle_side != null ? String(existingState.kanban_cycle_side) : null;
              const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 && Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
              const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig && !!cycleSide && !!curSide && cycleSide === curSide;
              if (firstBarAfterGap) {
                if (!payload.flags) payload.flags = {};
                payload.flags.first_bar_of_day_bridge = true;
              } else {
                if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.forced_watch_missing_trigger = true; }
                else if (!cycleOk) { finalStage = "enter"; if (!payload.flags) payload.flags = {}; payload.flags.forced_enter_gate = true; }
              }
            }
            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = rowTs;
              payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              if (firstBarAfterGap) {
                payload.kanban_cycle_enter_now_ts = rowTs;
                payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : rowTs;
                payload.kanban_cycle_side = sideFromStateOrScores(payload);
                if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                if (payload.entry_ts == null && Number.isFinite(rowTs)) payload.entry_ts = rowTs;
              } else {
                payload.kanban_cycle_enter_now_ts = existingState?.kanban_cycle_enter_now_ts ?? null;
                payload.kanban_cycle_trigger_ts = existingState?.kanban_cycle_trigger_ts ?? null;
                payload.kanban_cycle_side = existingState?.kanban_cycle_side ?? null;
              }
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }
            if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }
            if (finalStage === "enter_now" && prevStage !== "enter_now") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) { payload.entry_price = price; payload.entry_ts = rowTs; }
            }
            if (finalStage && existingState?.entry_price) { payload.entry_price = existingState.entry_price; payload.entry_ts = existingState.entry_ts; }
            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;
            stateMap[ticker] = payload;

            if (debug) {
              replayCtx.analysisRows = replayCtx.analysisRows || [];
              if (replayCtx.analysisRows.length < 300) {
                const shouldTrigger = finalStage === "enter_now" ? shouldTriggerTradeSimulation(ticker, payload, existingState) : false;
                const blockers = finalStage === "enter_now" ? getEntryBlockers(ticker, payload, existingState) : [];
                const compRaw = completionForSize(payload);
                const compToMax = computeCompletionToTpMax(payload);
                const compUsed = Number.isFinite(compToMax) ? compToMax : compRaw;
                const forcedReason = payload.flags?.forced_watch_missing_trigger ? "forced_watch_missing_trigger" : payload.flags?.forced_enter_now_gate ? "forced_enter_now_gate" : payload.flags?.first_bar_of_day_bridge ? "first_bar_of_day_bridge" : null;
                replayCtx.analysisRows.push({
                  ts: rowTs,
                  time: new Date(rowTs < 1e12 ? rowTs * 1000 : rowTs).toISOString(),
                  stage,
                  finalStage,
                  shouldTrigger: finalStage === "enter_now" ? shouldTrigger : null,
                  blockers: finalStage === "enter_now" && blockers.length ? blockers : null,
                  forcedReason,
                  rank: payload.rank ?? payload.rank_position ?? payload.position,
                  rr: payload.rr != null ? Number(payload.rr) : null,
                  comp: compUsed,
                  phase: payload.phase_pct != null ? Number(payload.phase_pct) : null,
                  state: payload.state,
                  trigger_reason: payload.trigger_reason || null,
                  price: payload.price != null ? Number(payload.price) : null,
                  htf: payload.htf_score != null ? Number(payload.htf_score) : null,
                  ltf: payload.ltf_score != null ? Number(payload.ltf_score) : null,
                  prevStage: existingState?.kanban_stage || null,
                });
              }
            }

            const countBefore = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            await processTradeSimulation(KV, ticker, payload, existingState, env, { forceUseIngestTs: true, replayBatchContext: replayCtx, asOfTs: rowTs });
            const countAfter = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
            processed += 1;
          } catch (e) {
            console.error(`[REPLAY-TICKER-D1] ${tickerParam} row error:`, e);
          }
        }

        await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
        await kvPutJSON(KV, `timed:latest:${tickerParam}`, stateMap[tickerParam] || {});
        try { await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50); } catch {}
        const resp = {
          ok: true,
          ticker: tickerParam,
          day: dayKey,
          source: "timed_trail",
          rowsProcessed: processed,
          tradesCreated,
          tradesPurged,
          laneCounts,
          prevPeriodSeeded,
        };
        if (debug && replayCtx.analysisRows) {
          const enterNowRows = replayCtx.analysisRows.filter((r) => r.finalStage === "enter_now");
          const forcedWatch = replayCtx.analysisRows.filter((r) => r.forcedReason === "forced_watch_missing_trigger");
          const forcedEnterNow = replayCtx.analysisRows.filter((r) => r.forcedReason === "forced_enter_now_gate");
          resp.analysis = {
            rows: replayCtx.analysisRows,
            enterNowCount: enterNowRows.length,
            forcedWatchCount: forcedWatch.length,
            forcedEnterNowCount: forcedEnterNow.length,
            firstBarBridgeCount: replayCtx.analysisRows.filter((r) => r.forcedReason === "first_bar_of_day_bridge").length,
          };
        }
        return sendJSON(resp, 200, corsHeaders(env, req));
      }

      // GET /timed/admin/replay-data-stats?key=...&date=YYYY-MM-DD&ticker=AAPL
      // Returns row counts and payload_json presence for timed_trail vs ingest_receipts (confirm D1 as replay source).
      if (routeKey === "GET /timed/admin/replay-data-stats") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }
        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const tsStartInt = Math.floor(Number(tsStart));
        const tsEndInt = Math.floor(Number(tsEnd));
        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();

        try {
          const trailTotal = tickerParam
            ? await db.prepare(
                `SELECT count(*) AS n, sum(CASE WHEN payload_json IS NOT NULL AND length(payload_json) > 0 THEN 1 ELSE 0 END) AS with_payload
                 FROM timed_trail WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3`,
              ).bind(tickerParam, tsStartInt, tsEndInt).first()
            : await db.prepare(
                `SELECT count(*) AS n, sum(CASE WHEN payload_json IS NOT NULL AND length(payload_json) > 0 THEN 1 ELSE 0 END) AS with_payload
                 FROM timed_trail WHERE ts >= ?1 AND ts <= ?2`,
              ).bind(tsStartInt, tsEndInt).first();
          const receiptTotal = tickerParam
            ? await db.prepare(
                `SELECT count(*) AS n FROM ingest_receipts WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3`,
              ).bind(tickerParam, tsStartInt, tsEndInt).first()
            : await db.prepare(
                `SELECT count(*) AS n FROM ingest_receipts WHERE ts >= ?1 AND ts <= ?2`,
              ).bind(tsStartInt, tsEndInt).first();

          const trailN = Number(trailTotal?.n) || 0;
          const trailWithPayload = Number(trailTotal?.with_payload) || 0;
          const receiptN = Number(receiptTotal?.n) || 0;

          return sendJSON({
            ok: true,
            date: dayKey,
            ticker: tickerParam || null,
            tsStart: tsStartInt,
            tsEnd: tsEndInt,
            timed_trail: { rows: trailN, rows_with_payload_json: trailWithPayload, usable: trailWithPayload > 0 },
            ingest_receipts: { rows: receiptN },
            recommendation: trailWithPayload > 0
              ? "Use replay-ticker-d1 (timed_trail) for single-ticker replay to avoid KV 429."
              : receiptN > 0
                ? "timed_trail has no payload_json; use replay-ingest (ingest_receipts) or backfill timed_trail from ingest."
                : "No data for this date/ticker; run ingest or backfill first.",
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: "query_failed", detail: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/admin/data-range?key=... — Returns first and last date with valid replay data (ingest_receipts, 7d retention).
      if (routeKey === "GET /timed/admin/data-range") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }
        try {
          const row = await db.prepare(
            `SELECT MIN(ts) AS min_ts, MAX(ts) AS max_ts, COUNT(*) AS total FROM ingest_receipts`
          ).first();
          const minTs = Number(row?.min_ts);
          const maxTs = Number(row?.max_ts);
          const total = Number(row?.total) || 0;
          if (!Number.isFinite(minTs) || !Number.isFinite(maxTs) || total === 0) {
            return sendJSON({ ok: true, firstDate: null, lastDate: null, totalRows: 0, source: "ingest_receipts" }, 200, corsHeaders(env, req));
          }
          const firstDate = nyTradingDayKey(minTs);
          const lastDate = nyTradingDayKey(maxTs);
          return sendJSON({
            ok: true,
            firstDate: firstDate || null,
            lastDate: lastDate || null,
            minTs,
            maxTs,
            totalRows: total,
            source: "ingest_receipts",
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: "query_failed", detail: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/admin/history?key=...&ticker=AAPL&date=YYYY-MM-DD
      // Time-travel endpoint: returns historical score + kanban lane timeline for a ticker on a given day.
      // Reads from trail_5m_facts (30+ day retention) with fallback to timed_trail (48h raw data).
      // Returns 5-minute bucketed snapshots: {ts, price, htf_score, ltf_score, state, kanban_stage, flags}
      if (routeKey === "GET /timed/admin/history") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));

        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        if (!tickerParam) return sendJSON({ ok: false, error: "missing ticker param" }, 400, corsHeaders(env, req));

        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());

        // Compute day boundaries (UTC ms)
        const dayStartMs = new Date(dayKey + "T00:00:00Z").getTime();
        const dayEndMs = new Date(dayKey + "T23:59:59Z").getTime();

        let source = "trail_5m_facts";
        let timeline = [];

        try {
          // Try trail_5m_facts first (long-term archive)
          const factsRes = await db
            .prepare(
              `SELECT bucket_ts, price_open, price_high, price_low, price_close,
                      htf_score_avg, htf_score_min, htf_score_max,
                      ltf_score_avg, ltf_score_min, ltf_score_max,
                      state, rank, completion, phase_pct,
                      kanban_stage_start, kanban_stage_end, kanban_changed,
                      had_squeeze_release, had_ema_cross, had_st_flip, had_momentum_elite,
                      sample_count
               FROM trail_5m_facts
               WHERE ticker = ?1 AND bucket_ts >= ?2 AND bucket_ts <= ?3
               ORDER BY bucket_ts ASC`,
            )
            .bind(tickerParam, dayStartMs, dayEndMs)
            .all();

          const factsRows = factsRes?.results || [];

          if (factsRows.length > 0) {
            timeline = factsRows.map((r) => ({
              ts: Number(r.bucket_ts),
              price_open: r.price_open != null ? Number(r.price_open) : null,
              price_high: r.price_high != null ? Number(r.price_high) : null,
              price_low: r.price_low != null ? Number(r.price_low) : null,
              price_close: r.price_close != null ? Number(r.price_close) : null,
              htf_score: r.htf_score_avg != null ? Number(r.htf_score_avg) : null,
              htf_score_range: r.htf_score_min != null ? [Number(r.htf_score_min), Number(r.htf_score_max)] : null,
              ltf_score: r.ltf_score_avg != null ? Number(r.ltf_score_avg) : null,
              ltf_score_range: r.ltf_score_min != null ? [Number(r.ltf_score_min), Number(r.ltf_score_max)] : null,
              state: r.state || null,
              rank: r.rank != null ? Number(r.rank) : null,
              kanban_stage: r.kanban_stage_end || r.kanban_stage_start || null,
              kanban_changed: !!r.kanban_changed,
              flags: {
                squeeze_release: !!r.had_squeeze_release,
                ema_cross: !!r.had_ema_cross,
                st_flip: !!r.had_st_flip,
                momentum_elite: !!r.had_momentum_elite,
              },
              samples: Number(r.sample_count) || 0,
            }));
          } else {
            // Fallback: read from timed_trail (raw 48h data) if facts are empty
            source = "timed_trail";
            const trailRes = await db
              .prepare(
                `SELECT ts, price, htf_score, ltf_score, state, rank, completion, phase_pct,
                        kanban_stage, flags_json
                 FROM timed_trail
                 WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3
                 ORDER BY ts ASC
                 LIMIT 5000`,
              )
              .bind(tickerParam, dayStartMs, dayEndMs)
              .all();

            const trailRows = trailRes?.results || [];

            // Bucket raw trail into 5-minute windows for consistency
            const bucketMs = 5 * 60 * 1000;
            const buckets = {};
            for (const r of trailRows) {
              const ts = Number(r.ts);
              if (!Number.isFinite(ts)) continue;
              const bucketTs = Math.floor(ts / bucketMs) * bucketMs;
              if (!buckets[bucketTs]) buckets[bucketTs] = [];
              buckets[bucketTs].push(r);
            }

            for (const [bucketTs, rows] of Object.entries(buckets).sort((a, b) => a[0] - b[0])) {
              const first = rows[0];
              const last = rows[rows.length - 1];
              let flags = {};
              try {
                if (last.flags_json) flags = JSON.parse(last.flags_json);
              } catch {}
              timeline.push({
                ts: Number(bucketTs),
                price_open: first.price != null ? Number(first.price) : null,
                price_close: last.price != null ? Number(last.price) : null,
                price_high: Math.max(...rows.map(r => Number(r.price)).filter(Number.isFinite)),
                price_low: Math.min(...rows.map(r => Number(r.price)).filter(Number.isFinite)),
                htf_score: last.htf_score != null ? Number(last.htf_score) : null,
                ltf_score: last.ltf_score != null ? Number(last.ltf_score) : null,
                state: last.state || null,
                rank: last.rank != null ? Number(last.rank) : null,
                kanban_stage: last.kanban_stage || null,
                kanban_changed: first.kanban_stage !== last.kanban_stage,
                flags: {
                  squeeze_release: !!flags.sq30_release || !!flags.squeeze_release,
                  ema_cross: !!flags.ema_cross_1h_13_48 || !!flags.ema_cross,
                  st_flip: !!flags.st_flip_30m || !!flags.st_flip,
                  momentum_elite: !!flags.momentum_elite,
                },
                samples: rows.length,
              });
            }
          }

          // Also get trade activity for this ticker on this day
          let trades = [];
          try {
            const tradesRes = await db
              .prepare(
                `SELECT trade_id, direction, entry_ts, entry_price, exit_ts, exit_price,
                        status, exit_reason, pnl_pct, trimmed_pct
                 FROM trades
                 WHERE ticker = ?1 AND entry_ts >= ?2 AND entry_ts <= ?3
                 ORDER BY entry_ts ASC`,
              )
              .bind(tickerParam, dayStartMs, dayEndMs)
              .all();
            trades = (tradesRes?.results || []).map((t) => ({
              trade_id: t.trade_id,
              direction: t.direction,
              entry_ts: Number(t.entry_ts),
              entry_price: t.entry_price != null ? Number(t.entry_price) : null,
              exit_ts: t.exit_ts != null ? Number(t.exit_ts) : null,
              exit_price: t.exit_price != null ? Number(t.exit_price) : null,
              status: t.status,
              exit_reason: t.exit_reason,
              pnl_pct: t.pnl_pct != null ? Number(t.pnl_pct) : null,
              trimmed_pct: t.trimmed_pct != null ? Number(t.trimmed_pct) : null,
            }));
          } catch {}

          // Get daily summary if available
          let dailySummary = null;
          try {
            dailySummary = await db
              .prepare(`SELECT * FROM trail_daily_summary WHERE ticker = ?1 AND date = ?2`)
              .bind(tickerParam, dayKey)
              .first();
          } catch {}

          return sendJSON({
            ok: true,
            ticker: tickerParam,
            date: dayKey,
            source,
            buckets: timeline.length,
            timeline,
            trades,
            dailySummary: dailySummary || null,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/replay-ingest?key=...&date=YYYY-MM-DD&bucket=...&ticker=...&scriptVersion=2.5.0&cleanSlate=1
      // Bucket-by-bucket replay from ingest_receipts (Script Version 2.5.0). Avoids D1 memory limits.
      // Client iterates buckets from 9:30 ET; pass bucket= to process one bucket per request.
      if (routeKey === "POST /timed/admin/replay-ingest") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }

        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 16, 0, 0);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd : Date.now();
        const bucketParam = url.searchParams.get("bucket");
        const bucketMs = 5 * 60 * 1000;
        const tickerFilter = (url.searchParams.get("ticker") || "").trim().toUpperCase() || null;
        const scriptVersion = url.searchParams.get("scriptVersion") || "2.5.0";
        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";
        const debug = url.searchParams.get("debug") === "1" || url.searchParams.get("debug") === "true";
        const limit = Math.min(200, Math.max(1, parseInt(url.searchParams.get("limit") || "100", 10)));
        const bucketOffset = Math.max(0, parseInt(url.searchParams.get("bucketOffset") || "0", 10));

        let currentBucket;
        if (bucketParam != null && bucketParam !== "") {
          currentBucket = parseInt(bucketParam, 10);
          if (!Number.isFinite(currentBucket)) {
            return sendJSON({ ok: false, error: "invalid_bucket" }, 400, corsHeaders(env, req));
          }
        } else {
          currentBucket = Math.floor(tsStart / bucketMs) * bucketMs;
        }

        if (currentBucket < tsStart || currentBucket > tsEnd) {
          return sendJSON({
            ok: true,
            date: dayKey,
            bucketProcessed: currentBucket,
            rowsProcessed: 0,
            tradesCreated: 0,
            tradesPurged: 0,
            nextBucket: null,
            hasMore: false,
            hasMoreInBucket: false,
          }, 200, corsHeaders(env, req));
        }

        try {
          const metaStmt = db.prepare(
            tickerFilter
              ? `SELECT receipt_id, ticker, ts FROM ingest_receipts
                 WHERE bucket_5m = ?1 AND (script_version = ?2 OR script_version IS NULL)
                 AND ticker = ?3
                 ORDER BY ts ASC LIMIT ?4 OFFSET ?5`
              : `SELECT receipt_id, ticker, ts FROM ingest_receipts
                 WHERE bucket_5m = ?1 AND (script_version = ?2 OR script_version IS NULL)
                 ORDER BY ts ASC LIMIT ?3 OFFSET ?4`,
          );
          const metaResult = tickerFilter
            ? await metaStmt.bind(currentBucket, scriptVersion, tickerFilter, limit, bucketOffset).all()
            : await metaStmt.bind(currentBucket, scriptVersion, limit, bucketOffset).all();
          const metaRows = metaResult?.results || [];

          const rows = [];
          for (const m of metaRows) {
            const receiptId = m?.receipt_id;
            if (!receiptId) continue;
            try {
              const payRow = await db.prepare(
                `SELECT payload_json FROM ingest_receipts WHERE receipt_id = ?1 LIMIT 1`,
              ).bind(String(receiptId)).first();
              const ticker = String(m?.ticker || "").toUpperCase();
              const ts = Number(m?.ts);
              if (ticker && Number.isFinite(ts)) {
                rows.push({ ticker, ts, payload_json: payRow?.payload_json ?? null });
              }
            } catch {
              // skip
            }
          }

          let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
          let tradesPurged = 0;
          const tickersInBucket = [...new Set(rows.map((r) => r.ticker))];

          if (cleanSlate && bucketOffset === 0) {
            const toRemove = allTrades.filter((t) => {
              const tkr = String(t?.ticker || "").toUpperCase();
              if (tickerFilter && tkr !== tickerFilter) return false;
              const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
              if (!Number.isFinite(entryTs) || entryTs <= 0) return false;
              if (entryTs < tsStart || entryTs > tsEnd + 86400000) return false;
              return true;
            });
            tradesPurged = toRemove.length;
            const purgedTickers = new Set(toRemove.map((t) => String(t?.ticker || "").toUpperCase()).filter(Boolean));
            tickersInBucket.forEach((t) => purgedTickers.add(t));
            allTrades = allTrades.filter((t) => !toRemove.includes(t));
            await kvPutJSON(KV, "timed:trades:all", allTrades);
            for (const tkr of purgedTickers) {
              if (!tkr) continue;
              const existing = (await kvGetJSON(KV, `timed:latest:${tkr}`)) || {};
              const reset = { ...existing, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null };
              await kvPutJSON(KV, `timed:latest:${tkr}`, reset);
            }
          }

          const stateMap = {};
          const findOpenInArray = (trades, sym) => trades.find((x) => String(x?.ticker || "").toUpperCase() === sym && isOpenTradeStatus(x?.status)) || null;
          const replayCtx = { allTrades };
          let tradesCreated = 0;

          for (const row of rows) {
            try {
              const ticker = row.ticker;
              let payload;
              try {
                payload = row.payload_json ? JSON.parse(row.payload_json) : null;
              } catch {
                continue;
              }
              if (!payload || typeof payload !== "object") continue;
              const rowTs = row.ts;
              payload.ts = rowTs;
              payload.ingest_ts = rowTs;
              // Replay: ensure trigger_ts for lifecycle gate (use ingest ts if missing)
              if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
                payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
              }
              // Normalize SL/TP from alternate field names (ingest payload may vary)
              if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
              if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
              const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
              if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);
              const existingState = stateMap[ticker] || (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
              const existingTs = Number(existingState?.ts ?? existingState?.ingest_ts);
              const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;
              if (isEarlierThanStored) {
                payload.entry_ts = null;
                payload.entry_price = null;
                payload.kanban_cycle_enter_now_ts = null;
                payload.kanban_cycle_trigger_ts = null;
                payload.kanban_cycle_side = null;
              } else {
                if (existingState?.entry_ts != null && payload.entry_ts == null) payload.entry_ts = Number(existingState.entry_ts);
                if (existingState?.entry_price != null && payload.entry_price == null) payload.entry_price = Number(existingState.entry_price);
                if (existingState?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existingState.kanban_cycle_enter_now_ts;
                if (existingState?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existingState.kanban_cycle_trigger_ts;
                if (existingState?.kanban_cycle_side != null) payload.kanban_cycle_side = existingState.kanban_cycle_side;
              }
              const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
              if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
                const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
                const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
                if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
                if (payload.entry_price == null && Number.isFinite(ep) && ep > 0) payload.entry_price = ep;
              }
              // Compute derived fields (rr, score) - not stored in ingest_receipts
              if (payload.rr == null || !Number.isFinite(Number(payload.rr))) {
                payload.rr = computeRR(payload);
                if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
              }
              payload.move_status = computeMoveStatus(payload);
              if (payload.flags) {
                payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
                payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
              }
              if (payload.score == null && payload.rank == null && payload.rank_position == null) {
                const dyn = computeDynamicScore(payload);
                payload.score = dyn;
                if (dyn >= 70) payload.rank_position = Math.max(1, Math.min(50, Math.round(160 - dyn)));
              }
              const prevStage = existingState?.kanban_stage;
              // Pass rowTs as asOfTs for replay-aware trigger freshness check
              const stage = classifyKanbanStage(payload, null, rowTs);
              let finalStage = stage;
              if (prevStage === "archive" && ["hold", "just_entered", "trim", "exit"].includes(stage)) {
                finalStage = "watch";
                if (!payload.flags) payload.flags = {};
                payload.flags.recycled_from_archive = true;
              }
              const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
              if (mgmt) {
                const curTriggerTs = Number(payload?.trigger_ts);
                const curSide = sideFromStateOrScores(payload);
                const cycleEnterTs = Number(existingState?.kanban_cycle_enter_now_ts);
                const cycleTrig = Number(existingState?.kanban_cycle_trigger_ts);
                const cycleSide = existingState?.kanban_cycle_side != null ? String(existingState.kanban_cycle_side) : null;
                const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 && Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
                const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig && !!cycleSide && !!curSide && cycleSide === curSide;
                if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                  finalStage = "watch";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_watch_missing_trigger = true;
                } else if (!cycleOk) {
                  finalStage = "enter";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_enter_gate = true;
                }
              }
              if (finalStage === "enter_now" || finalStage === "enter") {
                payload.kanban_cycle_enter_now_ts = rowTs;
                payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
                payload.kanban_cycle_side = sideFromStateOrScores(payload);
              } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
                payload.kanban_cycle_enter_now_ts = existingState?.kanban_cycle_enter_now_ts ?? null;
                payload.kanban_cycle_trigger_ts = existingState?.kanban_cycle_trigger_ts ?? null;
                payload.kanban_cycle_side = existingState?.kanban_cycle_side ?? null;
              } else {
                payload.kanban_cycle_enter_now_ts = null;
                payload.kanban_cycle_trigger_ts = null;
                payload.kanban_cycle_side = null;
              }
              if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
                payload.prev_kanban_stage = String(prevStage);
                payload.prev_kanban_stage_ts = rowTs;
              }
              if (finalStage === "enter_now" && prevStage !== "enter_now") {
                const price = Number(payload?.price);
                if (Number.isFinite(price) && price > 0) {
                  payload.entry_price = price;
                  payload.entry_ts = rowTs;
                }
              }
              if (finalStage && existingState?.entry_price) {
                payload.entry_price = existingState.entry_price;
                payload.entry_ts = existingState.entry_ts;
              }
              payload.kanban_stage = finalStage;
              payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
              stateMap[ticker] = payload;
              const countBefore = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
              const shouldTrigger = finalStage === "enter_now" ? shouldTriggerTradeSimulation(ticker, payload, existingState) : false;
              if (debug && tickerFilter) {
                replayCtx.debugRows = replayCtx.debugRows || [];
                replayCtx.debugEnterNow = (replayCtx.debugEnterNow || 0) + (finalStage === "enter_now" ? 1 : 0);
                if (finalStage === "enter_now" && replayCtx.debugRows.length < 15) {
                  const blockers = getEntryBlockers(ticker, payload, existingState);
                  const compRaw = completionForSize(payload);
                  const compToMax = computeCompletionToTpMax(payload);
                  const compUsed = Number.isFinite(compToMax) ? compToMax : compRaw;
                  replayCtx.debugRows.push({
                    ticker,
                    ts: rowTs,
                    stage: finalStage,
                    shouldTrigger,
                    blockers,
                    rank: payload.rank ?? payload.rank_position,
                    rr: payload.rr,
                    compFromPayload: payload.completion != null ? Number(payload.completion) : null,
                    compUsed,
                    compToMax: Number.isFinite(compToMax) ? compToMax : null,
                    price: payload.price != null ? Number(payload.price) : null,
                    trigger_price: payload.trigger_price != null ? Number(payload.trigger_price) : null,
                    tp: payload.tp != null ? Number(payload.tp) : null,
                    tp_max: computeTpMaxFromLevels(payload),
                    trigger_reason: payload.trigger_reason,
                  });
                } else if (finalStage === "watch" && payload.state === "HTF_BULL_LTF_BULL" && replayCtx.debugRows.length < 5) {
                  const ent = entryType(payload);
                  if (ent?.corridor) {
                    replayCtx.debugRows.push({ ticker, ts: rowTs, stage: "watch", reason: "momentum_in_corridor_but_watch", rank: payload.rank ?? payload.rank_position, score: payload.score, trigger_reason: payload.trigger_reason });
                  }
                }
              }
              await processTradeSimulation(KV, ticker, payload, existingState, env, { forceUseIngestTs: true, replayBatchContext: replayCtx, asOfTs: rowTs });
              const countAfter = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
              if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
            } catch (e) {
              console.error(`[REPLAY-INGEST] row error:`, e);
            }
          }

          for (const [ticker, payload] of Object.entries(stateMap)) {
            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
          }
          await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);

          const nextBucket = currentBucket + bucketMs;
          const hasMoreInBucket = rows.length >= limit;
          const nextBucketOffset = hasMoreInBucket ? bucketOffset + rows.length : null;
          const hasMore = hasMoreInBucket || nextBucket <= tsEnd;

          const resp = {
            ok: true,
            date: dayKey,
            ticker: tickerFilter || null,
            bucketProcessed: currentBucket,
            bucketOffset,
            rowsProcessed: rows.length,
            tradesCreated,
            tradesPurged,
            nextBucket: !hasMoreInBucket && nextBucket <= tsEnd ? nextBucket : null,
            nextBucketOffset: hasMoreInBucket ? nextBucketOffset : null,
            hasMore,
            hasMoreInBucket,
          };
          if (debug) {
            resp.debug = { rows: replayCtx?.debugRows || [], enterNowCount: replayCtx?.debugEnterNow || 0 };
          }
          return sendJSON(resp, 200, corsHeaders(env, req));
        } catch (e) {
          console.error("[REPLAY-INGEST] error:", e);
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/replay-day?key=...&date=YYYY-MM-DD&limit=...&offset=...&cleanSlate=1&bucketMinutes=5
      // Replay a day's timed_trail ingests from 9:30 AM ET, chronologically. Kanban + trade simulation.
      // cleanSlate=1: purge ALL trades and reset entry state for a clean simulation of the day only.
      // bucketMinutes=5: group ingests into 5-min buckets (latest per ticker per bucket) for structured progression.
      if (routeKey === "POST /timed/admin/replay-day") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "no_db_binding" },
            500,
            corsHeaders(env, req),
          );
        }

        const dateParam = url.searchParams.get("date") || null;
        const dayKey =
          dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam)
            ? dateParam
            : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsStartInt = Math.floor(Number(tsStart));
        const tsEndInt = Math.floor(Number(tsEnd));

        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";
        const useServerScores = url.searchParams.get("useServerScores") === "1";
        const bucketMinutes = Math.max(1, Math.min(60, Number(url.searchParams.get("bucketMinutes")) || 0));
        const tickerFilter = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        const qLimit = tickerFilter ? 1000 : Math.min(Number(url.searchParams.get("limit")) || 500, 2000);
        const qOffset = Number(url.searchParams.get("offset")) || 0;

        let rows = [];
        let totalRows = null;
        try {
          if (bucketMinutes > 0) {
            // Bucket mode: fetch receipt_id,ticker,ts first (avoids huge payload_json in bulk), then fetch payload per batch
            const metaRes = await db.prepare(
              `SELECT receipt_id, ticker, ts FROM ingest_receipts
               WHERE ts >= ?1 AND ts <= ?2
               ORDER BY ts ASC`,
            ).bind(tsStart, tsEnd).all();
            const metaRows = metaRes?.results || [];
            const bucketMs = bucketMinutes * 60 * 1000;
            const byBucket = {};
            for (const r of metaRows) {
              const ts = Number(r?.ts);
              if (!Number.isFinite(ts)) continue;
              const bucketTs = Math.floor(ts / bucketMs) * bucketMs;
              if (!byBucket[bucketTs]) byBucket[bucketTs] = {};
              const tkr = String(r?.ticker || "").toUpperCase();
              if (!tkr) continue;
              byBucket[bucketTs][tkr] = { receipt_id: r?.receipt_id, ticker: tkr, ts };
            }
            const buckets = Object.keys(byBucket).map(Number).sort((a, b) => a - b);
            const bucketedMeta = [];
            for (const bt of buckets) {
              for (const r of Object.values(byBucket[bt])) bucketedMeta.push(r);
            }
            totalRows = bucketedMeta.length;
            const batch = bucketedMeta.slice(qOffset, qOffset + qLimit);
            if (batch.length > 0) {
              const receiptIds = batch.map((b) => b?.receipt_id).filter(Boolean);
              const payloadByReceipt = {};
              const fetchBatch = 25;
              for (let i = 0; i < receiptIds.length; i += fetchBatch) {
                const chunk = receiptIds.slice(i, i + fetchBatch);
                const placeholders = chunk.map((_, j) => `?${j + 1}`).join(",");
                const payRes = await db.prepare(
                  `SELECT receipt_id, payload_json FROM ingest_receipts WHERE receipt_id IN (${placeholders})`,
                ).bind(...chunk).all();
                for (const p of payRes?.results || []) {
                  if (p?.receipt_id) payloadByReceipt[p.receipt_id] = p?.payload_json ?? null;
                }
              }
              rows = batch.map((b) => ({ ...b, payload_json: payloadByReceipt[b.receipt_id] ?? null }));
            } else {
              rows = [];
            }
          } else if (tickerFilter) {
            // Single-ticker: use d1GetTrailRange (NO payload_json - avoids D1 string limits), build minimal payload
            let trailRes;
            try {
              trailRes = await d1GetTrailRange(env, tickerFilter, tsStartInt, 500);
              if (!trailRes?.ok) {
                return sendJSON(
                  { ok: false, error: "trail_range_failed", detail: trailRes?.error || "unknown" },
                  500,
                  corsHeaders(env, req),
                );
              }
            } catch (trailErr) {
              return sendJSON(
                { ok: false, error: "trail_fetch_failed", detail: String(trailErr?.message || trailErr) },
                500,
                corsHeaders(env, req),
              );
            }
            const trail = trailRes?.trail || [];
            const inRange = trail.filter((p) => {
              const ts = Number(p?.ts);
              return Number.isFinite(ts) && ts >= tsStartInt && ts <= tsEndInt;
            });
            rows = inRange.map((p) => {
              const obj = {
                ticker: tickerFilter,
                ts: Number(p?.ts),
                price: p?.price,
                htf_score: p?.htf_score,
                ltf_score: p?.ltf_score,
                completion: p?.completion,
                phase_pct: p?.phase_pct,
                state: p?.state,
                rank: p?.rank,
                flags: p?.flags || {},
                trigger_reason: p?.trigger_reason,
                trigger_dir: p?.trigger_dir,
              };
              return { ticker: tickerFilter, ts: obj.ts, payload_json: JSON.stringify(obj) };
            });
            totalRows = rows.length;
          } else {
            // Multi-ticker: lightweight meta then fetch payload per row
            // First get total count for pagination
            const countResult = await db.prepare(
              `SELECT COUNT(*) as cnt FROM timed_trail WHERE ts >= ?1 AND ts <= ?2`,
            ).bind(tsStartInt, tsEndInt).first();
            totalRows = Number(countResult?.cnt) || 0;

            const metaStmt = db.prepare(
              `SELECT ticker, ts FROM timed_trail
               WHERE ts >= ?1 AND ts <= ?2
               ORDER BY ts ASC
               LIMIT ?3 OFFSET ?4`,
            );
            const metaResult = await metaStmt.bind(
              tsStartInt,
              tsEndInt,
              Math.min(500, Math.floor(qLimit)),
              Math.floor(qOffset),
            ).all();
            const metaRows = metaResult?.results || [];
            rows = [];
            for (const m of metaRows) {
              const rawTicker = String(m?.ticker || "").trim();
              const tsVal = Number(m?.ts);
              if (!rawTicker || !Number.isFinite(tsVal)) continue;
              try {
                const payRow = await db.prepare(
                  `SELECT payload_json FROM timed_trail WHERE ticker = ?1 AND ts = ?2 LIMIT 1`,
                ).bind(rawTicker, tsVal).first();
                rows.push({ ticker: rawTicker, ts: tsVal, payload_json: payRow?.payload_json ?? null });
              } catch {
                rows.push({ ticker: rawTicker, ts: tsVal, payload_json: null });
              }
            }
          }
        } catch (e) {
          return sendJSON(
            { ok: false, error: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }

        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        let tradesPurged = 0;
        if (qOffset === 0 && rows.length > 0) {
          if (cleanSlate) {
            if (tickerFilter) {
              // Single-ticker mode: purge only this ticker's trades in the day range
              const kept = allTrades.filter((t) => {
                const tkr = String(t?.ticker || "").toUpperCase();
                if (tkr !== tickerFilter) return true;
                const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
                if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
                if (entryTs < tsStart || entryTs > tsEnd) return true;
                tradesPurged += 1;
                return false;
              });
              allTrades = kept;
              await kvPutJSON(KV, "timed:trades:all", kept);
            } else {
              // Full replay: purge ALL trades
              tradesPurged = allTrades.length;
              allTrades = [];
              await kvPutJSON(KV, "timed:trades:all", []);
            }
          } else {
            // Purge trades in the day window only
            const kept = allTrades.filter((t) => {
              const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
              if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
              if (entryTs < tsStart || entryTs > tsEnd) return true;
              tradesPurged += 1;
              return false;
            });
            allTrades = kept;
            await kvPutJSON(KV, "timed:trades:all", kept);
          }
        }

        const uniqueTickers = [...new Set(rows.map((r) => String(r?.ticker || "").toUpperCase()).filter(Boolean))];
        const existingMap = await Promise.all(
          uniqueTickers.map((t) => kvGetJSON(KV, `timed:latest:${t}`)),
        ).then((arr) => Object.fromEntries(uniqueTickers.map((t, i) => [t, arr[i] || {}])));
        const stateMap = {};
        for (const t of uniqueTickers) {
          const ex = existingMap[t] || {};
          const exEntryTs = Number(ex?.entry_ts ?? ex?.entryTs);
          const shouldReset = cleanSlate && (qOffset === 0 || (Number.isFinite(exEntryTs) && exEntryTs < tsStart));
          if (shouldReset) {
            stateMap[t] = { ...ex, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null };
          } else {
            stateMap[t] = ex ? { ...ex } : {};
          }
        }

        const findOpenInArray = (trades, sym) =>
          trades.find(
            (x) =>
              String(x?.ticker || "").toUpperCase() === sym &&
              isOpenTradeStatus(x?.status),
          ) || null;

        const replayCtx = { allTrades };

        let processed = 0;
        let tradesCreated = 0;
        const laneCounts = {};
        const errors = [];
        const replayTimeline = []; // Per-snapshot timeline for time-travel

        for (const row of rows) {
          try {
            const ticker = String(row?.ticker || "").toUpperCase();
            if (!ticker) continue;
            let payload;
            try {
              payload = row.payload_json ? JSON.parse(row.payload_json) : null;
            } catch {
              continue;
            }
            if (!payload || typeof payload !== "object") continue;

            const rowTs = Number(row?.ts);
            if (!Number.isFinite(rowTs)) continue;
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            // Replay: ensure trigger_ts for lifecycle gate (use ingest ts if missing)
            if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
              payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
            }
            // Normalize SL/TP from alternate field names
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
            const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
            if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);

            const existing = stateMap[ticker] || {};
            const existingTs = Number(existing?.ts ?? existing?.ingest_ts);
            const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;

            if (isEarlierThanStored) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              if (existing?.entry_ts != null && payload.entry_ts == null)
                payload.entry_ts = Number(existing.entry_ts);
              if (existing?.entry_price != null && payload.entry_price == null)
                payload.entry_price = Number(existing.entry_price);
              if (existing?.kanban_cycle_enter_now_ts != null)
                payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
              if (existing?.kanban_cycle_trigger_ts != null)
                payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
              if (existing?.kanban_cycle_side != null)
                payload.kanban_cycle_side = existing.kanban_cycle_side;
            }

            const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
            if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
              const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
              const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
              if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
              if (payload.entry_price == null && Number.isFinite(ep) && ep > 0)
                payload.entry_price = ep;
            }

            // ─────────────────────────────────────────────────────────────────────
            // Server-side re-scoring: when useServerScores=1, re-compute scores
            // from D1 candles using the current scoring algorithm (EMA triplet).
            // This replaces the old TradingView payload scores with fresh ones.
            // ─────────────────────────────────────────────────────────────────────
            if (useServerScores) {
              try {
                const asOfGetter = (env, tkr, tf, lim) => d1GetCandlesAsOf(env, tkr, tf, lim, rowTs);
                const serverResult = await computeServerSideScores(ticker, asOfGetter, env, existing);
                if (serverResult) {
                  // Merge server-computed fields into the replay payload
                  payload.htf_score = serverResult.htf_score;
                  payload.ltf_score = serverResult.ltf_score;
                  payload.flip_watch_score = serverResult.flip_watch_score;
                  payload.completion = serverResult.completion;
                  payload.phase_pct = serverResult.phase_pct;
                  payload.state = serverResult.state;
                  payload.flags = { ...(payload.flags || {}), ...(serverResult.flags || {}) };
                  payload.ema_map = serverResult.ema_map;
                  payload.tf_tech = serverResult.tf_tech;
                  payload.sl = serverResult.sl;
                  payload.tp = serverResult.tp;
                  payload.tp_trim = serverResult.tp_trim;
                  payload.tp_exit = serverResult.tp_exit;
                  payload.tp_runner = serverResult.tp_runner;
                  payload.price = serverResult.price || payload.price;
                  payload.rr = serverResult.rr;
                  payload.rank = serverResult.rank;
                  // Server-computed TD Sequential takes precedence over webhook data
                  if (serverResult.td_sequential) {
                    payload.td_sequential = serverResult.td_sequential;
                    payload._td_server_computed = true;
                  }
                  payload._server_scored = true;
                }
              } catch (e) {
                // Non-critical: fall back to payload-based scoring
                console.warn(`[REPLAY] Server scoring failed for ${ticker}:`, e);
              }
            }

            // ─────────────────────────────────────────────────────────────────────
            // CRITICAL: Compute derived fields that live ingestion normally provides.
            // The ingest_receipts payload_json does NOT contain rr, rank, score, etc.
            // Without these, qualifiesForEnter gates (rr < 1.5) block ALL entries.
            // ─────────────────────────────────────────────────────────────────────
            if (payload.rr == null || !Number.isFinite(Number(payload.rr))) {
              payload.rr = computeRR(payload);
              if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
            }
            if (payload.score == null && payload.rank == null) {
              payload.score = computeRank(payload);
            }
            if (payload.rr_warning == null && Number.isFinite(payload.rr)) {
              payload.rr_warning = computeRRWarning(payload.rr);
            }

            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) {
              payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
              payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
            }

            const prevStage = existing?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            let finalStage = stage;

            if (
              prevStage === "archive" &&
              ["hold", "just_entered", "trim", "exit"].includes(stage)
            ) {
              finalStage = "watch";
              if (!payload.flags) payload.flags = {};
              payload.flags.recycled_from_archive = true;
            }

            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existing?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
              const cycleSide = existing?.kanban_cycle_side != null ? String(existing.kanban_cycle_side) : null;
              const sameTrig =
                Number.isFinite(curTriggerTs) &&
                curTriggerTs > 0 &&
                Number.isFinite(cycleTrig) &&
                cycleTrig > 0 &&
                cycleTrig === curTriggerTs;
              const cycleOk =
                Number.isFinite(cycleEnterTs) &&
                cycleEnterTs > 0 &&
                sameTrig &&
                !!cycleSide &&
                !!curSide &&
                cycleSide === curSide;

              if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                finalStage = "watch";
                if (!payload.flags) payload.flags = {};
                payload.flags.forced_watch_missing_trigger = true;
              } else if (!cycleOk) {
                finalStage = "enter";
                if (!payload.flags) payload.flags = {};
                payload.flags.forced_enter_gate = true;
              }
            }

            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = rowTs;
              payload.kanban_cycle_trigger_ts =
                Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0
                  ? payload.trigger_ts
                  : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              payload.kanban_cycle_enter_now_ts = existing?.kanban_cycle_enter_now_ts ?? null;
              payload.kanban_cycle_trigger_ts = existing?.kanban_cycle_trigger_ts ?? null;
              payload.kanban_cycle_side = existing?.kanban_cycle_side ?? null;
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }

            if (
              prevStage != null &&
              finalStage != null &&
              String(prevStage) !== String(finalStage)
            ) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }

            if ((finalStage === "enter_now" || finalStage === "enter") && prevStage !== "enter_now" && prevStage !== "enter") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) {
                payload.entry_price = price;
                payload.entry_ts = rowTs;
              }
            }
            if (finalStage && existing?.entry_price) {
              payload.entry_price = existing.entry_price;
              payload.entry_ts = existing.entry_ts;
            }

            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);

            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;

            // Capture per-snapshot timeline point (cap at 2000 to avoid huge responses)
            if (replayTimeline.length < 2000) {
              replayTimeline.push({
                ts: rowTs,
                ticker,
                price: payload.price != null ? Number(payload.price) : null,
                htf_score: payload.htf_score != null ? Number(payload.htf_score) : null,
                ltf_score: payload.ltf_score != null ? Number(payload.ltf_score) : null,
                state: payload.state || null,
                kanban_stage: finalStage,
                prev_stage: prevStage || null,
              });
            }

            stateMap[ticker] = payload;

            const countBefore = replayCtx.allTrades.filter(
              (x) => String(x?.ticker).toUpperCase() === ticker,
            ).length;
            await processTradeSimulation(KV, ticker, payload, existing, env, {
              forceUseIngestTs: true,
              replayBatchContext: replayCtx,
              asOfTs: rowTs,
            });
            const countAfter = replayCtx.allTrades.filter(
              (x) => String(x?.ticker).toUpperCase() === ticker,
            ).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;

            processed += 1;
          } catch (e) {
            errors.push({ ticker: row?.ticker || null, error: String(e?.message || e) });
          }
        }

        await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
        await Promise.all(
          Object.entries(stateMap).map(([t, p]) =>
            kvPutJSON(KV, `timed:latest:${t}`, p),
          ),
        );

        const nextOffset = qOffset + rows.length;
        const hasMore = rows.length >= qLimit;

        try {
          await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50);
        } catch (syncErr) {
          errors.push({ sync: String(syncErr?.message || syncErr) });
        }

        return sendJSON(
          {
            ok: true,
            day: dayKey,
            ticker: tickerFilter || undefined,
            cleanSlate: cleanSlate || undefined,
            bucketMinutes: bucketMinutes > 0 ? bucketMinutes : undefined,
            tsStart,
            tsEnd,
            totalRows: totalRows ?? undefined,
            rowsProcessed: processed,
            tradesCreated,
            tradesPurged: qOffset === 0 ? tradesPurged : undefined,
            laneCounts,
            timeline: replayTimeline,
            offset: qOffset,
            nextOffset: hasMore ? nextOffset : null,
            hasMore,
            errorsCount: errors.length,
            errors: errors.slice(0, 10),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/dedupe-trades?key=... - Remove duplicate trades (same ticker+direction+entry_ts)
      if (routeKey === "POST /timed/admin/dedupe-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const entryTsFor = (t) => {
            const et = Number(t?.entry_ts ?? t?.entryTs);
            if (Number.isFinite(et)) return et;
            const iso = t?.entryTime;
            if (iso) return isoToMs(iso) || null;
            const hist = Array.isArray(t?.history) ? t.history : [];
            const ent = hist.find((e) => String(e?.type || "").toUpperCase() === "ENTRY");
            return ent ? isoToMs(ent.timestamp ?? ent.ts) || null : null;
          };
          const seen = new Set();
          const deduped = [];
          for (const t of allTrades) {
            const ticker = String(t?.ticker || "").toUpperCase();
            const dir = String(t?.direction || "").toUpperCase();
            const et = entryTsFor(t);
            const key = `${ticker}:${dir}:${et != null ? et : t?.id || ""}`;
            if (seen.has(key)) continue;
            seen.add(key);
            deduped.push(t);
          }
          const removed = allTrades.length - deduped.length;
          if (removed > 0) await kvPutJSON(KV, tradesKey, deduped);
          return sendJSON(
            { ok: true, before: allTrades.length, after: deduped.length, removed },
            200,
            corsHeaders(env, req),
          );
        } catch (e) {
          return sendJSON(
            { ok: false, error: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/admin/refresh-latest-from-ingest?key=... - Restore KV from actual latest ingest_receipts per ticker.
      // Use after replay to fix stale data (replay only keeps last-seen-per-bucket; this gets true latest).
      if (routeKey === "POST /timed/admin/refresh-latest-from-ingest") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        const KV = env?.KV_TIMED;
        if (!db || !KV) {
          return sendJSON({ ok: false, error: "missing_db_or_kv" }, 500, corsHeaders(env, req, true));
        }

        const scriptVersion = url.searchParams.get("scriptVersion") || "2.5.0";
        const limit = Math.min(50, Math.max(1, parseInt(url.searchParams.get("limit") || "25", 10)));
        const offset = Math.max(0, parseInt(url.searchParams.get("offset") || "0", 10));
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const toProcess = Array.isArray(tickers) ? tickers.slice(offset, offset + limit) : [];

        let refreshed = 0;
        let errors = 0;
        for (const t of toProcess) {
          const ticker = String(t || "").toUpperCase();
          if (!ticker) continue;
          try {
            const row = await db.prepare(
              `SELECT payload_json, ts FROM ingest_receipts
               WHERE ticker = ?1 AND (script_version = ?2 OR script_version IS NULL)
               ORDER BY ts DESC LIMIT 1`
            ).bind(ticker, scriptVersion).first();
            if (!row?.payload_json) continue;
            let payload;
            try {
              payload = JSON.parse(String(row.payload_json));
            } catch {
              continue;
            }
            if (!payload || typeof payload !== "object") continue;
            const rowTs = Number(row.ts);
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
              payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
            }
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
            const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
            if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);
            const existing = (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
            if (existing?.entry_ts != null) payload.entry_ts = existing.entry_ts;
            if (existing?.entry_price != null) payload.entry_price = existing.entry_price;
            if (existing?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
            if (existing?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
            if (existing?.kanban_cycle_side != null) payload.kanban_cycle_side = existing.kanban_cycle_side;
            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) {
              payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
              payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
            }
            const prevStage = existing?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            payload.kanban_stage = stage;
            payload.kanban_meta = deriveKanbanMeta(payload, stage);
            if (prevStage != null && stage != null && String(prevStage) !== String(stage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }
            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
            refreshed++;
          } catch (e) {
            errors++;
          }
        }

        const syncResult = refreshed > 0
          ? await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 200).catch(() => ({}))
          : {};
        return sendJSON({
          ok: true,
          refreshed,
          errors,
          total: toProcess.length,
          offset,
          hasMore: offset + toProcess.length < (Array.isArray(tickers) ? tickers.length : 0),
          sync: syncResult,
        }, 200, corsHeaders(env, req, true));
      }

      // POST /timed/admin/force-sync?key=... - Force D1 sync from KV (refresh all tickers)
      if (routeKey === "POST /timed/admin/force-sync") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const result = await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 200);
          return sendJSON(result, 200, corsHeaders(env, req, true));
        } catch (error) {
          return sendJSON(
            { ok: false, error: String(error) },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/admin/fix-zero-ts-events?key=... - Fix EXIT/TRIM events with zero, missing, or bogus old ts (removes "Dec 31, 1969" from By day)
      const MIN_SANE_TS_MS = 946684800000; // Jan 1, 2000 00:00 UTC — treat anything before as bogus
      if (routeKey === "POST /timed/admin/fix-zero-ts-events") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const toMs = (tsLike) => {
          const n = typeof tsLike === "string" ? isoToMs(tsLike) : Number(tsLike);
          if (!Number.isFinite(n) || n <= 0) return null;
          return n < 1e12 ? n * 1000 : n;
        };
        const isBadTs = (ts) => ts == null || ts <= 0 || ts < MIN_SANE_TS_MS;

        let fixedKV = 0;
        const tradesKey = "timed:trades:all";
        const trades = (await kvGetJSON(KV, tradesKey)) || [];
        for (const tr of trades) {
          const hist = Array.isArray(tr.history) ? tr.history : [];
          let entryTs = Number(tr.entry_ts);
          if (!Number.isFinite(entryTs) || entryTs <= 0) entryTs = null;
          if (entryTs != null && entryTs < 1e12) entryTs = entryTs * 1000;
          let exitTs = Number(tr.exit_ts);
          if (!Number.isFinite(exitTs) || exitTs <= 0) exitTs = null;
          if (exitTs != null && exitTs < 1e12) exitTs = exitTs * 1000;
          for (const ev of hist) {
            const type = String(ev?.type || "").toUpperCase();
            if (type !== "EXIT" && type !== "TRIM") continue;
            const ts = toMs(ev?.timestamp ?? ev?.ts);
            if (!isBadTs(ts)) continue;
            const fallback = exitTs || entryTs || Date.now();
            const ms = Number.isFinite(fallback) ? fallback : Date.now();
            ev.ts = ms;
            ev.timestamp = new Date(ms).toISOString();
            fixedKV++;
          }
        }
        if (fixedKV > 0) await kvPutJSON(KV, tradesKey, trades);

        let fixedD1 = 0;
        if (env?.DB) {
          try {
            const bad = await env.DB.prepare(
              `SELECT event_id, trade_id, ts, type FROM trade_events WHERE type IN ('EXIT','TRIM') AND (ts IS NULL OR ts <= 0 OR ts < ?1)`
            ).bind(MIN_SANE_TS_MS).all();
            const rows = bad?.results || [];
            for (const row of rows) {
              const tid = row?.trade_id;
              const r = await env.DB.prepare(
                `SELECT exit_ts, entry_ts FROM trades WHERE trade_id = ?1`
              ).bind(tid).first();
              const exitTs = r?.exit_ts != null ? Number(r.exit_ts) : null;
              const entryTs = r?.entry_ts != null ? Number(r.entry_ts) : null;
              let ts = Number.isFinite(exitTs) && exitTs > 0 ? exitTs : null;
              if (ts == null) ts = Number.isFinite(entryTs) && entryTs > 0 ? entryTs : null;
              if (ts != null && ts < 1e12) ts = ts * 1000;
              if (ts == null || ts <= 0) ts = Date.now();
              await env.DB.prepare(
                `UPDATE trade_events SET ts = ?1 WHERE event_id = ?2`
              ).bind(Math.round(ts), row.event_id).run();
              fixedD1++;
            }
          } catch (e) {
            console.error("[fix-zero-ts-events] D1 fix failed:", e);
          }
        }

        return sendJSON(
          { ok: true, fixedKV, fixedD1, message: `Fixed ${fixedKV} KV history events and ${fixedD1} D1 trade_events with zero/missing ts.` },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/reset?key=... - Reset system state as if freshly launched (SAFE by default)
      // Default behavior (safe):
      // - Clears KV simulated trades + paper portfolio + activity feed
      // - Clears per-ticker Kanban entry stamps + lane transition memory + flip-watch stickiness
      // - Recomputes kanban_stage immediately (so UI is clean right away)
      // Optional (DANGEROUS; opt-in via query params):
      // - resetMl=1      -> clears ML model + training queue
      // - resetLedger=1  -> clears D1 ledger tables (alerts/trades/events)
      if (routeKey === "POST /timed/admin/reset") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const resetLedger =
          url.searchParams.get("resetLedger") === "1" ||
          url.searchParams.get("resetLedger") === "true";

        const resetMl =
          url.searchParams.get("resetMl") === "1" ||
          url.searchParams.get("resetMl") === "true";

        const now = Date.now();
        const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
        const tickers = Array.isArray(tickerIndex) ? tickerIndex : [];

        const resetPayload = (p) => {
          if (!p || typeof p !== "object") return p;

          // Clear Kanban state + entry stamps
          p.kanban_stage = null;
          p.prev_kanban_stage = null;
          p.prev_kanban_stage_ts = null;
          p.kanban_meta = null;
          p.kanban_cycle_enter_now_ts = null;
          p.kanban_cycle_trigger_ts = null;
          p.kanban_cycle_side = null;

          p.entry_price = null;
          p.entry_ts = null;
          p.entry_change_pct = null;

          // Clear flip watch stickiness
          p.flip_watch_score = null;
          p.flip_watch_reasons = null;
          p.flip_watch_until_ts = null;

          // Force recompute on next read/ingest
          p.move_status = null;

          // Clear forcing flags
          p.flags = p.flags && typeof p.flags === "object" ? p.flags : {};
          p.flags.flip_watch = false;
          for (const k of Object.keys(p.flags)) {
            if (
              k.startsWith("forced_") ||
              k === "recycled_from_archive" ||
              k === "move_invalidated" ||
              k === "move_completed"
            ) {
              try {
                delete p.flags[k];
              } catch {}
            }
          }

          // Recompute stage immediately so UI is clean after reset
          try {
            const stage = classifyKanbanStage(p);
            p.kanban_stage = stage;
            p.kanban_meta = deriveKanbanMeta(p, stage);
          } catch {
            p.kanban_stage = null;
            p.kanban_meta = null;
          }

          p.reset_at = now;
          return p;
        };

        // Clear KV simulated trades + paper portfolio + activity feed
        const kvCleared = [];
        try {
          await KV.delete("timed:trades:all");
          kvCleared.push("timed:trades:all");
        } catch {}
        try {
          await KV.delete(PORTFOLIO_KEY);
          kvCleared.push(PORTFOLIO_KEY);
        } catch {}
        try {
          await KV.delete("timed:activity:feed");
          kvCleared.push("timed:activity:feed");
        } catch {}

        // Clear ML model (optional; OFF by default)
        if (resetMl) {
          try {
            await KV.delete("timed:model:ml_v1");
            kvCleared.push("timed:model:ml_v1");
          } catch {}
          try {
            await KV.delete("timed:model:ml_v1:last_ts");
            kvCleared.push("timed:model:ml_v1:last_ts");
          } catch {}
        }

        // Archive open trades (always) + optionally clear ledger (OFF by default)
        let d1Cleared = [];
        try {
          if (env?.DB) {
            // Archive all open trades by default (non-destructive)
            try {
              const archiveSql = "UPDATE trades SET status = 'ARCHIVED' WHERE status NOT IN ('WIN', 'LOSS', 'ARCHIVED')";
              const archiveResult = await env.DB.prepare(archiveSql).run();
              d1Cleared.push({ sql: archiveSql, changes: archiveResult?.meta?.changes ?? 0 });
            } catch (archiveErr) {
              // ignore if table doesn't exist
            }
            
            if (resetLedger) {
              // Full ledger clear (DANGEROUS; opt-in only)
              // Clear new position-based tables first (due to foreign key constraints)
              // Also clear ticker_latest to ensure fresh state for /timed/all
              for (const sql of [
                "DELETE FROM execution_actions",
                "DELETE FROM lots",
                "DELETE FROM positions",
                "DELETE FROM trade_events",
                "DELETE FROM trades",
                "DELETE FROM alerts",
                "DELETE FROM ticker_latest",
              ]) {
                try {
                  const r = await env.DB.prepare(sql).run();
                  d1Cleared.push({ sql, changes: r?.meta?.changes ?? null });
                } catch {
                  // ignore missing tables
                }
              }
            }
            // ML queue
            if (resetMl) {
              try {
                const r = await env.DB.prepare("DELETE FROM ml_v1_queue").run();
                d1Cleared.push({
                  sql: "DELETE FROM ml_v1_queue",
                  changes: r?.meta?.changes ?? null,
                });
              } catch {}
            }
          }
        } catch {}

        // Reset per-ticker latest payloads (KV + D1 latest)
        const results = { processed: 0, updated: 0, skipped: 0, errors: [] };
        for (const t of tickers) {
          const ticker = normTicker(t);
          if (!ticker) continue;
          try {
            const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
            if (!latest || typeof latest !== "object") {
              results.skipped++;
              continue;
            }
            const next = resetPayload({ ...latest });
            await kvPutJSON(KV, `timed:latest:${ticker}`, next);
            try {
              ctx.waitUntil(d1UpsertTickerLatest(env, ticker, next));
              ctx.waitUntil(d1UpsertTickerIndex(env, ticker, next?.ts));
            } catch {}
            results.updated++;
            results.processed++;
          } catch (e) {
            results.errors.push({ ticker: String(t), error: String(e?.message || e) });
          }
        }

        return sendJSON(
          {
            ok: true,
            message: "System reset complete (as-of now).",
            now,
            tickers: { total: tickers.length, ...results },
            kvCleared,
            d1Cleared,
            resetMl,
            resetLedger,
            note: "Lanes recompute from fresh state; new KV simulated trades will be created as new data/alerts come in. D1 ledger is preserved unless resetLedger=1.",
          },
          200,
          corsHeaders(env, req),
        );
      }

      return sendJSON(
        { ok: false, error: "not_found" },
        404,
        corsHeaders(env, req),
      );
    } catch (topLevelErr) {
      // Catch any unhandled errors and return a proper response with CORS headers
      console.error(`[FETCH ERROR] Unhandled error in fetch handler:`, {
        error: String(topLevelErr),
        message: topLevelErr?.message,
        stack: topLevelErr?.stack,
        url: req?.url,
        method: req?.method,
        hasKV: !!env?.KV_TIMED,
        pathname: new URL(req?.url || "").pathname,
      });
      return sendJSON(
        {
          ok: false,
          error: "internal_error",
          message: "An unexpected error occurred",
          details:
            process.env.NODE_ENV === "development"
              ? String(topLevelErr)
              : undefined,
        },
        500,
        corsHeaders(env, req),
      );
    }
  },

  // Scheduled handler for periodic AI updates (9:45 AM, noon, 3:30 PM ET) and trade updates (every 5 min)
  async scheduled(event, env, ctx) {
    // Weekly Retrospective: Fridays at 9:15 PM UTC (4:15 PM ET, after market close)
    // Evaluates pattern performance, detects regime shifts, writes proposals.
    if (event.cron === "15 21 * * 5") {
      if (env?.DB) {
        ctx.waitUntil(
          runWeeklyRetrospective(env.DB)
            .then((r) => console.log(`[MODEL RETRO] Weekly retrospective: ${r.resolved} resolved, ${r.proposals.length} proposals, ${r.regimeShifts.length} regime shifts`))
            .catch((e) => console.warn(`[MODEL RETRO] Failed:`, String(e?.message || e).slice(0, 300)))
        );
      }
      return;
    }

    // Data lifecycle: aggregate timed_trail → trail_5m_facts, purge old raw data (4 AM UTC daily)
    // Also resolve expired model predictions.
    if (event.cron === "0 4 * * *") {
      ctx.waitUntil(runDataLifecycle(env));
      // Resolve model predictions whose horizon has expired (non-blocking)
      if (env?.DB) {
        ctx.waitUntil(
          resolveExpiredPredictions(env.DB, Date.now())
            .then((r) => console.log(`[MODEL] Resolved ${r.resolved} predictions`))
            .catch((e) => console.warn(`[MODEL] Resolution failed:`, String(e?.message || e).slice(0, 200)))
        );
      }
      return;
    }

    // ═══════════════════════════════════════════════════════════════════════
    // ALPACA BAR FETCHING — extended hours coverage
    //   Pre-market + RTH: */1 9-21 * * 1-5  (4AM-4PM ET = 9-21 UTC, every 1 min)
    //   After-hours:      */5 21-23 * * 1-5  (4PM-7PM ET, every 5 min)
    //                     */5 0-1 * * 2-6    (7PM-8PM ET, every 5 min)
    // This cron ONLY fetches bars from Alpaca and stores them in D1.
    // Scoring and trade updates happen in the */5 cron cycle below.
    // ═══════════════════════════════════════════════════════════════════════
    const isAlpacaBarCron = event.cron === "*/1 9-21 * * 1-5"
      || event.cron === "*/5 21-23 * * 1-5"
      || event.cron === "*/5 0-1 * * 2-6";
    if (isAlpacaBarCron) {
      if (env.ALPACA_ENABLED === "true" && env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY) {
        try {
          const allTickers = Object.keys(SECTOR_MAP);
          const result = await alpacaCronFetchLatest(env, allTickers, d1UpsertCandle);
          console.log(`[ALPACA CRON] Fetched bars: ${result.upserted} upserted, ${result.errors} errors`);
        } catch (err) {
          console.error("[ALPACA CRON] Error:", err);
        }
      }
      return; // Only bar fetching on this cron; the */5 cron handles scoring + trades
    }

    // ═══════════════════════════════════════════════════════════════════════
    // FAST SCORING CRON (*/1 13-21 * * 1-5) — dedicated scoring-only path
    // Scores ~60 tickers per 1-min cycle with rolling cursor + priority.
    // Full universe covered in ~4-5 cycles (4-5 minutes).
    // Skips D1 sync, trade updates, alerts — those run on the */5 cron.
    // Subrequest budget: ~60 * 9 = ~540 (well within 1,000 limit)
    // ═══════════════════════════════════════════════════════════════════════
    // TEMP: match "*/1 * * * *" for validation; revert to "*/1 13-21 * * 1-5"
    const isMarketHoursScoringCron = event.cron === "*/1 * * * *" || event.cron === "*/1 13-21 * * 1-5";
    if (isMarketHoursScoringCron && env.ALPACA_ENABLED === "true") {
      const KV = env.KV_TIMED;
      try {
        const scoringStart = Date.now();
        const allTickers = Object.keys(SECTOR_MAP);

        // Rolling cursor: advance through the universe across 1-min cycles
        const cursorKey = "timed:scoring:fast_cursor";
        let cursor = 0;
        try {
          cursor = Number(await KV.get(cursorKey)) || 0;
          if (!Number.isFinite(cursor) || cursor < 0 || cursor >= allTickers.length) cursor = 0;
        } catch { cursor = 0; }

        // Get open positions (always scored first, regardless of cursor)
        const openTradesCheck = ((await kvGetJSON(KV, "timed:trades:all")) || [])
          .filter(t => t.status === "OPEN" || t.status === "TP_HIT_TRIM");
        const openTickerSet = new Set(openTradesCheck.map(t => String(t.ticker || "").toUpperCase()));

        // Build kanban cache for priority ordering within the batch
        const kanbanCache = {};
        try {
          const d1Rows = await env.DB?.prepare(
            `SELECT ticker, kanban_stage FROM ticker_latest WHERE kanban_stage IN ('setup', 'enter', 'enter_now') LIMIT 100`
          ).all();
          for (const row of (d1Rows?.results || [])) {
            kanbanCache[row.ticker] = row.kanban_stage;
          }
        } catch { /* non-critical */ }

        // Batch of 45 tickers per 1-min cycle. Full universe in ~6 cycles (~6 min).
        // Subrequest budget: 45 * ~9 + overhead = ~420 (safe margin under 1,000)
        const FAST_BATCH = 45;
        const end = Math.min(cursor + FAST_BATCH, allTickers.length);
        const batchTickers = allTickers.slice(cursor, end);

        // Always include open-position tickers (P0 priority)
        const tickersToScore = [...openTickerSet];
        const batchSet = new Set(batchTickers);
        for (const t of batchTickers) {
          if (!openTickerSet.has(t)) tickersToScore.push(t);
        }

        // Priority sort within this batch
        tickersToScore.sort((a, b) => {
          const pa = openTickerSet.has(a) ? 0
            : (kanbanCache[a] === "setup" || kanbanCache[a] === "enter" || kanbanCache[a] === "enter_now") ? 1 : 2;
          const pb = openTickerSet.has(b) ? 0
            : (kanbanCache[b] === "setup" || kanbanCache[b] === "enter" || kanbanCache[b] === "enter_now") ? 1 : 2;
          return pa - pb;
        });

        let scored = 0, skipped = 0, errors = 0;

        const scoreTicker = async (ticker) => {
          try {
            const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);
            const result = await computeServerSideScores(ticker, d1GetCandles, env, existing);
            if (!result) { skipped++; return; }

            result.data_source = "alpaca";
            result.data_source_ts = Date.now();

            // Compute kanban_stage
            try {
              const openPos = openTradesCheck.find(t => String(t.ticker || "").toUpperCase() === ticker) || null;
              result.kanban_stage = classifyKanbanStage(result, openPos);
            } catch { /* non-critical */ }

            // Delta-based write
            if (hasPayloadChangedMeaningfully(existing, result)) {
              await kvPutJSON(KV, `timed:latest:${ticker}`, result);
              scored++;
            } else {
              skipped++;
            }
          } catch (e) {
            errors++;
            console.warn(`[FAST SCORING] ${ticker}:`, String(e));
          }
        };

        // Process in parallel batches of 10 (conservative for subrequest budget)
        const PARALLEL = 10;
        for (let i = 0; i < tickersToScore.length; i += PARALLEL) {
          const batch = tickersToScore.slice(i, i + PARALLEL);
          await Promise.allSettled(batch.map(scoreTicker));
        }

        // Advance cursor
        const nextCursor = end >= allTickers.length ? 0 : end;
        try { await KV.put(cursorKey, String(nextCursor), { expirationTtl: 3600 }); } catch {}

        const elapsed = Date.now() - scoringStart;
        console.log(`[FAST SCORING] ${scored} scored, ${skipped} skipped, ${errors} errors, ${elapsed}ms, cursor ${cursor}→${nextCursor} (${tickersToScore.length} tickers)`);
      } catch (e) {
        console.error("[FAST SCORING] Error:", e);
      }
      return; // Fast path done — no trade updates, D1 sync, or alerts on this cron
    }

    const KV = env.KV_TIMED;
    const now = new Date();
    const hour = now.getUTCHours();
    const minute = now.getUTCMinutes();
    const processedTickers = new Set();

    // KV → D1 warm-up (*/5 cron only). Reduced batch to 25 to stay within
    // Cloudflare's per-invocation subrequest limit alongside scoring.
    try {
      ctx.waitUntil(d1SyncLatestBatchFromKV(env, ctx, 25));
    } catch (e) {
      console.error("[D1 SYNC] scheduled kickoff failed:", String(e));
    }

    // ═══════════════════════════════════════════════════════════════════════
    // ALPACA SERVER-SIDE SCORING — STANDARD CRON (*/5, off-hours fallback)
    //
    // Scores ~60 tickers per 5-min cycle with rolling cursor + priority.
    // Full universe covered in ~25 minutes off-hours.
    // During market hours, the */1 fast cron handles scoring so this is additive.
    //
    // Priority order: P0 open positions → P1 setup/enter → P2 rest
    // Parallel: 10 tickers concurrently, each with 7 concurrent D1 reads
    // ═══════════════════════════════════════════════════════════════════════
    if (env.ALPACA_ENABLED === "true") {
      try {
        const scoringStart = Date.now();
        const allTickers = Object.keys(SECTOR_MAP);

        // Rolling cursor for off-hours/standard cron
        const cursorKey = "timed:scoring:std_cursor";
        let cursor = 0;
        try {
          cursor = Number(await KV.get(cursorKey)) || 0;
          if (!Number.isFinite(cursor) || cursor < 0 || cursor >= allTickers.length) cursor = 0;
        } catch { cursor = 0; }

        let scored = 0, skipped = 0, errors = 0, trailWrites = 0;

        // Get open positions for priority sorting and kanban context
        const openTradesCheck = ((await kvGetJSON(KV, "timed:trades:all")) || [])
          .filter(t => t.status === "OPEN" || t.status === "TP_HIT_TRIM");
        const openTickerSet = new Set(openTradesCheck.map(t => String(t.ticker || "").toUpperCase()));

        // Batch of 60 tickers from cursor position
        const STD_BATCH = 40;
        const end = Math.min(cursor + STD_BATCH, allTickers.length);
        const batchTickers = allTickers.slice(cursor, end);

        // Always include open positions
        const tickersToScore = [...openTickerSet];
        for (const t of batchTickers) {
          if (!openTickerSet.has(t)) tickersToScore.push(t);
        }

        const scoreTicker = async (ticker) => {
          try {
            const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);
            const result = await computeServerSideScores(ticker, d1GetCandles, env, existing);
            if (!result) { skipped++; return; }

            result.data_source = "alpaca";
            result.data_source_ts = Date.now();

            // Overnight signal injection (throttled to once/day)
            try {
              const currentSession = getSessionType(Date.now());
              if (currentSession === "RTH") {
                const overnightKey = `timed:overnight:${ticker}:${new Date().toISOString().slice(0, 10)}`;
                const alreadyDone = await KV.get(overnightKey);
                if (!alreadyDone) {
                  const lastCloseTs = Date.now() - 18 * 3600 * 1000;
                  const overnight = await computeOvernightSignals(ticker, lastCloseTs, Date.now(), d1GetCandles, env);
                  if (overnight?.overnightFlags && Object.keys(overnight.overnightFlags).length > 0) {
                    result.flags = { ...(result.flags || {}), ...overnight.overnightFlags };
                    result._overnight_signals = overnight.signals;
                  }
                  await KV.put(overnightKey, "1", { expirationTtl: 24 * 3600 });
                }
              }
            } catch { /* overnight injection non-critical */ }

            // Compute kanban_stage
            try {
              const openPos = openTradesCheck.find(t => String(t.ticker || "").toUpperCase() === ticker) || null;
              result.kanban_stage = classifyKanbanStage(result, openPos);
            } catch { /* non-critical */ }

            // Delta-based write
            if (hasPayloadChangedMeaningfully(existing, result)) {
              await kvPutJSON(KV, `timed:latest:${ticker}`, result);
              scored++;
            } else {
              skipped++;
            }

            // D1 trail point (10-minute cadence)
            const TRAIL_CADENCE_MS = 10 * 60 * 1000;
            const lastTrailTs = Number(existing?._last_trail_ts) || 0;
            if (Date.now() - lastTrailTs >= TRAIL_CADENCE_MS && env?.DB) {
              try {
                await d1InsertTrailPoint(env, ticker, result);
                result._last_trail_ts = Date.now();
                await kvPutJSON(KV, `timed:latest:${ticker}`, result);
                trailWrites++;
              } catch { /* trail write non-critical */ }
            }
          } catch (e) {
            errors++;
            console.warn(`[SCORING] ${ticker}:`, String(e));
          }
        };

        // Process in parallel batches of 10
        const PARALLEL = 10;
        for (let i = 0; i < tickersToScore.length; i += PARALLEL) {
          const batch = tickersToScore.slice(i, i + PARALLEL);
          await Promise.allSettled(batch.map(scoreTicker));
        }

        // Advance cursor
        const nextCursor = end >= allTickers.length ? 0 : end;
        try { await KV.put(cursorKey, String(nextCursor), { expirationTtl: 7 * 24 * 3600 }); } catch {}

        const elapsed = Date.now() - scoringStart;
        console.log(`[SCORING] ${scored} scored, ${skipped} skipped, ${errors} errors, ${trailWrites} trail, ${elapsed}ms, cursor ${cursor}→${nextCursor} (${tickersToScore.length} tickers)`);
      } catch (e) {
        console.error("[SCORING] Error:", e);
      }
    }

    // Always update open trades (runs every 5 minutes)
    try {
      const tradesKey = "timed:trades:all";
      const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
      const openTrades = allTrades.filter(
        (t) => t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
      );

      if (openTrades.length > 0) {
        console.log(
          `[TRADE UPDATE CRON] Updating ${openTrades.length} open trades`,
        );

        for (const trade of openTrades) {
          try {
            processedTickers.add(String(trade.ticker || "").toUpperCase());
            const latestData = await kvGetJSON(
              KV,
              `timed:latest:${trade.ticker}`,
            );
            if (latestData) {
              // Use processTradeSimulation to ensure entry price correction logic runs
              const prevLatest = null; // No previous data for scheduled updates
              await processTradeSimulation(
                KV,
                trade.ticker,
                latestData,
                prevLatest,
                env,
              );
            }
          } catch (err) {
            console.error(
              `[TRADE UPDATE CRON] Error updating trade ${trade.ticker}:`,
              err,
            );
          }
        }

        // Re-read trades to get latest state (processTradeSimulation saves them)
        const finalTrades = (await kvGetJSON(KV, tradesKey)) || [];
        // Sort and save (in case processTradeSimulation doesn't sort)
        finalTrades.sort((a, b) => {
          const timeA = new Date(a.entryTime || 0).getTime();
          const timeB = new Date(b.entryTime || 0).getTime();
          return timeB - timeA;
        });
        await kvPutJSON(KV, tradesKey, finalTrades);
        console.log(`[TRADE UPDATE CRON] Updated ${openTrades.length} trades`);
      }
    } catch (error) {
      console.error("[TRADE UPDATE CRON ERROR]", error);
    }

    // Always evaluate Kanban-driven executions for all tickers (covers missed/absent ingests).
    // This is critical for reliability: entries/trims/exits should still happen even if a watchlist alert didn’t fire.
    try {
      const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
      if (Array.isArray(tickers) && tickers.length > 0) {
        console.log(`[KANBAN CRON] Evaluating ${tickers.length} tickers`);
        for (const t of tickers) {
          const sym = String(t || "").toUpperCase();
          if (!sym) continue;
          if (processedTickers.has(sym)) continue;
          try {
            const latestData = await kvGetJSON(KV, `timed:latest:${sym}`);
            if (!latestData) continue;
            await processTradeSimulation(KV, sym, latestData, null, env);
          } catch (e) {
            console.error(`[KANBAN CRON] Error processing ${sym}:`, e);
          }
        }
      } else {
        console.log("[KANBAN CRON] No tickers list found (timed:tickers empty)");
      }
    } catch (e) {
      console.error("[KANBAN CRON] top-level error:", e);
    }

    // ═══════════════════════════════════════════════════════════════════════════
    // POSITION RECONCILIATION: Ensure ALL D1 open positions are monitored
    // This guarantees workflow follow-through: once a position opens, it MUST
    // flow through the workflow until EXIT. Catches orphaned positions where
    // TradingView alerts stopped firing or ticker fell out of KV index.
    // ═══════════════════════════════════════════════════════════════════════════
    try {
      const db = env?.DB;
      if (db) {
        // Fetch ALL open positions from D1 (source of truth)
        const openPositionsResult = await db.prepare(
          `SELECT ticker, position_id, stop_loss, take_profit, direction, cost_basis, total_qty, created_at 
           FROM positions WHERE status = 'OPEN'`
        ).all();
        
        const openPositions = openPositionsResult?.results || [];
        let reconciled = 0;
        let orphaned = 0;
        
        if (openPositions.length > 0) {
          console.log(`[POSITION RECONCILE] Found ${openPositions.length} open positions in D1`);
          
          for (const pos of openPositions) {
            const sym = String(pos.ticker).toUpperCase();
            
            // Skip if we already processed this ticker in KANBAN CRON
            if (processedTickers.has(sym)) continue;
            
            // Get latest data (try KV first, then D1 ticker_latest)
            let latestData = await kvGetJSON(KV, `timed:latest:${sym}`);
            
            if (!latestData) {
              // Fallback: try D1 ticker_latest
              try {
                const d1Latest = await db.prepare(
                  `SELECT payload_json FROM ticker_latest WHERE ticker = ?1`
                ).bind(sym).first();
                
                if (d1Latest?.payload_json) {
                  latestData = typeof d1Latest.payload_json === 'string' 
                    ? JSON.parse(d1Latest.payload_json) 
                    : d1Latest.payload_json;
                }
              } catch (parseErr) {
                console.warn(`[POSITION RECONCILE] ${sym} D1 payload parse failed:`, parseErr);
              }
            }
            
            if (latestData) {
              // Process with position context - ensures DEFEND/TRIM/EXIT logic runs
              try {
                await processTradeSimulation(KV, sym, latestData, null, env);
                processedTickers.add(sym);
                reconciled++;
                console.log(`[POSITION RECONCILE] Processed ${sym}`);
              } catch (procErr) {
                console.error(`[POSITION RECONCILE] ${sym} processTradeSimulation failed:`, procErr);
              }
            } else {
              // CRITICAL: Position exists but NO ticker data at all
              // This is an emergency - position is truly orphaned
              orphaned++;
              console.warn(
                `[POSITION RECONCILE] ⚠️ ORPHANED: ${sym} has open position (ID: ${pos.position_id}) ` +
                `but no ticker data! Entry: $${(pos.cost_basis / pos.total_qty || 0).toFixed(2)}, ` +
                `SL: ${pos.stop_loss || 'none'}, Created: ${new Date(pos.created_at).toISOString()}`
              );
              
              // TODO: Could implement emergency exit for orphaned positions here
              // For now, just log the warning for manual investigation
            }
          }
          
          if (reconciled > 0 || orphaned > 0) {
            console.log(`[POSITION RECONCILE] Summary: ${reconciled} reconciled, ${orphaned} orphaned`);
          }
        }
      }
    } catch (reconcileErr) {
      console.error("[POSITION RECONCILE] Error:", reconcileErr);
    }

    // Ingest coverage check (every 5 min during market hours)
    try {
      await checkIngestCoverage(KV, now);
    } catch (err) {
      console.error("[INGEST COVERAGE ERROR]", err);
    }

    // Proactive Alerts & Pattern Recognition (every 15 minutes during market hours)
    // This runs more frequently to catch time-sensitive conditions
    const isProactiveAlertTime = minute % 15 === 0; // Every 15 minutes

    if (isProactiveAlertTime) {
      try {
        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
        const openTrades = allTrades.filter(
          (t) => t.status === "OPEN" || t.status === "TP_HIT_TRIM",
        );

        // Fetch current ticker data for alert generation (use tickers index; don't arbitrarily truncate to 50)
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const tickerDataPromises = (Array.isArray(tickers) ? tickers : [])
          .slice(0, 600) // safety cap
          .map(async (t) => {
            try {
              const sym = String(t || "").toUpperCase();
              if (!sym) return null;
              const data = await kvGetJSON(KV, `timed:latest:${sym}`);
              if (!data) return null;
              return {
                ticker: sym,
                rank: Number(data.rank) || 0,
                rr: Number(data.rr) || 0,
                price: Number(data.price) || 0,
                completion: Number(data.completion) || 0,
                phase_pct: Number(data.phase_pct) || 0,
                flags: data.flags || {},
              };
            } catch {
              return null;
            }
          });

        const allTickers = (await Promise.all(tickerDataPromises)).filter(Boolean);

        // Generate proactive alerts
        const proactiveAlerts = generateProactiveAlerts(allTickers, allTrades);

        // Store high-priority alerts in KV for retrieval
        if (proactiveAlerts.filter((a) => a.priority === "high").length > 0) {
          const alertsKey = `timed:ai:alerts:${
            now.toISOString().split("T")[0]
          }`;
          const existingAlerts = (await kvGetJSON(KV, alertsKey)) || [];
          const newHighPriorityAlerts = proactiveAlerts
            .filter((a) => a.priority === "high")
            .map((a) => ({
              ...a,
              timestamp: now.toISOString(),
            }));

          // Merge and keep only last 50 alerts
          const updatedAlerts = [
            ...newHighPriorityAlerts,
            ...existingAlerts,
          ].slice(0, 50);
          await kvPutJSON(KV, alertsKey, updatedAlerts);

          console.log(
            `[PROACTIVE ALERTS] Generated ${proactiveAlerts.length} alerts, ${newHighPriorityAlerts.length} high-priority`,
          );
        }
      } catch (error) {
        console.error("[PROACTIVE ALERTS ERROR]", error);
      }
    }

    // AI Updates (only at specific times: 9:45 AM, noon, 3:30 PM ET)
    const isAITime =
      (hour === 14 && minute === 45) || // 9:45 AM ET
      (hour === 17 && minute === 0) || // 12:00 PM ET
      (hour === 20 && minute === 30); // 3:30 PM ET

    if (!isAITime) {
      return; // Only do AI updates at specific times
    }

    const openaiApiKey = env.OPENAI_API_KEY;
    if (!openaiApiKey) {
      console.error("[SCHEDULED] OpenAI API key not configured");
      return;
    }

    try {
      // Determine update time label
      let updateTime = "Market Update";
      if (hour === 14 && minute === 45) {
        updateTime = "Morning Market Update (9:45 AM ET)";
      } else if (hour === 17 && minute === 0) {
        updateTime = "Midday Market Update (12:00 PM ET)";
      } else if (hour === 20 && minute === 30) {
        updateTime = "Afternoon Market Update (3:30 PM ET)";
      }

      // Fetch all ticker data
      const allKeys = await KV.list({ prefix: "timed:latest:" });
      const tickerDataPromises = allKeys.keys.slice(0, 50).map(async (key) => {
        try {
          const data = await kvGetJSON(KV, key.name);
          if (data) {
            const ticker = key.name.replace("timed:latest:", "");
            return {
              ticker,
              rank: Number(data.rank) || 0,
              rr: Number(data.rr) || 0,
              price: Number(data.price) || 0,
              state: String(data.state || ""),
              phase_pct: Number(data.phase_pct) || 0,
              completion: Number(data.completion) || 0,
              flags: data.flags || {},
            };
          }
          return null;
        } catch (err) {
          return null;
        }
      });

      const allTickers = (await Promise.all(tickerDataPromises))
        .filter(Boolean)
        .sort((a, b) => (b.rank || 0) - (a.rank || 0));

      // Fetch recent activity
      const activityKeys = await KV.list({ prefix: "timed:activity:" });
      const activityPromises = activityKeys.keys.slice(-20).map(async (key) => {
        try {
          const data = await kvGetJSON(KV, key.name);
          if (data) {
            return {
              ticker: String(data.ticker || "UNKNOWN"),
              type: String(data.type || "event"),
              ts: Number(data.ts) || Date.now(),
              price: Number(data.price) || 0,
            };
          }
          return null;
        } catch (err) {
          return null;
        }
      });

      const activityEvents = (await Promise.all(activityPromises))
        .filter(Boolean)
        .sort((a, b) => b.ts - a.ts)
        .slice(0, 10);

      // Analyze for proactive alerts
      const primeSetups = allTickers.filter(
        (t) =>
          t.rank >= 75 &&
          t.rr >= 1.5 &&
          t.completion < 0.4 &&
          t.phase_pct < 0.6,
      );

      const highRiskPositions = allTickers.filter(
        (t) => t.completion > 0.7 || t.phase_pct > 0.8,
      );

      // Build monitoring prompt
      const monitoringPrompt = `You are providing a ${updateTime} for the Timed Trading platform.

## CURRENT MARKET DATA
- **${allTickers.length} total tickers** being monitored
- **${
        primeSetups.length
      } prime setups** (Rank ≥75, RR ≥1.5, Completion <40%, Phase <60%)
- **${
        highRiskPositions.length
      } high-risk positions** (Completion >70% or Phase >80%)
- **${activityEvents.length} recent activity events**

### Top Prime Setups:
${
  primeSetups
    .slice(0, 10)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: Rank ${
        t.rank
      } | RR ${rrFormatted} | Price $${t.price.toFixed(2)} | Phase ${(
        t.phase_pct * 100
      ).toFixed(0)}% | Completion ${(t.completion * 100).toFixed(0)}%`;
    })
    .join("\n") || "None"
}

### Recent Activity:
${
  activityEvents
    .slice(0, 10)
    .map(
      (a) =>
        `- ${new Date(a.ts).toLocaleTimeString()}: **${a.ticker}** ${
          a.type
        } at $${a.price.toFixed(2)}`,
    )
    .join("\n") || "None"
}

Provide a concise market update with:
1. **🎯 Key Opportunities** (Top 3-5 setups to watch)
2. **⚠️ Warnings** (High-risk positions or market conditions)
3. **📊 Market Insights** (Overall conditions, trends)

Be concise (3-5 sentences per section).`;

      // Call OpenAI API
      const aiResponse = await fetch(
        "https://api.openai.com/v1/chat/completions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${openaiApiKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model:
              env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                ? env.OPENAI_MODEL
                : "gpt-3.5-turbo",
            messages: [{ role: "system", content: monitoringPrompt }],
            temperature: 0.7,
            max_tokens: 800,
          }),
        },
      );

      if (!aiResponse.ok) {
        throw new Error(`OpenAI API error: ${aiResponse.status}`);
      }

      const aiData = await aiResponse.json();
      const aiMessage =
        aiData.choices?.[0]?.message?.content || "Market update unavailable.";

      // Store update in KV
      const updateKey = `timed:ai:update:${
        now.toISOString().split("T")[0]
      }:${hour}:${minute}`;
      const updateData = {
        timestamp: now.toISOString(),
        updateTime,
        analysis: aiMessage,
        stats: {
          totalTickers: allTickers.length,
          primeSetups: primeSetups.length,
          highRiskPositions: highRiskPositions.length,
          recentActivity: activityEvents.length,
        },
      };

      await KV.put(updateKey, JSON.stringify(updateData));

      // Also store in a list for easy retrieval
      const updatesListKey = `timed:ai:updates:list`;
      const existingList = (await kvGetJSON(KV, updatesListKey)) || [];
      existingList.unshift({
        key: updateKey,
        timestamp: now.toISOString(),
        updateTime,
      });
      // Keep only last 30 updates
      await KV.put(updatesListKey, JSON.stringify(existingList.slice(0, 30)));

      console.log(
        `[SCHEDULED] Generated ${updateTime} at ${now.toISOString()}`,
      );
    } catch (error) {
      console.error("[SCHEDULED ERROR]", error);
    }

    // ML Model Training (every 6 hours)
    // Train model from labeled queue entries
    try {
      const result = await mlV1TrainFromQueue(env, KV, 75);
      if (result.ok && result.trained > 0) {
        console.log(
          `[ML TRAINING] Trained on ${result.trained} examples, model n=${result.model_n}`,
        );
      } else if (result.ok) {
        console.log(`[ML TRAINING] No new labels ready for training`);
      }
    } catch (error) {
      console.error("[ML TRAINING ERROR]", error);
    }
  },
};

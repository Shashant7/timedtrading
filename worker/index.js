// Timed Trading Worker — KV latest + trail + rank + top lists + Discord alerts (CORRIDOR-ONLY)
import { DASHBOARD_HTML } from "./dashboard-html.js";
export { PriceHub } from "./price-hub.js";
export { AlpacaStream } from "./alpaca-stream.js";
import {
  kvGetJSON,
  kvPutJSON,
  kvPutText,
  kvPutJSONWithRetry,
  stableHash,
  d1InsertTrailPoint,
  d1InsertIngestReceipt,
  slimPayloadForD1,
  minimalPayloadForD1,
} from "./storage.js";
import {
  normTicker,
  isNum,
  normalizeTfKey,
  validateTimedPayload,
  validateCapturePayload,
  validateCandlesPayload,
} from "./ingest.js";
import {
  KANBAN_STAGE_ORDER,
  LEGACY_STAGE_MAP,
  normalizeStage,
  enforceStageMonotonicity,
  getTradeDirection,
} from "./trading.js";
import {
  sendJSON,
  corsHeaders,
  ackJSON,
  readBodyAsJSON,
  requireKeyOr401,
  requireKeyOrAdmin,
  checkRateLimit,
  checkRateLimitFixedWindow,
  authenticateUser,
  requireUser,
} from "./api.js";
import {
  notifyDiscord,
  shouldSendDiscordAlert,
  generateProactiveAlerts,
  createWeeklyDigestEmbed,
  createInvestorAlertEmbed,
} from "./alerts.js";
import {
  alpacaCronFetchLatest,
  alpacaCronFetchCrypto,
  alpacaBackfill,
  alpacaFetchSnapshots,
  alpacaFetchAllBars,
  alpacaBarToCandle,
  computeServerSideScores,
  computeTfBundle,
  assembleTickerData,
  getSessionType,
  signalFreshness,
  computeOvernightSignals,
  computeTDSequential,
  computeTDSequentialMultiTF,
} from "./indicators.js";
import { createExecutionAdapter } from "./execution.js";
import {
  loadCalendar,
  fetchAndCacheCalendar,
  isEquityHoliday as _calIsEquityHoliday,
  isFuturesEarlyClose as _calIsFuturesEarlyClose,
  isFuturesFullClose as _calIsFuturesFullClose,
  isEquityEarlyClose as _calIsEquityEarlyClose,
  isWithinOperatingHours as _calIsWithinOH,
  isTickerSessionActive as _calIsTickerSessionActive,
  previousTradingDay as _calPreviousTradingDay,
  getETDateStr as _calGetETDateStr,
  RTH_OPEN as _RTH_OPEN,
  RTH_CLOSE as _RTH_CLOSE,
  PM_START as _PM_START,
  FUT_EARLY as _FUT_EARLY,
  isNyRegularMarketOpen as _calIsNyRegularMarketOpen,
  getSessionType as _calGetSessionType,
  getETMinutes as _calGetETMinutes,
} from "./market-calendar.js";

// Module-level calendar object — loaded once per cron/request via loadCalendar(env).
// Enables existing zero-arg functions (isWithinOperatingHours, etc.) to use dynamic data.
let _cronCalendar = null;
// Cached set of removed tickers (populated on first read, refreshed per cron cycle)
let _removedTickersCache = null;
import {
  shouldLogPrediction,
  logPrediction,
  matchPatterns,
  getActivePatterns,
  resolveExpiredPredictions,
  getModelHealth,
  runWeeklyRetrospective,
  computeMultiLevelPredictions,
  extractTDSeqFeatures,
} from "./model.js";
import {
  computeInvestorScore,
  computeRelativeStrength,
  computeRSRank,
  computeMarketHealth,
  classifyInvestorStage,
  detectAccumulationZone,
  generateThesis,
  checkThesisHealth,
  computePortfolioAnalytics,
  generateRebalancingSuggestions,
} from "./investor.js";
import {
  generateDailyBrief,
  gatherDailyBriefData,
  cleanupDailyBrief,
  handleGetBrief,
  handleGetBadge,
  handleGetArchive,
  handleGetArchiveBrief,
  handleMarkPrediction,
  fetchFinnhubEarnings,
} from "./daily-brief.js";
import {
  syncAllETFHoldings,
  handleGetETFGroups,
  handleGetETFHoldings,
  getETFWeightForTicker,
  computeETFWeightBoost,
  loadETFWeightMap,
} from "./etf-holdings.js";

// ─── PriceHub DO notification helper ───────────────────────────────────────
// Fire-and-forget POST to the Durable Object to fan out data to WS clients.
// Always non-blocking (wrapped in ctx.waitUntil) and failure-tolerant.
async function notifyPriceHub(env, payload) {
  if (!env.PRICE_HUB) return;
  try {
    const id = env.PRICE_HUB.idFromName("global");
    const hub = env.PRICE_HUB.get(id);
    await hub.fetch(new Request("https://internal/ws/notify", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
    }));
  } catch (e) {
    console.warn("[WS NOTIFY] Error:", String(e).slice(0, 200));
  }
}

// ─── AlpacaStream DO helpers ─────────────────────────────────────────────
// Manages the AlpacaStream Durable Object lifecycle from cron triggers
async function alpacaStreamStart(env, symbols) {
  if (!env.ALPACA_STREAM) return null;
  try {
    const id = env.ALPACA_STREAM.idFromName("global");
    const stub = env.ALPACA_STREAM.get(id);
    const res = await stub.fetch(new Request("https://internal/start", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ symbols }),
    }));
    return res.json();
  } catch (e) {
    console.warn("[ALPACA_STREAM] start failed:", String(e).slice(0, 200));
    return null;
  }
}

async function alpacaStreamStop(env) {
  if (!env.ALPACA_STREAM) return null;
  try {
    const id = env.ALPACA_STREAM.idFromName("global");
    const stub = env.ALPACA_STREAM.get(id);
    const res = await stub.fetch(new Request("https://internal/stop", { method: "POST" }));
    return res.json();
  } catch (e) {
    console.warn("[ALPACA_STREAM] stop failed:", String(e).slice(0, 200));
    return null;
  }
}

async function alpacaStreamGetPrices(env) {
  if (!env.ALPACA_STREAM) return null;
  try {
    const id = env.ALPACA_STREAM.idFromName("global");
    const stub = env.ALPACA_STREAM.get(id);
    const res = await stub.fetch(new Request("https://internal/prices"));
    const json = await res.json();
    return json.ok ? json.prices : null;
  } catch (e) {
    console.warn("[ALPACA_STREAM] getPrices failed:", String(e).slice(0, 200));
    return null;
  }
}

async function alpacaStreamStatus(env) {
  if (!env.ALPACA_STREAM) return { ok: false, error: "not_configured" };
  try {
    const id = env.ALPACA_STREAM.idFromName("global");
    const stub = env.ALPACA_STREAM.get(id);
    const res = await stub.fetch(new Request("https://internal/status"));
    return res.json();
  } catch (e) {
    return { ok: false, error: String(e).slice(0, 200) };
  }
}

// ─── Pattern Library Cache (for Kanban integration) ────────────────────────
// Avoids hitting D1 on every ingest. Refreshes every 5 minutes.
let _patternCache = { patterns: [], ts: 0 };
const PATTERN_CACHE_TTL_MS = 5 * 60 * 1000; // 5 minutes

async function getCachedPatterns(DB) {
  if (!DB) return [];
  const now = Date.now();
  if (_patternCache.patterns.length > 0 && now - _patternCache.ts < PATTERN_CACHE_TTL_MS) {
    return _patternCache.patterns;
  }
  try {
    const patterns = await getActivePatterns(DB);
    // Pre-parse definition_json for fast matching
    const parsed = patterns.map(p => {
      try {
        return {
          ...p,
          definition_json: typeof p.definition_json === "string" ? JSON.parse(p.definition_json) : p.definition_json,
        };
      } catch { return null; }
    }).filter(Boolean);
    _patternCache = { patterns: parsed, ts: now };
    return parsed;
  } catch (e) {
    console.warn("[PATTERN CACHE] Failed to refresh:", String(e?.message || e).slice(0, 100));
    return _patternCache.patterns; // return stale cache on error
  }
}

/**
 * Match a payload against cached patterns and return enrichment data.
 * Designed to be called in the ingest hot path (synchronous matching, async cache refresh).
 */
function matchPatternsForPayload(payload, cachedPatterns) {
  if (!cachedPatterns || cachedPatterns.length === 0) return null;
  const matched = matchPatterns(payload, cachedPatterns);
  if (matched.length === 0) return null;

  const bullMatches = matched.filter(m => m.expected_direction === "UP");
  const bearMatches = matched.filter(m => m.expected_direction === "DOWN");
  const bestBull = bullMatches.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];
  const bestBear = bearMatches.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];

  const bullConf = bestBull?.confidence || 0;
  const bearConf = bestBear?.confidence || 0;
  const netSignal = bullConf - bearConf;

  return {
    matched: matched.map(m => ({ id: m.pattern_id, name: m.name, dir: m.expected_direction, conf: m.confidence, ev: m.expected_value })),
    bullCount: bullMatches.length,
    bearCount: bearMatches.length,
    bestBull: bestBull ? { id: bestBull.pattern_id, name: bestBull.name, conf: bestBull.confidence, ev: bestBull.expected_value } : null,
    bestBear: bestBear ? { id: bestBear.pattern_id, name: bestBear.name, conf: bestBear.confidence, ev: bestBear.expected_value } : null,
    netSignal: Math.round(netSignal * 1000) / 1000,
    direction: netSignal > 0.1 ? "BULLISH" : netSignal < -0.1 ? "BEARISH" : "NEUTRAL",
  };
}

// Routes:
// POST /timed/ingest?key=...
// GET  /timed/all
// GET  /timed/latest?ticker=XYZ
// GET  /timed/tickers
// GET  /timed/trail?ticker=XYZ
// GET  /timed/top?bucket=long|short|setup&n=10
// GET  /timed/momentum?ticker=XYZ
// GET  /timed/momentum/history?ticker=XYZ
// GET  /timed/momentum/all
// GET  /timed/sectors - Get all sectors and ratings
// GET  /timed/sectors/:sector/tickers?limit=10 - Get top tickers in sector
// GET  /timed/sectors/recommendations?limit=10&totalLimit=50 - Get top tickers across overweight sectors
// POST /timed/ingest-candles?key=... (multi-timeframe OHLCV capture)
// GET  /timed/candles?ticker=XYZ&tf=30&limit=200 (multi-timeframe OHLCV series)
// POST /timed/watchlist/add?key=... - Add tickers to watchlist
// POST /timed/cleanup-no-scores?key=... - Remove tickers without score data from index
// GET  /timed/health
// GET  /timed/version
// POST /timed/purge?key=... (manual purge)
// POST /timed/clear-rate-limit?key=...&ip=...&endpoint=... (clear rate limit)
// GET  /timed/trades?version=2.1.0 (get trades, optional version filter)
// POST /timed/trades?key=... (create/update trade)
// DELETE /timed/trades/:id?key=... (delete trade)
// GET  /timed/alert-debug?ticker=XYZ (debug why alerts aren't firing)
// GET  /timed/debug/trades (get all trades with details)
// GET  /timed/debug/tickers (get all tickers with latest data)
// GET  /timed/debug/config (check Discord and other config)
// POST /timed/debug/simulate-trades?key=... (manually simulate trades for all tickers)

/** Route table: [method, pathOrPredicate, key]. pathOrPredicate is exact path string or (pathname) => bool for param routes. */
const ROUTES = [
  ["POST", "/timed/ingest", "POST /timed/ingest"],
  ["POST", "/timed/ingest-capture", "POST /timed/ingest-capture"],
  ["POST", "/timed/ingest-candles", "POST /timed/ingest-candles"],
  ["POST", "/timed/heartbeat", "POST /timed/heartbeat"],
  ["GET", "/timed/latest", "GET /timed/latest"],
  ["GET", "/timed/tickers", "GET /timed/tickers"],
  ["GET", "/timed/all", "GET /timed/all"],
  ["GET", "/timed/prices", "GET /timed/prices"],
  ["GET", "/timed/earnings/upcoming", "GET /timed/earnings/upcoming"],
  ["GET", "/timed/candles", "GET /timed/candles"],
  ["GET", "/timed/market-calendar", "GET /timed/market-calendar"],
  ["GET", "/timed/trail/performance", "GET /timed/trail/performance"],
  ["GET", "/timed/trail", "GET /timed/trail"],
  ["GET", "/timed/top", "GET /timed/top"],
  ["GET", "/timed/momentum", "GET /timed/momentum"],
  ["GET", "/timed/momentum/history", "GET /timed/momentum/history"],
  ["GET", "/timed/momentum/all", "GET /timed/momentum/all"],
  ["GET", "/timed/sectors", "GET /timed/sectors"],
  ["GET", "/timed/sectors/recommendations", "GET /timed/sectors/recommendations"],
  ["GET", (p) => p.startsWith("/timed/sectors/") && p.endsWith("/tickers"), "GET /timed/sectors/:sector/tickers"],
  ["POST", "/timed/debug/fix-index", "POST /timed/debug/fix-index"],
  ["POST", "/timed/watchlist/add", "POST /timed/watchlist/add"],
  ["POST", "/timed/watchlist/remove", "POST /timed/watchlist/remove"],
  ["GET", "/timed/activity", "GET /timed/activity"],
  ["GET", "/timed/queued-actions", "GET /timed/queued-actions"],
  ["GET", "/timed/check-ticker", "GET /timed/check-ticker"],
  ["GET", "/timed/ingest-status", "GET /timed/ingest-status"],
  ["GET", "/timed/ingestion/stats", "GET /timed/ingestion/stats"],
  ["GET", "/timed/ingest-audit", "GET /timed/ingest-audit"],
  ["GET", "/timed/health", "GET /timed/health"],
  ["GET", "/timed/alpaca-stream/status", "GET /timed/alpaca-stream/status"],
  ["POST", "/timed/alpaca-stream/start", "POST /timed/alpaca-stream/start"],
  ["POST", "/timed/alpaca-stream/stop", "POST /timed/alpaca-stream/stop"],
  ["GET", "/timed/auth", "GET /timed/auth"],
  ["POST", "/timed/purge", "POST /timed/purge"],
  ["POST", "/timed/rebuild-index", "POST /timed/rebuild-index"],
  ["POST", "/timed/clear-rate-limit", "POST /timed/clear-rate-limit"],
  ["POST", "/timed/cleanup-tickers", "POST /timed/cleanup-tickers"],
  ["GET", "/timed/social-additions", "GET /timed/social-additions"],
  ["GET", "/timed/cors-debug", "GET /timed/cors-debug"],
  ["GET", "/timed/version", "GET /timed/version"],
  ["GET", "/timed/alert-debug", "GET /timed/alert-debug"],
  ["GET", "/timed/alert-replay", "GET /timed/alert-replay"],
  ["GET", (p) => p.startsWith("/timed/ledger/trades/") && p.endsWith("/decision-card"), "GET /timed/ledger/trades/:id/decision-card"],
  ["GET", (p) => p.startsWith("/timed/ledger/trades/"), "GET /timed/ledger/trades/:id"],
  ["GET", "/timed/ledger/trades", "GET /timed/ledger/trades"],
  ["GET", "/timed/ledger/alerts", "GET /timed/ledger/alerts"],
  ["GET", "/timed/ledger/summary", "GET /timed/ledger/summary"],
  ["GET", "/timed/trades", "GET /timed/trades"],
  ["GET", "/timed/portfolio", "GET /timed/portfolio"],
  ["GET", "/timed/account-summary", "GET /timed/account-summary"],
  ["POST", "/timed/trades", "POST /timed/trades"],
  ["DELETE", (p) => p.startsWith("/timed/trades/"), "DELETE /timed/trades/:id"],
  ["OPTIONS", "/timed/ai/chat", "OPTIONS /timed/ai/chat"],
  ["POST", "/timed/ai/chat", "POST /timed/ai/chat"],
  ["GET", "/timed/ai/updates", "GET /timed/ai/updates"],
  ["GET", "/timed/ai/daily-summary", "GET /timed/ai/daily-summary"],
  ["GET", "/timed/ai/monitor", "GET /timed/ai/monitor"],
  // ── Daily Brief ──
  ["GET", "/timed/daily-brief", "GET /timed/daily-brief"],
  ["GET", "/timed/daily-brief/badge", "GET /timed/daily-brief/badge"],
  ["GET", "/timed/daily-brief/archive", "GET /timed/daily-brief/archive"],
  ["GET", (p) => p.startsWith("/timed/daily-brief/archive/"), "GET /timed/daily-brief/archive/:id"],
  ["POST", "/timed/daily-brief/predict", "POST /timed/daily-brief/predict"],
  ["POST", "/timed/daily-brief/generate", "POST /timed/daily-brief/generate"],
  // ── Investor Intelligence endpoints ──
  ["GET", "/timed/investor/scores", "GET /timed/investor/scores"],
  ["GET", "/timed/investor/market-health", "GET /timed/investor/market-health"],
  ["GET", "/timed/investor/portfolio", "GET /timed/investor/portfolio"],
  ["GET", "/timed/investor/ticker", "GET /timed/investor/ticker"],
  ["POST", "/timed/investor/compute", "POST /timed/investor/compute"],
  ["POST", "/timed/investor/weekly-digest", "POST /timed/investor/weekly-digest"],
  // ── Investor Positions & DCA ──
  ["GET", "/timed/investor/positions", "GET /timed/investor/positions"],
  ["POST", "/timed/investor/positions", "POST /timed/investor/positions"],
  ["PUT", "/timed/investor/positions", "PUT /timed/investor/positions"],
  ["DELETE", "/timed/investor/positions", "DELETE /timed/investor/positions"],
  ["POST", "/timed/investor/positions/lot", "POST /timed/investor/positions/lot"],
  ["GET", "/timed/investor/dca/plans", "GET /timed/investor/dca/plans"],
  ["POST", "/timed/investor/dca/configure", "POST /timed/investor/dca/configure"],
  ["POST", "/timed/investor/dca/execute", "POST /timed/investor/dca/execute"],
  ["POST", "/timed/investor/auto-rebalance", "POST /timed/investor/auto-rebalance"],
  ["DELETE", "/timed/investor/purge-ticker", "DELETE /timed/investor/purge-ticker"],
  ["GET", "/timed/debug/trades", "GET /timed/debug/trades"],
  ["GET", "/timed/debug/tickers", "GET /timed/debug/tickers"],
  ["GET", "/timed/debug/config", "GET /timed/debug/config"],
  ["GET", "/timed/debug/staleness", "GET /timed/debug/staleness"],
  ["GET", "/timed/debug/daily", "GET /timed/debug/daily"],
  ["POST", "/timed/ml/train", "POST /timed/ml/train"],
  ["POST", "/timed/ml/backfill-queue", "POST /timed/ml/backfill-queue"],
  ["POST", "/timed/admin/replay-ticker", "POST /timed/admin/replay-ticker"],
  ["POST", "/timed/admin/replay-ticker-d1", "POST /timed/admin/replay-ticker-d1"],
  ["GET", "/timed/admin/replay-data-stats", "GET /timed/admin/replay-data-stats"],
  ["GET", "/timed/admin/data-range", "GET /timed/admin/data-range"],
  ["GET", "/timed/admin/history", "GET /timed/admin/history"],
  ["POST", "/timed/admin/replay-ingest", "POST /timed/admin/replay-ingest"],
  ["POST", "/timed/admin/replay-day", "POST /timed/admin/replay-day"],
  ["POST", "/timed/admin/dedupe-trades", "POST /timed/admin/dedupe-trades"],
  ["POST", "/timed/admin/refresh-latest-from-ingest", "POST /timed/admin/refresh-latest-from-ingest"],
  ["POST", "/timed/admin/force-sync", "POST /timed/admin/force-sync"],
  ["POST", "/timed/admin/fix-zero-ts-events", "POST /timed/admin/fix-zero-ts-events"],
  ["POST", "/timed/admin/reset", "POST /timed/admin/reset"],
  ["GET", "/timed/watchlist/coverage", "GET /timed/watchlist/coverage"],
  ["GET", "/timed/saved", "GET /timed/saved"],
  ["POST", "/timed/saved/toggle", "POST /timed/saved/toggle"],
  ["POST", "/timed/cleanup-no-scores", "POST /timed/cleanup-no-scores"],
  ["POST", "/timed/purge-trades-by-version", "POST /timed/purge-trades-by-version"],
  ["POST", "/timed/debug/migrate-brk", "POST /timed/debug/migrate-brk"],
  ["POST", "/timed/debug/cleanup-duplicates", "POST /timed/debug/cleanup-duplicates"],
  ["GET", "/timed/debug/score-analysis", "GET /timed/debug/score-analysis"],
  ["POST", "/timed/debug/purge-ticker", "POST /timed/debug/purge-ticker"],
  ["POST", "/timed/debug/cleanup-all-duplicates", "POST /timed/debug/cleanup-all-duplicates"],
  ["POST", "/timed/debug/recalculate-ranks", "POST /timed/debug/recalculate-ranks"],
  ["POST", "/timed/debug/fix-entry-prices", "POST /timed/debug/fix-entry-prices"],
  ["POST", "/timed/debug/fix-backfill-trades", "POST /timed/debug/fix-backfill-trades"],
  ["POST", "/timed/debug/clear-all-trades", "POST /timed/debug/clear-all-trades"],
  ["POST", "/timed/debug/simulate-trades", "POST /timed/debug/simulate-trades"],
  ["POST", "/timed/admin/reprocess-kanban", "POST /timed/admin/reprocess-kanban"],
  ["POST", "/timed/admin/backfill-trades", "POST /timed/admin/backfill-trades"],
  ["POST", "/timed/admin/backfill-positions", "POST /timed/admin/backfill-positions"],
  ["POST", "/timed/admin/backfill-alerts", "POST /timed/admin/backfill-alerts"],
  ["POST", "/timed/admin/backfill-derived", "POST /timed/admin/backfill-derived"],
  ["POST", "/timed/admin/alpaca-backfill", "POST /timed/admin/alpaca-backfill"],
  ["POST", "/timed/admin/alpaca-compute", "POST /timed/admin/alpaca-compute"],
  ["POST", "/timed/admin/purge-ticker-candles", "POST /timed/admin/purge-ticker-candles"],
  ["GET", "/timed/admin/alpaca-status", "GET /timed/admin/alpaca-status"],
  ["GET", "/timed/admin/ingestion-status", "GET /timed/admin/ingestion-status"],
  ["GET", "/timed/admin/backfill-status", "GET /timed/admin/backfill-status"],
  ["POST", "/timed/admin/refresh-prices", "POST /timed/admin/refresh-prices"],
  ["POST", "/timed/admin/candle-replay", "POST /timed/admin/candle-replay"],
  ["POST", "/timed/admin/run-lifecycle", "POST /timed/admin/run-lifecycle"],
  ["POST", "/timed/admin/model-resolve", "POST /timed/admin/model-resolve"],
  ["POST", "/timed/admin/model-retro", "POST /timed/admin/model-retro"],
  ["POST", "/timed/admin/model-approve", "POST /timed/admin/model-approve"],
  ["GET", "/timed/model/health", "GET /timed/model/health"],
  ["GET", "/timed/model/predictions", "GET /timed/model/predictions"],
  ["GET", "/timed/model/patterns", "GET /timed/model/patterns"],
  ["GET", "/timed/model/changelog", "GET /timed/model/changelog"],
  ["GET", "/timed/model/signals", "GET /timed/model/signals"],
  ["GET", "/timed/model/direction-accuracy", "GET /timed/model/direction-accuracy"],
  ["GET", "/timed/model/retrospective", "GET /timed/model/retrospective"],
  // Screener / Discovery / Enrichment
  ["GET", "/timed/screener/candidates", "GET /timed/screener/candidates"],
  ["POST", "/timed/screener/candidates", "POST /timed/screener/candidates"],
  ["POST", "/timed/enrich-metadata", "POST /timed/enrich-metadata"],
  ["GET", "/timed/enrich-metadata", "GET /timed/enrich-metadata"],
  ["POST", "/timed/enrich-alpaca", "POST /timed/enrich-alpaca"],
  // User / Auth
  ["GET", "/timed/auth/login", "GET /timed/auth/login"],
  ["GET", "/timed/me", "GET /timed/me"],
  ["POST", "/timed/accept-terms", "POST /timed/accept-terms"],
  // ── User-Added Tickers (Phase 5) ──
  ["GET", "/timed/user-tickers", "GET /timed/user-tickers"],
  ["POST", "/timed/user-tickers", "POST /timed/user-tickers"],
  ["DELETE", (p) => /^\/timed\/user-tickers\/[A-Z0-9._!-]+$/i.test(p), "DELETE /timed/user-tickers/:ticker"],
  ["GET", "/timed/user-tickers/system-stats", "GET /timed/user-tickers/system-stats"],
  ["GET", "/timed/admin/users", "GET /timed/admin/users"],
  ["POST", (p) => /^\/timed\/admin\/users\/[^/]+\/tier$/.test(p), "POST /timed/admin/users/:email/tier"],
  // ── Admin: UPTICKS & Sector Ratings ──
  ["GET", "/timed/admin/upticks", "GET /timed/admin/upticks"],
  ["PUT", "/timed/admin/upticks", "PUT /timed/admin/upticks"],
  ["GET", "/timed/admin/sector-ratings", "GET /timed/admin/sector-ratings"],
  ["PUT", "/timed/admin/sector-ratings", "PUT /timed/admin/sector-ratings"],
  // ── ETF Holdings Sync ──
  ["GET", "/timed/etf/groups", "GET /timed/etf/groups"],
  ["GET", (p) => /^\/timed\/etf\/holdings\/[A-Z]+$/i.test(p), "GET /timed/etf/holdings/:symbol"],
  ["POST", "/timed/etf/sync", "POST /timed/etf/sync"],
  // ── Notifications ──
  ["POST", "/timed/push/subscribe", "POST /timed/push/subscribe"],
  ["GET", "/timed/notifications", "GET /timed/notifications"],
  ["POST", "/timed/notifications/read", "POST /timed/notifications/read"],
  ["POST", "/timed/notifications/clear", "POST /timed/notifications/clear"],
  // ── Stripe / Subscriptions ──
  ["POST", "/timed/stripe/create-checkout", "POST /timed/stripe/create-checkout"],
  ["POST", "/timed/stripe/webhook", "POST /timed/stripe/webhook"],
  ["POST", "/timed/stripe/portal", "POST /timed/stripe/portal"],
  ["GET", "/timed/subscription", "GET /timed/subscription"],
  // ── Calibration Pipeline ──
  ["POST", "/timed/calibration/upload-moves", "POST /timed/calibration/upload-moves"],
  ["POST", "/timed/calibration/upload-autopsy", "POST /timed/calibration/upload-autopsy"],
  ["POST", "/timed/calibration/run", "POST /timed/calibration/run"],
  ["GET", "/timed/calibration/report", "GET /timed/calibration/report"],
  ["POST", "/timed/calibration/apply", "POST /timed/calibration/apply"],
];

function getRouteKey(method, pathname) {
  for (const [m, p, key] of ROUTES) {
    if (m !== method) continue;
    if (typeof p === "function") {
      if (p(pathname)) return key;
      continue;
    }
    if (p === pathname) return key;
  }
  return null;
}

// Trading day key in US/Eastern (for daily change vs yesterday close)
const NY_DAY_FMT = new Intl.DateTimeFormat("en-CA", {
  timeZone: "America/New_York",
  year: "numeric",
  month: "2-digit",
  day: "2-digit",
});
const NY_WD_FMT = new Intl.DateTimeFormat("en-US", {
  timeZone: "America/New_York",
  weekday: "short",
});
function nyTradingDayKey(tsMs) {
  const ms = Number(tsMs);
  if (!Number.isFinite(ms)) return null;
  try {
    return NY_DAY_FMT.format(new Date(ms)); // YYYY-MM-DD
  } catch {
    return null;
  }
}
function isNyWeekend(tsMs) {
  const ms = Number(tsMs);
  if (!Number.isFinite(ms)) return false;
  try {
    const wd = String(NY_WD_FMT.format(new Date(ms))).toLowerCase();
    return wd.startsWith("sat") || wd.startsWith("sun");
  } catch {
    return false;
  }
}

// Check if NY regular trading hours — delegates to calendar-aware version when available.
// Handles weekends, holidays, and early-close days.
function isNyRegularMarketOpen(now = new Date()) {
  if (_cronCalendar) return _calIsNyRegularMarketOpen(_cronCalendar, now);
  // Fallback before calendar is loaded (cold start): weekday + time only
  try {
    const wd = String(NY_WD_FMT.format(now)).toLowerCase();
    const isWeekday = wd.startsWith("mon") || wd.startsWith("tue") || wd.startsWith("wed") || wd.startsWith("thu") || wd.startsWith("fri");
    if (!isWeekday) return false;
    const parts = new Intl.DateTimeFormat("en-US", { timeZone: "America/New_York", hour12: false, hour: "2-digit", minute: "2-digit" }).formatToParts(now);
    const map = {};
    for (const p of parts) map[p.type] = Number(p.value);
    const mins = (map.hour || 0) * 60 + (map.minute || 0);
    return mins >= 570 && mins < 960;
  } catch {
    return true; // fail open
  }
}

// Convert a wall-clock time in a TZ (YYYY-MM-DD at 00:00:00) to a UTC ms timestamp.
// We use a small fixed-point iteration to handle DST correctly.
const NY_TS_PARTS_FMT = new Intl.DateTimeFormat("en-US", {
  timeZone: "America/New_York",
  hour12: false,
  year: "numeric",
  month: "2-digit",
  day: "2-digit",
  hour: "2-digit",
  minute: "2-digit",
  second: "2-digit",
});
function tzOffsetMs(ts, timeZone) {
  const d = new Date(Number(ts));
  const parts = new Intl.DateTimeFormat("en-US", {
    timeZone,
    hour12: false,
    year: "numeric",
    month: "2-digit",
    day: "2-digit",
    hour: "2-digit",
    minute: "2-digit",
    second: "2-digit",
  }).formatToParts(d);
  const map = {};
  for (const p of parts) if (p.type !== "literal") map[p.type] = p.value;
  const asIso = `${map.year}-${map.month}-${map.day}T${map.hour}:${map.minute}:${map.second}Z`;
  const wallAsUtc = Date.parse(asIso);
  return wallAsUtc - Number(ts);
}
function nyWallMidnightToUtcMs(dayKey) {
  if (!dayKey) return null;
  const t0 = Date.parse(`${dayKey}T00:00:00Z`); // wall time interpreted as UTC
  if (!Number.isFinite(t0)) return null;
  let ts = t0;
  for (let i = 0; i < 3; i++) {
    const off = tzOffsetMs(ts, "America/New_York");
    const next = t0 - off;
    if (!Number.isFinite(next)) break;
    if (Math.abs(next - ts) < 1000) {
      ts = next;
      break;
    }
    ts = next;
  }
  return ts;
}

// Convert a NY wall-clock time (YYYY-MM-DD at HH:MM:SS) to a UTC ms timestamp.
// Uses the same fixed-point iteration as nyWallMidnightToUtcMs for DST correctness.
function nyWallTimeToUtcMs(dayKey, hh = 0, mm = 0, ss = 0) {
  if (!dayKey) return null;
  const H = String(Math.max(0, Math.min(23, Number(hh) || 0))).padStart(2, "0");
  const M = String(Math.max(0, Math.min(59, Number(mm) || 0))).padStart(2, "0");
  const S = String(Math.max(0, Math.min(59, Number(ss) || 0))).padStart(2, "0");
  const t0 = Date.parse(`${dayKey}T${H}:${M}:${S}Z`); // wall time interpreted as UTC
  if (!Number.isFinite(t0)) return null;
  let ts = t0;
  for (let i = 0; i < 3; i++) {
    const off = tzOffsetMs(ts, "America/New_York");
    const next = t0 - off;
    if (!Number.isFinite(next)) break;
    if (Math.abs(next - ts) < 1000) {
      ts = next;
      break;
    }
    ts = next;
  }
  return ts;
}

function prevTradingDayKey(dayKey) {
  if (!dayKey) return null;
  // Work with a stable noon UTC anchor so DST shifts don’t jump dates.
  let ms = Date.parse(`${dayKey}T12:00:00Z`);
  if (!Number.isFinite(ms)) return null;
  for (let i = 0; i < 10; i++) {
    ms -= 24 * 60 * 60 * 1000;
    const k = nyTradingDayKey(ms);
    if (!k) continue;
    if (!isNyWeekend(ms)) return k;
  }
  return null;
}

// Return today's NY date rolled back to the last weekday (skip Sat/Sun).
// On weekends, returns the most recent Friday. On weekdays, returns today.
// This is the "current trading day" for daily-change calculations.
function currentTradingDayKey() {
  let ms = Date.now();
  for (let i = 0; i < 3; i++) {
    const k = nyTradingDayKey(ms);
    if (k && !isNyWeekend(ms)) return k;
    ms -= 24 * 60 * 60 * 1000;
  }
  return nyTradingDayKey(Date.now()); // fallback
}

// True when previous state is from before today's market open and current bar is at/after open (AH/PM gap bridge).
function isFirstBarOfDayAfterGap(existingTs, currentTs, marketOpenTs) {
  if (!Number.isFinite(marketOpenTs)) return false;
  const cur = Number(currentTs);
  if (!Number.isFinite(cur) || cur < marketOpenTs) return false;
  const prev = Number(existingTs);
  return !Number.isFinite(prev) || prev < marketOpenTs;
}

async function computePrevCloseFromTrail(db, ticker, asOfTs) {
  if (!db || !ticker) return null;
  const dayKey = nyTradingDayKey(asOfTs);
  const prevKey = prevTradingDayKey(dayKey);
  if (!prevKey) return null;
  // Watchlist semantics: previous close = prior trading day regular session close (4pm ET).
  const closeCutoff = nyWallTimeToUtcMs(prevKey, 16, 0, 0);
  if (!Number.isFinite(closeCutoff)) return null;
  const lookbackStart = closeCutoff - 14 * 24 * 60 * 60 * 1000;
  try {
    const row = await db
      .prepare(
        `SELECT price AS price, ts AS ts
         FROM timed_trail
         WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3 AND price IS NOT NULL
         ORDER BY ts DESC
         LIMIT 1`,
      )
      .bind(String(ticker).toUpperCase(), lookbackStart, closeCutoff + 1000)
      .first();
    const p = Number(row?.price);
    const ts = Number(row?.ts);
    if (!Number.isFinite(p) || p <= 0) return null;
    return { close: p, ts: Number.isFinite(ts) ? ts : null, dayKey: prevKey };
  } catch {
    return null;
  }
}

// Derive a minimal ticker context from common payload fields.
// This is a fallback for when Pine capture throttles `payload.context`.
function deriveTickerContext(obj) {
  const pickStr = (...vals) => {
    for (const v of vals) {
      if (typeof v === "string") {
        const s = v.trim();
        if (s) return s;
      }
    }
    return "";
  };

  const fundamentals = obj?.fundamentals && typeof obj.fundamentals === "object"
    ? obj.fundamentals
    : {};
  const profile =
    obj?.profile && typeof obj.profile === "object"
      ? obj.profile
      : obj?.company_profile && typeof obj.company_profile === "object"
        ? obj.company_profile
        : {};
  const meta = obj?.meta && typeof obj.meta === "object" ? obj.meta : {};

  const name = pickStr(
    obj?.name,
    obj?.company_name,
    fundamentals?.name,
    fundamentals?.longName,
    fundamentals?.shortName,
    profile?.name,
    meta?.name,
  );
  const description = pickStr(
    obj?.description,
    fundamentals?.description,
    fundamentals?.business_summary,
    fundamentals?.longBusinessSummary,
    profile?.description,
    profile?.summary,
  );
  const sector = pickStr(obj?.sector, fundamentals?.sector, profile?.sector);
  const industry = pickStr(
    obj?.industry,
    fundamentals?.industry,
    profile?.industry,
  );
  const website = pickStr(obj?.website, fundamentals?.website, profile?.website);

  const out = {};
  if (name) out.name = name;
  if (description) out.description = description;
  if (sector) out.sector = sector;
  if (industry) out.industry = industry;
  if (website) out.website = website;

  return Object.keys(out).length > 0 ? out : null;
}

function mergeTickerContext(existing, incoming) {
  const a =
    existing && typeof existing === "object" && !Array.isArray(existing)
      ? existing
      : null;
  const b =
    incoming && typeof incoming === "object" && !Array.isArray(incoming)
      ? incoming
      : null;
  if (!a && !b) return null;
  if (!a) return b;
  if (!b) return a;

  const out = { ...a };
  for (const [k, v] of Object.entries(b)) {
    if (v == null) continue;
    if (typeof v === "string") {
      const s = v.trim();
      if (!s) continue;
      out[k] = s;
      continue;
    }
    out[k] = v;
  }
  return out;
}

function sanitizeTickerContext(ctx, hostObj = null) {
  if (!ctx || typeof ctx !== "object" || Array.isArray(ctx)) return null;
  const host = hostObj && typeof hostObj === "object" ? hostObj : null;

  const cleanStr = (s, fallback = "") => {
    if (s == null) return fallback;
    let v = String(s);
    // If something double-escaped upstream, normalize literal "\\r" sequences too.
    if (v.includes("\\r")) v = v.replace(/\\r/g, "r");
    // Some upstream strings contain a literal carriage return (\r) where "r" should be (seen in sector/name).
    // Prefer a known-good fallback when available; otherwise treat it as "r".
    if (v.includes("\r")) {
      if (fallback) return String(fallback);
      v = v.replace(/\r/g, "r");
    }
    return v.trim();
  };

  const out = { ...ctx };
  if (typeof out.name === "string") out.name = cleanStr(out.name, host?.name);
  if (typeof out.description === "string")
    out.description = cleanStr(out.description, host?.description);
  if (typeof out.sector === "string")
    out.sector = cleanStr(out.sector, host?.sector);
  if (typeof out.industry === "string")
    out.industry = cleanStr(out.industry, host?.industry);
  if (typeof out.country === "string")
    out.country = cleanStr(out.country, host?.country);

  // Nested string fields (keep objects but clean known strings).
  if (
    out.technical_rating &&
    typeof out.technical_rating === "object" &&
    !Array.isArray(out.technical_rating) &&
    typeof out.technical_rating.status === "string"
  ) {
    out.technical_rating = { ...out.technical_rating };
    out.technical_rating.status = cleanStr(out.technical_rating.status);
  }

  return out;
}

function numParam(url, key, fallback) {
  const v = url?.searchParams?.get(key);
  if (v == null || v === "") return fallback;
  const n = Number(v);
  return Number.isFinite(n) ? n : fallback;
}

async function ensureTickerIndex(KV, ticker) {
  try {
    const key = "timed:tickers";

    // Respect the persistent removal blocklist — never re-add removed tickers
    try {
      const blocklist = await KV.get("timed:removed", "json");
      if (Array.isArray(blocklist) && blocklist.includes(ticker)) {
        return; // Ticker was intentionally removed, don't re-add
      }
    } catch (_) { /* best-effort blocklist check */ }

    // Use retry logic to handle race conditions
    let retries = 3;
    let success = false;

    while (retries > 0 && !success) {
      const cur = (await kvGetJSON(KV, key)) || [];

      if (!cur.includes(ticker)) {
        cur.push(ticker);
        cur.sort();
        await kvPutJSON(KV, key, cur);

        // Verify it was added (with small delay to ensure KV consistency)
        await new Promise((resolve) => setTimeout(resolve, 50));
        const verify = (await kvGetJSON(KV, key)) || [];
        const wasAdded = verify.includes(ticker);

        if (wasAdded) {
          console.log(
            `[TICKER INDEX] Added ${ticker} to index. New count: ${cur.length}, Verified: ${wasAdded}`,
          );
          success = true;
        } else {
          // Retry if verification failed (possible race condition)
          console.warn(
            `[TICKER INDEX] ${ticker} verification failed, retrying... (retries left: ${
              retries - 1
            })`,
          );
          retries--;
          if (retries > 0) {
            await new Promise((resolve) => setTimeout(resolve, 100));
          }
        }

        if (
          !wasAdded &&
          retries === 0 &&
          (ticker === "BMNR" || ticker === "BABA" || ticker === "ETHT")
        ) {
          console.error(
            `[TICKER INDEX ERROR] ${ticker} was NOT added to index after ${3} retries!`,
            {
              beforeAdd: cur.length,
              afterAdd: verify.length,
              tickerInVerify: verify.includes(ticker),
              verifySample: verify.slice(0, 10),
            },
          );
        }
      } else {
        // Already in index - success
        if (ticker === "BMNR" || ticker === "BABA" || ticker === "ETHT") {
          console.log(
            `[TICKER INDEX DEBUG] ${ticker} already in index (count: ${cur.length})`,
          );
        }
        success = true;
      }
    }
  } catch (err) {
    console.error(`[TICKER INDEX ERROR] Failed to ensure ${ticker} in index:`, {
      error: String(err),
      message: err.message,
      stack: err.stack,
    });
    // Don't throw - we don't want index failures to break ingestion
  }
}

// ── ETF Rebalance: auto-add net-new tickers to system ──
// Called by syncAllETFHoldings when new tickers appear in GRNY/GRNI/GRNJ.
// Adds to ticker index + SECTOR_MAP, triggers deep backfill + immediate scoring.
async function etfAutoAddTickers(env, tickers, weightMap, ctx) {
  const KV = env?.KV_TIMED;
  if (!KV || !Array.isArray(tickers) || tickers.length === 0) return [];

  const added = [];
  for (const rawTicker of tickers) {
    const ticker = String(rawTicker).toUpperCase().trim();
    if (!ticker || !/^[A-Z]{1,5}(-[A-Z]{1,2})?$/.test(ticker)) continue;
    if (SECTOR_MAP[ticker]) { added.push(ticker); continue; } // already in core

    try {
      // Derive sector from ETF holdings data if available
      const weights = weightMap?.[ticker];
      let sector = "Unknown";
      // The holdings HTML includes sector info — stored in the full holdings KV
      // For now, default to Unknown; the scoring pipeline enriches via Finnhub context later.
      SECTOR_MAP[ticker] = sector;
      await KV.put(`timed:sector_map:${ticker}`, sector);
      await ensureTickerIndex(KV, ticker);
      added.push(ticker);
      console.log(`[ETF AUTO-ADD] Added ${ticker} to system (sector: ${sector})`);
    } catch (e) {
      console.warn(`[ETF AUTO-ADD] Failed to add ${ticker}:`, String(e?.message || e).slice(0, 150));
    }
  }

  // Deep backfill + score in background (don't block the sync response)
  if (added.length > 0 && ctx?.waitUntil) {
    ctx.waitUntil((async () => {
      // Backfill in batches of 5 to stay under subrequest limits
      for (let i = 0; i < added.length; i += 5) {
        const batch = added.slice(i, i + 5);
        try {
          await alpacaBackfill(env, batch, d1UpsertCandle, "all", null);
          console.log(`[ETF AUTO-ADD] Backfilled ${batch.join(",")}`);
        } catch (e) {
          console.warn(`[ETF AUTO-ADD] Backfill failed for ${batch.join(",")}:`, String(e?.message || e).slice(0, 200));
        }
      }
      // Score each ticker after backfill
      for (const ticker of added) {
        try {
          const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);
          const result = await computeServerSideScores(ticker, d1GetCandles, env, existing);
          if (result) {
            const now = Date.now();
            result.data_source = "alpaca";
            result.data_source_ts = now;
            result.ingest_ts = now;
            result.ingest_time = new Date(now).toISOString();
            result.trigger_ts = now;
            result.rank = computeRank(result);
            result.score = result.rank;
            if (existing?.price) result.price = existing.price;
            if (existing?.prev_close) result.prev_close = existing.prev_close;
            if (existing?.day_change) result.day_change = existing.day_change;
            if (existing?.day_change_pct) result.day_change_pct = existing.day_change_pct;
            await kvPutJSON(KV, `timed:latest:${ticker}`, result);
            console.log(`[ETF AUTO-ADD] Scored ${ticker}: score=${result.score}, state=${result.state}`);
          }
        } catch (e) {
          console.warn(`[ETF AUTO-ADD] Score failed for ${ticker}:`, String(e?.message || e).slice(0, 150));
        }
      }
    })());
  }

  return added;
}

const MARKET_PULSE_SYMS = [
  "SPX","US500","ES1!","NQ1!","RTY1!","YM1!","VX1!",
  "CL1!","GC1!","SI1!","HG1!","NG1!",
  "BTCUSD","ETHUSD",
];

function marketType(ticker) {
  const t = String(ticker || "").toUpperCase();
  if (t.endsWith("USDT") || t.endsWith("USD")) return "CRYPTO_24_7";
  if (t.endsWith("1!")) return "FUTURES_24_5";
  if (["DXY", "US500", "SPX", "USOIL", "GOLD", "SILVER", "GC1!", "SI1!"].includes(t)) return "MACRO";
  return "EQUITY_RTH";
}

function getEasternParts(date = new Date()) {
  const fmt = new Intl.DateTimeFormat("en-US", {
    timeZone: "America/New_York",
    weekday: "short",
    hour: "2-digit",
    minute: "2-digit",
    hour12: false,
  });
  const parts = fmt.formatToParts(date);
  const obj = {};
  for (const p of parts) obj[p.type] = p.value;
  return {
    weekday: obj.weekday || "",
    hour: Number(obj.hour || 0),
    minute: Number(obj.minute || 0),
  };
}

function isMarketHoursET(date = new Date()) {
  const { weekday, hour, minute } = getEasternParts(date);
  if (["Sat", "Sun"].includes(weekday)) return false;
  const mins = hour * 60 + minute;
  return mins >= 9 * 60 + 30 && mins <= 16 * 60;
}

// Operating hours gate: 4 AM - 8 PM ET weekdays, excluding market holidays.
// Uses dynamic calendar from market-calendar.js (Alpaca API + KV cache).
// Falls back to static logic if calendar hasn't been loaded yet.
function isWithinOperatingHours(now = new Date()) {
  if (_cronCalendar) return _calIsWithinOH(_cronCalendar, now);
  // Static fallback (before calendar is loaded in cron)
  const { weekday, hour, minute } = getEasternParts(now);
  if (["Sat", "Sun"].includes(weekday)) return false;
  const mins = hour * 60 + minute;
  return mins >= 4 * 60 && mins < 20 * 60;
}

function minutesSince(ts) {
  if (!ts || typeof ts !== "number") return null;
  return (Date.now() - ts) / 60000;
}

function formatUtcHourBucket(ts) {
  if (!Number.isFinite(ts)) return null;
  return new Date(ts).toISOString().slice(0, 13); // YYYY-MM-DDTHH (UTC)
}

function buildAlertDedupeKey({ ticker, action, side, ts }) {
  const t = String(ticker || "").toUpperCase();
  const act = String(action || "").toUpperCase();
  const dir = String(side || "").toUpperCase();
  const bucket = formatUtcHourBucket(ts);
  const day = bucket ? bucket.slice(0, 10) : null;
  if (!t || !act || !bucket) {
    return { key: null, bucket: null, day };
  }
  return {
    key: `timed:alerted:${t}:${act}:${dir || "UNKNOWN"}:${bucket}`,
    bucket,
    day,
  };
}

async function shouldSendTradeDiscordEvent(
  KV,
  { tradeId, type, ts, bucketMs },
  ttlSec = 48 * 60 * 60,
) {
  try {
    const id = String(tradeId || "").trim();
    const t = String(type || "")
      .trim()
      .toUpperCase();
    const ms = Number(ts);
    if (!id || !t || !Number.isFinite(ms)) {
      return { ok: true, key: null, deduped: false };
    }
    // Bucketed idempotency. Default 1-minute buckets for entries/exits/trims.
    // DEFEND uses 30-minute buckets (no value in alerting more than twice per hour).
    const bMs = Number(bucketMs) || 60000;
    const bucket = Math.floor(ms / bMs);
    const key = `timed:dedupe:trade_event:${id}:${t}:${bucket}`;
    const already = await KV.get(key);
    if (already) return { ok: true, key, deduped: true };
    await kvPutText(KV, key, "1", ttlSec);
    return { ok: true, key, deduped: false };
  } catch (e) {
    // Fail open: better to alert than silently drop.
    return {
      ok: false,
      key: null,
      deduped: false,
      error: String(e?.message || e),
    };
  }
}

function stalenessBucket(ticker, ts) {
  const mt = marketType(ticker);
  const age = minutesSince(ts);
  if (age == null) return { mt, bucket: "UNKNOWN", ageMin: null };

  const warn = mt === "EQUITY_RTH" ? 120 : mt === "FUTURES_24_5" ? 60 : 30;
  const stale = mt === "EQUITY_RTH" ? 480 : mt === "FUTURES_24_5" ? 180 : 120;

  if (age <= warn) return { mt, bucket: "FRESH", ageMin: age };
  if (age <= stale) return { mt, bucket: "AGING", ageMin: age };
  return { mt, bucket: "STALE", ageMin: age };
}

/**
 * Check if a payload has changed meaningfully from the existing KV state.
 * Returns true if the write should proceed, false if it can be skipped.
 * Always writes if: kanban_stage changed, scores changed by >0.5, price changed by >0.1%, or no existing data.
 */
function hasPayloadChangedMeaningfully(existing, newPayload) {
  if (!existing || typeof existing !== "object") return true;
  if (!newPayload || typeof newPayload !== "object") return true;

  // Schema migration: force write if new payload has ema_map but existing doesn't
  if (newPayload.ema_map && !existing.ema_map) return true;

  // Always write if kanban stage changed
  const oldStage = String(existing?.kanban_stage || "");
  const newStage = String(newPayload?.kanban_stage || "");
  if (oldStage !== newStage) return true;

  // Always write if state changed
  const oldState = String(existing?.state || "");
  const newState = String(newPayload?.state || "");
  if (oldState !== newState) return true;

  // Always write if there's a trade event (entry_ts changed)
  const oldEntry = Number(existing?.entry_ts);
  const newEntry = Number(newPayload?.entry_ts);
  if (Number.isFinite(newEntry) && newEntry !== oldEntry) return true;

  // Score delta check (skip if HTF and LTF both moved < 0.5)
  const htfDelta = Math.abs((Number(newPayload?.htf_score) || 0) - (Number(existing?.htf_score) || 0));
  const ltfDelta = Math.abs((Number(newPayload?.ltf_score) || 0) - (Number(existing?.ltf_score) || 0));
  if (htfDelta >= 0.5 || ltfDelta >= 0.5) return true;

  // Price delta check (skip if price moved < 0.1%)
  const oldPrice = Number(existing?.price);
  const newPrice = Number(newPayload?.price);
  if (Number.isFinite(oldPrice) && Number.isFinite(newPrice) && oldPrice > 0) {
    const priceDelta = Math.abs(newPrice - oldPrice) / oldPrice;
    if (priceDelta >= 0.001) return true;
  } else if (Number.isFinite(newPrice)) {
    return true; // no old price, new one exists
  }

  // Flags change (any new flags that weren't there before)
  const oldFlags = existing?.flags || {};
  const newFlags = newPayload?.flags || {};
  for (const key of Object.keys(newFlags)) {
    if (newFlags[key] && !oldFlags[key]) return true;
  }

  // COST OPTIMIZATION: 5-minute time gate REMOVED.
  // The old gate fired on every scoring cycle (which runs every 5 min), making
  // all the delta checks above it pointless. Now KV writes only happen when
  // there's an actual meaningful change, saving ~50-70% of KV writes during RTH.

  return false;
}

function computeRR(d) {
  // RR is always based on CURRENT price — "if I enter now, what's my R:R?"
  // Using trigger_price caused two bugs:
  //   1. trigger near SL → inflated RR (e.g. 26x when realistic is 1.7x)
  //   2. SL recalculated to wrong side of trigger → null RR
  // Current price is the only actionable reference for trade decisions.
  const price = Number(d.price);
  const sl = Number(d.sl);
  if (!Number.isFinite(price) || price <= 0 || !Number.isFinite(sl) || sl <= 0)
    return null;

  // Prefer 3-Tier TP exit level (swing-scaled, 1.0× weekly ATR), then legacy TPs
  let tp = Number(d.tp_exit);
  if (!Number.isFinite(tp) || tp <= 0) tp = Number(d.tp_runner);
  const has3TierTP = Number.isFinite(tp) && tp > 0;
  if (!has3TierTP) {
    tp = Number(d.tp_max_price);
    if (!Number.isFinite(tp) || tp <= 0) tp = Number(d.tp_target_price);
    if (!Number.isFinite(tp) || tp <= 0) tp = Number(d.tp);
    // Legacy tp_levels fallback (only when no 3-tier TPs)
    if (d.tp_levels && Array.isArray(d.tp_levels) && d.tp_levels.length > 0) {
      const tpPrices = d.tp_levels
        .map((tpItem) => {
          if (typeof tpItem === "object" && tpItem !== null && tpItem.price != null) {
            return Number(tpItem.price);
          }
          return Number(tpItem);
        })
        .filter((p) => Number.isFinite(p));
      if (tpPrices.length > 0) {
        const state = String(d.state || "");
        const isShort = state.includes("BEAR");
        tp = isShort ? Math.min(...tpPrices) : Math.max(...tpPrices);
      }
    }
  }

  if (!Number.isFinite(tp)) return null;

  // Determine direction from state to calculate risk/reward correctly
  const state = String(d.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");

  let risk, gain;

  if (isLong) {
    // For LONG: SL below price, TP above price
    risk = price - sl;
    gain = tp - price;
  } else if (isShort) {
    // For SHORT: SL above price, TP below price
    risk = sl - price;
    gain = price - tp;
  } else {
    // Fallback to absolute values if direction unclear
    risk = Math.abs(price - sl);
    gain = Math.abs(tp - price);
  }

  // Ensure both risk and gain are positive
  if (risk <= 0 || gain <= 0) return null;
  return gain / risk;
}

/**
 * RR WARNING SYSTEM: Data-driven warnings based on historical win rates.
 * 
 * From GOLD_PATTERNS_ANALYSIS.md:
 * - RR 0-2: 60.8% win rate (good)
 * - RR 2-5: 54.8% win rate (acceptable)
 * - RR 5-10: 16.4% win rate (AVOID!)
 * - RR 10-20: 29.4% win rate (medium)
 * - RR 20+: 85.9% win rate (excellent)
 * 
 * @param {number} rr - Risk/Reward ratio
 * @returns {object|null} - Warning info or null if no warning
 */
function computeRRWarning(rr) {
  if (!Number.isFinite(rr) || rr <= 0) return null;
  
  if (rr >= 5 && rr <= 10) {
    return {
      level: "WARNING",
      severity: "high",
      message: "RR 5-10 has historically low win rate (16.4%)",
      winRateEstimate: 0.164,
      recommendation: "Consider tighter stop or skip this trade",
      color: "orange",
    };
  }
  
  if (rr > 10 && rr < 20) {
    return {
      level: "CAUTION",
      severity: "medium",
      message: "RR 10-20 has moderate win rate (29.4%)",
      winRateEstimate: 0.294,
      recommendation: "Only if high conviction setup",
      color: "yellow",
    };
  }
  
  if (rr >= 20) {
    return {
      level: "FAVORABLE",
      severity: "none",
      message: "RR 20+ has excellent win rate (85.9%)",
      winRateEstimate: 0.859,
      recommendation: "Strong setup - favorable odds",
      color: "green",
    };
  }
  
  if (rr >= 2 && rr < 5) {
    return {
      level: "GOOD",
      severity: "none",
      message: "RR 2-5 has solid win rate (54.8%)",
      winRateEstimate: 0.548,
      recommendation: null,
      color: "blue",
    };
  }
  
  if (rr < 2) {
    return {
      level: "GOOD",
      severity: "none",
      message: "RR 0-2 has best win rate (60.8%)",
      winRateEstimate: 0.608,
      recommendation: null,
      color: "blue",
    };
  }
  
  return null;
}

// Helper function: completionForSize (normalize completion to 0-1)
// NOTE: Pine computes completion, but we keep a worker-side fallback for safety.
function completionForSize(ticker) {
  const c = Number(ticker?.completion);
  if (Number.isFinite(c)) return Math.max(0, Math.min(1, c));

  const price = Number(ticker?.price);
  const triggerPrice = Number(ticker?.trigger_price);
  const tp = Number(ticker?.tp);
  if (
    !Number.isFinite(price) ||
    !Number.isFinite(triggerPrice) ||
    !Number.isFinite(tp)
  )
    return 0;

  const denom = Math.abs(tp - triggerPrice);
  if (!(denom > 0)) return 0;

  const raw = Math.abs(price - triggerPrice) / denom;
  return Math.max(0, Math.min(1, raw));
}

function computeTpMaxFromLevels(ticker) {
  const tpMaxRaw = Number(ticker?.tp_max_price);
  if (Number.isFinite(tpMaxRaw) && tpMaxRaw > 0) return tpMaxRaw;
  const tpLevels = Array.isArray(ticker?.tp_levels) ? ticker.tp_levels : [];
  const tpPrices = tpLevels
    .map((tpItem) => {
      if (
        typeof tpItem === "object" &&
        tpItem !== null &&
        tpItem.price != null
      ) {
        return Number(tpItem.price);
      }
      return typeof tpItem === "number" ? Number(tpItem) : Number(tpItem);
    })
    .filter((p) => Number.isFinite(p));
  if (tpPrices.length === 0) return null;
  const state = String(ticker?.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");
  return isShort ? Math.min(...tpPrices) : Math.max(...tpPrices);
}

function computeCompletionToTpMax(ticker) {
  const price = Number(ticker?.price);
  const triggerPrice = Number(ticker?.trigger_price);
  const tpMax = computeTpMaxFromLevels(ticker);
  if (
    !Number.isFinite(price) ||
    !Number.isFinite(triggerPrice) ||
    !Number.isFinite(tpMax)
  )
    return null;
  const denom = Math.abs(tpMax - triggerPrice);
  if (!(denom > 0)) return null;
  const raw = Math.abs(price - triggerPrice) / denom;
  return Math.max(0, Math.min(1, raw));
}

function computeRRWith(entryRef, slRef, tpRef, state) {
  const e = Number(entryRef);
  const sl = Number(slRef);
  const tp = Number(tpRef);
  if (!Number.isFinite(e) || !Number.isFinite(sl) || !Number.isFinite(tp))
    return null;

  const s = String(state || "");
  const isLong = s.includes("BULL");
  const isShort = s.includes("BEAR");

  let risk, gain;
  if (isLong) {
    risk = e - sl;
    gain = tp - e;
  } else if (isShort) {
    risk = sl - e;
    gain = e - tp;
  } else {
    risk = Math.abs(e - sl);
    gain = Math.abs(tp - e);
  }
  if (!(risk > 0) || !(gain > 0)) return null;
  return gain / risk;
}

function computeDynamicStopBreakeven(ticker) {
  const state = String(ticker?.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");
  const sl = Number(ticker?.sl);
  const trig = Number(ticker?.trigger_price);
  if (!Number.isFinite(sl) || sl <= 0) return null;
  if (!Number.isFinite(trig) || trig <= 0) return sl;
  if (isShort) return Math.min(sl, trig);
  if (isLong) return Math.max(sl, trig);
  return sl;
}

function computeRRTargets(ticker) {
  const state = String(ticker?.state || "");
  const price = Number(ticker?.price);
  const triggerPrice = Number(ticker?.trigger_price);
  const sl = Number(ticker?.sl);
  // Prefer 3-Tier tp_exit (swing-scaled), then legacy TPs
  const tpLikely =
    Number(ticker?.tp_exit) ||
    Number(ticker?.tp_runner) ||
    Number(ticker?.tp_target_price) ||
    Number(ticker?.tp_target) ||
    Number(ticker?.tp);
  const tpRef = Number.isFinite(tpLikely) && tpLikely > 0 ? tpLikely : null;
  if (!tpRef || !Number.isFinite(sl) || sl <= 0) return null;

  const entryRef =
    Number.isFinite(triggerPrice) && triggerPrice > 0 ? triggerPrice : null;
  const rrEntryLikely = entryRef
    ? computeRRWith(entryRef, sl, tpRef, state)
    : null;

  const dynStop = computeDynamicStopBreakeven(ticker);
  const rrNowLikely =
    Number.isFinite(price) && Number.isFinite(dynStop)
      ? computeRRWith(price, dynStop, tpRef, state)
      : null;

  return {
    tp_likely: tpRef,
    sl_dynamic: Number.isFinite(dynStop) ? dynStop : null,
    rr_entry_likely: Number.isFinite(rrEntryLikely) ? rrEntryLikely : null,
    rr_now_likely: Number.isFinite(rrNowLikely) ? rrNowLikely : null,
  };
}

function computeDataCompleteness(tickerData) {
  const hasTfTech = !!(
    tickerData?.tf_tech && typeof tickerData.tf_tech === "object"
  );
  const hasTriggersField = "triggers" in (tickerData || {});
  const triggersNonEmpty =
    Array.isArray(tickerData?.triggers) &&
    tickerData.triggers.some((t) => typeof t === "string" && t.trim());
  const hasTpLevels =
    Array.isArray(tickerData?.tp_levels) && tickerData.tp_levels.length > 0;
  const hasDailyEma = !!tickerData?.daily_ema_cloud;
  const hasIchD = !!tickerData?.ichimoku_d;
  const hasIchW = !!tickerData?.ichimoku_w;

  const missing = [];
  if (!hasTfTech) missing.push("tf_tech");
  if (!hasTriggersField) missing.push("triggers_field");
  if (!hasTpLevels) missing.push("tp_levels");
  if (!hasDailyEma) missing.push("daily_ema_cloud");
  if (!hasIchD) missing.push("ichimoku_d");
  if (!hasIchW) missing.push("ichimoku_w");

  // Score is intentionally simple + stable for UI filters.
  // 100 = fully instrumented, lower scores indicate missing context.
  let score = 100;
  if (!hasTfTech) score -= 35;
  if (!hasTriggersField) score -= 5;
  if (!hasTpLevels) score -= 10;
  if (!hasDailyEma) score -= 10;
  if (!hasIchD) score -= 15;
  if (!hasIchW) score -= 10;
  score = Math.max(0, Math.min(100, score));

  return {
    score,
    missing,
    has_tf_tech: hasTfTech,
    has_triggers_field: hasTriggersField,
    triggers_non_empty: triggersNonEmpty,
    has_tp_levels: hasTpLevels,
    has_daily_ema_cloud: hasDailyEma,
    has_ichimoku_d: hasIchD,
    has_ichimoku_w: hasIchW,
  };
}

function tfTechAlignmentSummary(tickerData) {
  const tfTech = tickerData?.tf_tech;
  if (!tfTech || typeof tfTech !== "object") return null;

  const side = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  if (!side) return null;

  const TF_ORDER = ["W", "D", "4H", "1H", "30", "10"];
  const WEIGHTS = { W: 2.0, D: 2.0, "4H": 1.5, "1H": 1.5, 30: 1.0, 10: 1.0 };

  let alignedW = 0;
  let opposedW = 0;
  let presentW = 0;
  const stacks = {};

  for (const k of TF_ORDER) {
    const row = tfTech[k];
    const stack = Number(row?.ema?.stack);
    if (!Number.isFinite(stack)) continue;
    presentW += WEIGHTS[k] || 1.0;
    stacks[k] = stack;
    const isAligned = side === "LONG" ? stack >= 4 : stack <= -4;
    const isOpposed = side === "LONG" ? stack <= -4 : stack >= 4;
    if (isAligned) alignedW += WEIGHTS[k] || 1.0;
    if (isOpposed) opposedW += WEIGHTS[k] || 1.0;
  }

  // Convert to a bounded score contribution:
  // - strong alignment across TFs => +0..+10
  // - strong opposition => down to -8
  const raw = alignedW - opposedW;
  const score = Math.max(-8, Math.min(10, raw * 2));

  const sq30 = tfTech["30"]?.sq;
  const sq10 = tfTech["10"]?.sq;
  const squeezeOn = !!(sq30?.s === 1 || sq10?.s === 1);
  const squeezeRel = !!(sq30?.r === 1 || sq10?.r === 1);

  return {
    score,
    side,
    aligned_weight: Math.round(alignedW * 10) / 10,
    opposed_weight: Math.round(opposedW * 10) / 10,
    present_weight: Math.round(presentW * 10) / 10,
    squeeze_on: squeezeOn,
    squeeze_release: squeezeRel,
    stacks,
  };
}

/**
 * GOLD STANDARD SCORING: Data-driven trigger scoring based on historical analysis.
 * 
 * Winner Correlation Data (from GOLD_PATTERNS_ANALYSIS.md):
 * - LTF Pullback (setup state): 84.3% of winners
 * - State Transition: 36.6% of winners
 * - HTF Improving: 34.1% of winners
 * - Squeeze ON (coiling): 21.8% of winners
 * - Squeeze Release: 8.8% of winners (WAS OVERWEIGHTED!)
 * - EMA Cross: 6.3% of winners (WAS OVERWEIGHTED!)
 * 
 * REDUCED WEIGHTS to match data:
 * - Squeeze Release 30M: +6 → +2
 * - EMA Cross 1H: +6 → +2
 * - Buyable Dip 1H: +7 → +3
 */
function triggerSummaryAndScore(tickerData) {
  const side = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  const list = Array.isArray(tickerData?.triggers)
    ? tickerData.triggers
        .filter((t) => typeof t === "string" && t.trim())
        .map((t) => t.trim())
    : [];

  const uniq = Array.from(new Set(list));
  let score = 0;

  const has = (s) => uniq.includes(s);
  const matchSide = (bull, bear) => {
    if (!side) return 0;
    if (side === "LONG" && has(bull)) return 1;
    if (side === "SHORT" && has(bear)) return 1;
    if (side === "LONG" && has(bear)) return -1;
    if (side === "SHORT" && has(bull)) return -1;
    return 0;
  };

  // REDUCED WEIGHTS based on Gold Standard analysis
  if (has("SQUEEZE_RELEASE_30M")) score += 2;  // Was +6, only 8.8% correlation
  score += 2 * matchSide("EMA_CROSS_1H_13_48_BULL", "EMA_CROSS_1H_13_48_BEAR");  // Was +6, only 6.3% correlation
  score += 1 * matchSide("EMA_CROSS_30M_13_48_BULL", "EMA_CROSS_30M_13_48_BEAR");  // Was +2
  if (has("ST_FLIP_1H")) score += 1;
  if (has("ST_FLIP_30M")) score += 1;
  score += 3 * matchSide("BUYABLE_DIP_1H_13_48_LONG", "BUYABLE_DIP_1H_13_48_SHORT");  // Was +7

  // LTF triggers (5m, 10m) — keep same weights (minor contributors)
  if (has("SQUEEZE_RELEASE_10M")) score += 1;  // Was +3
  if (has("SQUEEZE_RELEASE_5M")) score += 1;   // Was +2
  if (has("SQUEEZE_RELEASE_3M")) score += 0.5; // Was +1
  if (has("SQUEEZE_RELEASE_1M")) score += 0.5; // Was +1
  score += 1 * matchSide("EMA_CROSS_10M_13_48_BULL", "EMA_CROSS_10M_13_48_BEAR");  // Was +2
  score += 0.5 * matchSide("EMA_CROSS_5M_13_48_BULL", "EMA_CROSS_5M_13_48_BEAR");
  score += 0.5 * matchSide("EMA_CROSS_3M_13_48_BULL", "EMA_CROSS_3M_13_48_BEAR");
  score += 0.5 * matchSide("EMA_CROSS_1M_13_48_BULL", "EMA_CROSS_1M_13_48_BEAR");
  if (has("ST_FLIP_10M")) score += 0.5;
  if (has("ST_FLIP_5M")) score += 0.5;
  if (has("ST_FLIP_3M")) score += 0.5;
  if (has("ST_FLIP_1M")) score += 0.5;

  // Fallback for legacy payloads without triggers[] populated
  const flags = tickerData?.flags || {};
  if (uniq.length === 0) {
    if (flags.sq30_release) score += 2;           // Was +4
    if (flags.ema_cross_1h_13_48) score += 2;     // Was +5
    if (flags.buyable_dip_1h_13_48) score += 3;   // Was +7
    if (flags.sq10_release) score += 1;           // Was +3
    if (flags.sq5_release) score += 1;            // Was +2
    if (flags.sq3_release) score += 0.5;
    if (flags.sq1_release) score += 0.5;
    if (flags.ema_cross_10m_13_48) score += 1;
    if (flags.ema_cross_5m_13_48) score += 0.5;
    if (flags.ema_cross_3m_13_48) score += 0.5;
    if (flags.ema_cross_1m_13_48) score += 0.5;
    if (flags.st_flip_10m) score += 0.5;
    if (flags.st_flip_5m) score += 0.5;
    if (flags.st_flip_3m) score += 0.5;
    if (flags.st_flip_1m) score += 0.5;
  }

  score = Math.max(-6, Math.min(12, score));  // Reduced cap from 18 to 12

  return {
    score,
    side,
    count: uniq.length,
    top: uniq.slice(0, 5),
  };
}

/**
 * GOLD STANDARD SCORE: Data-driven scoring based on historical winner analysis.
 * 
 * This replaces complex scoring with signals that actually predict winners:
 * - LTF Pullback (setup state): 84.3% correlation
 * - State Transition: 36.6% correlation
 * - HTF Improving: 34.1% correlation
 * - Squeeze ON (coiling): 21.8% correlation
 * - Corridor alignment: High value (quality setups)
 * 
 * @param {object} d - Ticker data
 * @param {object} existing - Previous ticker state (for transition detection)
 * @returns {number} - Score 0-100
 */
function computeGoldScore(d, existing = null) {
  let score = 0;
  const state = String(d?.state || "");
  const htf = Number(d?.htf_score) || 0;
  const ltf = Number(d?.ltf_score) || 0;
  const flags = d?.flags || {};
  
  // ═══════════════════════════════════════════════════════════════════════
  // HIGHEST VALUE: LTF Pullback setup state (84.3% of winners)
  // ═══════════════════════════════════════════════════════════════════════
  const isSetup = state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";
  if (isSetup) score += 25;
  
  // LTF depth in pullback (deeper = better setup)
  const isBullSetup = state === "HTF_BULL_LTF_PULLBACK";
  const isBearSetup = state === "HTF_BEAR_LTF_PULLBACK";
  if (isBullSetup && ltf <= -5) score += 10;   // Deep pullback
  if (isBullSetup && ltf <= -10) score += 5;   // Very deep pullback
  if (isBearSetup && ltf >= 5) score += 10;    // Deep bear pullback
  if (isBearSetup && ltf >= 10) score += 5;    // Very deep
  
  // ═══════════════════════════════════════════════════════════════════════
  // HIGH VALUE: State transition & HTF improving (34-37% correlation)
  // ═══════════════════════════════════════════════════════════════════════
  if (existing && typeof existing === "object") {
    const prevState = existing.state;
    const prevHtf = Number(existing.htf_score) || 0;
    
    // State just changed
    if (prevState && prevState !== state) {
      score += 15;
      d.__state_just_changed = true;
    }
    
    // HTF improving (moving in favorable direction)
    const isBull = state.includes("BULL");
    const isBear = state.includes("BEAR");
    if ((isBull && htf > prevHtf) || (isBear && htf < prevHtf)) {
      score += 10;
      d.__htf_improving = true;
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════
  // MEDIUM VALUE: Squeeze ON - coiling (21.8% correlation)
  // Note: Squeeze ON is more predictive than Squeeze Release!
  // ═══════════════════════════════════════════════════════════════════════
  if (flags.sq30_on && !flags.sq30_release) score += 8;
  
  // ═══════════════════════════════════════════════════════════════════════
  // REDUCED VALUE: Squeeze release, EMA cross (was overweighted)
  // ═══════════════════════════════════════════════════════════════════════
  if (flags.sq30_release) score += 4;           // Was +12
  if (flags.ema_cross_1h_13_48) score += 2;     // Was +5-6
  
  // ═══════════════════════════════════════════════════════════════════════
  // CORRIDOR BONUS: Quality setup indicator
  // ═══════════════════════════════════════════════════════════════════════
  const inCorridor = corridorSide(d) != null;
  if (inCorridor) score += 12;
  if (inCorridor && isSetup) score += 8;  // Perfect setup: corridor + pullback
  
  // ═══════════════════════════════════════════════════════════════════════
  // MOMENTUM ALIGNMENT: Both TFs aligned
  // ═══════════════════════════════════════════════════════════════════════
  const isMomentum = state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  if (isMomentum && inCorridor) score += 5;
  
  return Math.max(0, Math.min(100, Math.round(score)));
}

function triggerReasonCorroboration(tickerData) {
  const rawReason =
    tickerData?.trigger_reason != null
      ? String(tickerData.trigger_reason).trim()
      : "";
  const rawDir =
    tickerData?.trigger_dir != null
      ? String(tickerData.trigger_dir).trim()
      : "";
  if (!rawReason) return { corroborated: true, note: "" };

  const triggers = Array.isArray(tickerData?.triggers)
    ? tickerData.triggers
        .filter((t) => typeof t === "string" && t.trim())
        .map((t) => t.trim())
    : [];
  const flags =
    tickerData?.flags && typeof tickerData.flags === "object"
      ? tickerData.flags
      : {};

  const hasAny = (...xs) => xs.some((x) => triggers.includes(x));

  // Only guard the noisy categories that can "stick" on HTF series.
  if (rawReason === "EMA_CROSS_1H_13_48") {
    const ok =
      hasAny("EMA_CROSS_1H_13_48_BULL", "EMA_CROSS_1H_13_48_BEAR") ||
      !!flags.ema_cross_1h_13_48;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }
  if (rawReason === "EMA_CROSS_30M_13_48") {
    const ok =
      hasAny("EMA_CROSS_30M_13_48_BULL", "EMA_CROSS_30M_13_48_BEAR") ||
      !!flags.ema_cross_30m_13_48;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }
  // LTF EMA cross (10m, 5m): corroborate if triggers[] or flags match
  if (
    /^EMA_CROSS_(10M|5M|3M|1M)_13_48$/i.test(rawReason) ||
    (rawReason.includes("EMA_CROSS") && /10M|5M|3M|1M/.test(rawReason))
  ) {
    const hasEmaTrigger =
      triggers.some(
        (t) =>
          /^EMA_CROSS_(10M|5M|3M|1M)_13_48_(BULL|BEAR)$/i.test(t),
      );
    const hasEmaFlag =
      !!(
        flags.ema_cross_10m_13_48 ||
        flags.ema_cross_5m_13_48 ||
        flags.ema_cross_3m_13_48 ||
        flags.ema_cross_1m_13_48
      );
    const ok = hasEmaTrigger || hasEmaFlag;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }
  // LTF squeeze release (10m, 5m)
  if (
    /^SQUEEZE_RELEASE_(10M|5M|3M|1M)$/i.test(rawReason) ||
    (rawReason.includes("SQUEEZE_RELEASE") && /10M|5M|3M|1M/.test(rawReason))
  ) {
    const hasSqTrigger = triggers.some((t) =>
      /^SQUEEZE_RELEASE_(10M|5M|3M|1M)$/i.test(t),
    );
    const hasSqFlag =
      !!(flags.sq10_release || flags.sq5_release || flags.sq3_release || flags.sq1_release);
    const ok = hasSqTrigger || hasSqFlag;
    return {
      corroborated: ok,
      note: ok
        ? ""
        : `uncorroborated ${rawReason}${rawDir ? " (" + rawDir + ")" : ""}`,
    };
  }

  return { corroborated: true, note: "" };
}

/**
 * Detect "Flip Watch" - tickers about to transition from PULLBACK to momentum
 * Based on analysis of top movers: 76% flipped from PULLBACK to momentum within 6h
 * Common traits: Low completion (<15%), Early phase (<35%), Strong HTF, In/near corridor
 */
function detectFlipWatch(tickerData, trail = []) {
  const state = String(tickerData?.state || "");
  const htfScore = Number(tickerData?.htf_score);
  const ltfScore = Number(tickerData?.ltf_score);
  const completion = Number(tickerData?.completion);
  const phase = Number(tickerData?.phase_pct);
  const flags = tickerData?.flags || {};

  // Must be in PULLBACK state (setup quadrant)
  const inPullback =
    state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";
  if (!inPullback) return null;

  const isBullSetup = state === "HTF_BULL_LTF_PULLBACK";
  const isBearSetup = state === "HTF_BEAR_LTF_PULLBACK";

  // Check corridor status
  const inCorridor = (() => {
    if (!Number.isFinite(htfScore) || !Number.isFinite(ltfScore)) return false;
    if (isBullSetup) {
      return htfScore > 0 && ltfScore >= -10 && ltfScore <= 0;
    } else if (isBearSetup) {
      return htfScore < 0 && ltfScore >= 0 && ltfScore <= 10;
    }
    return false;
  })();

  const nearCorridor = (() => {
    if (inCorridor) return false; // already in, not "near"
    if (!Number.isFinite(htfScore) || !Number.isFinite(ltfScore)) return false;
    if (isBullSetup) {
      // Near corridor: HTF positive, LTF slightly below corridor (-15 to -10)
      return htfScore > 0 && ltfScore >= -15 && ltfScore < -10;
    } else if (isBearSetup) {
      // Near corridor: HTF negative, LTF slightly above corridor (10 to 15)
      return htfScore < 0 && ltfScore > 10 && ltfScore <= 15;
    }
    return false;
  })();

  // Score components (0-100 scale)
  const reasons = [];
  let score = 0;

  // 1. Corridor status (30 points)
  if (inCorridor) {
    score += 30;
    reasons.push("In corridor");
  } else if (nearCorridor) {
    score += 20;
    reasons.push("Near corridor");
  }

  // 2. HTF strength (20 points) - Strong HTF indicates trend support
  const htfStrength = Math.abs(htfScore);
  if (htfStrength >= 20) {
    score += 20;
    reasons.push(`Strong HTF (${htfScore.toFixed(1)})`);
  } else if (htfStrength >= 15) {
    score += 15;
    reasons.push(`Moderate HTF (${htfScore.toFixed(1)})`);
  } else if (htfStrength >= 10) {
    score += 10;
    reasons.push(`Weak HTF (${htfScore.toFixed(1)})`);
  }

  // 3. Low completion (20 points) - 64% of winners had completion <15%
  if (Number.isFinite(completion)) {
    if (completion < 0.15) {
      score += 20;
      reasons.push(`Very low completion (${Math.round(completion * 100)}%)`);
    } else if (completion < 0.25) {
      score += 15;
      reasons.push(`Low completion (${Math.round(completion * 100)}%)`);
    } else if (completion < 0.35) {
      score += 10;
      reasons.push(`Moderate completion (${Math.round(completion * 100)}%)`);
    }
  }

  // 4. Early phase (15 points) - 52% of winners had phase <35%
  if (Number.isFinite(phase)) {
    if (phase < 0.35) {
      score += 15;
      reasons.push(`Early phase (${Math.round(phase * 100)}%)`);
    } else if (phase < 0.5) {
      score += 10;
      reasons.push(`Mid phase (${Math.round(phase * 100)}%)`);
    }
  }

  // 5. Squeeze signals (15 points) - 40% had sq30_on, 32% had sq30_release
  if (flags.sq30_release) {
    score += 15;
    reasons.push("Squeeze released");
  } else if (flags.sq30_on) {
    score += 10;
    reasons.push("Squeeze building");
  }

  // 6. HTF improving (bonus 10 points) - momentum building
  if (flags.htf_improving_4h) {
    score += 10;
    reasons.push("HTF improving");
  }

  // 7. LTF approaching flip zone (bonus) - LTF moving toward zero
  if (Number.isFinite(ltfScore)) {
    const ltfAbs = Math.abs(ltfScore);
    if (ltfAbs <= 5) {
      score += 5;
      reasons.push("LTF near flip zone");
    }
  }

  // 8. Check recent trail for momentum building (if available)
  if (Array.isArray(trail) && trail.length >= 2) {
    // Look at last 6 points (~30 minutes at 5m cadence)
    const recent = trail.slice(-6);
    const htfScores = recent
      .map((p) => Number(p?.htf_score))
      .filter(Number.isFinite);
    const ltfScores = recent
      .map((p) => Number(p?.ltf_score))
      .filter(Number.isFinite);

    if (htfScores.length >= 3) {
      // Check if HTF is strengthening
      const htfLast = htfScores[htfScores.length - 1];
      const htfFirst = htfScores[0];
      const htfImproving = isBullSetup
        ? htfLast > htfFirst
        : htfLast < htfFirst;
      if (htfImproving) {
        score += 5;
        reasons.push("HTF strengthening");
      }
    }

    if (ltfScores.length >= 3) {
      // Check if LTF is moving toward momentum zone
      const ltfLast = ltfScores[ltfScores.length - 1];
      const ltfFirst = ltfScores[0];
      const ltfMovingToMomentum = isBullSetup
        ? ltfLast > ltfFirst
        : ltfLast < ltfFirst;
      if (ltfMovingToMomentum) {
        score += 5;
        reasons.push("LTF moving to momentum");
      }
    }
  }

  // Require minimum score of 50 to flag as flip watch
  if (score < 50) return null;

  return {
    score,
    reasons,
    state,
    htf_score: htfScore,
    ltf_score: ltfScore,
    completion,
    phase,
    in_corridor: inCorridor,
    near_corridor: nearCorridor,
  };
}

/** 8 Kanban lanes (Worker = source of truth):
 *  watch, setup_watch | flip_watch, just_flipped | enter_now | just_entered | hold | trim | exit | archive
 *  UI maps: Watching | Almost Ready | Enter Now | Just Entered | Hold | Trim | Exit | Archived
 */

/**
 * Compute completion towards a specific TP tier (for 3-tier system).
 * Uses the TRIM TP (first tier) for trim lane decisions instead of generic completion.
 * @param {object} tickerData - Ticker payload
 * @param {string} tier - "TRIM", "EXIT", or "RUNNER"
 * @returns {number} - Completion percentage (0-1) towards the specified tier's TP
 */
function computeCompletionToTier(tickerData, tier = "TRIM") {
  const price = Number(tickerData?.price);
  const entryPrice = Number(tickerData?.entry_price);
  const direction = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  
  if (!Number.isFinite(price) || !Number.isFinite(entryPrice) || !direction) {
    return Number(tickerData?.completion) || 0; // Fallback to generic completion
  }
  
  // Build or get TP array
  const tpArray = tickerData?.tpArray || build3TierTPArray(tickerData, entryPrice, direction);
  if (!Array.isArray(tpArray) || tpArray.length === 0) {
    return Number(tickerData?.completion) || 0;
  }
  
  // Find the target tier's TP
  const targetTp = tpArray.find(tp => tp.tier === tier);
  if (!targetTp || !Number.isFinite(targetTp.price)) {
    return Number(tickerData?.completion) || 0;
  }
  
  const tpPrice = targetTp.price;
  const isLong = direction === "LONG";
  
  // Calculate completion: how much of the move from entry to TP has been achieved
  const totalMove = Math.abs(tpPrice - entryPrice);
  if (totalMove <= 0) return 0;
  
  const currentMove = isLong
    ? Math.max(0, price - entryPrice)
    : Math.max(0, entryPrice - price);
  
  return Math.min(1, currentMove / totalMove);
}

/**
 * Check if a ticker qualifies for ENTER stage based on consolidated criteria.
 * 4 data-driven paths derived from Gold Standard analysis:
 * - Path 1: Gold Standard LONG (67.7% of big UP moves)
 * - Path 2: Gold Standard SHORT (82.7% of big DOWN moves)
 * - Path 3: Momentum + High Score (balanced approach)
 * - Path 4: Setup + Squeeze Release (explosive move)
 * 
 * @param {object} d - Ticker data
 * @returns {object} - { qualifies, path, confidence, reason }
 */
function qualifiesForEnter(d, asOfTs = null) {
  const state = String(d?.state || "");
  const inCorridor = corridorSide(d) != null;
  const score = Number(d?.score ?? d?.rank) || 0;
  const flags = d?.flags || {};
  const htf = Number(d?.htf_score) || 0;
  const ltf = Number(d?.ltf_score) || 0;
  const completion = Number(d?.completion) || 0;
  const phase = Number(d?.phase_pct) || 0;
  const rr = Number(d?.rr) || 0;
  
  // ── PRECISION SCORING ENGINE v2 fields ──
  const stSupportScore = d?.st_support?.supportScore ?? 0.5; // 0.0–1.0, 0.5 = neutral
  const fuel30 = d?.fuel?.["30"]?.fuelPct ?? 50;
  const fuel10 = d?.fuel?.["10"]?.fuelPct ?? 50;
  const fuelD = d?.fuel?.D?.fuelPct ?? 50;
  const primaryFuel = Math.max(fuel30, fuel10); // best LTF fuel reading
  // EMA triplet: depth (0-10), structure (-1 to +1), momentum (-1 to +1)
  const emaDepth30 = d?.ema_map?.["30"]?.depth ?? 5;
  const emaDepthD = d?.ema_map?.D?.depth ?? 5;
  const emaStruct30 = d?.ema_map?.["30"]?.structure ?? 0;
  const emaStructD = d?.ema_map?.D?.structure ?? 0;
  const emaMom30 = d?.ema_map?.["30"]?.momentum ?? 0;
  const emaMomD = d?.ema_map?.D?.momentum ?? 0;
  const activeGates = d?.active_gates || [];
  const hasActiveGate = activeGates.length > 0;
  const hasActiveBullGate = activeGates.some(g => g.side === "bull" && !g.completed);
  const hasActiveBearGate = activeGates.some(g => g.side === "bear" && !g.completed);
  const multiHorizonGate = activeGates.filter(g => !g.completed).length >= 2; // Day + Week both active
  
  // ═══════════════════════════════════════════════════════════════════════════
  // UNIVERSAL HARD GATES: Apply to ALL entries
  // ═══════════════════════════════════════════════════════════════════════════
  
  // Trigger freshness: reject stale triggers
  // Live: 15 minutes max (server-side scoring refreshes trigger_ts every cycle)
  // Replay: 7 days max (allows historical data processing)
  const triggerTs = Number(d?.trigger_ts) || 0;
  const now = asOfTs > 0 ? asOfTs : Date.now();
  const isReplayMode = asOfTs > 0;
  const maxTriggerAgeMs = isReplayMode ? 7 * 24 * 60 * 60 * 1000 : 15 * 60 * 1000;
  const triggerAgeMs = triggerTs > 0 ? (now - triggerTs) : Infinity;
  if (triggerAgeMs > maxTriggerAgeMs) {
    return { qualifies: false, reason: "trigger_stale" };
  }
  
  // ── Phase 1a: Entry Quality Score Gate ──
  // Minimum quality score from Phoenix-inspired multi-TF alignment check.
  // Momentum entries need >= 60, pullback entries need >= 45.
  // Volatility tier can raise the minimum (HIGH/EXTREME harder to qualify).
  const eqScore = Number(d?.entry_quality?.score) || 0;
  const volTier = String(d?.volatility_tier || "MEDIUM");
  const volEntryMin = volTier === "EXTREME" ? 70 : volTier === "HIGH" ? 65 : volTier === "MEDIUM" ? 55 : 50;

  // ── Phase 1c: RSI Exhaustion Block on 1H ──
  // No LONG if 1H RSI > 72, no SHORT if 1H RSI < 28 (swing-appropriate levels)
  const rsi1H = Number(d?.entry_quality?.details?.rsi1H) || 50;
  const inferredSideForRSI = sideFromStateOrScores(d);
  if (inferredSideForRSI === "LONG" && rsi1H > 72) {
    return { qualifies: false, reason: "rsi_1h_overbought", rsi1H };
  }
  if (inferredSideForRSI === "SHORT" && rsi1H < 28) {
    return { qualifies: false, reason: "rsi_1h_oversold", rsi1H };
  }

  // Completion gate: must have room to run
  // Phase 1c: tightened from 50%/70% to 40%/60%
  const isPullback = state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";
  const maxCompletion = isPullback ? 0.60 : 0.40;
  if (completion > maxCompletion) {
    return { qualifies: false, reason: "move_too_advanced" };
  }
  
  // Fuel gate (replaces binary phase gate): continuous 0-100% measure of move exhaustion
  // Phase 1c: tightened fuel minimums (40→45 momentum, 30→35 pullback)
  const hasFuelData = d?.fuel != null;
  if (hasFuelData) {
    const minFuel = isPullback ? 35 : 45;
    if (primaryFuel < minFuel) {
      return { qualifies: false, reason: "fuel_exhausted", fuelPct: primaryFuel };
    }
  } else {
    // Legacy phase gate — Phase 1c: tightened from 0.60/0.45 to 0.50/0.35
    const maxPhase = isPullback ? 0.50 : 0.35;
    if (Math.abs(phase) > maxPhase) {
      return { qualifies: false, reason: "phase_too_late" };
    }
  }
  
  // RR gate: must have favorable risk/reward
  // Phase 1c: tighten minimums — 1.5 for momentum, 1.2 for pullbacks
  // Skip R:R check for gold_short entries (TradingView sends LONG-oriented SL/TP)
  const isPotentialGoldShort = state === "HTF_BULL_LTF_BULL" && htf >= 25 && ltf >= 15;
  const rrKnown = Number.isFinite(rr) && rr > 0;
  const rrMin = isPullback ? 1.2 : 1.5;
  if (rrKnown && rr < rrMin && !isPotentialGoldShort) {
    return { qualifies: false, reason: "rr_too_low" };
  }
  
  // ─────────────────────────────────────────────────────────────────────────────
  // CRITICAL: Price vs SL validation - reject stale signals already past SL
  // VERSION: 2.6.4 - Direction-aware SL validation
  // ─────────────────────────────────────────────────────────────────────────────
  // A signal that has already breached its SL is INVALID for entry
  // BUT: TradingView sends SL assuming LONG direction. For SHORT entries,
  // the SL will be computed/flipped at trade creation time, so we only validate
  // if the raw SL is already on the correct side for the intended direction.
  //
  // For LONG: raw sl should be BELOW price (standard TradingView format)
  //           if price < sl, the LONG entry has already failed its stop
  // For SHORT: raw sl is typically BELOW price (TradingView LONG format)
  //            we'll compute a new SL above price at trade creation, so skip validation
  const currentPrice = Number(d?.price);
  const sl = Number(d?.sl);
  
  if (Number.isFinite(currentPrice) && currentPrice > 0 && Number.isFinite(sl) && sl > 0) {
    // Infer intended direction from state (used for general classification)
    // BUT: Entry paths like gold_short override this direction at trade creation
    // So we only apply strict SL validation for LONG entries from PULLBACK states
    const inferredDirection = sideFromStateOrScores(d);
    const isBullishPullback = state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_RALLY";
    
    // Only validate SL for LONG entries from pullback states (where SL is correctly below price)
    // SHORT entries (gold_short from HTF_BULL_LTF_BULL) will have SL computed above price later
    if (inferredDirection === "LONG" && isBullishPullback && currentPrice < sl) {
      // Price already below SL for a LONG pullback entry - signal has failed
      return { qualifies: false, reason: "price_below_sl_long" };
    }
    
    // For LONG entries: check minimum distance from SL (only if SL is below price)
    // JOURNEY DATA: Median pullback is 1.22%. If SL is < 0.8% away, there's no room
    // to survive even a small dip. Require at least 0.8% distance.
    if (inferredDirection === "LONG" && sl < currentPrice) {
      const distToSL = (currentPrice - sl) / currentPrice;
      if (distToSL < 0.008) {
        return { qualifies: false, reason: "price_too_close_to_sl" };
      }
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // SECTOR ALIGNMENT: Boost confidence when the sector is aligned
  // Real-world proof: NVDA, AVGO, TSM all LONG on 2/5/26, all ran because
  // the entire semiconductor sector (6+ tickers) had HTF > 15.
  // ═══════════════════════════════════════════════════════════════════════════
  const ticker = String(d?.ticker || "").toUpperCase();
  const sectorAlign = getSectorAlignmentCached(ticker);
  const sectorAligned = !!(sectorAlign?.aligned);
  const sectorBull = sectorAlign?.direction === "BULL";
  const sectorBear = sectorAlign?.direction === "BEAR";
  const sectorStrength = sectorAlign?.strength || 0;

  // ═══════════════════════════════════════════════════════════════════════════
  // ST SUPPORT MAP GATE: Multi-TF SuperTrend alignment check
  // supportScore: 0.0 = all bearish, 0.5 = neutral, 1.0 = all bullish
  // For LONG momentum entries: require >= 0.5 (majority of TFs bullish)
  // For pullback entries: require >= 0.3 (allow counter-LTF dips)
  // Golden Gate active = bypass support gate (probabilistic edge overrides)
  // ═══════════════════════════════════════════════════════════════════════════
  const hasSupportData = d?.st_support != null;
  if (hasSupportData) {
    const isBullEntry = state.includes("BULL_LTF_BULL") || state === "HTF_BULL_LTF_PULLBACK";
    const isBearEntry = state.includes("BEAR_LTF_BEAR") || state === "HTF_BEAR_LTF_PULLBACK";
    const minSupport = isPullback ? 0.3 : 0.5;
    
    if (isBullEntry && stSupportScore < minSupport && !hasActiveBullGate) {
      return { qualifies: false, reason: "st_support_weak_bull", supportScore: stSupportScore };
    }
    if (isBearEntry && (1 - stSupportScore) < minSupport && !hasActiveBearGate) {
      return { qualifies: false, reason: "st_support_weak_bear", supportScore: stSupportScore };
    }
  }

  // ═══════════════════════════════════════════════════════════════════════════
  // CONFIRMATION SIGNALS: Required for higher quality entries
  // Signals from server-side scoring (flags) now carry timestamps and are
  // subject to freshness decay. TradingView trigger-based signals are treated
  // as inherently fresh (they arrive in real-time).
  // ═══════════════════════════════════════════════════════════════════════════
  
  // Detect SuperTrend and EMA confirmation signals from triggers
  const triggers = d?.triggers || [];
  const triggerSet = new Set(triggers.map(t => String(t).toUpperCase()));
  
  // Freshness threshold: signals below this are considered stale
  const FRESHNESS_MIN = 0.3;
  
  // Helper: check flag + freshness in one step
  const flagFresh = (flag, flagTs, signalType) => {
    if (!flag) return false;
    if (!flagTs || flagTs <= 0) return true; // legacy data without timestamp — accept
    return signalFreshness(flagTs, now, signalType) >= FRESHNESS_MIN;
  };
  
  // SuperTrend flip (bullish or bearish) on any timeframe
  // Triggers from TradingView are always fresh; flag-based signals use decay
  const hasStFlipBull = triggerSet.has("ST_FLIP_30M") || triggerSet.has("ST_FLIP_1H") || 
                        triggerSet.has("ST_FLIP_10M") || triggerSet.has("ST_FLIP_3M") ||
                        flagFresh(flags.st_flip_30m, flags.st_flip_30m_ts, "momentum") ||
                        flagFresh(flags.st_flip_1h, flags.st_flip_1h_ts, "structural") ||
                        flagFresh(flags.st_flip_10m, flags.st_flip_10m_ts, "momentum") ||
                        flagFresh(flags.st_flip_3m, flags.st_flip_3m_ts, "momentum");
  
  // EMA cross signals (confirmation of momentum)
  const hasEmaCrossBull = triggerSet.has("EMA_CROSS_1H_13_48_BULL") || triggerSet.has("EMA_CROSS_30M_13_48_BULL") ||
                          triggerSet.has("EMA_CROSS_10M_13_48_BULL") ||
                          flagFresh(flags.ema_cross_1h_13_48, flags.ema_cross_1h_13_48_ts, "entry") ||
                          flagFresh(flags.ema_cross_30m_13_48, flags.ema_cross_30m_13_48_ts, "entry");
  const hasEmaCrossBear = triggerSet.has("EMA_CROSS_1H_13_48_BEAR") || triggerSet.has("EMA_CROSS_30M_13_48_BEAR") ||
                          triggerSet.has("EMA_CROSS_10M_13_48_BEAR");
  
  // Squeeze release (explosive potential)
  const hasSqRelease = triggerSet.has("SQUEEZE_RELEASE_30M") || triggerSet.has("SQUEEZE_RELEASE_1H") ||
                       flagFresh(flags.sq30_release, flags.sq30_release_ts, "momentum") ||
                       flagFresh(flags.sq1h_release, flags.sq1h_release_ts, "entry");
  
  // LTF momentum confirmation: LTF score should be turning (not deeply negative for LONG)
  // For pullback entries, we want to see LTF recovering (ltf > -10) or momentum signals
  const ltfRecovering = ltf > -10 || hasStFlipBull || hasEmaCrossBull || hasSqRelease;
  
  // ── PRECISION ENRICHMENT HELPER ──
  // Wraps entry path results with precision scoring context.
  // Phase 1a: Apply entry quality score gate here (after path-specific logic).
  // Golden Gate active → confidence upgrade. Multi-horizon gate → highest conviction.
  const enrichResult = (result) => {
    if (!result.qualifies) return result;

    // Learning loop: check if this entry path is auto-disabled due to poor performance
    if (result.path && _pathPerfCache.size > 0) {
      const perf = _pathPerfCache.get(result.path);
      if (perf && perf.enabled === 0) {
        return { qualifies: false, reason: "path_auto_disabled", path: result.path, disableReason: perf.disable_reason };
      }
    }

    // Phase 1a: Entry quality gate — reject low-quality setups
    // Momentum paths: minimum volEntryMin (55-70 depending on vol tier)
    // Pullback/gold paths: minimum 45 (pullbacks naturally have lower alignment)
    const isGoldPath = result.path?.includes("gold") || result.path?.includes("pullback");
    let minQuality = isGoldPath ? 45 : volEntryMin;

    // ── DATA-DRIVEN: Squeeze release caution gate (Phase 1 analysis) ──
    // Squeeze releases have -33.7% lift toward DOWN moves (#1 predictive bearish feature).
    // Squeeze Release in bull context: 70.2% DOWN. In bear context: 65.5% DOWN.
    // When squeeze release is active, require higher entry quality to filter noise.
    const isLongEntry = !result.path?.includes("short");
    if (hasSqRelease && isLongEntry && !isGoldPath) {
      minQuality = Math.max(minQuality, volEntryMin + 10); // Raise bar by 10 during squeeze release for LONG
    }

    // ── DATA-DRIVEN: Sector-specific entry quality adjustments (Phase 1 analysis) ──
    // Financials: only 13.6% UP (strongly bearish) — require higher conviction for LONG
    // Crypto: 43.9% UP (moderate bearish) — slightly higher bar for LONG
    // Basic Materials / Precious Metals / Energy: 83-100% UP — allow slightly easier entry
    const tickerForSector = String(d?.ticker || "").toUpperCase();
    const sectorForEntry = SECTOR_MAP[tickerForSector] || "";
    if (isLongEntry) {
      if (sectorForEntry === "Financials") {
        minQuality = Math.max(minQuality, minQuality + 12); // Financials LONG: much higher bar
      } else if (sectorForEntry === "Crypto") {
        minQuality = Math.max(minQuality, minQuality + 8);  // Crypto LONG: higher bar
      } else if (sectorForEntry === "Basic Materials" || sectorForEntry === "Precious Metals" || sectorForEntry === "Energy") {
        minQuality = Math.max(35, minQuality - 5);          // Bullish sectors: slightly easier
      }
    }

    if (eqScore > 0 && eqScore < minQuality) {
      return { qualifies: false, reason: "entry_quality_too_low", eqScore, minQuality, sectorAdj: sectorForEntry };
    }

    // Golden Gate confidence boost
    const isLong = !result.path?.includes("short");
    const gateMatch = isLong ? hasActiveBullGate : hasActiveBearGate;
    if (gateMatch) {
      // Upgrade confidence: low → medium, medium → high
      if (result.confidence === "low") result.confidence = "medium";
      else if (result.confidence === "medium" && multiHorizonGate) result.confidence = "high";
      result.gate_boost = true;
    }
    if (multiHorizonGate) result.multi_horizon_gate = true;
    // Attach precision metrics for downstream logging/decisions
    result.precision = {
      fuelPct: primaryFuel,
      supportScore: stSupportScore,
      emaDepth30, emaDepthD,
      emaStruct30, emaStructD,
      emaMom30, emaMomD,
      activeGateCount: activeGates.length,
    };
    // Phase 1a: attach entry quality for model learning and dashboard
    result.entryQuality = eqScore;
    return result;
  };
  
  // ═══════════════════════════════════════════════════════════════════════════
  // ENTRY PATHS: Each path has its own corridor/setup requirements
  // ═══════════════════════════════════════════════════════════════════════════
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 1: GOLD LONG (67.7% of big UP moves start from HTF_BULL_LTF_PULLBACK)
  // Historical: median HTF=20, median LTF=-9 at move start
  // Strategy: Buy the pullback in a bullish trend when LTF starts recovering
  // SECTOR ALIGNMENT BOOST: When sector is bullish, relax thresholds and boost confidence
  // ═══════════════════════════════════════════════════════════════════════════
  if (state === "HTF_BULL_LTF_PULLBACK") {
    // DATA: gold_long had 82% loss rate (292 trades, -$20k). The pullbackCorridor
    // was too loose — any LTF -5 to -10 passed because ltfRecovering was trivially true.
    // Tighten: require HTF >= 10 (stronger trend), and require a REAL confirmation signal
    // (SuperTrend flip, EMA cross, or squeeze release), not just ltf > -10.
    const htfMin = (sectorBull && sectorStrength >= 50) ? 8 : 10;
    const pullbackCorridor = htf >= htfMin && ltf >= -25 && ltf <= 3;
    const hasRealConfirmation = hasStFlipBull || hasEmaCrossBull || hasSqRelease;
    if (pullbackCorridor) {
      // High confidence: deep pullback WITH real recovery confirmation signal
      if (ltf <= -5 && hasRealConfirmation) {
        const conf = (sectorBull && sectorStrength >= 60) ? "high_sector" : "high";
        return enrichResult({ qualifies: true, path: "gold_long", confidence: conf, reason: "pullback_with_confirmation", sectorStrength });
      }
      // Medium→High with sector: shallow pullback with SuperTrend or EMA confirmation
      if (ltf <= 0 && (hasStFlipBull || hasEmaCrossBull)) {
        const conf = (sectorBull && sectorStrength >= 60) ? "high" : "medium";
        return enrichResult({ qualifies: true, path: "gold_long_shallow", confidence: conf, reason: "shallow_with_signal", sectorStrength });
      }
      // Medium confidence: deep pullback with strong HTF structure
      // DATA: gold_long_deep had 81% loss rate (223 trades, -$16k). Tighten:
      //   HTF 10→15, LTF -8→-12, require real confirmation OR strong sector alignment
      if (ltf <= -12 && htf >= 15 && (hasRealConfirmation || (sectorBull && sectorStrength >= 60))) {
        return enrichResult({ qualifies: true, path: "gold_long_deep", confidence: "medium", reason: "deep_pullback_structure", sectorStrength });
      }
      // SECTOR UNLOCK: When sector is strongly aligned, allow entry with just HTF+pullback
      // This captures the NVDA/AVGO/TSM pattern — individual ticker may not have all signals
      // but the sector conviction is the confirmation
      if (sectorBull && sectorStrength >= 70 && htf >= 8 && ltf <= 0) {
        return enrichResult({ qualifies: true, path: "gold_long_sector", confidence: "medium", reason: "sector_aligned_pullback", sectorStrength });
      }
      // Low confidence: corridor pullback
      // DATA: gold_long_corridor had 73% loss rate (106 trades, -$4.1k).
      // Now requires real confirmation signal + strong HTF + sector alignment
      if (ltf <= -5 && htf >= 15 && inCorridor && hasRealConfirmation && sectorBull) {
        return enrichResult({ qualifies: true, path: "gold_long_corridor", confidence: "low", reason: "corridor_pullback_confirmed", sectorStrength });
      }
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 2: GOLD SHORT (82.7% of big DOWN moves start from HTF_BULL_LTF_BULL)
  // Historical: median HTF=28, median LTF=19 at move start
  // Strategy: Fade the blow-off top when BOTH HTF and LTF are overextended
  // This is a mean-reversion play, NOT a trend trade
  // ═══════════════════════════════════════════════════════════════════════════
  if (state === "HTF_BULL_LTF_BULL") {
    // High confidence: extreme overextension (clear blow-off top)
    if (htf >= 35 && ltf >= 25) {
      return enrichResult({ qualifies: true, path: "gold_short", confidence: "high", reason: "extreme_blowoff" });
    }
    // High confidence: moderate overextension WITH bearish signal confirmation
    if (htf >= 28 && ltf >= 18 && (hasEmaCrossBear || hasSqRelease)) {
      return enrichResult({ qualifies: true, path: "gold_short_confirmed", confidence: "high", reason: "blowoff_with_signal" });
    }
    // Medium confidence: at the blow-off level
    // DATA (candle replay Jan 13-Feb 7): HTF_BULL_LTF_BULL had 29.3% WR overall.
    // Tighten: require BOTH high thresholds AND signal confirmation (no "ltf >= 25" fallback)
    if (htf >= 30 && ltf >= 22 && (hasEmaCrossBear || hasSqRelease)) {
      return enrichResult({ qualifies: true, path: "gold_short_medium", confidence: "medium", reason: "near_blowoff" });
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 2B: GOLD SHORT (bear-side pullback - mirror of Gold LONG)
  // HTF_BEAR_LTF_PULLBACK: short the pullback in a bearish trend
  // SECTOR ALIGNMENT BOOST: When sector is bearish, relax thresholds
  // ═══════════════════════════════════════════════════════════════════════════
  if (state === "HTF_BEAR_LTF_PULLBACK") {
    const htfMin = (sectorBear && sectorStrength >= 50) ? -3 : -5;
    const bearPullbackCorridor = htf <= htfMin && ltf >= -5 && ltf <= 25;
    if (bearPullbackCorridor) {
      const ltfBearRecovering = ltf < 10 || flags.st_flip_bear || hasEmaCrossBear || hasSqRelease;
      if (ltf >= 5 && ltfBearRecovering) {
        const conf = (sectorBear && sectorStrength >= 60) ? "high_sector" : "high";
        return enrichResult({ qualifies: true, path: "gold_short_pullback", confidence: conf, reason: "bear_pullback_with_confirmation", sectorStrength });
      }
      if (ltf >= 0 && (flags.st_flip_bear || hasEmaCrossBear)) {
        const conf = (sectorBear && sectorStrength >= 60) ? "high" : "medium";
        return enrichResult({ qualifies: true, path: "gold_short_pullback_shallow", confidence: conf, reason: "bear_shallow_with_signal", sectorStrength });
      }
      if (ltf >= 8 && htf <= -10) {
        return enrichResult({ qualifies: true, path: "gold_short_pullback_deep", confidence: "medium", reason: "bear_deep_pullback", sectorStrength });
      }
      // SECTOR UNLOCK: Bear sector alignment
      if (sectorBear && sectorStrength >= 70 && htf <= -8 && ltf >= 0) {
        return enrichResult({ qualifies: true, path: "gold_short_sector", confidence: "medium", reason: "sector_aligned_bear_pullback", sectorStrength });
      }
      if (ltf >= 0 && htf <= -10 && inCorridor) {
        return enrichResult({ qualifies: true, path: "gold_short_corridor", confidence: "low", reason: "bear_corridor_pullback", sectorStrength });
      }
    }
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 3: MOMENTUM (aligned HTF+LTF with confirmation signal)
  // Both HTF and LTF aligned + SuperTrend/EMA/Squeeze confirmation
  // ═══════════════════════════════════════════════════════════════════════════
  // DATA (candle replay Jan 13-Feb 7): HTF_BULL_LTF_BULL had 29.3% WR.
  // Tighten momentum: require RR >= 3.0 (RR 3-5 had 66.2% WR) and higher score
  const isMomentum = state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  if (isMomentum && score >= 85 && rr >= 3.0 && (hasStFlipBull || hasEmaCrossBull || hasSqRelease)) {
    return enrichResult({ qualifies: true, path: "momentum_score", confidence: "medium", reason: "momentum_with_signal" });
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 4: SQUEEZE RELEASE (explosive move from compression)
  // Pullback state + squeeze just released + decent score and RR
  // ═══════════════════════════════════════════════════════════════════════════
  const isSetup = state.includes("PULLBACK");
  if (isSetup && hasSqRelease && score >= 70 && rr >= 2.0) {
    return enrichResult({ qualifies: true, path: "squeeze_setup", confidence: "medium", reason: "squeeze_release" });
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // PATH 5: MOMENTUM ELITE (high-conviction flag from TradingView)
  // ═══════════════════════════════════════════════════════════════════════════
  if ((flags.thesis_match || flags.momentum_elite) && score >= 70 && rr >= 2.0) {
    return enrichResult({ qualifies: true, path: "elite", confidence: "medium", reason: "momentum_elite" });
  }
  
  return { qualifies: false, reason: "criteria_not_met" };
}

/**
 * Classify kanban stage for a ticker using 7-lane workflow system.
 * 
 * DISCOVERY MODE (no position): watch → setup → enter
 * MANAGEMENT MODE (has position): just_entered → defend → trim → exit
 * 
 * LANES:
 *   watch        - Valid data, monitoring pool
 *   setup        - Pullback forming, preparing for entry
 *   enter        - Entry criteria met, execute position
 *   just_entered - Position open < 15 min, initial hold
 *   defend       - Warning signals, tighten SL to protect gains
 *   trim         - At EXTREMES, take profit NOW (RSI >= 80, Phase >= 75)
 *   exit         - SL breach or critical, close position NOW
 * 
 * @param {object} tickerData - Ticker payload with scores, state, flags, etc.
 * @param {object|null} openPosition - Optional: open position from D1 (for position-aware classification)
 * @returns {string|null} - Kanban stage or null
 */
function classifyKanbanStage(tickerData, openPosition = null, asOfTs = null) {
  const state = String(tickerData?.state || "");
  const hasPosition = !!(openPosition && openPosition.status === "OPEN");
  
  // ═══════════════════════════════════════════════════════════════════════════
  // MANAGEMENT MODE: Open position drives stage
  // Position-based classification takes absolute priority
  // 7-Lane Flow: just_entered → defend → trim → exit
  // ═══════════════════════════════════════════════════════════════════════════
  if (hasPosition) {
    const completion = Number(tickerData?.completion) || 0;
    const phase = Number(tickerData?.phase_pct) || 0;
    const currentPrice = Number(tickerData?.price);
    const direction = String(openPosition.direction || "").toUpperCase();
    const entryPrice = Number(openPosition.entryPrice || openPosition.avgEntry);
    const entryTs = Number(openPosition.entry_ts || openPosition.created_at) || 0;
    const now = (asOfTs != null && Number.isFinite(Number(asOfTs))) ? Number(asOfTs) : Date.now();
    const positionAgeMin = entryTs > 0 ? (now - entryTs) / (1000 * 60) : 999;
    
    // Calculate P&L
    let pnlPct = 0;
    if (Number.isFinite(entryPrice) && entryPrice > 0 && Number.isFinite(currentPrice)) {
      pnlPct = direction === "LONG"
        ? ((currentPrice - entryPrice) / entryPrice) * 100
        : ((entryPrice - currentPrice) / entryPrice) * 100;
    }
    
    // Get RSI and Phase from ticker data for extreme detection
    const rsi5_10m = Number(tickerData?.tf_tech?.["10"]?.rsi?.r5) || 50;
    const rsi5_30m = Number(tickerData?.tf_tech?.["30"]?.rsi?.r5) || 50;
    const phase_10m = Number(tickerData?.tf_tech?.["10"]?.ph?.v) || 0;
    const phase_30m = Number(tickerData?.tf_tech?.["30"]?.ph?.v) || 0;
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 1: EXIT - Immediate close conditions (highest priority)
    // ─────────────────────────────────────────────────────────────────────────
    
    // Check SL breach using position's trailing SL
    const positionSL = Number(openPosition.sl);
    if (Number.isFinite(positionSL) && positionSL > 0 && Number.isFinite(currentPrice)) {
      const slBreached = direction === "LONG" 
        ? currentPrice <= positionSL 
        : currentPrice >= positionSL;
      if (slBreached) {
        tickerData.__exit_reason = "sl_breached";
        return "exit";
      }
    }
    
    // Hard exit at -8% loss (capital protection)
    if (pnlPct <= -8) {
      tickerData.__exit_reason = "max_loss";
      return "exit";
    }
    
    // Check move status for critical issues
    const tickerDataWithPositionSL = Number.isFinite(positionSL) && positionSL > 0
      ? { ...tickerData, sl: positionSL }
      : tickerData;
    const moveStatus = computeMoveStatus(tickerDataWithPositionSL);
    const reasons = moveStatus?.reasons || [];
    const severity = String(moveStatus?.severity || "").toUpperCase();
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 1: EXIT - Only HARD invalidation signals (close position NOW)
    // SL breach, max loss, or truly critical regime break.
    // "below_trigger" alone is NOT an exit signal - it goes to DEFEND.
    // ─────────────────────────────────────────────────────────────────────────
    
    // Hard exit at -4% loss (capital protection)
    // DATA: Loser P10 is around -0.5%, but some outliers reach -4%.
    // -4% is catastrophic for a day/swing trade - exit immediately.
    if (pnlPct <= -4) {
      tickerData.__exit_reason = "max_loss";
      return "exit";
    }
    
    // SL breach: the position's trailing stop has been hit
    if (
      reasons.includes("sl_breached") ||
      severity === "CRITICAL" ||
      reasons.includes("trigger_breached_5pct")
    ) {
      tickerData.__exit_reason = reasons.join(",") || "critical";
      return "exit";
    }

    // ─────────────────────────────────────────────────────────────────────────
    // BIAS FLIP EXIT: Multi-TF consensus has fully reversed against our direction.
    // If we're SHORT and the state is now HTF_BULL_LTF_BULL (full bullish alignment),
    // the thesis is invalidated — exit the trade. Same for LONG + HTF_BEAR_LTF_BEAR.
    // This catches positions like TT (SHORT in a bullish state) that should be closed.
    // For partial flips (HTF flipped but LTF not confirmed), move to DEFEND instead.
    //
    // Note: gold_short entries are intentional counter-trend plays, but if the state
    // stays/returns to full bull after 2+ hours, the mean-reversion failed — exit anyway.
    // ─────────────────────────────────────────────────────────────────────────
    const bfState = String(tickerData?.state || "");
    const bfHtfBull = bfState.startsWith("HTF_BULL");
    const bfHtfBear = bfState.startsWith("HTF_BEAR");
    const bfLtfBull = bfState.includes("LTF_BULL");
    const bfLtfBear = bfState.includes("LTF_BEAR");
    // Require minimum 2 hours before bias-flip exit (gives counter-trend plays time to develop)
    const biasFlipMinAge = positionAgeMin >= 120;
    
    // Full alignment against trade direction → EXIT (after min hold time)
    if (biasFlipMinAge && direction === "SHORT" && bfHtfBull && bfLtfBull) {
      tickerData.__exit_reason = "bias_flip_full_bull_vs_short";
      console.log(`[BIAS FLIP EXIT] ${tickerData?.ticker}: SHORT position (${Math.round(positionAgeMin)}m old) but state is ${bfState} (full bullish). Thesis invalidated.`);
      return "exit";
    }
    if (biasFlipMinAge && direction === "LONG" && bfHtfBear && bfLtfBear) {
      tickerData.__exit_reason = "bias_flip_full_bear_vs_long";
      console.log(`[BIAS FLIP EXIT] ${tickerData?.ticker}: LONG position (${Math.round(positionAgeMin)}m old) but state is ${bfState} (full bearish). Thesis invalidated.`);
      return "exit";
    }
    
    // HTF flipped but LTF not confirmed → DEFEND (partial flip, thesis weakening)
    if (direction === "SHORT" && bfHtfBull && !bfLtfBull) {
      tickerData.__exit_reason = "bias_flip_htf_bull_vs_short";
      return "defend";
    }
    if (direction === "LONG" && bfHtfBear && !bfLtfBear) {
      tickerData.__exit_reason = "bias_flip_htf_bear_vs_long";
      return "defend";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 2: TRIM - At extremes, take partial profit
    // JOURNEY DATA: TRIM before pullback signals: ST flip (21%), ATR spike (14%),
    //   RSI OB (4%). RSI extreme (>=80) catches most peaks (57% of exhaustion signals).
    // PRECISION ENGINE: Fuel gauge "critical" (<25%) is now the primary trim signal,
    //   replacing the binary phase >= 75 check. Also triggers on Golden Gate completion.
    // ─────────────────────────────────────────────────────────────────────────
    
    const isRsiExtreme = direction === "LONG"
      ? (rsi5_10m >= 80 || rsi5_30m >= 80)
      : (rsi5_10m <= 20 || rsi5_30m <= 20);
    
    // Fuel gauge: "critical" = move exhausted, take profit
    // Uses continuous phase+RSI measure instead of binary phase >= 75 check
    const fuel30 = tickerData?.fuel?.["30"];
    const fuel10 = tickerData?.fuel?.["10"];
    const isFuelCritical = (fuel30?.status === "critical") || (fuel10?.status === "critical");
    
    // Legacy phase extreme fallback (for data without fuel fields)
    const isPhaseExtreme = !fuel30 && (direction === "LONG"
      ? (phase_10m >= 75 || phase_30m >= 75)
      : (phase_10m <= -75 || phase_30m <= -75));
    
    // POSITION-AWARE COMPLETION: Use actual entry-to-TP progress, not indicator
    // completion (which measures trigger-to-TP and can be misleadingly high for
    // positions that just entered near the current indicator level).
    const positionTP = Number(openPosition.tp);
    let positionCompletion = 0;
    if (Number.isFinite(entryPrice) && Number.isFinite(positionTP) && Number.isFinite(currentPrice) && entryPrice > 0) {
      const range = Math.abs(positionTP - entryPrice);
      if (range > 0) {
        positionCompletion = direction === "LONG"
          ? (currentPrice - entryPrice) / range
          : (entryPrice - currentPrice) / range;
        positionCompletion = Math.max(0, Math.min(1, positionCompletion));
      }
    }
    const isNearTp = positionCompletion >= 0.85;
    const isPnlExtreme = pnlPct >= 5;
    
    // SuperTrend flip against direction: preceded 21% of pullbacks in journey data
    // Only trigger TRIM if position is profitable (avoid trimming into a loss)
    const stFlipAgainst = pnlPct > 1.0 && (
      (direction === "LONG" && tickerData?.flags?.st_flip_bear) ||
      (direction === "SHORT" && tickerData?.flags?.st_flip_bull)
    );
    
    // Golden Gate completion: price reached 61.8% ATR level (the gate target)
    // This is a natural trim point — the probabilistic edge has been captured
    const gateCompleted = (tickerData?.active_gates || []).some(g => g.completed);
    
    // POSITION AGE GUARD: Don't trim brand-new positions.
    // Indicator-level signals (RSI extreme, fuel critical, phase extreme) can fire
    // immediately after entry because they reflect the broader move, not the position.
    // Give the position at least 30 min to develop before trimming — unless P&L is
    // already extreme (>=5%) or actual position completion is near TP.
    const trimGuardActive = positionAgeMin < 30 && pnlPct < 3.0;
    const trimSignal = isRsiExtreme || isFuelCritical || isPhaseExtreme || isNearTp || isPnlExtreme || stFlipAgainst || gateCompleted;
    
    if (trimSignal && !trimGuardActive) {
      tickerData.__trim_reason = isRsiExtreme ? "rsi_extreme" : 
                                  isFuelCritical ? "fuel_critical" :
                                  isPhaseExtreme ? "phase_extreme" :
                                  gateCompleted ? "gate_completed" :
                                  isNearTp ? "near_tp" :
                                  isPnlExtreme ? "pnl_extreme" : "st_flip_against";
      return "trim";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 3: DEFEND - Warning signals (tighten SL, protect capital)
    // Includes: adverse P&L, below_trigger, RSI weakening, phase against
    // Key change: "below_trigger" and "left_entry_corridor" now route here,
    // NOT to EXIT. These are soft signals = defend the position, not panic sell.
    //
    // SECTOR ALIGNMENT PATIENCE: When the sector is aligned with our direction,
    // we widen the DEFEND threshold. Sector alignment means the dip is likely
    // temporary (see: NVDA/AVGO/TSM 2/5/26 — dipped at open, recovered strong
    // because sector was aligned). Conversely, if sector is AGAINST our direction,
    // be more defensive.
    // ─────────────────────────────────────────────────────────────────────────
    const sectorAlignForPosition = getSectorAlignmentCached(String(tickerData?.ticker || "").toUpperCase());
    const sectorWithUs = sectorAlignForPosition?.aligned &&
      ((direction === "LONG" && sectorAlignForPosition.direction === "BULL") ||
       (direction === "SHORT" && sectorAlignForPosition.direction === "BEAR"));
    const sectorAgainstUs = sectorAlignForPosition?.aligned &&
      ((direction === "LONG" && sectorAlignForPosition.direction === "BEAR") ||
       (direction === "SHORT" && sectorAlignForPosition.direction === "BULL"));

    // Adverse P&L threshold: wider when sector is with us (dips are buying opps)
    // Normal: -2%, Sector aligned: -3%, Sector against: -1.5%
    const adverseThreshold = sectorWithUs ? -3 : sectorAgainstUs ? -1.5 : -2;
    const isAdverseMove = pnlPct < adverseThreshold && pnlPct > -6;
    
    // Below trigger / left corridor - position is weakening but not dead
    const isBelowTrigger = reasons.includes("below_trigger") || reasons.includes("above_trigger");
    const isLeftCorridor = reasons.includes("left_entry_corridor");
    
    // RSI divergence (price up but RSI weakening)
    const isRsiWeakening = direction === "LONG"
      ? (rsi5_30m < 40 && pnlPct > 0)
      : (rsi5_30m > 60 && pnlPct > 0);
    
    // Phase against direction
    const isPhaseAgainst = direction === "LONG"
      ? (phase_30m < -25)
      : (phase_30m > 25);
    
    // Any warning signal with gains = defend
    const hasGains = pnlPct > 0.5;
    const needsDefense = (isRsiWeakening || isPhaseAgainst) && hasGains;
    
    // PRECISION ENGINE: Fuel "low" (25-50%) = move approaching exhaustion
    const isFuelLow = (fuel30?.status === "low") || (fuel10?.status === "low");
    const fuelDefend = isFuelLow && hasGains; // only defend on fuel if we have gains to protect
    
    // PRECISION ENGINE: ST support score dropping below 0.3 = multi-TF support collapsing
    const stSupportScore = tickerData?.st_support?.supportScore ?? 0.5;
    const supportCollapsing = (direction === "LONG" && stSupportScore < 0.3) ||
                              (direction === "SHORT" && stSupportScore > 0.7);
    
    // Skip DEFEND if near TP — position should TRIM, not defend.
    // Let it fall through to "hold" so TRIM takes priority on next evaluation.
    if (!isNearTp && (isAdverseMove || isBelowTrigger || isLeftCorridor || needsDefense || fuelDefend || supportCollapsing)) {
      tickerData.__defend_reason = isAdverseMove ? "adverse_move" :
                                    isBelowTrigger ? "below_trigger" :
                                    isLeftCorridor ? "left_corridor" :
                                    supportCollapsing ? "st_support_collapse" :
                                    fuelDefend ? "fuel_low" :
                                    isRsiWeakening ? "rsi_weakening" :
                                    isPhaseAgainst ? "phase_against" : "warning";
      return "defend";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // PRIORITY 4: JUST_ENTERED - Position age < 15 minutes
    // Initial hold period, no action needed
    // ─────────────────────────────────────────────────────────────────────────
    
    if (positionAgeMin < 15) {
      return "just_entered";
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // DEFAULT: HOLD - Healthy position, past initial period, no warning signals
    // This is the "all clear" state - position is working as expected
    // ─────────────────────────────────────────────────────────────────────────
    return "hold";
  }
  
  // ═══════════════════════════════════════════════════════════════════════════
  // DISCOVERY MODE: No position, evaluate entry opportunity
  // Lane semantics:
  //   SETUP  = qualifiesForEnter passes (good signal, confirmation, room to run)
  //            BUT execution gates may block (position limits, RTH, cooldowns).
  //   ENTER  = qualifiesForEnter passes AND execution gates are clear.
  //            The system WILL enter on the next scoring cycle.
  // ═══════════════════════════════════════════════════════════════════════════
  
  // Check entry qualification using consolidated criteria
  // Pass asOfTs for replay support (historical trigger freshness check)
  const entry = qualifiesForEnter(tickerData, asOfTs);
  if (entry.qualifies) {
    // Store entry context for UI display
    tickerData.__entry_path = entry.path;
    tickerData.__entry_confidence = entry.confidence;
    tickerData.__entry_reason = entry.reason;
    tickerData.__entry_quality = entry.entryQuality || 0;
    // PATTERN BOOST: Upgrade entry confidence when patterns strongly match
    const pm = tickerData?.pattern_match;
    if (pm && pm.direction === "BULLISH" && pm.bestBull?.conf > 0.6) {
      tickerData.__entry_confidence = "high";
      tickerData.__entry_reason = (tickerData.__entry_reason || "") + ` +pattern:${pm.bestBull.name}`;
    }
    // ── Execution readiness (informational only) ──
    // Execution gates (RTH, position limits, concentration) are tracked on the
    // payload as __execution_ready / __execution_block_reason for the UI to
    // display warnings, but they no longer DOWNGRADE "enter" → "setup".
    // The Enter lane shows all qualifying entry OPPORTUNITIES.  The execution
    // engine (processTradeSimulation) enforces the actual gates at trade time.
    return "enter";
  }
  
  // Check if in SETUP zone (corridor + pullback state)
  const inCorridor = corridorSide(tickerData) != null;
  const isSetup = state.includes("PULLBACK");
  
  // SETUP: In corridor with setup state - preparing for entry
  if (inCorridor && isSetup) {
    return "setup";
  }
  
  // SETUP: Flip watch active (about to transition) - treat as setup
  const flags = tickerData?.flags || {};
  if (flags.flip_watch && inCorridor) {
    return "setup";
  }
  
  // ─────────────────────────────────────────────────────────────────────────
  // PATTERN-AWARE PROMOTION: Watch → Setup when patterns strongly match
  // If the model sees high-confidence bull patterns on a watch ticker that
  // is in or near a corridor, treat it as a setup (the model sees something
  // that the rule-based system doesn't yet classify as setup).
  // ─────────────────────────────────────────────────────────────────────────
  const pmDiscovery = tickerData?.pattern_match;
  if (pmDiscovery && pmDiscovery.direction === "BULLISH" && pmDiscovery.bullCount >= 2 && pmDiscovery.bestBull?.conf > 0.55) {
    const htfScore = Number(tickerData?.htf_score) || 0;
    const ltfScore = Number(tickerData?.ltf_score) || 0;
    // Only promote if scores are reasonably positive (model + scores agree)
    if (htfScore > 40 && ltfScore > 30) {
      tickerData.__setup_reason = `pattern_model:${pmDiscovery.bestBull.name}(${pmDiscovery.bullCount} bull patterns)`;
      return "setup";
    }
  }
  
  // WATCH: Valid data, monitoring pool
  const hasValidData =
    state &&
    Number.isFinite(Number(tickerData?.price)) &&
    String(tickerData?.ticker || "").trim();
  
  if (hasValidData) {
    return "watch";
  }
  
  // No stage - not in trading pipeline
  return null;
}

function deriveKanbanMeta(tickerData, stage) {
  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  const completion = Number(tickerData?.completion) || 0;
  const phase = Number(tickerData?.phase_pct) || 0;
  const phaseZone = String(tickerData?.phase_zone || "").toUpperCase();
  const severity = String(ms?.severity || "").toUpperCase();
  const reasons = Array.isArray(ms?.reasons) ? ms.reasons : [];

  // ENTER stage: show entry path and confidence
  if (stage === "enter" || stage === "enter_now") {
    const path = tickerData?.__entry_path || "unknown";
    const confidence = tickerData?.__entry_confidence || "medium";
    const reason = tickerData?.__entry_reason || "criteria_met";
    const eqScore = tickerData?.__entry_quality || Number(tickerData?.entry_quality?.score) || 0;
    const emoji = confidence === "high" ? "🎯" : "✅";
    return {
      bucket: path,
      emoji,
      reason,
      confidence,
      entryQuality: eqScore,
      reasons: [reason],
    };
  }

  // JUST_ENTERED stage: show initial hold status
  if (stage === "just_entered") {
    return {
      bucket: "holding",
      emoji: "🆕",
      reason: "just_opened",
      reasons: ["position_new"],
    };
  }

  // HOLD stage: healthy position, working as expected
  if (stage === "hold") {
    return {
      bucket: "holding",
      emoji: "💎",
      reason: "position_healthy",
      reasons: ["on_track"],
    };
  }

  // DEFEND stage: show why we're defending (tighten SL)
  if (stage === "defend") {
    const defendReason = tickerData?.__defend_reason || "warning";
    const emoji = "🛡";
    const reasonMap = {
      adverse_move: "Price moving against",
      below_trigger: "Below entry anchor",
      left_corridor: "Left entry corridor",
      rsi_weakening: "RSI divergence",
      phase_against: "Phase turning",
      warning: "Warning signals",
    };
    return {
      bucket: "tighten_sl",
      emoji,
      reason: reasonMap[defendReason] || "defending",
      reasons: [defendReason],
    };
  }

  // TRIM stage: show why we're trimming (EXTREMES only)
  if (stage === "trim") {
    const trimReason = tickerData?.__trim_reason || "extreme";
    const emoji = "✂️";
    const reasonMap = {
      rsi_extreme: "RSI at extreme",
      phase_extreme: "Phase at extreme",
      near_tp: "Near TP target",
      pnl_extreme: "P&L > 6%",
    };
    return {
      bucket: "take_profit",
      emoji,
      reason: reasonMap[trimReason] || `${Math.round(completion * 100)}% complete`,
      reasons: [trimReason],
    };
  }

  // EXIT stage: show urgency
  if (stage === "exit") {
    const exitReason = tickerData?.__exit_reason || reasons[0] || "exit_signal";
    const emoji = severity === "CRITICAL" ? "🚨" : "🚪";
    const reasonMap = {
      sl_breached: "SL hit",
      max_loss: "Max loss (-8%)",
      critical: "Critical issue",
      left_entry_corridor: "Left corridor",
      large_adverse_move: "Large adverse move",
    };
    return {
      bucket: "close_now",
      emoji,
      reason: reasonMap[exitReason] || exitReason,
      reasons: [exitReason],
    };
  }

  // SETUP stage: show readiness indicators
  if (stage === "setup") {
    const flags = tickerData?.flags || {};
    // PATTERN-PROMOTED setup: model identified high-confidence patterns
    if (tickerData?.__setup_reason?.startsWith("pattern_model:")) {
      const pm = tickerData?.pattern_match;
      return {
        bucket: "pattern_setup",
        emoji: "🧠",
        reason: `Model: ${pm?.bestBull?.name || "pattern match"}`,
        reasons: ["pattern_model", ...(pm?.matched?.map(m => m.id) || [])],
        patternMatch: pm,
      };
    }
    if (flags.flip_watch) {
      return { bucket: "flip_watch", emoji: "🔄", reason: "about_to_flip", reasons: ["flip_watch"] };
    }
    if (flags.sq30_on) {
      return { bucket: "squeeze_building", emoji: "🎯", reason: "squeeze_on", reasons: ["squeeze_on"] };
    }
    return { bucket: "preparing", emoji: "⏳", reason: "pullback_forming", reasons: ["setup"] };
  }

  // WATCH stage: show monitoring
  if (stage === "watch") {
    return null;  // No special meta for watch
  }

  return null;
}

function computeMoveStatus(tickerData) {
  const side = sideFromStateOrScores(tickerData); // LONG | SHORT | null
  const flags = tickerData?.flags || {};
  const momentumElite = !!flags.momentum_elite;

  const price = Number(tickerData?.price);
  const sl = Number(tickerData?.sl);
  const tp = computeTpMaxFromLevels(tickerData) ?? Number(tickerData?.tp);
  const triggerTsRaw = Number(tickerData?.trigger_ts);
  const entryTsRaw = Number(
    tickerData?.entry_ts ?? tickerData?.kanban_cycle_enter_now_ts,
  );
  const entryPriceRaw = Number(tickerData?.entry_price);
  let triggerTs = triggerTsRaw;
  const curTs = Number(tickerData?.ts ?? tickerData?.ingest_ts ?? Date.now());

  const reasons = [];

  // If we can't infer direction, don't mark invalidated.
  if (!side) {
    return {
      status: "ACTIVE",
      side: null,
      severity: "NONE",
      reasons: [],
    };
  }

  // Only consider a "move" ACTIVE once we've actually entered the cycle.
  // ENTER_NOW stamps entry_ts/entry_price (or cycle enter ts), which is our proxy for “we took it”.
  // Without this, tickers can incorrectly show HOLD/DEFEND/TRIM/EXIT just because they have a trigger_ts.
  const hasEntered = Number.isFinite(entryTsRaw) && entryTsRaw > 0;
  if (!hasEntered) {
    return {
      status: "NONE",
      side,
      severity: "NONE",
      reasons: [],
    };
  }

  // If we don't have a trigger timestamp, this isn't an active "move" yet.
  // This prevents labeling the entire universe as ACTIVE/HOLD/TRIM/EXIT.
  if (!Number.isFinite(triggerTs) || triggerTs <= 0) {
    // Back-compat: if the user has acted (ENTER_NOW stamps entry_ts/entry_price),
    // we still need move-status logic even if trigger_ts is missing.
    if (Number.isFinite(entryTsRaw) && entryTsRaw > 0) {
      triggerTs = entryTsRaw;
    } else {
      return {
        status: "NONE",
        side,
        severity: "NONE",
        reasons: [],
      };
    }
  }

  // If the trigger is stale, don't keep the ticker stuck in "move" lanes forever.
  // This is especially important when the market is closed and many names won't ingest frequently.
  // Treat old triggers as no active move so opportunity lanes (Flip Watch / Enter Now) can surface.
  if (Number.isFinite(curTs) && curTs > 0) {
    const ageMs = curTs - triggerTs;
    const STALE_TRIGGER_MS = 14 * 24 * 60 * 60 * 1000; // 14 days
    if (Number.isFinite(ageMs) && ageMs > STALE_TRIGGER_MS) {
      const entryAgeMs =
        Number.isFinite(entryTsRaw) && entryTsRaw > 0 ? curTs - entryTsRaw : null;
      const entryFresh =
        entryAgeMs != null &&
        Number.isFinite(entryAgeMs) &&
        entryAgeMs >= 0 &&
        entryAgeMs <= STALE_TRIGGER_MS;
      if (entryFresh) {
        triggerTs = entryTsRaw;
      } else {
        return {
          status: "NONE",
          side,
          severity: "NONE",
          reasons: [],
        };
      }
    }
  }

  // Soft invalidation: breached trigger/entry anchor (clear “get out” signal even before SL).
  // This avoids cases like AGQ: ENTER_NOW → large adverse move → no EXIT lane until SL.
  const anchorPrice = (() => {
    const trigPx = Number(tickerData?.trigger_price);
    if (Number.isFinite(trigPx) && trigPx > 0) return trigPx;
    if (Number.isFinite(entryPriceRaw) && entryPriceRaw > 0) return entryPriceRaw;
    return null;
  })();
  if (Number.isFinite(price) && Number.isFinite(anchorPrice) && anchorPrice > 0) {
    const adversePct = Math.abs((price - anchorPrice) / anchorPrice);
    // DATA-DRIVEN: Require minimum 2.0% adverse move before flagging trigger invalidation.
    // Journey analysis (103 pullbacks): median pullback 1.22%, P75 = 2.20%.
    // Sub-2.0% dips are normal pullbacks during sustained moves. Flag only when
    // the adverse move exceeds the P75 pullback threshold.
    const MIN_ADVERSE_PCT = 0.020; // 2.0% (raised from 1.5%)
    if (side === "LONG" && price < anchorPrice && adversePct >= MIN_ADVERSE_PCT) reasons.push("below_trigger");
    if (side === "SHORT" && price > anchorPrice && adversePct >= MIN_ADVERSE_PCT) reasons.push("above_trigger");
    if (
      (reasons.includes("below_trigger") || reasons.includes("above_trigger")) &&
      Number.isFinite(adversePct) &&
      adversePct >= 0.05
    ) {
      reasons.push("trigger_breached_5pct");
    }
  }

  // Hard invalidation: SL breach
  if (Number.isFinite(price) && Number.isFinite(sl) && sl > 0) {
    if (side === "LONG" && price <= sl) reasons.push("sl_breached");
    if (side === "SHORT" && price >= sl) reasons.push("sl_breached");
  }

  // Completion: TP reached/exceeded (move is "done" from entry standpoint)
  if (Number.isFinite(price) && Number.isFinite(tp) && tp > 0) {
    if (side === "LONG" && price >= tp) reasons.push("tp_reached");
    if (side === "SHORT" && price <= tp) reasons.push("tp_reached");
  }

  // Regime breaks: HTF structure disagrees with direction
  // NOTE: These are useful for discovery (setup/enter) but too noisy for position management.
  // DATA: daily_ema_regime_break caused 19 exits (47% WR) - nearly coin flip.
  // Only include as informational; NOT used for exit decisions on open positions.
  // The Kanban stage classifier ignores WARNING-only severity for EXIT.
  if (!dailyEmaRegimeOk(tickerData, side))
    reasons.push("daily_ema_regime_break");
  if (!ichimokuRegimeOk(tickerData, side))
    reasons.push("ichimoku_regime_break");

  // Late-cycle: disqualifier unless Momentum Elite
  if (isLateCycle(tickerData) && !momentumElite) reasons.push("late_cycle");

  // Overextension: extremely high completion means little edge left (relative to MAX TP)
  const comp = (() => {
    const cMax = computeCompletionToTpMax(tickerData);
    return Number.isFinite(cMax) ? cMax : completionForSize(tickerData);
  })();
  if (Number.isFinite(comp) && comp >= 0.95) reasons.push("overextended");

  // If we have a trigger timestamp and we're not in the entry corridor anymore,
  // only flag as "left_entry_corridor" if price moved ADVERSELY (not in our favor).
  // A favorable move out of corridor is a good thing (price going our way).
  if (Number.isFinite(triggerTs) && triggerTs > 0) {
    const ent = entryType(tickerData);
    if (ent && ent.corridor === false) {
      // Only count as "left corridor" if the move was adverse
      // Check if price moved against our position
      const isAdverseCorridorExit = (() => {
        if (!Number.isFinite(price) || !Number.isFinite(anchorPrice) || anchorPrice <= 0) {
          return false; // Can't determine, don't trigger
        }
        const priceDelta = price - anchorPrice;
        // For LONG: adverse if price went DOWN
        // For SHORT: adverse if price went UP
        if (side === "LONG") return priceDelta < 0;
        if (side === "SHORT") return priceDelta > 0;
        return false;
      })();
      
      if (isAdverseCorridorExit) {
        reasons.push("left_entry_corridor");
      }
    }
  }

  // Adverse move detection (tightened from 15% to 10% for earlier exits)
  if (Number.isFinite(price) && Number.isFinite(anchorPrice) && anchorPrice > 0) {
    const adverseMove = (price - anchorPrice) / anchorPrice;
    const isAdverse = 
      (side === "LONG" && adverseMove < 0) ||
      (side === "SHORT" && adverseMove > 0);
    
    if (isAdverse) {
      const absMove = Math.abs(adverseMove);
      // Critical: >10% adverse move = hard exit (was 15%)
      if (absMove >= 0.10) {
        reasons.push("large_adverse_move");
      }
      // Warning: >5% adverse move = defensive signal
      else if (absMove >= 0.05) {
        reasons.push("adverse_move_warning");
      }
    }
  }

  // IMPORTANT: do NOT mark the entire universe invalidated for "soft" reasons.
  // Only hard-stop conditions should become INVALIDATED / COMPLETED.
  const isCompleted = reasons.includes("tp_reached");
  const isInvalidated = 
    reasons.includes("sl_breached") || 
    reasons.includes("large_adverse_move");

  const status = isCompleted
    ? "COMPLETED"
    : isInvalidated
      ? "INVALIDATED"
      : "ACTIVE";

  // Severity is used by Kanban stage logic and UI; keep it consistent:
  // NONE | WARNING | CRITICAL
  const severity = reasons.includes("sl_breached") || reasons.includes("trigger_breached_5pct")
    ? "CRITICAL"
    : reasons.length
      ? "WARNING"
      : "NONE";

  return {
    status,
    side,
    severity,
    reasons,
  };
}

function sideFromStateOrScores(tickerData) {
  // Phase 2b: Primary — use swing-TF consensus direction (fixes NFLX-type errors)
  // When 4/5 TFs agree on direction, that overrides the lagging state-based direction.
  const consensusDir = tickerData?.swing_consensus?.direction;
  if (consensusDir === "LONG" || consensusDir === "SHORT") return consensusDir;

  // Fallback — state-based direction (original logic)
  const state = String(tickerData?.state || "");
  if (state.includes("BULL")) return "LONG";
  if (state.includes("BEAR")) return "SHORT";
  const h = Number(tickerData?.htf_score);
  const l = Number(tickerData?.ltf_score);
  if (Number.isFinite(h) && Number.isFinite(l)) {
    if (h > 0) return "LONG";
    if (h < 0) return "SHORT";
  }
  return null;
}

function dailyEmaRegimeOk(tickerData, side) {
  const cloud = tickerData?.daily_ema_cloud;
  const pos =
    cloud?.position != null ? String(cloud.position).toLowerCase() : "";
  if (!pos) return true;
  if (side === "LONG") return pos !== "below";
  if (side === "SHORT") return pos !== "above";
  return true;
}

function ichimokuRegimeOk(tickerData, side) {
  const dPos =
    tickerData?.ichimoku_d?.position != null
      ? String(tickerData.ichimoku_d.position).toLowerCase()
      : "";
  const wPos =
    tickerData?.ichimoku_w?.position != null
      ? String(tickerData.ichimoku_w.position).toLowerCase()
      : "";

  // If we don't have Ichimoku in the payload yet, don't block.
  if (!dPos && !wPos) return true;

  const dBadLong = dPos === "below";
  const wBadLong = wPos === "below";
  const dBadShort = dPos === "above";
  const wBadShort = wPos === "above";

  // Block only when BOTH HTFs disagree with the trade direction.
  if (side === "LONG") return !(dBadLong && wBadLong);
  if (side === "SHORT") return !(dBadShort && wBadShort);
  return true;
}

function isLateCycle(tickerData) {
  const z = String(tickerData?.phase_zone || "").toUpperCase();
  const phase = Number(tickerData?.phase_pct) || 0;
  // Zones are: LOW / MEDIUM / HIGH / EXTREME (from Pine).
  if (z === "EXTREME") return true;
  if (z === "HIGH") return true;
  // Additional safety for legacy payloads without zones.
  return phase >= 0.7;
}

// Helper function: entryType (check if ticker is in corridor)
function entryType(ticker) {
  // Corridor is defined in score-space (HTF/LTF bands), not by TP/SL price bounds.
  // This must match `corridorSide()` and the UI corridor filters.
  return { corridor: corridorSide(ticker) != null };
}

// Dynamic SCORE calculation that considers real-time conditions
// NOTE: This returns a SCORE (0-200+), not a RANK (position 1-135)
// RANK is determined by sorting all tickers by this score
function computeDynamicScore(ticker) {
  const baseScore = Number(ticker.rank) || 50; // Base score from worker (0-100)
  const htf = Number(ticker.htf_score) || 0;
  const ltf = Number(ticker.ltf_score) || 0;
  const comp = completionForSize(ticker);
  const phase = Number(ticker.phase_pct) || 0;
  const rr = Number(ticker.rr) || 0;
  const flags = ticker.flags || {};
  const state = String(ticker.state || "");
  const holdIntent = String(
    ticker.hold_intent || ticker.horizon_bucket || "",
  ).toUpperCase();

  const sqRel = !!flags.sq30_release;
  const sqOn = !!flags.sq30_on;
  const phaseZoneChange = !!flags.phase_zone_change;
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  const ent = entryType(ticker);
  const inCorridor = ent.corridor;

  let dynamicScore = baseScore;

  // Data completeness penalty: prefer fully-instrumented names.
  const completeness =
    ticker?.data_completeness || computeDataCompleteness(ticker);
  if (completeness && typeof completeness === "object") {
    if (completeness.score < 70) dynamicScore -= 6;
    else if (completeness.score < 85) dynamicScore -= 3;
  }

  // Per-TF technical structure: reward aligned multi-timeframe stacks.
  const tfAlign = ticker?.tf_summary || tfTechAlignmentSummary(ticker);
  if (
    tfAlign &&
    typeof tfAlign === "object" &&
    Number.isFinite(tfAlign.score)
  ) {
    dynamicScore += tfAlign.score;
    if (tfAlign.squeeze_on && !sqRel && inCorridor) dynamicScore += 1;
    if (tfAlign.squeeze_release && inCorridor) dynamicScore += 2;
  }

  // Explicit triggers[] “why now” boost (bounded).
  const trig = ticker?.trigger_summary || triggerSummaryAndScore(ticker);
  if (trig && typeof trig === "object" && Number.isFinite(trig.score)) {
    dynamicScore += trig.score;
  }

  // Move status: deprioritize invalidated/completed moves
  const ms = ticker?.move_status || computeMoveStatus(ticker);
  if (ms && typeof ms === "object") {
    if (ms.status === "INVALIDATED") dynamicScore -= 30;
    else if (ms.status === "COMPLETED") dynamicScore -= 20;
  }

  // Corridor bonus (high priority - active setups)
  if (inCorridor) {
    dynamicScore += 12; // Strong bonus for being in corridor

    // Extra bonus if aligned AND in corridor (perfect setup)
    if (aligned) {
      dynamicScore += 8;
    }
  }

  // Squeeze release in corridor = very strong signal
  if (sqRel && inCorridor) {
    dynamicScore += 10;
  }

  // Squeeze on in corridor = building pressure
  if (sqOn && inCorridor && !sqRel) {
    dynamicScore += 5;
  }

  // RR bonus (scaled - better RR = higher score)
  if (rr >= 2.0) {
    dynamicScore += 8; // Excellent RR
  } else if (rr >= 1.5) {
    dynamicScore += 5; // Good RR
  } else if (rr >= 1.0) {
    dynamicScore += 2; // Acceptable RR
  }

  // Phase bonus (early phase = better opportunity)
  if (phase < 0.3) {
    dynamicScore += 6; // Very early
  } else if (phase < 0.5) {
    dynamicScore += 3; // Early
  } else if (phase > 0.7) {
    dynamicScore -= 5; // Late phase penalty
  }

  // Completion bonus (low completion = more room to run)
  if (comp < 0.3) {
    dynamicScore += 5; // Early in move
  } else if (comp > 0.8) {
    dynamicScore -= 8; // Near completion penalty
  }

  // Phase 2: Hold-intent scoring (small nudge; only when HTF strength supports it)
  // Goal: favor longer-duration setups when HTF strength is high, without overpowering other gates.
  const htfAbs = Math.abs(htf);
  if (holdIntent === "POSITION" && htfAbs >= 15) {
    dynamicScore += 2;
  } else if (holdIntent === "SWING" && htfAbs >= 10) {
    dynamicScore += 1;
  }

  // Score strength bonus (strong HTF/LTF scores)
  const htfStrength = Math.min(8, Math.abs(htf) * 0.15);
  const ltfStrength = Math.min(6, Math.abs(ltf) * 0.12);
  dynamicScore += htfStrength + ltfStrength;

  // Phase zone change bonus
  if (phaseZoneChange) {
    dynamicScore += 4;
  }

  // NO CAP - let scores go above 100 to help tickers separate from one another
  // Minimum is 0, but no maximum cap
  dynamicScore = Math.max(0, dynamicScore);

  return Math.round(dynamicScore * 100) / 100; // Round to 2 decimals for precision
}

// Compute RR at trigger price (for alert evaluation)
// This evaluates RR at the entry point, not current price
// This is critical because price moves after trigger, which decreases RR
function computeRRAtTrigger(d) {
  // Use trigger_price if available, otherwise fall back to current price
  const triggerPrice =
    d.trigger_price != null ? Number(d.trigger_price) : Number(d.price);
  const sl = Number(d.sl);
  if (!Number.isFinite(triggerPrice) || !Number.isFinite(sl)) return null;

  // Use MAX TP from tp_levels if available, otherwise fall back to first TP
  let tp = Number(d.tp);
  if (d.tp_levels && Array.isArray(d.tp_levels) && d.tp_levels.length > 0) {
    // Extract prices from tp_levels (handle both object and number formats)
    const tpPrices = d.tp_levels
      .map((tpItem) => {
        if (
          typeof tpItem === "object" &&
          tpItem !== null &&
          tpItem.price != null
        ) {
          return Number(tpItem.price);
        }
        return typeof tpItem === "number" ? Number(tpItem) : Number(tpItem);
      })
      .filter((p) => Number.isFinite(p));

    if (tpPrices.length > 0) {
      // Best-case TP depends on direction:
      //   LONG  → highest price (max reward going up)
      //   SHORT → lowest price  (max reward going down)
      const stateDir = String(d.state || "");
      tp = stateDir.includes("BEAR")
        ? Math.min(...tpPrices)
        : Math.max(...tpPrices);
    }
  }

  if (!Number.isFinite(tp)) return null;

  // Determine direction from state to calculate risk/reward correctly
  const state = String(d.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");

  let risk, gain;

  if (isLong) {
    risk = triggerPrice - sl;
    gain = tp - triggerPrice;
  } else if (isShort) {
    risk = sl - triggerPrice;
    gain = triggerPrice - tp;
  } else {
    risk = Math.abs(triggerPrice - sl);
    gain = Math.abs(tp - triggerPrice);
  }

  // Ensure both risk and gain are positive
  if (risk <= 0 || gain <= 0) return null;
  return gain / risk;
}

// ─────────────────────────────────────────────────────────────
// Horizon + ETA v2 (Worker-derived, % based)
// ─────────────────────────────────────────────────────────────

function clampNum(x, lo, hi) {
  const n = Number(x);
  if (!Number.isFinite(n)) return lo;
  return Math.max(lo, Math.min(hi, n));
}

function median(values) {
  const arr = Array.isArray(values)
    ? values.filter((n) => Number.isFinite(Number(n))).map((n) => Number(n))
    : [];
  if (arr.length === 0) return null;
  arr.sort((a, b) => a - b);
  const mid = Math.floor(arr.length / 2);
  if (arr.length % 2 === 1) return arr[mid];
  return (arr[mid - 1] + arr[mid]) / 2;
}

// Infer ATR (absolute) from ATR_FIB tp_levels by solving:
// price_i - price_j = (mult_i - mult_j) * ATR
function inferAtrAbsFromTpLevels(tpLevels, timeframe) {
  if (!Array.isArray(tpLevels) || tpLevels.length < 2) return null;
  const tf = String(timeframe || "").toUpperCase();

  const atrFib = tpLevels
    .map((tp) => {
      const type = String(tp?.type || "").toUpperCase();
      const t = String(tp?.timeframe || "").toUpperCase();
      const price = Number(tp?.price);
      const mult = Number(tp?.multiplier);
      if (type !== "ATR_FIB") return null;
      if (t !== tf) return null;
      if (!Number.isFinite(price) || price <= 0) return null;
      if (!Number.isFinite(mult) || mult <= 0) return null;
      return { price, mult };
    })
    .filter(Boolean);

  if (atrFib.length < 2) return null;

  const ests = [];
  for (let i = 0; i < atrFib.length; i++) {
    for (let j = i + 1; j < atrFib.length; j++) {
      const dm = Math.abs(atrFib[i].mult - atrFib[j].mult);
      const dp = Math.abs(atrFib[i].price - atrFib[j].price);
      if (dm <= 1e-9) continue;
      if (!Number.isFinite(dp) || dp <= 0) continue;
      const atr = dp / dm;
      if (Number.isFinite(atr) && atr > 0) ests.push(atr);
    }
  }

  const atrMed = median(ests);
  if (!Number.isFinite(atrMed) || atrMed <= 0) return null;
  return atrMed;
}

function horizonBucketFromEtaDays(etaDays) {
  const eta = Number(etaDays);
  if (!Number.isFinite(eta) || eta <= 0) return "UNKNOWN";
  if (eta <= 7) return "SHORT_TERM";
  if (eta <= 30) return "SWING";
  return "POSITIONAL";
}

function deriveHorizonAndMetrics(payload) {
  if (!payload || typeof payload !== "object") return {};

  const state = String(payload.state || "");
  const direction = state.includes("BULL")
    ? "LONG"
    : state.includes("BEAR")
      ? "SHORT"
      : null;
  const isLong = direction === "LONG";

  const entryRef =
    payload.trigger_price != null && Number(payload.trigger_price) > 0
      ? Number(payload.trigger_price)
      : Number(payload.price);
  const sl = Number(payload.sl);

  const out = {
    entry_ref: Number.isFinite(entryRef) ? entryRef : null,
    risk_pct: null,
    tp_max_price: null,
    tp_max_pct: null,
    tp_target_price: null,
    tp_target_pct: null,
    expected_return_pct: null,
    eta_days_v2: null,
    eta_days_next: null,
    eta_days_max: null,
    eta_confidence: 0.4,
    horizon_bucket: "UNKNOWN",
    // Alias for downstream clarity (Phase 2: hold-intent scoring/labeling)
    hold_intent: "UNKNOWN",
  };

  if (!direction || !Number.isFinite(entryRef) || entryRef <= 0) {
    const etaFallback = Number(payload.eta_days);
    out.horizon_bucket = horizonBucketFromEtaDays(etaFallback);
    out.eta_days_v2 = Number.isFinite(etaFallback) ? etaFallback : null;
    out.eta_confidence = Number.isFinite(etaFallback) ? 0.35 : 0.2;
    out.hold_intent = out.horizon_bucket;
    return out;
  }

  if (Number.isFinite(sl) && sl > 0) {
    const riskAbs = Math.abs(entryRef - sl);
    const riskPct = riskAbs / entryRef;
    if (Number.isFinite(riskPct) && riskPct > 0) {
      out.risk_pct = Math.round(riskPct * 10000) / 100;
    }
  }

  const tpLevelsRaw = Array.isArray(payload.tp_levels) ? payload.tp_levels : [];
  const minDistPct = 0.01;

  const tpCandidates = tpLevelsRaw
    .map((tp) => {
      const price = Number(tp?.price);
      if (!Number.isFinite(price) || price <= 0) return null;
      const distancePct = Math.abs(price - entryRef) / entryRef;
      if (!Number.isFinite(distancePct) || distancePct < minDistPct)
        return null;
      if (isLong && price <= entryRef) return null;
      if (!isLong && price >= entryRef) return null;
      return {
        price,
        distancePct,
        timeframe: String(tp?.timeframe || "D").toUpperCase(),
        type: String(tp?.type || "ATR_FIB").toUpperCase(),
        source: String(tp?.source || "").trim(),
        confidence: Number(tp?.confidence),
        multiplier: tp?.multiplier == null ? null : Number(tp?.multiplier),
        _fused: tp?._fused || null,
      };
    })
    .filter(Boolean);

  if (tpCandidates.length > 0) {
    const tpMax = isLong
      ? Math.max(...tpCandidates.map((t) => t.price))
      : Math.min(...tpCandidates.map((t) => t.price));
    if (Number.isFinite(tpMax) && tpMax > 0) {
      out.tp_max_price = tpMax;
      const tpMaxPct = (Math.abs(tpMax - entryRef) / entryRef) * 100;
      if (Number.isFinite(tpMaxPct) && tpMaxPct > 0) {
        out.tp_max_pct = Math.round(tpMaxPct * 100) / 100;
      }
    }
  }

  const atrD = inferAtrAbsFromTpLevels(tpLevelsRaw, "D");
  const atrW = inferAtrAbsFromTpLevels(tpLevelsRaw, "W");
  const atr4 = inferAtrAbsFromTpLevels(tpLevelsRaw, "240");

  let dailyAtrPct = null;
  if (Number.isFinite(atrD) && atrD > 0) dailyAtrPct = atrD / entryRef;
  else if (Number.isFinite(atrW) && atrW > 0) dailyAtrPct = atrW / entryRef / 5;
  else if (Number.isFinite(atr4) && atr4 > 0)
    dailyAtrPct = (atr4 / entryRef) * 1.8;

  const htfAbs = Math.abs(Number(payload.htf_score) || 0);
  const ltfAbs = Math.abs(Number(payload.ltf_score) || 0);
  const momentumFactor = clampNum(
    0.85 + (htfAbs / 50) * 0.25 + (ltfAbs / 50) * 0.25,
    0.75,
    1.45,
  );

  let expectedDailyMovePct = null;
  if (Number.isFinite(dailyAtrPct) && dailyAtrPct > 0) {
    expectedDailyMovePct = clampNum(
      dailyAtrPct * 0.35 * momentumFactor,
      0.003,
      dailyAtrPct * 1.1,
    );
    out.eta_confidence += 0.25;
  } else if (Number.isFinite(out.risk_pct) && out.risk_pct > 0) {
    expectedDailyMovePct = clampNum(
      (out.risk_pct / 100) * 0.25 * momentumFactor,
      0.003,
      0.02,
    );
    out.eta_confidence += 0.1;
  } else {
    expectedDailyMovePct = 0.006;
    out.eta_confidence += 0.05;
  }

  // Intelligent target TP: use horizon-aware TP array to pick a realistic target
  const tpArray = buildIntelligentTPArray(payload, entryRef, direction);
  const targetTp =
    tpArray && tpArray.length > 1
      ? tpArray[1]
      : tpArray && tpArray.length > 0
        ? tpArray[0]
        : null;
  if (targetTp && Number.isFinite(targetTp.price) && targetTp.price > 0) {
    out.tp_target_price = Number(targetTp.price);
    const targetPct =
      (Math.abs(out.tp_target_price - entryRef) / entryRef) * 100;
    if (Number.isFinite(targetPct) && targetPct > 0) {
      out.tp_target_pct = Math.round(targetPct * 100) / 100;
      out.expected_return_pct = out.tp_target_pct;
    }
    if (Number.isFinite(expectedDailyMovePct) && expectedDailyMovePct > 0) {
      const etaTarget = targetPct / 100 / expectedDailyMovePct;
      if (Number.isFinite(etaTarget) && etaTarget > 0) {
        out.eta_days_v2 = Math.round(clampNum(etaTarget, 0.2, 180) * 100) / 100;
        out.eta_confidence += 0.15;
      }
    }
  }

  const qualityScore = (tp) => {
    const tf = String(tp?.timeframe || "D").toUpperCase();
    const type = String(tp?.type || "").toUpperCase();
    const conf = Number(tp?.confidence);
    const tfScore =
      tf === "W" ? 3 : tf === "D" ? 2 : tf === "240" || tf === "4H" ? 1 : 0;
    const typeScore = type.startsWith("FUSED")
      ? 3
      : type === "STRUCTURE"
        ? 3
        : type === "LIQUIDITY"
          ? 2
          : type === "FVG"
            ? 1.5
            : type === "GAP"
              ? 1
              : type === "ATR_FIB"
                ? 1
                : 0.5;
    const confScore = Number.isFinite(conf)
      ? clampNum((conf - 0.6) / 0.3, 0, 1)
      : 0.5;
    return tfScore + typeScore + confScore;
  };

  const scored = tpCandidates
    .map((tp) => ({
      ...tp,
      _q: qualityScore(tp),
      _eta: tp.distancePct / expectedDailyMovePct,
    }))
    .filter((tp) => Number.isFinite(tp._eta) && tp._eta > 0)
    .sort((a, b) => {
      const aScore = a._q / (1 + a.distancePct * 12);
      const bScore = b._q / (1 + b.distancePct * 12);
      return bScore - aScore;
    });

  const next = scored[0] || null;
  if (next) {
    out.eta_days_next = Math.round(clampNum(next._eta, 0.2, 180) * 100) / 100;
    if (!Number.isFinite(out.eta_days_v2)) {
      out.eta_days_v2 = out.eta_days_next;
      out.eta_confidence += 0.2;
    }
  }

  if (Number.isFinite(out.tp_max_price) && out.tp_max_price > 0) {
    const distMaxPct = Math.abs(out.tp_max_price - entryRef) / entryRef;
    const etaMax = distMaxPct / expectedDailyMovePct;
    if (Number.isFinite(etaMax) && etaMax > 0) {
      out.eta_days_max = Math.round(clampNum(etaMax, 0.5, 365) * 100) / 100;
    }
  }

  if (
    !Number.isFinite(out.expected_return_pct) &&
    Number.isFinite(out.tp_max_pct)
  ) {
    out.expected_return_pct = out.tp_max_pct;
  }

  out.eta_confidence =
    Math.round(clampNum(out.eta_confidence, 0.1, 0.95) * 100) / 100;
  const etaForBucket = Number.isFinite(out.eta_days_v2)
    ? out.eta_days_v2
    : Number(payload.eta_days);
  out.horizon_bucket = horizonBucketFromEtaDays(etaForBucket);
  out.hold_intent = out.horizon_bucket;

  return out;
}

function normalizeDay(ts) {
  const ms = Number(ts);
  if (!Number.isFinite(ms)) return null;
  return Math.floor(ms / 86400000);
}

function buildDailyCloseSeries(trail = [], maxDays = 20) {
  if (!Array.isArray(trail) || trail.length === 0) return [];
  const dayMap = new Map();
  for (const point of trail) {
    const day = normalizeDay(point.ts);
    const price = Number(point.price);
    if (!Number.isFinite(day) || !Number.isFinite(price)) continue;
    // Keep last price of the day
    dayMap.set(day, price);
  }
  const days = Array.from(dayMap.keys()).sort((a, b) => a - b);
  const clipped = days.slice(-1 * Math.max(1, maxDays + 1));
  return clipped.map((day) => ({ day, close: dayMap.get(day) }));
}

function buildReturnMap(series = []) {
  const map = new Map();
  for (let i = 1; i < series.length; i++) {
    const prev = series[i - 1];
    const cur = series[i];
    if (!prev || !cur) continue;
    const ret = (cur.close - prev.close) / Math.max(1e-9, prev.close);
    if (!Number.isFinite(ret)) continue;
    map.set(cur.day, ret);
  }
  return map;
}

function pearsonCorrelation(a = [], b = []) {
  if (!Array.isArray(a) || !Array.isArray(b)) return null;
  const n = Math.min(a.length, b.length);
  if (n < 5) return null;
  const x = a.slice(-n);
  const y = b.slice(-n);
  const mean = (arr) => arr.reduce((s, v) => s + v, 0) / arr.length;
  const meanX = mean(x);
  const meanY = mean(y);
  let num = 0;
  let denX = 0;
  let denY = 0;
  for (let i = 0; i < n; i++) {
    const dx = x[i] - meanX;
    const dy = y[i] - meanY;
    num += dx * dy;
    denX += dx * dx;
    denY += dy * dy;
  }
  const den = Math.sqrt(denX * denY);
  if (!Number.isFinite(den) || den <= 0) return null;
  return num / den;
}

async function computeOpenTradesCorrelation(env, KV, options = {}) {
  const cacheKey = "timed:corr:open_trades";
  const ttlSec = Number(options.ttlSec || 300);
  const now = Date.now();
  try {
    const cached = await kvGetJSON(KV, cacheKey);
    if (
      cached &&
      cached.computedAt &&
      now - cached.computedAt < ttlSec * 1000
    ) {
      return cached;
    }
  } catch {
    // ignore cache errors
  }

  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  const trades = (await kvGetJSON(KV, "timed:trades:all")) || [];
  const openTickers = Array.from(
    new Set(
      trades
        .filter((t) => {
          const status = String(t?.status || "").toUpperCase();
          return status === "OPEN" || status === "TP_HIT_TRIM" || !status;
        })
        .map((t) => String(t?.ticker || "").toUpperCase())
        .filter(Boolean),
    ),
  );

  if (openTickers.length < 2) {
    return {
      ok: true,
      computedAt: now,
      tickers: openTickers,
      avgCorrByTicker: {},
    };
  }

  const sinceTs = now - 35 * 24 * 60 * 60 * 1000;
  const seriesMap = new Map();

  await Promise.all(
    openTickers.map(async (ticker) => {
      const res = await d1GetTrailRange(env, ticker, sinceTs, 8000);
      const trail = res && Array.isArray(res.trail) ? res.trail : [];
      const dailySeries = buildDailyCloseSeries(trail, 20);
      seriesMap.set(ticker, dailySeries);
    }),
  );

  const returnMapByTicker = new Map();
  for (const ticker of openTickers) {
    const series = seriesMap.get(ticker) || [];
    returnMapByTicker.set(ticker, buildReturnMap(series));
  }

  const avgCorrByTicker = {};
  const sectorMap = new Map();
  const sectorCounts = {};
  for (const ticker of openTickers) {
    try {
      const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
      const sector =
        latest?.sector || latest?.fundamentals?.sector || "UNKNOWN";
      sectorMap.set(ticker, sector);
      sectorCounts[sector] = (sectorCounts[sector] || 0) + 1;
    } catch {
      sectorMap.set(ticker, "UNKNOWN");
      sectorCounts.UNKNOWN = (sectorCounts.UNKNOWN || 0) + 1;
    }
  }
  for (const ticker of openTickers) {
    const baseMap = returnMapByTicker.get(ticker);
    if (!baseMap || baseMap.size < 5) continue;
    const corrVals = [];
    for (const other of openTickers) {
      if (other === ticker) continue;
      const otherMap = returnMapByTicker.get(other);
      if (!otherMap || otherMap.size < 5) continue;
      const commonDays = [];
      for (const [day, ret] of baseMap.entries()) {
        if (otherMap.has(day)) {
          commonDays.push([ret, otherMap.get(day)]);
        }
      }
      if (commonDays.length < 5) continue;
      const a = commonDays.map((v) => v[0]);
      const b = commonDays.map((v) => v[1]);
      const corr = pearsonCorrelation(a, b);
      if (Number.isFinite(corr)) corrVals.push(Math.abs(corr));
    }
    if (corrVals.length > 0) {
      const avg =
        corrVals.reduce((sum, v) => sum + v, 0) / Math.max(1, corrVals.length);
      const diversity = Math.round(Math.max(0, 1 - avg) * 100);
      avgCorrByTicker[ticker] = {
        avg_corr: Math.round(avg * 1000) / 1000,
        diversity_score: diversity,
        corr_count: corrVals.length,
      };
    }
  }

  // Fallback proxy: sector concentration when return series is insufficient.
  for (const ticker of openTickers) {
    if (avgCorrByTicker[ticker]) continue;
    const sector = sectorMap.get(ticker) || "UNKNOWN";
    const sameSector = Math.max(1, sectorCounts[sector] || 1);
    const total = Math.max(1, openTickers.length);
    const share = sameSector / total;
    const avg = Math.min(0.95, 0.3 + 0.7 * share);
    const diversity = Math.round(Math.max(0, 1 - avg) * 100);
    avgCorrByTicker[ticker] = {
      avg_corr: Math.round(avg * 1000) / 1000,
      diversity_score: diversity,
      corr_count: 0,
      _proxy: "sector",
    };
  }

  const result = {
    ok: true,
    computedAt: now,
    tickers: openTickers,
    avgCorrByTicker,
  };

  try {
    await kvPutJSON(KV, cacheKey, result, ttlSec);
  } catch {
    // ignore cache set errors
  }

  return result;
}

// ── Corridor helpers (must match UI corridors)
// LONG ltf -10..22: wider upper bound so momentum entries (LTF 12-22) still qualify
// SHORT ltf -12..10. Accept htf_score/htfScore, ltf_score/ltfScore (ingest payloads may use either)
function inLongCorridor(d) {
  const h = Number(d?.htf_score ?? d?.htfScore);
  const l = Number(d?.ltf_score ?? d?.ltfScore);
  return (
    Number.isFinite(h) && Number.isFinite(l) && h > 0 && l >= -10 && l <= 22
  );
}
function inShortCorridor(d) {
  const h = Number(d?.htf_score ?? d?.htfScore);
  const l = Number(d?.ltf_score ?? d?.ltfScore);
  return (
    Number.isFinite(h) && Number.isFinite(l) && h < 0 && l >= -12 && l <= 10
  );
}
function corridorSide(d) {
  if (inLongCorridor(d)) return "LONG";
  if (inShortCorridor(d)) return "SHORT";
  return null;
}

function fmt2(x) {
  const n = Number(x);
  return Number.isFinite(n) ? n.toFixed(2) : "—";
}
function pct01(x) {
  const n = Number(x);
  return Number.isFinite(n) ? `${Math.round(n * 100)}%` : "—";
}

// ─────────────────────────────────────────────────────────────
// Trade Simulation Functions (Worker-Level)
// ─────────────────────────────────────────────────────────────

const TRADE_SIZE = 1000; // $1000 per trade (legacy, used by entry-price-correction fallback)
const PORTFOLIO_START_CASH = 100000;
const PORTFOLIO_KEY = "timed:portfolio:v1";

// ── Dynamic Position Sizing Configuration ─────────────────────────────
// Risk-based sizing: positions are sized so a stop-loss hit risks a % of account,
// scaled by a multi-signal confidence score.
let _sizingConfig = null;
function getSizingConfig(env) {
  if (_sizingConfig) return _sizingConfig;
  const e = (key, def) => {
    const v = Number(env?.[key]);
    return Number.isFinite(v) && v > 0 ? v : def;
  };
  _sizingConfig = {
    BASE_RISK_PCT: e("SIZING_BASE_RISK_PCT", 0.01),     // 1% baseline
    MIN_RISK_PCT: e("SIZING_MIN_RISK_PCT", 0.005),      // 0.5% floor
    MAX_RISK_PCT: e("SIZING_MAX_RISK_PCT", 0.02),       // 2% ceiling
    MIN_NOTIONAL: e("SIZING_MIN_NOTIONAL", 500),         // $500 floor
    MAX_NOTIONAL: e("SIZING_MAX_NOTIONAL", 8000),        // $8,000 ceiling
    VIX_HIGH: e("SIZING_VIX_HIGH", 25),
    VIX_EXTREME: e("SIZING_VIX_EXTREME", 35),
  };
  return _sizingConfig;
}

function clamp(x, lo, hi) {
  const n = Number(x);
  if (!Number.isFinite(n)) return lo;
  return Math.max(lo, Math.min(hi, n));
}

// ── Historical Win Rate Cache ─────────────────────────────────────────
// Caches win rates by (sector, state, entryPath) from recent closed trades.
let _winRateCache = new Map();
let _winRateCacheTs = 0;
const WIN_RATE_CACHE_TTL = 5 * 60 * 1000; // 5 min

function computeHistoricalWinRate(allTrades, sector, state, entryPath) {
  const cacheKey = `${sector || "?"}|${state || "?"}|${entryPath || "?"}`;
  if (Date.now() - _winRateCacheTs < WIN_RATE_CACHE_TTL && _winRateCache.has(cacheKey)) {
    return _winRateCache.get(cacheKey);
  }

  if (Date.now() - _winRateCacheTs >= WIN_RATE_CACHE_TTL) {
    _winRateCache = new Map();
    _winRateCacheTs = Date.now();
  }

  const closed = (Array.isArray(allTrades) ? allTrades : [])
    .filter(t => t.status === "WIN" || t.status === "LOSS");
  const matching = closed.filter(t => {
    const tSector = getSector(String(t.ticker || "").toUpperCase()) || "UNKNOWN";
    if (sector && sector !== "UNKNOWN" && tSector !== sector) return false;
    const stateMatch = !state || (t.state || "") === state;
    const pathMatch = !entryPath || (t.entryPath || "") === entryPath;
    return stateMatch || pathMatch;
  }).slice(-50);

  let winRate = 0.5;
  if (matching.length >= 5) {
    const wins = matching.filter(t => t.status === "WIN").length;
    winRate = wins / matching.length;
  }

  // Blend with D1 path_performance when available (60% D1 / 40% in-memory)
  if (entryPath && _pathPerfCache.size > 0) {
    const d1Row = _pathPerfCache.get(entryPath);
    if (d1Row && d1Row.total_trades >= 10) {
      const d1WR = d1Row.recent_win_rate != null ? d1Row.recent_win_rate : d1Row.win_rate;
      if (d1WR != null) {
        winRate = matching.length >= 10 ? (winRate * 0.4 + d1WR * 0.6) : d1WR;
      }
    }
  }

  _winRateCache.set(cacheKey, winRate);
  return winRate;
}

// Per-path performance cache (populated from D1 path_performance table)
let _pathPerfCache = new Map();
let _pathPerfCacheTs = 0;
const PATH_PERF_CACHE_TTL = 10 * 60 * 1000; // 10 min

async function getPathPerformance(env, entryPath) {
  if (!entryPath) return null;
  if (Date.now() - _pathPerfCacheTs < PATH_PERF_CACHE_TTL && _pathPerfCache.has(entryPath)) {
    return _pathPerfCache.get(entryPath);
  }
  const db = env?.DB;
  if (!db) return null;
  try {
    await d1EnsureLearningSchema(env);
    if (Date.now() - _pathPerfCacheTs >= PATH_PERF_CACHE_TTL) {
      _pathPerfCache = new Map();
      _pathPerfCacheTs = Date.now();
      const { results } = await db.prepare(`SELECT * FROM path_performance`).all();
      for (const row of (results || [])) {
        _pathPerfCache.set(row.entry_path, row);
      }
    }
    return _pathPerfCache.get(entryPath) || null;
  } catch {
    return null;
  }
}

function isPathDisabled(pathPerf) {
  if (!pathPerf) return false;
  return pathPerf.enabled === 0;
}

// Refresh path_performance from direction_accuracy aggregates
async function refreshPathPerformance(env) {
  const db = env?.DB;
  if (!db) return { ok: false, reason: "no_db" };
  try {
    await d1EnsureLearningSchema(env);
    const { results } = await db.prepare(
      `SELECT entry_path,
       COUNT(*) as total,
       SUM(CASE WHEN status='WIN' THEN 1 ELSE 0 END) as wins,
       SUM(CASE WHEN status='LOSS' THEN 1 ELSE 0 END) as losses,
       SUM(CASE WHEN status='FLAT' THEN 1 ELSE 0 END) as flats,
       ROUND(AVG(pnl_pct),4) as avg_pnl_pct,
       ROUND(AVG(pnl),2) as avg_pnl,
       ROUND(AVG(max_favorable_excursion),4) as avg_mfe,
       ROUND(AVG(max_adverse_excursion),4) as avg_mae
       FROM direction_accuracy WHERE status != 'OPEN' AND entry_path IS NOT NULL
       GROUP BY entry_path`
    ).all();

    const now = Date.now();
    const thirtyDaysAgo = now - 30 * 86400000;
    const recentRows = (await db.prepare(
      `SELECT entry_path,
       COUNT(*) as recent_trades,
       ROUND(CAST(SUM(CASE WHEN status='WIN' THEN 1 ELSE 0 END) AS REAL) / NULLIF(COUNT(*),0),4) as recent_win_rate
       FROM direction_accuracy WHERE status != 'OPEN' AND entry_path IS NOT NULL AND ts > ?
       GROUP BY entry_path`
    ).bind(thirtyDaysAgo).all()).results || [];
    const recentMap = {};
    for (const r of recentRows) recentMap[r.entry_path] = r;

    let updated = 0;
    for (const row of (results || [])) {
      const path = row.entry_path;
      if (!path) continue;
      const w = row.wins || 0;
      const l = row.losses || 0;
      const winRate = (w + l) > 0 ? w / (w + l) : null;
      const recent = recentMap[path] || {};
      const recentWR = recent.recent_win_rate ?? null;
      const recentTrades = recent.recent_trades || 0;

      const AUTO_DISABLE_MIN_TRADES = 15;
      const AUTO_DISABLE_WIN_RATE = 0.25;
      let enabled = 1;
      let disableReason = null;
      if (row.total >= AUTO_DISABLE_MIN_TRADES && winRate !== null && winRate < AUTO_DISABLE_WIN_RATE) {
        enabled = 0;
        disableReason = `win_rate_${(winRate * 100).toFixed(1)}pct_below_25pct_threshold_(n=${row.total})`;
      }
      if (recentTrades >= 10 && recentWR !== null && recentWR < 0.20) {
        enabled = 0;
        disableReason = `recent_30d_wr_${(recentWR * 100).toFixed(1)}pct_below_20pct_(n=${recentTrades})`;
      }

      await db.prepare(
        `INSERT INTO path_performance (entry_path, total_trades, wins, losses, flats, win_rate,
         avg_pnl, avg_pnl_pct, avg_mfe, avg_mae, recent_win_rate, recent_trades,
         enabled, disable_reason, last_updated)
         VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
         ON CONFLICT(entry_path) DO UPDATE SET
         total_trades=excluded.total_trades, wins=excluded.wins, losses=excluded.losses,
         flats=excluded.flats, win_rate=excluded.win_rate, avg_pnl=excluded.avg_pnl,
         avg_pnl_pct=excluded.avg_pnl_pct, avg_mfe=excluded.avg_mfe, avg_mae=excluded.avg_mae,
         recent_win_rate=excluded.recent_win_rate, recent_trades=excluded.recent_trades,
         enabled=excluded.enabled, disable_reason=excluded.disable_reason, last_updated=excluded.last_updated`
      ).bind(path, row.total, w, l, row.flats || 0, winRate,
        row.avg_pnl, row.avg_pnl_pct, row.avg_mfe, row.avg_mae,
        recentWR, recentTrades, enabled, disableReason, now
      ).run();
      updated++;
    }
    _pathPerfCache = new Map();
    _pathPerfCacheTs = 0;
    return { ok: true, updated };
  } catch (e) {
    return { ok: false, error: String(e?.message || e).slice(0, 200) };
  }
}

// ── Learned Consensus Weights Cache ───────────────────────────────────
// Stores per-TF weights for computeSwingConsensus, loaded from model_config.
let _consensusWeights = null;
let _consensusWeightsCacheTs = 0;
const CONSENSUS_WEIGHTS_TTL = 15 * 60 * 1000;

async function getLearnedConsensusWeights(env) {
  if (_consensusWeights && Date.now() - _consensusWeightsCacheTs < CONSENSUS_WEIGHTS_TTL) {
    return _consensusWeights;
  }
  const db = env?.DB;
  if (!db) return null;
  try {
    await d1EnsureLearningSchema(env);
    const row = await db.prepare(
      `SELECT config_value FROM model_config WHERE config_key = 'consensus_tf_weights'`
    ).first();
    if (row?.config_value) {
      _consensusWeights = JSON.parse(row.config_value);
      _consensusWeightsCacheTs = Date.now();
      return _consensusWeights;
    }
  } catch { /* fallback to null = equal weights */ }
  return null;
}

// ── Learned Signal Weights Cache ──────────────────────────────────────
let _signalWeights = null;
let _signalWeightsCacheTs = 0;
const SIGNAL_WEIGHTS_TTL = 15 * 60 * 1000;

async function getLearnedSignalWeights(env) {
  if (_signalWeights && Date.now() - _signalWeightsCacheTs < SIGNAL_WEIGHTS_TTL) {
    return _signalWeights;
  }
  const db = env?.DB;
  if (!db) return null;
  try {
    await d1EnsureLearningSchema(env);
    const row = await db.prepare(
      `SELECT config_value FROM model_config WHERE config_key = 'consensus_signal_weights'`
    ).first();
    if (row?.config_value) {
      _signalWeights = JSON.parse(row.config_value);
      _signalWeightsCacheTs = Date.now();
      return _signalWeights;
    }
  } catch { /* fallback to null = default weights */ }
  return null;
}

// Update consensus weights from trade outcome analysis
async function updateConsensusWeights(env) {
  const db = env?.DB;
  if (!db) return { ok: false, reason: "no_db" };
  try {
    await d1EnsureLearningSchema(env);

    // Analyze which TFs were correct at entry for winning vs losing trades
    const { results: rows } = await db.prepare(
      `SELECT tf_stack_json, direction_correct, traded_direction, status
       FROM direction_accuracy
       WHERE status IN ('WIN','LOSS') AND tf_stack_json IS NOT NULL
       ORDER BY ts DESC LIMIT 500`
    ).all();

    if (!rows || rows.length < 20) return { ok: true, skipped: true, reason: "insufficient_data" };

    const tfKeys = ["10m", "30m", "1H", "4H", "D"];
    const tfKeyToConfigKey = { "10m": "10", "30m": "30", "1H": "60", "4H": "240", "D": "D" };
    const tfCorrect = {};
    const tfTotal = {};
    for (const k of tfKeys) { tfCorrect[k] = 0; tfTotal[k] = 0; }

    for (const row of rows) {
      let stack;
      try { stack = JSON.parse(row.tf_stack_json); } catch { continue; }
      if (!Array.isArray(stack)) continue;

      const isWin = row.status === "WIN";
      const isLong = row.traded_direction === "LONG";

      for (const entry of stack) {
        const tf = entry.tf;
        if (!tfKeys.includes(tf)) continue;
        if (entry.bias === "unknown") continue;

        tfTotal[tf]++;
        const tfAligned = isLong ? entry.bias === "bullish" : entry.bias === "bearish";
        // TF was "correct" if it aligned with direction AND trade won,
        // or if it opposed direction AND trade lost
        if ((tfAligned && isWin) || (!tfAligned && !isWin)) {
          tfCorrect[tf]++;
        }
      }
    }

    // Convert accuracy to weights: accuracy 50% → weight 1.0, 70% → 1.4, 30% → 0.6
    const weights = {};
    for (const tf of tfKeys) {
      const configKey = tfKeyToConfigKey[tf];
      if (tfTotal[tf] < 10) {
        weights[configKey] = 1.0; // insufficient data, keep equal
      } else {
        const accuracy = tfCorrect[tf] / tfTotal[tf];
        weights[configKey] = Math.round(Math.max(0.3, Math.min(2.0, accuracy * 2)) * 100) / 100;
      }
    }

    const now = Date.now();
    await db.prepare(
      `INSERT INTO model_config (config_key, config_value, description, updated_at, updated_by)
       VALUES ('consensus_tf_weights', ?, 'Learned per-TF weights for swing consensus voting', ?, 'system')
       ON CONFLICT(config_key) DO UPDATE SET config_value=excluded.config_value, updated_at=excluded.updated_at`
    ).bind(JSON.stringify(weights), now).run();

    _consensusWeights = weights;
    _consensusWeightsCacheTs = now;

    return { ok: true, weights, sample_size: rows.length };
  } catch (e) {
    return { ok: false, error: String(e?.message || e).slice(0, 200) };
  }
}

// Update per-signal weights from trade outcome analysis.
// Reads signal_snapshot_json from closed trades, computes which signals
// (ema_cross, supertrend, ema_structure, ema_depth, rsi) predicted correctly.
async function updateSignalWeights(env) {
  const db = env?.DB;
  if (!db) return { ok: false, reason: "no_db" };
  try {
    await d1EnsureLearningSchema(env);
    const { results: rows } = await db.prepare(
      `SELECT signal_snapshot_json, traded_direction, status
       FROM direction_accuracy
       WHERE status IN ('WIN','LOSS') AND signal_snapshot_json IS NOT NULL
       ORDER BY ts DESC LIMIT 500`
    ).all();

    if (!rows || rows.length < 20) return { ok: true, skipped: true, reason: "insufficient_data" };

    const signalKeys = ["ema_cross", "supertrend", "ema_structure", "ema_depth", "rsi"];
    const correct = {};
    const total = {};
    for (const k of signalKeys) { correct[k] = 0; total[k] = 0; }

    for (const row of rows) {
      let snap;
      try { snap = JSON.parse(row.signal_snapshot_json); } catch { continue; }
      if (!snap?.tf || typeof snap.tf !== "object") continue;

      const isWin = row.status === "WIN";
      const isLong = row.traded_direction === "LONG";

      for (const tfData of Object.values(snap.tf)) {
        const sigs = tfData.signals;
        if (!sigs || typeof sigs !== "object") continue;

        for (const sk of signalKeys) {
          const val = sigs[sk];
          if (val == null || !Number.isFinite(val)) continue;

          total[sk]++;
          const sigBullish = sk === "ema_depth" ? val > 5 : val > 0;
          const aligned = isLong ? sigBullish : !sigBullish;
          if ((aligned && isWin) || (!aligned && !isWin)) {
            correct[sk]++;
          }
        }
      }
    }

    const DEFAULT_W = { ema_cross: 0.15, supertrend: 0.25, ema_structure: 0.25, ema_depth: 0.20, rsi: 0.15 };
    const weights = {};
    for (const sk of signalKeys) {
      if (total[sk] < 15) {
        weights[sk] = DEFAULT_W[sk];
      } else {
        const accuracy = correct[sk] / total[sk];
        weights[sk] = Math.round(Math.max(0.05, Math.min(0.50, accuracy * DEFAULT_W[sk] * 2)) * 100) / 100;
      }
    }

    // Normalize so weights sum to 1.0
    const sum = Object.values(weights).reduce((a, b) => a + b, 0);
    if (sum > 0) {
      for (const sk of signalKeys) weights[sk] = Math.round((weights[sk] / sum) * 100) / 100;
    }

    const now = Date.now();
    await db.prepare(
      `INSERT INTO model_config (config_key, config_value, description, updated_at, updated_by)
       VALUES ('consensus_signal_weights', ?, 'Learned per-signal weights for TF bias scoring', ?, 'system')
       ON CONFLICT(config_key) DO UPDATE SET config_value=excluded.config_value, updated_at=excluded.updated_at`
    ).bind(JSON.stringify(weights), now).run();

    _signalWeights = weights;
    _signalWeightsCacheTs = now;

    return { ok: true, weights, sample_size: rows.length };
  } catch (e) {
    return { ok: false, error: String(e?.message || e).slice(0, 200) };
  }
}

// ── Learned Scoring Weight Adjustments Cache ─────────────────────────
// EMA-based multipliers for HTF/LTF per-TF weights, stored in model_config.
let _scoringWeightAdj = null;
let _scoringWeightAdjTs = 0;

async function getLearnedScoringWeights(env) {
  if (_scoringWeightAdj && Date.now() - _scoringWeightAdjTs < CONSENSUS_WEIGHTS_TTL) {
    return _scoringWeightAdj;
  }
  const db = env?.DB;
  if (!db) return null;
  try {
    await d1EnsureLearningSchema(env);
    const row = await db.prepare(
      `SELECT config_value FROM model_config WHERE config_key = 'scoring_weight_adj'`
    ).first();
    if (row?.config_value) {
      _scoringWeightAdj = JSON.parse(row.config_value);
      _scoringWeightAdjTs = Date.now();
      return _scoringWeightAdj;
    }
  } catch { /* fallback to null = default weights */ }
  return null;
}

// EMA update: after each batch of closed trades, nudge per-TF scoring weights
// toward configurations that produced winning trades.
// EMA alpha = 0.1 (slow adaptation, ~10 trade half-life)
async function updateScoringWeightAdjustments(env) {
  const db = env?.DB;
  if (!db) return { ok: false, reason: "no_db" };
  try {
    await d1EnsureLearningSchema(env);
    const EMA_ALPHA = 0.1;
    const TF_KEYS = ["W", "D", "240", "60", "30", "10", "5"];

    // Get current adjustments (or initialize at 1.0)
    let current = {};
    try {
      const row = await db.prepare(
        `SELECT config_value FROM model_config WHERE config_key = 'scoring_weight_adj'`
      ).first();
      if (row?.config_value) current = JSON.parse(row.config_value);
    } catch { /* start fresh */ }
    for (const k of TF_KEYS) { if (!current[k]) current[k] = 1.0; }

    // Analyze recent closed trades from direction_accuracy
    const { results: trades } = await db.prepare(
      `SELECT htf_score, ltf_score, direction_correct, traded_direction, tf_stack_json
       FROM direction_accuracy WHERE status IN ('WIN','LOSS') AND tf_stack_json IS NOT NULL
       ORDER BY ts DESC LIMIT 200`
    ).all();

    if (!trades || trades.length < 20) return { ok: true, skipped: true, reason: "insufficient_data" };

    // For each TF, compute a "hit rate" — how often that TF's alignment
    // correlated with the trade being correct
    const tfHits = {};
    const tfTotal = {};
    for (const k of TF_KEYS) { tfHits[k] = 0; tfTotal[k] = 0; }

    const labelToKey = { "10m": "10", "30m": "30", "1H": "60", "4H": "240", "D": "D", "W": "W" };

    for (const t of trades) {
      let stack;
      try { stack = JSON.parse(t.tf_stack_json); } catch { continue; }
      if (!Array.isArray(stack)) continue;
      const isCorrect = t.direction_correct === 1;
      const isLong = t.traded_direction === "LONG";

      for (const entry of stack) {
        const k = labelToKey[entry.tf];
        if (!k || entry.bias === "unknown") continue;
        tfTotal[k]++;
        const aligned = isLong ? entry.bias === "bullish" : entry.bias === "bearish";
        if ((aligned && isCorrect) || (!aligned && !isCorrect)) tfHits[k]++;
      }
    }

    // EMA update: nudge each weight toward the accuracy signal
    const updated = {};
    for (const k of TF_KEYS) {
      const prev = current[k] || 1.0;
      if (tfTotal[k] < 10) { updated[k] = prev; continue; }
      const accuracy = tfHits[k] / tfTotal[k];
      // Target multiplier: accuracy 50% → 1.0, 70% → 1.4, 30% → 0.6
      const target = Math.max(0.3, Math.min(2.0, accuracy * 2));
      updated[k] = Math.round((prev * (1 - EMA_ALPHA) + target * EMA_ALPHA) * 1000) / 1000;
    }

    const now = Date.now();
    await db.prepare(
      `INSERT INTO model_config (config_key, config_value, description, updated_at, updated_by)
       VALUES ('scoring_weight_adj', ?, 'EMA-adjusted per-TF scoring weight multipliers', ?, 'system')
       ON CONFLICT(config_key) DO UPDATE SET config_value=excluded.config_value, updated_at=excluded.updated_at`
    ).bind(JSON.stringify(updated), now).run();

    _scoringWeightAdj = updated;
    _scoringWeightAdjTs = now;
    return { ok: true, weights: updated, sample_size: trades.length };
  } catch (e) {
    return { ok: false, error: String(e?.message || e).slice(0, 200) };
  }
}

// EMA update: adjust scoring weights based on which TF scores best predicted outcomes
async function updateScoringWeights(env) {
  const db = env?.DB;
  if (!db) return { ok: false, reason: "no_db" };
  try {
    await d1EnsureLearningSchema(env);
    const EMA_ALPHA = 0.15;

    const { results: rows } = await db.prepare(
      `SELECT da.traded_direction, da.htf_score, da.ltf_score, da.tf_stack_json,
       da.direction_correct, da.pnl_pct, da.status
       FROM direction_accuracy da
       WHERE da.status IN ('WIN','LOSS') AND da.htf_score IS NOT NULL
       ORDER BY da.ts DESC LIMIT 300`
    ).all();

    if (!rows || rows.length < 20) return { ok: true, skipped: true, reason: "insufficient_data" };

    // Load existing adjustments or start from neutral
    const existing = await db.prepare(
      `SELECT config_value FROM model_config WHERE config_key = 'scoring_weight_adj'`
    ).first();
    const current = existing?.config_value ? JSON.parse(existing.config_value) : {};
    const adj = {
      W: current.W || 1.0, D: current.D || 1.0, "240": current["240"] || 1.0,
      "60": current["60"] || 1.0, "30": current["30"] || 1.0,
      "10": current["10"] || 1.0, "5": current["5"] || 1.0,
    };

    // For each trade, check if HTF-heavy or LTF-heavy weighting was more predictive
    let htfWins = 0, htfLosses = 0, ltfWins = 0, ltfLosses = 0;
    for (const r of rows) {
      const isWin = r.status === "WIN";
      const htfMag = Math.abs(r.htf_score || 0);
      const ltfMag = Math.abs(r.ltf_score || 0);
      // Strong HTF signal = HTF magnitude > 15
      if (htfMag > 15) { if (isWin) htfWins++; else htfLosses++; }
      // Strong LTF signal = LTF magnitude > 10
      if (ltfMag > 10) { if (isWin) ltfWins++; else ltfLosses++; }
    }

    // Compute accuracy for HTF vs LTF signal strength
    const htfAcc = (htfWins + htfLosses) > 10 ? htfWins / (htfWins + htfLosses) : 0.5;
    const ltfAcc = (ltfWins + ltfLosses) > 10 ? ltfWins / (ltfWins + ltfLosses) : 0.5;

    // EMA update: nudge HTF TF weights up if HTF-heavy signals are more accurate, and vice versa
    const htfMultiplier = 0.8 + htfAcc * 0.4; // range: 0.8-1.2
    const ltfMultiplier = 0.8 + ltfAcc * 0.4;

    for (const k of ["W", "D", "240", "60"]) {
      adj[k] = adj[k] * (1 - EMA_ALPHA) + htfMultiplier * EMA_ALPHA;
      adj[k] = Math.round(Math.max(0.5, Math.min(1.5, adj[k])) * 1000) / 1000;
    }
    for (const k of ["30", "10", "5"]) {
      adj[k] = adj[k] * (1 - EMA_ALPHA) + ltfMultiplier * EMA_ALPHA;
      adj[k] = Math.round(Math.max(0.5, Math.min(1.5, adj[k])) * 1000) / 1000;
    }

    const now = Date.now();
    await db.prepare(
      `INSERT INTO model_config (config_key, config_value, description, updated_at, updated_by)
       VALUES ('scoring_weight_adj', ?, 'EMA-learned HTF/LTF weight adjustments', ?, 'system')
       ON CONFLICT(config_key) DO UPDATE SET config_value=excluded.config_value, updated_at=excluded.updated_at`
    ).bind(JSON.stringify(adj), now).run();

    _scoringWeightAdj = adj;
    _scoringWeightAdjTs = now;

    return { ok: true, adj, htfAcc: Math.round(htfAcc * 100), ltfAcc: Math.round(ltfAcc * 100), sample: rows.length };
  } catch (e) {
    return { ok: false, error: String(e?.message || e).slice(0, 200) };
  }
}

// ── ML Model Prediction Lookup ────────────────────────────────────────
async function getMLPredictionConfidence(env, ticker) {
  const db = env?.DB;
  if (!db) return 0.5; // neutral default
  try {
    const row = await db.prepare(
      `SELECT confidence, direction FROM model_predictions
       WHERE ticker = ?1 AND resolved = 0 AND ts > ?2
       ORDER BY ts DESC LIMIT 1`
    ).bind(ticker, Date.now() - 7 * 86400000).first();
    if (row && Number.isFinite(Number(row.confidence))) {
      return clamp(Number(row.confidence), 0, 1);
    }
  } catch (e) {
    console.warn("[SIZING] ML prediction lookup failed:", String(e).slice(0, 100));
  }
  return 0.5;
}

// ── Enhanced Multi-Signal Confidence ──────────────────────────────────
// Weights (total = 1.0):
//   Rank: 0.30, R:R: 0.15, Scores: 0.10, ML: 0.15,
//   Win Rate: 0.10, Sector Alignment: 0.10, VIX: 0.10
//   Flag bonuses: up to +0.10
function computeTradeConfidence(tickerData, opts = {}) {
  const t = tickerData && typeof tickerData === "object" ? tickerData : {};
  const flags = t.flags && typeof t.flags === "object" ? t.flags : {};
  const rank = Number(t.rank) || 0;
  const rr =
    Number(t.rr_now_likely) || Number(t.rr_entry_likely) || Number(t.rr) || 0;
  const h = Math.abs(Number(t.htf_score) || 0);
  const l = Math.abs(Number(t.ltf_score) || 0);

  // 1. Rank: 60→0, 90→1 (weight: 0.30)
  const cRank = clamp((rank - 60) / 30, 0, 1);
  // 2. R:R: 1.0→0, 2.5→1 (weight: 0.15)
  const cRr = clamp((rr - 1.0) / 1.5, 0, 1);
  // 3. HTF/LTF scores: soft contribution (weight: 0.10)
  const cScore = clamp((h / 60) * 0.6 + (l / 35) * 0.4, 0, 1);
  // 4. ML model prediction (weight: 0.15)
  const cMl = clamp(Number(opts.mlConfidence) || 0.5, 0, 1);
  // 5. Historical win rate (weight: 0.10)
  const cWinRate = clamp(Number(opts.winRate) || 0.5, 0, 1);
  // 6. Sector alignment (weight: 0.10)
  const cSector = clamp(Number(opts.sectorAlignmentScore) || 0.5, 0, 1);
  // 7. VIX regime: inverse — low VIX = high confidence (weight: 0.10)
  const cVix = clamp(Number(opts.vixScore) || 0.5, 0, 1);

  // Flag bonuses (up to +0.10)
  const bonus =
    (flags.momentum_elite ? 0.04 : 0) +
    (flags.thesis_match ? 0.03 : 0) +
    (flags.sq30_release ? 0.02 : 0) +
    (flags.prime ? 0.03 : 0);

  const confidence = clamp(
    0.30 * cRank +
    0.15 * cRr +
    0.10 * cScore +
    0.15 * cMl +
    0.10 * cWinRate +
    0.10 * cSector +
    0.10 * cVix +
    bonus,
    0,
    1,
  );

  // Return both the composite score and the breakdown for auditability
  const breakdown = {
    rank: cRank, rr: cRr, scores: cScore,
    mlPrediction: cMl, winRate: cWinRate,
    sectorAlignment: cSector, vixRegime: cVix,
    flagBonus: bonus,
  };

  return { confidence, breakdown };
}

// ── Risk-Based Position Sizing ────────────────────────────────────────
// Sizes positions so that if the stop-loss is hit, the account loses
// confidence-scaled risk % of its value, capped by notional limits.
function computeRiskBasedSize(confidence, accountValue, entryPrice, stopLoss, vixLevel, env) {
  const cfg = getSizingConfig(env);

  // 1. Map confidence (0-1) to risk % (MIN_RISK_PCT → MAX_RISK_PCT)
  const riskPct = cfg.MIN_RISK_PCT + (cfg.MAX_RISK_PCT - cfg.MIN_RISK_PCT) * clamp(confidence, 0, 1);

  // 2. VIX dampener (reduce size in high-volatility regimes)
  let vixMultiplier = 1.0;
  const vix = Number(vixLevel);
  if (Number.isFinite(vix) && vix > 0) {
    if (vix > cfg.VIX_EXTREME) vixMultiplier = 0.5;
    else if (vix > cfg.VIX_HIGH) vixMultiplier = 0.75;
  }

  // 3. Max dollar risk for this trade
  const acctVal = Number.isFinite(accountValue) && accountValue > 0 ? accountValue : PORTFOLIO_START_CASH;
  const maxDollarRisk = acctVal * riskPct * vixMultiplier;

  // 4. Risk per share = distance from entry to stop loss
  const riskPerShare = Math.abs(Number(entryPrice) - Number(stopLoss));
  if (!Number.isFinite(riskPerShare) || riskPerShare <= 0) {
    // Fallback: if no valid SL distance, use notional-based sizing
    const fallbackNotional = clamp(
      cfg.MIN_NOTIONAL + (cfg.MAX_NOTIONAL - cfg.MIN_NOTIONAL) * confidence,
      cfg.MIN_NOTIONAL,
      cfg.MAX_NOTIONAL,
    );
    return {
      shares: fallbackNotional / entryPrice,
      notional: fallbackNotional,
      riskPct,
      maxDollarRisk,
      riskPerShare: 0,
      vixMultiplier,
      method: "notional_fallback",
    };
  }

  // 5. Shares from risk budget
  let shares = maxDollarRisk / riskPerShare;
  let notional = shares * Number(entryPrice);

  // 6. Apply notional safety caps
  if (notional > cfg.MAX_NOTIONAL) {
    notional = cfg.MAX_NOTIONAL;
    shares = notional / Number(entryPrice);
  }
  if (notional < cfg.MIN_NOTIONAL) {
    notional = cfg.MIN_NOTIONAL;
    shares = notional / Number(entryPrice);
  }

  // 7. Cap by available cash (handled by caller, but ensure notional is capped)
  return {
    shares,
    notional,
    riskPct,
    maxDollarRisk,
    riskPerShare,
    vixMultiplier,
    method: "risk_based",
  };
}

async function getPortfolioState(KV) {
  try {
    const p = await kvGetJSON(KV, PORTFOLIO_KEY);
    if (p && typeof p === "object" && Number.isFinite(Number(p.cash))) return p;
  } catch {
    // ignore
  }
  const now = Date.now();
  return {
    version: 1,
    startCash: PORTFOLIO_START_CASH,
    cash: PORTFOLIO_START_CASH,
    created_at: now,
    updated_at: now,
  };
}

async function putPortfolioState(KV, p) {
  try {
    const now = Date.now();
    const next = { ...(p || {}), updated_at: now };
    if (!Number.isFinite(Number(next.startCash)))
      next.startCash = PORTFOLIO_START_CASH;
    if (!Number.isFinite(Number(next.cash)))
      next.cash = Number(next.startCash) || PORTFOLIO_START_CASH;
    await kvPutJSON(KV, PORTFOLIO_KEY, next);
    return next;
  } catch {
    return p;
  }
}

// Legacy notional function — kept for backward compatibility in edge cases
function tradeNotionalFromConfidence(confidence, cashAvailable) {
  const cfg = getSizingConfig();
  const base =
    cfg.MIN_NOTIONAL +
    (cfg.MAX_NOTIONAL - cfg.MIN_NOTIONAL) * clamp(confidence, 0, 1);
  const maxByCash = Number.isFinite(Number(cashAvailable))
    ? Number(cashAvailable)
    : base;
  const capped = Math.min(base, maxByCash, cfg.MAX_NOTIONAL);
  return clamp(capped, cfg.MIN_NOTIONAL, cfg.MAX_NOTIONAL);
}

function computeSharesForTrade(ticker, entryPrice, notional) {
  const sym = String(ticker || "").toUpperCase();
  const isFutures = FUTURES_SPECS[sym] || sym.endsWith("1!");
  if (isFutures && FUTURES_SPECS[sym]) {
    return { shares: 1, pointValue: FUTURES_SPECS[sym].pointValue };
  }
  const px = Number(entryPrice);
  const n = Number(notional);
  if (!Number.isFinite(px) || px <= 0 || !Number.isFinite(n) || n <= 0)
    return { shares: null, pointValue: 1 };
  return { shares: n / px, pointValue: 1 };
}

// ── Gather All Sizing Signals ─────────────────────────────────────────
// Collects ML prediction, win rate, sector alignment, and VIX data
// for the enhanced confidence calculation.
async function gatherSizingSignals(env, sym, tickerData, allTrades) {
  const direction = String(tickerData?.__entry_path || tickerData?.entry_path || "").toLowerCase().includes("short") ? "SHORT" : "LONG";

  // ML model prediction (async D1 lookup)
  const mlConfidence = await getMLPredictionConfidence(env, sym);

  // Historical win rate
  const sector = getSector(sym) || "UNKNOWN";
  const state = tickerData?.state || "";
  const entryPath = tickerData?.__entry_path || tickerData?.entry_path || "";
  const winRate = computeHistoricalWinRate(allTrades, sector, state, entryPath);

  // Sector alignment
  let sectorAlignmentScore = 0.5; // neutral
  const sa = getSectorAlignmentCached(sym);
  if (sa) {
    // If sector trend aligns with trade direction, boost; if opposed, penalize
    const sectorDir = String(sa.direction || "").toUpperCase();
    const aligned = (direction === "LONG" && sectorDir === "BULLISH") ||
                    (direction === "SHORT" && sectorDir === "BEARISH");
    const opposed = (direction === "LONG" && sectorDir === "BEARISH") ||
                    (direction === "SHORT" && sectorDir === "BULLISH");
    const strength = clamp(Number(sa.strength) || 0.5, 0, 1);
    if (aligned) sectorAlignmentScore = 0.5 + strength * 0.5; // 0.5 → 1.0
    else if (opposed) sectorAlignmentScore = 0.5 - strength * 0.4; // 0.5 → 0.1
  }

  // VIX regime
  let vixLevel = 0;
  let vixScore = 0.5; // neutral
  try {
    const vixData = await kvGetJSON(env?.KV_TIMED, "timed:latest:VIX");
    vixLevel = Number(vixData?.price) || 0;
    if (vixLevel > 0) {
      // VIX < 15: very calm → high confidence boost (0.9)
      // VIX 15-20: calm → slight boost (0.7)
      // VIX 20-25: normal → neutral (0.5)
      // VIX 25-35: elevated → penalize (0.3)
      // VIX > 35: extreme → strong penalize (0.1)
      if (vixLevel < 15) vixScore = 0.9;
      else if (vixLevel < 20) vixScore = 0.7;
      else if (vixLevel < 25) vixScore = 0.5;
      else if (vixLevel < 35) vixScore = 0.3;
      else vixScore = 0.1;
    }
  } catch {
    // VIX unavailable — use neutral
  }

  return { mlConfidence, winRate, sectorAlignmentScore, vixScore, vixLevel, sector };
}

// Futures contract specifications (point value per contract)
const FUTURES_SPECS = {
  "ES1!": { pointValue: 50, name: "E-mini S&P 500" },
  "NQ1!": { pointValue: 20, name: "E-mini Nasdaq-100" },
  "MES1!": { pointValue: 5, name: "Micro E-mini S&P 500" },
  "MNQ1!": { pointValue: 2, name: "Micro E-mini Nasdaq-100" },
  "YM1!": { pointValue: 5, name: "E-mini Dow" },
  "RTY1!": { pointValue: 50, name: "E-mini Russell 2000" },
  "CL1!": { pointValue: 1000, name: "Crude Oil WTI" },
  ES: { pointValue: 50, name: "E-mini S&P 500" },
  NQ: { pointValue: 20, name: "E-mini Nasdaq-100" },
  YM: { pointValue: 5, name: "E-mini Dow" },
};

const FUTURES_TICKERS = new Set([
  // Base symbols
  "ES", "NQ", "YM", "RTY", "CL", "GC", "SI", "HG", "NG",
  // TradingView continuous contract symbols
  "ES1!", "NQ1!", "YM1!", "RTY1!", "CL1!", "GC1!", "SI1!", "HG1!", "NG1!",
  // Micro futures
  "MES", "MNQ", "MES1!", "MNQ1!",
]);

// Non-equity instruments that should NOT be traded with equity logic
// These need special handling (different market structure, sizing, SL logic)
const NON_EQUITY_BLOCKLIST = new Set([
  // Volatility indices
  "VX1!", "UVXY", "SVXY", "VXX", "VIXY",
  // Commodities / Metals
  "SILVER", "GOLD", "COPPER", "PLATINUM", "PALLADIUM",
  // Crypto (if ever ingested)
  "BTC", "ETH", "BTCUSD", "ETHUSD",
  // Leveraged / Inverse ETFs (decay makes SL/TP unreliable)
  "SQQQ", "TQQQ", "SPXU", "SPXL", "UDOW", "SDOW",
  "LABU", "LABD", "SOXL", "SOXS", "FNGU", "FNGD",
  "TNA", "TZA", "NUGT", "DUST", "JNUG", "JDST",
]);

// Check if ticker should trigger a trade (matches UI logic)
function shouldTriggerTradeSimulation(ticker, tickerData, prevData) {
  const tickerUpper = String(ticker || "").toUpperCase();

  // Skip futures
  if (FUTURES_TICKERS.has(tickerUpper)) return false;

  // Must have valid entry/exit levels (support alternate field names)
  const slVal = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
  const tpVal = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
  if (!tickerData.price || !Number.isFinite(slVal) || slVal <= 0 || !Number.isFinite(tpVal) || tpVal <= 0) return false;

  const flags = tickerData.flags || {};
  const flipWatch = !!flags.flip_watch;
  const state = String(tickerData.state || "");
  const alignedLong = state === "HTF_BULL_LTF_BULL";
  const alignedShort = state === "HTF_BEAR_LTF_BEAR";
  const aligned = alignedLong || alignedShort;

  const h = Number(tickerData.htf_score);
  const l = Number(tickerData.ltf_score);

  // ─────────────────────────────────────────────────────────────────────────────
  // GOLD STANDARD ENTRY LOGIC (direction-specific based on historical analysis)
  // ─────────────────────────────────────────────────────────────────────────────
  
  // LONG: Traditional corridor + NEW pullback setup (HTF_BULL_LTF_PULLBACK)
  // 67.7% of big UP moves started from HTF_BULL_LTF_PULLBACK
  const longCorridorClassic = h > 0 && l >= -10 && l <= 22;  // Original
  const longPullbackSetup = state === "HTF_BULL_LTF_PULLBACK" && h >= 10 && l >= -15 && l <= 5;  // Gold standard
  const inLongCorridor = longCorridorClassic || longPullbackSetup;

  // SHORT: Traditional corridor + NEW blow-off top setup (HTF_BULL_LTF_BULL with high scores)
  // 82.7% of big DOWN moves started from HTF_BULL_LTF_BULL when BOTH scores overextended!
  const shortCorridorClassic = h < 0 && l >= -12 && l <= 10;  // Original (rarely works)
  const shortBlowOffTop = state === "HTF_BULL_LTF_BULL" && h >= 25 && l >= 15;  // Gold standard
  const inShortCorridor = shortCorridorClassic || shortBlowOffTop;

  const inCorridor = inLongCorridor || inShortCorridor;

  // Determine side based on which corridor we're in
  let side = null;
  if (inLongCorridor && (alignedLong || longPullbackSetup)) {
    side = "LONG";
  } else if (inShortCorridor) {
    side = "SHORT";
  }

  // For LONG: allow aligned OR pullback setup
  // For SHORT: allow aligned OR blow-off top setup
  const corridorAlignedOK = 
    (side === "LONG" && (alignedLong || longPullbackSetup)) || 
    (side === "SHORT" && (alignedShort || shortBlowOffTop));

  if (!inCorridor || !corridorAlignedOK) return false;
  
  // Log gold standard match for debugging
  const gsLong = matchesGoldStandardLong(tickerData);
  const gsShort = matchesGoldStandardShort(tickerData);
  if (gsLong.match || gsShort.match) {
    console.log(`[GOLD_STANDARD] ${tickerUpper} side=${side} gsLong=${gsLong.score} gsShort=${gsShort.score} state=${state} htf=${h} ltf=${l}`);
  }

  // Check for trigger conditions
  const enteredAligned = prevData && prevData.state !== state && aligned;
  const prevH = prevData ? Number(prevData.htf_score) : NaN;
  const prevL = prevData ? Number(prevData.ltf_score) : NaN;
  const prevInCorridor =
    Number.isFinite(prevH) &&
    Number.isFinite(prevL) &&
    ((prevH > 0 && prevL >= -10 && prevL <= 22) ||
      (prevH < 0 && prevL >= -12 && prevL <= 10));
  const justEnteredCorridor = !!prevData && !prevInCorridor && inCorridor;
  const trigReason = String(tickerData.trigger_reason || "");
  const trigOk = trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");
  const sqRelease = !!flags.sq30_release;

  const shouldConsiderAlert =
    inCorridor &&
    corridorAlignedOK &&
    (justEnteredCorridor || enteredAligned || trigOk || sqRelease || flipWatch);

  const momentumElite = !!flags.momentum_elite;
  // Phase 1c: tightened thresholds from testing mode to production swing-trading gates
  const baseMinRR = 1.5;   // Phase 1c: up from 0.3 (testing) to proper swing RR
  const baseMaxComp = 0.60; // Phase 1c: down from 0.8 to 0.60 — enter earlier
  const baseMaxPhase = 0.70; // Phase 1c: down from 0.85 to 0.70 — avoid extremes
  const minRR = momentumElite ? Math.max(1.0, baseMinRR * 0.8) : baseMinRR;
  const maxComp = flipWatch || sqRelease
    ? Math.min(0.75, baseMaxComp * 1.2)
    : momentumElite
      ? Math.min(0.70, baseMaxComp * 1.1)
      : baseMaxComp;
  const maxPhase = momentumElite
    ? Math.min(0.80, baseMaxPhase * 1.15)
    : baseMaxPhase;

  // Relaxed rank threshold for testing (will tighten after validating exit system)
  const rank = Number(tickerData.rank ?? tickerData.rank_position ?? tickerData.position) || 0;
  const minRank = momentumElite ? 40 : 50;
  const rankOk = rank >= minRank;

  const rr = Number(tickerData.rr) || 0;
  const compRaw = completionForSize(tickerData);
  const compToMax = computeCompletionToTpMax(tickerData);
  const comp = Number.isFinite(compToMax) ? compToMax : compRaw;
  const phase = Number(tickerData.phase_pct) || 0;

  const rrOk = rr >= minRR;
  const compOk = comp <= maxComp;
  const phaseOk = phase <= maxPhase;

  const momentumEliteTrigger =
    momentumElite &&
    inCorridor &&
    corridorAlignedOK &&
    (trigOk || sqRelease || flipWatch || justEnteredCorridor);
  const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

  // Don't enter if the move has already invalidated/completed
  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  if (ms && (ms.status === "INVALIDATED" || ms.status === "COMPLETED"))
    return false;

  // Phase 1/3 gates applied to simulation entries too.
  const inferredSide = side || sideFromStateOrScores(tickerData);
  if (!dailyEmaRegimeOk(tickerData, inferredSide)) return false;
  if (!ichimokuRegimeOk(tickerData, inferredSide)) return false;
  if (isLateCycle(tickerData) && !momentumElite) return false;
  // Fresh trigger: pullback→re-align, squeeze release, flip_watch, or just entered corridor (market moved in).
  const prevStateStr = prevData ? String(prevData.state || "") : "";
  const enteredFromPullback =
    !!enteredAligned && prevStateStr.includes("PULLBACK");
  const freshPullbackOk =
    enteredFromPullback ||
    sqRelease ||
    (trigReason === "SQUEEZE_RELEASE" || trigReason.includes("SQUEEZE_RELEASE")) ||
    (trigReason.includes("EMA_CROSS")) ||
    flipWatch ||
    justEnteredCorridor;
  if (!freshPullbackOk) return false;

  return enhancedTrigger && rrOk && compOk && phaseOk && rankOk;
}

// Debug: return blockers for trade entry (same logic as shouldTriggerTradeSimulation)
function getEntryBlockers(ticker, tickerData, prevData) {
  const blockers = [];
  const tickerUpper = String(ticker || "").toUpperCase();
  if (FUTURES_TICKERS.has(tickerUpper)) return ["futures_disabled"];

  const slVal = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
  const tpVal = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
  if (!tickerData.price || !Number.isFinite(slVal) || slVal <= 0 || !Number.isFinite(tpVal) || tpVal <= 0) {
    blockers.push("missing_levels");
    return blockers;
  }

  const flags = tickerData.flags || {};
  const flipWatch = !!flags.flip_watch;
  const state = String(tickerData.state || "");
  const alignedLong = state === "HTF_BULL_LTF_BULL";
  const alignedShort = state === "HTF_BEAR_LTF_BEAR";
  const aligned = alignedLong || alignedShort;
  const h = Number(tickerData.htf_score);
  const l = Number(tickerData.ltf_score);

  // GOLD STANDARD: Direction-specific corridor logic
  const longCorridorClassic = h > 0 && l >= -10 && l <= 22;
  const longPullbackSetup = state === "HTF_BULL_LTF_PULLBACK" && h >= 10 && l >= -15 && l <= 5;
  const inLongCorridor = longCorridorClassic || longPullbackSetup;
  
  const shortCorridorClassic = h < 0 && l >= -12 && l <= 10;
  const shortBlowOffTop = state === "HTF_BULL_LTF_BULL" && h >= 25 && l >= 15;
  const inShortCorridor = shortCorridorClassic || shortBlowOffTop;
  
  const inCorridor = inLongCorridor || inShortCorridor;
  
  let side = null;
  if (inLongCorridor && (alignedLong || longPullbackSetup)) side = "LONG";
  else if (inShortCorridor) side = "SHORT";
  
  const corridorAlignedOK = 
    (side === "LONG" && (alignedLong || longPullbackSetup)) || 
    (side === "SHORT" && (alignedShort || shortBlowOffTop));

  if (!inCorridor) blockers.push("not_in_corridor");
  if (inCorridor && !corridorAlignedOK) blockers.push("corridor_misaligned");
  
  // Add gold standard info for debugging
  const gsLong = matchesGoldStandardLong(tickerData);
  const gsShort = matchesGoldStandardShort(tickerData);
  if (gsLong.match) blockers.push(`gs_long_match(${gsLong.score})`);
  if (gsShort.match) blockers.push(`gs_short_match(${gsShort.score})`);

  const prevH = prevData ? Number(prevData.htf_score) : NaN;
  const prevL = prevData ? Number(prevData.ltf_score) : NaN;
  const prevInCorridor = Number.isFinite(prevH) && Number.isFinite(prevL) &&
    ((prevH > 0 && prevL >= -10 && prevL <= 22) || (prevH < 0 && prevL >= -12 && prevL <= 10));
  const justEnteredCorridor = !!prevData && !prevInCorridor && inCorridor;
  const trigReason = String(tickerData.trigger_reason || "");
  const trigOk = trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");
  const sqRelease = !!flags.sq30_release;
  const enteredAligned = prevData && prevData.state !== state && aligned;

  const shouldConsiderAlert = inCorridor && corridorAlignedOK &&
    (justEnteredCorridor || enteredAligned || trigOk || sqRelease || flipWatch);
  const momentumElite = !!flags.momentum_elite;
  const momentumEliteTrigger = momentumElite && inCorridor && corridorAlignedOK &&
    (trigOk || sqRelease || flipWatch || justEnteredCorridor);
  const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

  // Phase 1c: tightened thresholds for swing trading
  const rank = Number(tickerData.rank ?? tickerData.rank_position ?? tickerData.position) || 0;
  const minRank = momentumElite ? 40 : 50;
  if (rank < minRank) blockers.push(`rank_below_min(${rank}<${minRank})`);

  const rr = Number(tickerData.rr) || 0;
  const minRR = momentumElite ? Math.max(1.0, 1.5 * 0.8) : 1.5;
  if (rr < minRR) blockers.push(`rr_below_min(${rr?.toFixed(2)}<${minRR})`);

  const compRaw = completionForSize(tickerData);
  const compToMax = computeCompletionToTpMax(tickerData);
  const comp = Number.isFinite(compToMax) ? compToMax : compRaw;
  const maxComp = flipWatch || sqRelease ? 0.75 : momentumElite ? 0.70 : 0.60;
  if (comp > maxComp) blockers.push(`completion_high(${(comp*100).toFixed(0)}%>${(maxComp*100).toFixed(0)}%)`);

  const phase = Number(tickerData.phase_pct) || 0;
  const maxPhase = momentumElite ? 0.80 : 0.70;
  if (phase > maxPhase) blockers.push(`phase_high(${(phase*100).toFixed(0)}%>${(maxPhase*100).toFixed(0)}%)`);

  // Phase 1a: Entry quality gate
  const eqScore = Number(tickerData?.entry_quality?.score) || 0;
  if (eqScore > 0 && eqScore < 50) blockers.push(`entry_quality_low(${eqScore})`);

  // Phase 1c: RSI exhaustion block
  const rsi1HDebug = Number(tickerData?.entry_quality?.details?.rsi1H) || 50;
  const debugSide = sideFromStateOrScores(tickerData);
  if (debugSide === "LONG" && rsi1HDebug > 72) blockers.push(`rsi_1h_overbought(${rsi1HDebug.toFixed(0)})`);
  if (debugSide === "SHORT" && rsi1HDebug < 28) blockers.push(`rsi_1h_oversold(${rsi1HDebug.toFixed(0)})`);

  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  if (ms?.status === "INVALIDATED") blockers.push("move_invalidated");
  if (ms?.status === "COMPLETED") blockers.push("move_completed");

  const inferredSide = side || sideFromStateOrScores(tickerData);
  if (!dailyEmaRegimeOk(tickerData, inferredSide)) blockers.push("htf_regime_gate");
  if (!ichimokuRegimeOk(tickerData, inferredSide)) blockers.push("ichimoku_regime_gate");
  if (isLateCycle(tickerData) && !momentumElite) blockers.push("late_cycle");

  const prevStateStr = prevData ? String(prevData.state || "") : "";
  const enteredFromPullback = !!enteredAligned && prevStateStr.includes("PULLBACK");
  const freshPullbackOk = enteredFromPullback || sqRelease ||
    (trigReason === "SQUEEZE_RELEASE" || trigReason.includes("SQUEEZE_RELEASE")) ||
    trigReason.includes("EMA_CROSS") || flipWatch || justEnteredCorridor;
  if (!freshPullbackOk) blockers.push("no_fresh_pullback");

  if (!enhancedTrigger) blockers.push("no_enhanced_trigger");

  return blockers;
}

function isOpenTradeStatus(status) {
  const s = String(status || "").toUpperCase();
  return s === "OPEN" || s === "TP_HIT_TRIM" || !s;
}

async function findOpenTradeForTicker(KV, ticker, direction = null) {
  const trades = (await kvGetJSON(KV, "timed:trades:all")) || [];
  const t = String(ticker || "").toUpperCase();
  const dir = direction ? String(direction).toUpperCase() : null;
  return (
    trades.find((trade) => {
      if (!trade) return false;
      if (String(trade.ticker || "").toUpperCase() !== t) return false;
      if (dir && String(trade.direction || "").toUpperCase() !== dir)
        return false;
      return isOpenTradeStatus(trade.status);
    }) || null
  );
}

async function checkIngestCoverage(KV, now = new Date()) {
  if (!isMarketHoursET(now)) return { ok: true, skipped: true };
  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
  const missing = [];
  const maxAgeMin = 10;

  for (const ticker of tickers) {
    if (marketType(ticker) !== "EQUITY_RTH") continue;
    const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
    const lastTsRaw = latest?.ingest_ts ?? latest?.ts ?? null;
    const lastTs = Number(lastTsRaw);
    const ageMin = Number.isFinite(lastTs)
      ? (now.getTime() - lastTs) / 60000
      : null;

    if (!Number.isFinite(ageMin) || ageMin > maxAgeMin) {
      missing.push({
        ticker: String(ticker).toUpperCase(),
        ageMin,
        lastTs,
        state: latest?.state,
        rank: latest?.rank,
        price: latest?.price,
      });
      const missKey = `timed:ingest:missing:${String(ticker).toUpperCase()}`;
      const already = await KV.get(missKey);
      if (!already) {
        await kvPutText(KV, missKey, "1", 60 * 60);
        await appendActivity(KV, {
          type: "ingest_missing",
          ticker: String(ticker).toUpperCase(),
          action: "missing_ingest",
          age_min: Number.isFinite(ageMin) ? Math.round(ageMin) : null,
          last_ingest_ts: Number.isFinite(lastTs) ? lastTs : null,
          state: latest?.state,
          rank: latest?.rank,
          price: latest?.price,
        });
      }
    } else {
      const missKey = `timed:ingest:missing:${String(ticker).toUpperCase()}`;
      await KV.delete(missKey);
    }
  }

  return { ok: true, missing, checked: tickers.length };
}

function buildEntryDecision(ticker, tickerData, prevState) {
  const tickerUpper = String(ticker || "").toUpperCase();
  const blockers = [];
  const warnings = [];
  const flags = tickerData.flags || {};
  const flipWatch = !!flags.flip_watch;
  const state = String(tickerData.state || "");

  const alignedLong = state === "HTF_BULL_LTF_BULL";
  const alignedShort = state === "HTF_BEAR_LTF_BEAR";
  const aligned = alignedLong || alignedShort;

  const h = Number(tickerData.htf_score);
  const l = Number(tickerData.ltf_score);
  const inCorridor =
    Number.isFinite(h) &&
    Number.isFinite(l) &&
    ((h > 0 && l >= -10 && l <= 22) || (h < 0 && l >= -12 && l <= 10));
  const side =
    h > 0 && l >= -10 && l <= 22
      ? "LONG"
      : h < 0 && l >= -12 && l <= 10
        ? "SHORT"
        : null;
  const corridorAlignedOK =
    (side === "LONG" && alignedLong) || (side === "SHORT" && alignedShort);

  const enteredAligned = aligned && prevState && prevState !== state;
  const trigReason = String(tickerData.trigger_reason || "");
  const trigOk = trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");
  const sqRelease = !!flags.sq30_release;
  // Note: do NOT treat mere presence of trigger_price/trigger_ts as a trigger.
  // Many payloads include those fields continuously, causing over-trading.
  const hasTrigger = false;

  const shouldConsiderAlert =
    inCorridor &&
    corridorAlignedOK &&
    (enteredAligned || trigOk || sqRelease || hasTrigger);

  const momentumElite = !!flags.momentum_elite;
  const baseMinRR = 1.2;
  const baseMaxComp = 0.5;
  const baseMaxPhase = 0.65;
  const minRR = momentumElite ? Math.max(1.0, baseMinRR * 0.9) : baseMinRR;
  const maxComp = flipWatch || sqRelease
    ? Math.min(0.6, baseMaxComp * 1.2)
    : momentumElite
      ? Math.min(0.55, baseMaxComp * 1.1)
      : baseMaxComp;
  const maxPhase = momentumElite
    ? Math.min(0.75, baseMaxPhase * 1.15)
    : baseMaxPhase;

  const price = Number(tickerData.price);
  const triggerPrice = Number(tickerData.trigger_price);
  const entryPrice =
    Number.isFinite(price) && price > 0
      ? price
      : Number.isFinite(triggerPrice) && triggerPrice > 0
        ? triggerPrice
        : null;
  const entryPriceSource =
    Number.isFinite(price) && price > 0
      ? "price"
      : Number.isFinite(triggerPrice) && triggerPrice > 0
        ? "trigger_price"
        : null;

  // Normalize sl/tp from alternate field names (payloads may vary)
  const slVal = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
  const tpVal = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
  if (Number.isFinite(slVal) && tickerData.sl == null) tickerData.sl = slVal;
  if (Number.isFinite(tpVal) && tickerData.tp == null) tickerData.tp = tpVal;

  const hasLevels = Number.isFinite(slVal) && slVal > 0 && Number.isFinite(tpVal) && tpVal > 0;
  const rrAtEntry =
    entryPrice != null ? calculateRRAtEntry(tickerData, entryPrice) : null;
  const compRaw = completionForSize(tickerData);
  const compToMax = computeCompletionToTpMax(tickerData);
  const comp = Number.isFinite(compToMax) ? compToMax : compRaw;
  const phase = Number(tickerData.phase_pct) || 0;

  const rrOk =
    (rrAtEntry != null && Number.isFinite(rrAtEntry))
      ? rrAtEntry >= minRR
      : (hasLevels && entryPrice != null);
  const compOk = comp <= maxComp;
  const phaseOk = phase <= maxPhase;

  const rank = Number(tickerData.rank ?? tickerData.rank_position ?? tickerData.position) || 0;
  const minRank = momentumElite ? 60 : 70;
  const rankOk = rank >= minRank;

  if (FUTURES_TICKERS.has(tickerUpper)) blockers.push("futures_disabled");
  if (!Number.isFinite(entryPrice) || !hasLevels)
    blockers.push("missing_levels");
  if (!inCorridor) blockers.push("not_in_corridor");
  if (inCorridor && !corridorAlignedOK) blockers.push("corridor_misaligned");
  if (!shouldConsiderAlert) blockers.push("no_trigger");

  // Move invalidation/completion gate (don't suggest entries on broken/done moves)
  const ms = tickerData?.move_status || computeMoveStatus(tickerData);
  if (ms && ms.status === "INVALIDATED") blockers.push("move_invalidated");
  if (ms && ms.status === "COMPLETED") blockers.push("move_completed");

  // Phase 1: HTF regime gate + late-cycle disqualifier + pullback-only entry constraint
  const inferredSide = side || sideFromStateOrScores(tickerData);
  if (!dailyEmaRegimeOk(tickerData, inferredSide))
    blockers.push("htf_regime_gate");
  if (!ichimokuRegimeOk(tickerData, inferredSide))
    blockers.push("ichimoku_regime_gate");

  const lateCycle = isLateCycle(tickerData);
  if (lateCycle && !momentumElite) blockers.push("late_cycle");
  else if (lateCycle && momentumElite) warnings.push("late_cycle");

  // Pullback-only entry: require a pullback→re-alignment transition OR a squeeze release OR flip_watch.
  const enteredFromPullback =
    !!enteredAligned && String(prevState || "").includes("PULLBACK");
  const freshPullbackOk =
    enteredFromPullback || sqRelease || trigReason === "SQUEEZE_RELEASE" ||
    trigReason.includes("SQUEEZE_RELEASE") || trigReason.includes("EMA_CROSS") || flipWatch;
  if (!freshPullbackOk) blockers.push("no_fresh_pullback");

  if (!rankOk) blockers.push("rank_below_min");
  if (!rrOk) blockers.push("rr_below_min");
  if (!compOk) blockers.push("completion_high");
  if (!phaseOk) blockers.push("phase_high");

  const staleness = String(tickerData.staleness || "").toUpperCase();
  if (staleness && staleness !== "FRESH") warnings.push("stale_data");

  return {
    ok: blockers.length === 0,
    action: "ENTRY",
    side: side || (alignedLong ? "LONG" : alignedShort ? "SHORT" : null),
    blockers,
    warnings,
    entry_price: entryPrice,
    entry_price_source: entryPriceSource,
    checks: {
      aligned,
      in_corridor: inCorridor,
      corridor_aligned: corridorAlignedOK,
      entered_aligned: enteredAligned,
      trigger_ok: trigOk,
      squeeze_release: sqRelease,
      has_trigger: hasTrigger,
      rank,
      rank_min: minRank,
      rr_at_entry: rrAtEntry,
      rr_min: minRR,
      completion: comp,
      completion_max: maxComp,
      phase,
      phase_max: maxPhase,
    },
  };
}

function computeTradePnlComponents(trade, tickerData) {
  const direction = String(trade?.direction || "").toUpperCase();
  const isLong = direction === "LONG";
  const entryPrice = Number(trade?.entryPrice);
  const currentPrice = Number(tickerData?.price ?? trade?.currentPrice);
  const shares = Number(trade?.shares);
  const pointValue = Number(trade?.pointValue) || 1;
  const trimmedPct = clamp(Number(trade?.trimmedPct || 0), 0, 1);
  const remainingPct = Math.max(0, 1 - trimmedPct);
  if (
    !Number.isFinite(entryPrice) ||
    !Number.isFinite(currentPrice) ||
    !Number.isFinite(shares)
  ) {
    return {
      pnl: null,
      pnlPct: null,
      realized: Number(trade?.realizedPnl || 0) || 0,
      unrealized: null,
    };
  }
  const dirSign = isLong ? 1 : -1;
  const unrealized =
    (currentPrice - entryPrice) * shares * pointValue * remainingPct * dirSign;
  const realized = Number(trade?.realizedPnl || 0) || 0;
  const pnl = realized + unrealized;
  const notional =
    Number(trade?.notional) ||
    (Number.isFinite(entryPrice) ? entryPrice * shares : null);
  const pnlPct =
    Number.isFinite(notional) && notional !== 0 ? (pnl / notional) * 100 : null;
  return { pnl, pnlPct, realized, unrealized };
}

// Helper: Score TP level for intelligent selection
function scoreTPLevel(tpLevel, entryPrice, direction, allTPs, horizonConfig) {
  const isLong = direction === "LONG";
  const price = Number(tpLevel.price || tpLevel);

  // Base score from confidence (0.60-0.85, normalize to 0-1)
  const confidence = Number(tpLevel.confidence || 0.75);
  let score = (confidence - 0.6) / (0.85 - 0.6); // Normalize to 0-1

  // Timeframe priority: Weekly > Daily > 4H
  const tf = String(tpLevel.timeframe || "D").toUpperCase();
  if (tf === "W") score += 0.3;
  else if (tf === "D") score += 0.2;
  else if (tf === "240" || tf === "4H") score += 0.1;

  // Type priority: STRUCTURE > ATR_FIB > LIQUIDITY > FVG > GAP
  const type = String(tpLevel.type || "ATR_FIB").toUpperCase();
  if (type === "STRUCTURE") score += 0.25;
  else if (type === "ATR_FIB") {
    // Boost key Fibonacci levels (61.8%, 100%, 161.8%)
    const mult = Number(tpLevel.multiplier || 0);
    if (mult === 0.618 || mult === 1.0 || mult === 1.618) score += 0.2;
    else if (mult === 0.382 || mult === 0.786 || mult === 1.236) score += 0.15;
    else score += 0.1;
  } else if (type === "LIQUIDITY") score += 0.15;
  else if (type === "FVG") score += 0.1;
  else if (type === "GAP") score += 0.05;

  // Distance from entry (use horizon-aware bands)
  const distancePct = Math.abs(price - entryPrice) / entryPrice;
  const bands = horizonConfig || {};
  const sweetMin = Number(bands.sweetMin ?? 0.02);
  const sweetMax = Number(bands.sweetMax ?? 0.05);
  const okMin = Number(bands.okMin ?? 0.01);
  const okMax = Number(bands.okMax ?? 0.08);
  const minDist = Number(bands.minDistancePct ?? 0.01);
  const tooFar = Number(bands.tooFarPct ?? 0.15);

  if (distancePct >= sweetMin && distancePct <= sweetMax) {
    score += 0.2; // Sweet spot
  } else if (distancePct >= okMin && distancePct <= okMax) {
    score += 0.1; // Acceptable range
  } else if (distancePct < minDist) {
    score -= 0.2; // Too close - penalize
  } else if (distancePct > tooFar) {
    score -= 0.1; // Too far - slight penalty
  }

  // Clustering penalty: if many TPs are very close, prefer ones that stand out
  const clusteringThreshold = entryPrice * 0.005; // 0.5% clustering threshold
  const nearbyTPs = allTPs.filter((tp) => {
    const tpPrice = Number(tp.price || tp);
    return Math.abs(tpPrice - price) < clusteringThreshold;
  }).length;

  if (nearbyTPs > 3) {
    score -= 0.15; // Heavy clustering penalty
  } else if (nearbyTPs > 1) {
    score -= 0.05; // Light clustering penalty
  }

  return score;
}

// Helper: Fuse many TP candidates into a few "confluence" TP zones.
// We cluster nearby TPs and return weighted centroids (still direction-safe).
function fuseTPCandidates(
  tpCandidates,
  entryPrice,
  direction,
  risk,
  horizonConfig,
) {
  if (!Array.isArray(tpCandidates) || tpCandidates.length === 0) return [];
  const isLong = direction === "LONG";

  // Cluster distance: a blend of % of entry and fraction of risk.
  // This keeps clustering stable across different price ranges.
  const clusterAbs = Math.max(entryPrice * 0.003, (Number(risk) || 0) * 0.25); // ~0.3% or 0.25R

  const items = tpCandidates
    .map((tp) => {
      const price = Number(tp?.price);
      if (!Number.isFinite(price) || price <= 0) return null;
      return { ...tp, price };
    })
    .filter(Boolean)
    .sort((a, b) => a.price - b.price);

  const tfPriority = (tf) => {
    const t = String(tf || "D").toUpperCase();
    if (t === "W") return 3;
    if (t === "D") return 2;
    if (t === "240" || t === "4H") return 1;
    return 0;
  };

  const clusters = [];
  for (const tp of items) {
    const s = scoreTPLevel(tp, entryPrice, direction, items, horizonConfig);
    const w = Math.max(0.1, 1 + s); // keep weights positive
    const last = clusters[clusters.length - 1];
    if (!last) {
      clusters.push({
        items: [{ tp, s, w }],
        min: tp.price,
        max: tp.price,
        sumW: w,
        sumWP: w * tp.price,
      });
      continue;
    }

    // Add to cluster if close to its current centroid (or within min/max band)
    const centroid = last.sumWP / Math.max(1e-9, last.sumW);
    const closeToCentroid = Math.abs(tp.price - centroid) <= clusterAbs;
    const closeToBand =
      tp.price >= last.min - clusterAbs && tp.price <= last.max + clusterAbs;

    if (closeToCentroid || closeToBand) {
      last.items.push({ tp, s, w });
      last.min = Math.min(last.min, tp.price);
      last.max = Math.max(last.max, tp.price);
      last.sumW += w;
      last.sumWP += w * tp.price;
    } else {
      clusters.push({
        items: [{ tp, s, w }],
        min: tp.price,
        max: tp.price,
        sumW: w,
        sumWP: w * tp.price,
      });
    }
  }

  const fused = clusters
    .map((c, idx) => {
      const price = c.sumWP / Math.max(1e-9, c.sumW);
      // Direction safety: ignore clusters that ended up on wrong side (paranoia)
      if (isLong && price <= entryPrice) return null;
      if (!isLong && price >= entryPrice) return null;

      const bestTf = c.items
        .map((x) => x.tp?.timeframe)
        .sort((a, b) => tfPriority(b) - tfPriority(a))[0];

      const confidences = c.items
        .map((x) => Number(x.tp?.confidence))
        .filter((n) => Number.isFinite(n));
      const confidence =
        confidences.length > 0
          ? Math.max(...confidences) // prefer the strongest member
          : 0.75;

      const sources = Array.from(
        new Set(
          c.items.map((x) => String(x.tp?.source || "").trim()).filter(Boolean),
        ),
      );
      const types = Array.from(
        new Set(
          c.items.map((x) => String(x.tp?.type || "").trim()).filter(Boolean),
        ),
      );

      // Confluence score: sum of member scores + small boost for multiple confirmations,
      // and a light penalty for a very wide cluster.
      const sumScore = c.items.reduce((acc, x) => acc + (x.s || 0), 0);
      const confluenceBoost = 0.2 * Math.log(1 + c.items.length);
      const spreadPct = (c.max - c.min) / Math.max(1e-9, entryPrice);
      const spreadPenalty = Math.min(0.2, spreadPct * 2); // cap penalty
      const fusedScore = sumScore + confluenceBoost - spreadPenalty;

      return {
        price,
        source:
          sources.length > 0
            ? `FUSED(${c.items.length}): ${sources.slice(0, 2).join(", ")}`
            : `FUSED(${c.items.length})`,
        type:
          types.length > 0 ? `FUSED:${types.slice(0, 2).join(",")}` : "FUSED",
        timeframe: bestTf || "D",
        confidence,
        multiplier: null,
        label: `TP_FUSED_${idx + 1}`,
        _fused: {
          idx,
          count: c.items.length,
          min: c.min,
          max: c.max,
          score: fusedScore,
        },
      };
    })
    .filter(Boolean)
    .sort((a, b) => (b._fused?.score || 0) - (a._fused?.score || 0));

  return fused;
}

// ─────────────────────────────────────────────────────────────────────────────
// GOLD STANDARD PATTERNS (from historical movers analysis)
// ─────────────────────────────────────────────────────────────────────────────
// Derived from 637 significant moves (331 UP, 306 DOWN) across 160 tickers.
// These patterns identify the optimal entry conditions for LONG vs SHORT.
const GOLD_STANDARD_PATTERNS = {
  // LONG ENTRIES (from 331 UP moves, median +5.94%, P90 +15.19%)
  // Primary setup: HTF_BULL_LTF_PULLBACK (67.7% of big up moves started here)
  // Key insight: Buy the pullback when HTF is bullish but LTF has dipped
  LONG: {
    // Optimal state at entry (in order of preference)
    preferredStates: ["HTF_BULL_LTF_PULLBACK", "HTF_BEAR_LTF_BEAR", "HTF_BULL_LTF_BULL"],
    stateWeights: { HTF_BULL_LTF_PULLBACK: 1.0, HTF_BEAR_LTF_BEAR: 0.5, HTF_BULL_LTF_BULL: 0.4 },
    // Score thresholds at move start (from historical analysis)
    htf: { min: 10, optimal: 20, max: 50 },    // Median at start: +20, Avg: +16
    ltf: { min: -25, optimal: -9, max: 5 },    // Median at start: -9 (in pullback)
    // Corridor (LTF range for entry)
    corridor: { min: -15, max: 10 },           // Wider than SHORT; catch pullbacks
    // Pre-move signal frequency (for scoring)
    signals: {
      ltfPullback: 0.843,      // 84.3% of winners had LTF in pullback
      stateTransition: 0.366,  // 36.6% had state change before move
      htfImproving: 0.341,     // 34.1% had HTF momentum improving
      squeezeOn: 0.218,        // 21.8% had squeeze active (coiling)
      flipWatch: 0.163,        // 16.3% had flip watch
      stFlip: 0.118,           // 11.8% had ST flip
      squeezeRelease: 0.088,   // 8.8% had squeeze release
    },
    // Move statistics (for TP calibration)
    moveStats: { median: 5.94, p75: 9.5, p90: 15.19, avg: 8.17 },
    // TP multipliers (widened to let winners run — old: 0.6/1.0/1.5)
    tpMultipliers: { trim: 1.5, exit: 2.5, runner: 4.0 },
  },

  // SHORT ENTRIES (from 306 DOWN moves, median -6.34%)
  // CRITICAL: 82.7% started from HTF_BULL_LTF_BULL (overextended momentum!)
  // Key insight: SHORT the blow-off top, NOT the bearish setup
  SHORT: {
    // Optimal state at entry - COUNTER-INTUITIVE!
    preferredStates: ["HTF_BULL_LTF_BULL", "HTF_BEAR_LTF_PULLBACK", "HTF_BULL_LTF_PULLBACK"],
    stateWeights: { HTF_BULL_LTF_BULL: 1.0, HTF_BEAR_LTF_PULLBACK: 0.3, HTF_BULL_LTF_PULLBACK: 0.2 },
    // Score thresholds at move start (BOTH positive = overextended)
    htf: { min: 20, optimal: 28, max: 50 },    // Median at start: +28 (strongly bullish!)
    ltf: { min: 10, optimal: 19, max: 35 },    // Median at start: +19 (also strong)
    // Corridor (LTF range for SHORT entry) - HIGH values indicate blow-off top
    corridor: { min: 12, max: 35 },            // Both HTF and LTF must be strong
    // Pre-move signal frequency
    signals: {
      ltfPullback: 0.905,      // 90.5% (note: "pullback" here means LTF was positive)
      stateTransition: 0.373,  // 37.3% had state change
      htfImproving: 0.359,     // 35.9% had HTF still improving (!)
      stFlip: 0.180,           // 18.0% had ST flip
      squeezeOn: 0.196,        // 19.6% had squeeze
      momentumElite: 0.144,    // 14.4% had momentum elite
    },
    // Move statistics (for TP calibration)
    moveStats: { median: 6.34, p75: 10.5, p90: 18.0, avg: 9.61 },
    // TP multipliers (widened to let winners run — old: 0.6/1.0/1.618)
    tpMultipliers: { trim: 1.5, exit: 2.5, runner: 4.0 },
  },
};

// Helper: Check if ticker matches gold standard LONG pattern
function matchesGoldStandardLong(tickerData) {
  const state = String(tickerData?.state || "");
  const htf = Number(tickerData?.htf_score);
  const ltf = Number(tickerData?.ltf_score);
  const flags = tickerData?.flags || {};
  const gs = GOLD_STANDARD_PATTERNS.LONG;

  // Must have valid scores
  if (!Number.isFinite(htf) || !Number.isFinite(ltf)) return { match: false, score: 0 };

  let score = 0;
  const reasons = [];

  // State matching (primary criterion)
  if (gs.preferredStates.includes(state)) {
    score += gs.stateWeights[state] * 30;
    reasons.push(`state:${state}`);
  }

  // HTF in optimal range
  if (htf >= gs.htf.min && htf <= gs.htf.max) {
    const htfScore = htf >= gs.htf.optimal ? 25 : 15;
    score += htfScore;
    reasons.push(`htf:${htf.toFixed(1)}`);
  }

  // LTF in pullback (negative or low) - KEY for LONG
  if (ltf >= gs.ltf.min && ltf <= gs.ltf.max) {
    // Closer to optimal (-9) = higher score
    const ltfDist = Math.abs(ltf - gs.ltf.optimal);
    const ltfScore = Math.max(0, 25 - ltfDist);
    score += ltfScore;
    reasons.push(`ltf:${ltf.toFixed(1)}`);
  }

  // Signal bonuses
  if (flags.sq30_release) { score += 10; reasons.push("squeeze_release"); }
  if (flags.flip_watch) { score += 8; reasons.push("flip_watch"); }
  if (flags.momentum_elite && htf >= 15) { score += 5; reasons.push("momentum_elite"); }

  return { match: score >= 50, score, reasons };
}

// Helper: Check if ticker matches gold standard SHORT pattern (blow-off top)
function matchesGoldStandardShort(tickerData) {
  const state = String(tickerData?.state || "");
  const htf = Number(tickerData?.htf_score);
  const ltf = Number(tickerData?.ltf_score);
  const flags = tickerData?.flags || {};
  const gs = GOLD_STANDARD_PATTERNS.SHORT;

  // Must have valid scores
  if (!Number.isFinite(htf) || !Number.isFinite(ltf)) return { match: false, score: 0 };

  let score = 0;
  const reasons = [];

  // State matching - CRITICAL: look for HTF_BULL_LTF_BULL (blow-off top)
  if (gs.preferredStates.includes(state)) {
    score += gs.stateWeights[state] * 30;
    reasons.push(`state:${state}`);
  }

  // HTF must be STRONGLY POSITIVE for short (overextended)
  if (htf >= gs.htf.min && htf <= gs.htf.max) {
    // Higher HTF = stronger blow-off signal
    const htfScore = htf >= gs.htf.optimal ? 25 : 15;
    score += htfScore;
    reasons.push(`htf:${htf.toFixed(1)}`);
  }

  // LTF must also be POSITIVE (both overextended = blow-off top)
  if (ltf >= gs.ltf.min && ltf <= gs.ltf.max) {
    // Closer to optimal (+19) = higher score
    const ltfDist = Math.abs(ltf - gs.ltf.optimal);
    const ltfScore = Math.max(0, 25 - ltfDist);
    score += ltfScore;
    reasons.push(`ltf:${ltf.toFixed(1)}`);
  }

  // Additional blow-off indicators
  const completion = Number(tickerData?.completion) || 0;
  const phase = Number(tickerData?.phase_pct) || 0;
  if (completion >= 0.7) { score += 10; reasons.push("high_completion"); }
  if (phase >= 0.6) { score += 8; reasons.push("high_phase"); }
  if (flags.st_flip_bear) { score += 12; reasons.push("st_flip_bear"); }

  return { match: score >= 50, score, reasons };
}

// ─────────────────────────────────────────────────────────────────────────────
// Direction-specific SL Adjustment Logic
// ─────────────────────────────────────────────────────────────────────────────
// Based on historical analysis:
// - LONG entries from pullback: tighter initial SL (smaller risk, higher RR)
// - SHORT entries from blow-off top: wider initial SL (allow volatility)
// 
// This function suggests SL adjustments based on direction and pattern confidence.
function computeDirectionAwareSL(tickerData, baseSL, direction, entryPrice) {
  const isLong = direction === "LONG";
  const gsMatch = isLong ? matchesGoldStandardLong(tickerData) : matchesGoldStandardShort(tickerData);
  
  // If not a gold standard match, return base SL unchanged
  if (!gsMatch.match) return { sl: baseSL, adjusted: false, reason: null };
  
  // Get ATR for SL calculations
  let atr = Number(tickerData?.atr);
  if (!Number.isFinite(atr) || atr <= 0) {
    atr = Math.abs(entryPrice - baseSL);  // Infer from existing SL
  }
  
  let adjustedSL = baseSL;
  let reason = null;
  
  if (isLong) {
    // LONG from pullback: SL must survive typical pullbacks
    // JOURNEY DATA (28 detailed journeys, 103 pullbacks):
    //   Pullback depth: P25=0.60%, Median=1.22%, P75=2.20%, P90=3.29%
    //   In ATR:         P25=1.53,  Median=2.53,  P75=4.52,  P90=6.18
    // SL at 1.5x ATR survives ~40% of pullbacks; 2.5x survives ~50%.
    // We want to survive most normal pullbacks but cut losses on breakdowns.
    if (gsMatch.score >= 70) {
      const adjusted = entryPrice - atr * 1.5;  // 1.5x ATR (was 0.65x) — above median pullback
      if (adjusted > baseSL && adjusted < entryPrice) {
        adjustedSL = adjusted;
        reason = `GS_LONG_TIGHT_SL(score=${gsMatch.score},1.5ATR)`;
      }
    } else if (gsMatch.score >= 50) {
      // Medium confidence: wider buffer at 2.0x ATR
      const adjusted = entryPrice - atr * 2.0;  // 2.0x ATR (was 0.8x)
      if (adjusted > baseSL && adjusted < entryPrice) {
        adjustedSL = adjusted;
        reason = `GS_LONG_MED_SL(score=${gsMatch.score},2.0ATR)`;
      }
    }
  } else {
    // SHORT from blow-off top: wider SL to handle volatility at tops
    // JOURNEY DATA: Short candidate pullbacks (against-move) can spike 2-4 ATR
    // before reversing. Need room for the initial squeeze.
    if (gsMatch.score >= 70) {
      const wider = entryPrice + atr * 1.8;  // 1.8x ATR (was 1.0x) — room for squeeze
      if (wider > entryPrice && (wider > baseSL || baseSL < entryPrice)) {
        adjustedSL = wider;
        reason = `GS_SHORT_SL(score=${gsMatch.score},1.8ATR)`;
      }
    }
  }
  
  return { 
    sl: adjustedSL, 
    adjusted: adjustedSL !== baseSL, 
    reason,
    gsScore: gsMatch.score,
    gsReasons: gsMatch.reasons
  };
}

// ─────────────────────────────────────────────────────────────────────────────
// 3-TIER TP SYSTEM CONFIGURATION
// ─────────────────────────────────────────────────────────────────────────────
// Instead of variable 4-5 TP levels with 10-25-50-100% trims, we normalize to
// exactly 3 tiers with fixed quantities and progressive SL trailing.
// NOTE: These are now direction-aware via GOLD_STANDARD_PATTERNS.tpMultipliers
const THREE_TIER_CONFIG = {
  // ATR multiplier ranges for each tier.
  // HISTORICAL MOVERS DATA (Feb 2026, 817 moves across 164 tickers):
  //   Median UP move: +8.34%, Median DOWN move: -6.81%
  //   Median duration: ~47 hours (2 trading days)
  //   Old TP1 at 0.6x ATR (~1.2%) was far too tight — avg winner was only 0.4%.
  //
  // WIDENED TIERS to let winners run closer to median move size:
  // TRIM at 1.5-2.5x ATR (~3%), EXIT at 2.5-4x ATR (~5%), RUNNER at 4-7x ATR (~8%).
  // Equal trim tranches (33/33/34) instead of front-loaded 50/25/25.
  TRIM:   { minMult: 1.5, maxMult: 2.5, trimPct: 0.33, label: "TRIM TP" },   // 33% off at 1.5-2.5x ATR
  EXIT:   { minMult: 2.5, maxMult: 4.0, trimPct: 0.66, label: "EXIT TP" },   // another 33% at 2.5-4x ATR
  RUNNER: { minMult: 4.0, maxMult: 7.0, trimPct: 1.0,  label: "RUNNER TP" }, // final 34% at 4-7x ATR
};

// Helper: Infer ATR from TP levels when not directly available
function inferAtrFromTPLevels(tickerData, entryPrice) {
  const tpLevels = tickerData?.tp_levels;
  if (!Array.isArray(tpLevels) || tpLevels.length === 0) return null;
  
  // Find a TP with a known multiplier to back-calculate ATR
  for (const tp of tpLevels) {
    const price = Number(typeof tp === "object" ? tp.price : tp);
    const mult = Number(typeof tp === "object" ? tp.multiplier : null);
    if (Number.isFinite(price) && Number.isFinite(mult) && mult > 0 && Number.isFinite(entryPrice)) {
      const distance = Math.abs(price - entryPrice);
      return distance / mult;
    }
  }
  
  // Fallback: estimate ATR as ~2% of entry price (typical for stocks)
  return Number.isFinite(entryPrice) ? entryPrice * 0.02 : null;
}

// Helper: Build 3-tier TP array with ATR-based selection
// Normalizes variable TP levels to exactly 3 tiers: TRIM (60%), EXIT (80%), RUNNER (100%)
function build3TierTPArray(tickerData, entryPrice, direction) {
  const isLong = direction === "LONG";
  const sl = Number(tickerData.sl);

  if (!Number.isFinite(entryPrice) || !Number.isFinite(sl)) {
    return [];
  }

  // ── PRECISION ENGINE: Use ATR Fibonacci level-based TPs if available ──
  // These are computed from daily ATR levels: TRIM=1.5x, EXIT=2.5x, RUNNER=4.0x
  const pTrim = Number(tickerData.tp_trim);
  const pExit = Number(tickerData.tp_exit);
  const pRunner = Number(tickerData.tp_runner);
  const hasPrecisionTPs = Number.isFinite(pTrim) && pTrim > 0 &&
                          Number.isFinite(pExit) && pExit > 0 &&
                          Number.isFinite(pRunner) && pRunner > 0;

  if (hasPrecisionTPs) {
    // Validate TPs are in the correct direction
    const trimValid = isLong ? pTrim > entryPrice : pTrim < entryPrice;
    const exitValid = isLong ? pExit > entryPrice : pExit < entryPrice;
    const runnerValid = isLong ? pRunner > entryPrice : pRunner < entryPrice;

    if (trimValid && exitValid && runnerValid) {
      const result = [
        {
          price: pTrim,
          trimPct: THREE_TIER_CONFIG.TRIM.trimPct,
          tier: "TRIM",
          label: `TRIM TP (${Math.round(THREE_TIER_CONFIG.TRIM.trimPct * 100)}%) @ 1.5x ATR`,
          source: "ATR Fibonacci (Daily 1.5x)",
          timeframe: "D",
          multiplier: 1.5,
        },
        {
          price: pExit,
          trimPct: THREE_TIER_CONFIG.EXIT.trimPct,
          tier: "EXIT",
          label: `EXIT TP (${Math.round(THREE_TIER_CONFIG.EXIT.trimPct * 100)}%) @ 2.5x ATR`,
          source: "ATR Fibonacci (Daily 2.5x)",
          timeframe: "D",
          multiplier: 2.5,
        },
        {
          price: pRunner,
          trimPct: THREE_TIER_CONFIG.RUNNER.trimPct,
          tier: "RUNNER",
          label: `RUNNER TP (${Math.round(THREE_TIER_CONFIG.RUNNER.trimPct * 100)}%) @ 4.0x ATR`,
          source: "ATR Fibonacci (Daily 4.0x)",
          timeframe: "D",
          multiplier: 4.0,
        },
      ];
      // Sort by distance from entry (closest first)
      result.sort((a, b) => Math.abs(a.price - entryPrice) - Math.abs(b.price - entryPrice));
      return result;
    }
  }

  // ── FALLBACK: Legacy TP computation (tp_levels / ATR multipliers) ──

  // Get ATR from ticker data or infer from TP levels
  let atr = Number(tickerData.atr);
  if (!Number.isFinite(atr) || atr <= 0) {
    atr = inferAtrFromTPLevels(tickerData, entryPrice);
  }
  if (!Number.isFinite(atr) || atr <= 0) {
    // Last resort: use distance to SL as ATR proxy
    atr = Math.abs(entryPrice - sl);
  }

  // Extract all TP levels with metadata
  let tpLevels = [];
  if (
    tickerData.tp_levels &&
    Array.isArray(tickerData.tp_levels) &&
    tickerData.tp_levels.length > 0
  ) {
    tpLevels = tickerData.tp_levels
      .map((tpItem) => {
        if (typeof tpItem === "object" && tpItem !== null) {
          const price = Number(tpItem.price);
          const mult = tpItem.multiplier ? Number(tpItem.multiplier) : null;
          // If no multiplier, calculate it from ATR
          const calculatedMult = Number.isFinite(mult) ? mult :
            (Number.isFinite(price) && Number.isFinite(atr) && atr > 0
              ? Math.abs(price - entryPrice) / atr
              : null);
          return {
            price,
            source: tpItem.source || "ATR Level",
            type: tpItem.type || "ATR_FIB",
            timeframe: tpItem.timeframe || "D",
            confidence: Number(tpItem.confidence || 0.75),
            multiplier: calculatedMult,
            label: tpItem.label || "TP",
          };
        }
        const price = Number(tpItem);
        const calculatedMult = Number.isFinite(price) && Number.isFinite(atr) && atr > 0
          ? Math.abs(price - entryPrice) / atr
          : null;
        return {
          price,
          source: "ATR Level",
          type: "ATR_FIB",
          timeframe: "D",
          confidence: 0.75,
          multiplier: calculatedMult,
          label: "TP",
        };
      })
      .filter((item) => Number.isFinite(item.price) && item.price > 0);
  }

  // Add primary TP if valid
  const primaryTP = Number(tickerData.tp);
  if (Number.isFinite(primaryTP) && primaryTP > 0) {
    const calculatedMult = Number.isFinite(atr) && atr > 0
      ? Math.abs(primaryTP - entryPrice) / atr
      : null;
    tpLevels.push({
      price: primaryTP,
      source: "Primary TP",
      type: "ATR_FIB",
      timeframe: "D",
      confidence: 0.75,
      multiplier: calculatedMult,
      label: "TP",
    });
  }

  // Filter by direction (TP must be in profit direction)
  const validTPs = tpLevels.filter((item) => {
    const price = Number(item.price);
    if (!Number.isFinite(price) || price <= 0) return false;
    return isLong ? price > entryPrice : price < entryPrice;
  });

  // Group TPs by tier based on ATR multiplier
  const tiers = {
    TRIM: [],
    EXIT: [],
    RUNNER: [],
  };

  for (const tp of validTPs) {
    const mult = tp.multiplier;
    if (!Number.isFinite(mult)) continue;

    if (mult >= THREE_TIER_CONFIG.TRIM.minMult && mult < THREE_TIER_CONFIG.EXIT.minMult) {
      tiers.TRIM.push(tp);
    } else if (mult >= THREE_TIER_CONFIG.EXIT.minMult && mult < THREE_TIER_CONFIG.RUNNER.minMult) {
      tiers.EXIT.push(tp);
    } else if (mult >= THREE_TIER_CONFIG.RUNNER.minMult) {
      tiers.RUNNER.push(tp);
    }
  }

  // Select best TP from each tier (prefer HTF, then highest confidence)
  const selectBestFromTier = (tierTPs) => {
    if (tierTPs.length === 0) return null;
    
    // HTF priority: W > D > 4H > others
    const htfPriority = (tf) => {
      const t = String(tf || "D").toUpperCase();
      if (t === "W") return 3;
      if (t === "D") return 2;
      if (t === "240" || t === "4H") return 1;
      return 0;
    };
    
    tierTPs.sort((a, b) => {
      const htfDiff = htfPriority(b.timeframe) - htfPriority(a.timeframe);
      if (htfDiff !== 0) return htfDiff;
      return (b.confidence || 0) - (a.confidence || 0);
    });
    
    return tierTPs[0];
  };

  const trimTp = selectBestFromTier(tiers.TRIM);
  const exitTp = selectBestFromTier(tiers.EXIT);
  const runnerTp = selectBestFromTier(tiers.RUNNER);

  // ─────────────────────────────────────────────────────────────────────────────
  // GOLD STANDARD: Direction-specific TP multipliers
  // Based on historical analysis: LONG median +5.94%, SHORT median -6.34%
  // ─────────────────────────────────────────────────────────────────────────────
  const gsConfig = isLong ? GOLD_STANDARD_PATTERNS.LONG : GOLD_STANDARD_PATTERNS.SHORT;
  const gsTpMult = gsConfig.tpMultipliers;
  
  // Build the 3-tier array, interpolating missing tiers
  const result = [];

  // TRIM TP (0.618x - 1.0x ATR) - 60% off
  if (trimTp) {
    result.push({
      price: trimTp.price,
      trimPct: THREE_TIER_CONFIG.TRIM.trimPct,
      tier: "TRIM",
      label: `TRIM TP (${Math.round(THREE_TIER_CONFIG.TRIM.trimPct * 100)}%)`,
      source: trimTp.source,
      timeframe: trimTp.timeframe,
      multiplier: trimTp.multiplier,
    });
  } else {
    // Interpolate: use direction-specific multiplier from gold standard
    const trimMult = gsTpMult.trim || 1.5;
    const interpPrice = isLong
      ? entryPrice + atr * trimMult
      : entryPrice - atr * trimMult;
    result.push({
      price: interpPrice,
      trimPct: THREE_TIER_CONFIG.TRIM.trimPct,
      tier: "TRIM",
      label: `TRIM TP (${Math.round(THREE_TIER_CONFIG.TRIM.trimPct * 100)}%)`,
      source: `ATR Interpolated (GS ${direction})`,
      timeframe: "D",
      multiplier: trimMult,
    });
  }

  // EXIT TP (1.0x - 1.618x ATR) - 80% cumulative
  if (exitTp) {
    result.push({
      price: exitTp.price,
      trimPct: THREE_TIER_CONFIG.EXIT.trimPct,
      tier: "EXIT",
      label: `EXIT TP (${Math.round(THREE_TIER_CONFIG.EXIT.trimPct * 100)}%)`,
      source: exitTp.source,
      timeframe: exitTp.timeframe,
      multiplier: exitTp.multiplier,
    });
  } else {
    // Interpolate: use direction-specific multiplier from gold standard
    const exitMult = gsTpMult.exit || 2.5;
    const interpPrice = isLong
      ? entryPrice + atr * exitMult
      : entryPrice - atr * exitMult;
    result.push({
      price: interpPrice,
      trimPct: THREE_TIER_CONFIG.EXIT.trimPct,
      tier: "EXIT",
      label: `EXIT TP (${Math.round(THREE_TIER_CONFIG.EXIT.trimPct * 100)}%)`,
      source: `ATR Interpolated (GS ${direction})`,
      timeframe: "D",
      multiplier: exitMult,
    });
  }

  // RUNNER TP (1.618x+ ATR) - 100% cumulative
  if (runnerTp) {
    result.push({
      price: runnerTp.price,
      trimPct: THREE_TIER_CONFIG.RUNNER.trimPct,
      tier: "RUNNER",
      label: `RUNNER TP (${Math.round(THREE_TIER_CONFIG.RUNNER.trimPct * 100)}%)`,
      source: runnerTp.source,
      timeframe: runnerTp.timeframe,
      multiplier: runnerTp.multiplier,
    });
  } else {
    // Interpolate: use direction-specific multiplier from gold standard
    const runnerMult = gsTpMult.runner || 4.0;
    const interpPrice = isLong
      ? entryPrice + atr * runnerMult
      : entryPrice - atr * runnerMult;
    result.push({
      price: interpPrice,
      trimPct: THREE_TIER_CONFIG.RUNNER.trimPct,
      tier: "RUNNER",
      label: `RUNNER TP (${Math.round(THREE_TIER_CONFIG.RUNNER.trimPct * 100)}%)`,
      source: `ATR Interpolated (GS ${direction})`,
      timeframe: "D",
      multiplier: runnerMult,
    });
  }

  // Ensure TPs are sorted by distance from entry (closest first)
  result.sort((a, b) => {
    const distA = Math.abs(a.price - entryPrice);
    const distB = Math.abs(b.price - entryPrice);
    return distA - distB;
  });

  return result;
}

// Helper: Build intelligent TP array with progressive trim levels (25%, 50%, 75%)
// This creates a systematic TP array that allows holding winners longer
// DEPRECATED: Use build3TierTPArray instead - kept for backward compatibility
function buildIntelligentTPArray(tickerData, entryPrice, direction) {
  const isLong = direction === "LONG";
  const sl = Number(tickerData.sl);

  if (!Number.isFinite(entryPrice) || !Number.isFinite(sl)) {
    return [];
  }

  // Calculate risk (distance from entry to SL)
  const risk = Math.abs(entryPrice - sl);
  if (risk <= 0) return [];

  // Horizon-aware settings (short vs swing vs positional)
  const bucketRaw = String(
    tickerData.horizon_bucket ||
      horizonBucketFromEtaDays(tickerData.eta_days_v2 ?? tickerData.eta_days) ||
      "",
  )
    .trim()
    .toUpperCase();
  const bucket = bucketRaw || "SWING";

  const horizonConfigMap = {
    SHORT_TERM: {
      minDistancePct: 0.05, // 5% min run-up before first trim (was 3%)
      sweetMin: 0.05,
      sweetMax: 0.12,
      okMin: 0.03,
      okMax: 0.18,
      tooFarPct: 0.25,
      minDistanceBetweenTPs: 0.04,
      maxTPs: 3,
      trimLevels: [0.2, 0.5, 1.0],
      fallbackMultipliers: [0.7, 1.0, 1.4],
    },
    SWING: {
      minDistancePct: 0.06, // 6% min run-up before first trim (was 4%)
      sweetMin: 0.08,
      sweetMax: 0.2,
      okMin: 0.05,
      okMax: 0.3,
      tooFarPct: 0.45,
      minDistanceBetweenTPs: 0.06,
      maxTPs: 4,
      trimLevels: [0.1, 0.25, 0.5, 1.0],
      fallbackMultipliers: [0.6, 1.0, 1.6],
    },
    POSITIONAL: {
      minDistancePct: 0.08, // 8% min run-up before first trim (was 6%)
      sweetMin: 0.15,
      sweetMax: 0.4,
      okMin: 0.1,
      okMax: 0.6,
      tooFarPct: 0.8,
      minDistanceBetweenTPs: 0.1,
      maxTPs: 4,
      trimLevels: [0.1, 0.25, 0.5, 1.0],
      fallbackMultipliers: [0.5, 1.0, 1.8],
    },
  };
  const horizonConfig = horizonConfigMap[bucket] || horizonConfigMap.SWING;

  // Extract all TP levels with metadata
  let tpLevels = [];
  if (
    tickerData.tp_levels &&
    Array.isArray(tickerData.tp_levels) &&
    tickerData.tp_levels.length > 0
  ) {
    tpLevels = tickerData.tp_levels
      .map((tpItem) => {
        if (typeof tpItem === "object" && tpItem !== null) {
          return {
            price: Number(tpItem.price),
            source: tpItem.source || "ATR Level",
            type: tpItem.type || "ATR_FIB",
            timeframe: tpItem.timeframe || "D",
            confidence: Number(tpItem.confidence || 0.75),
            multiplier: tpItem.multiplier ? Number(tpItem.multiplier) : null,
            label: tpItem.label || "TP",
          };
        }
        return {
          price: Number(tpItem),
          source: "ATR Level",
          type: "ATR_FIB",
          timeframe: "D",
          confidence: 0.75,
          multiplier: null,
          label: "TP",
        };
      })
      .filter((item) => Number.isFinite(item.price) && item.price > 0);
  }

  // Add primary TP if valid
  const primaryTP = Number(tickerData.tp);
  if (Number.isFinite(primaryTP) && primaryTP > 0) {
    tpLevels.push({
      price: primaryTP,
      source: "Primary TP",
      type: "ATR_FIB",
      timeframe: "D",
      confidence: 0.75,
      multiplier: null,
      label: "TP",
    });
  }

  // Filter by direction and ensure they're beyond entry
  // Also filter out TPs that are too close - these are likely noise
  const minDistancePct = horizonConfig.minDistancePct;
  const validTPs = tpLevels
    .filter((item) => {
      const price = Number(item.price);
      if (!Number.isFinite(price) || price <= 0) return false;

      // Direction check
      const directionValid = isLong ? price > entryPrice : price < entryPrice;
      if (!directionValid) return false;

      // Distance check - filter out TPs too close to entry
      const distancePct = Math.abs(price - entryPrice) / entryPrice;
      if (distancePct < minDistancePct) return false;

      return true;
    })
    .sort((a, b) => {
      // Sort by distance from entry (closest first for LONG, furthest first for SHORT)
      const distA = Math.abs(a.price - entryPrice);
      const distB = Math.abs(b.price - entryPrice);
      return isLong ? distA - distB : distB - distA;
    });

  if (validTPs.length === 0) {
    // Fallback: create basic TP array from primary TP, enforcing min run-up
    if (Number.isFinite(primaryTP) && primaryTP > 0) {
      const rawDist = Math.abs(primaryTP - entryPrice) / entryPrice;
      const minRun = horizonConfig.minDistancePct;
      const scale = rawDist >= minRun ? 1 : minRun / Math.max(rawDist, 0.001);
      const baseDist = Math.abs(primaryTP - entryPrice) * scale;
      const tp1 = isLong
        ? entryPrice + baseDist
        : entryPrice - baseDist;
      const tp2 = isLong
        ? entryPrice + baseDist * 1.5
        : entryPrice - baseDist * 1.5;
      const tp3 = isLong
        ? entryPrice + baseDist * 2.0
        : entryPrice - baseDist * 2.0;

      return [
        { price: tp1, trimPct: 0.25, label: "TP1 (25%)" },
        { price: tp2, trimPct: 0.5, label: "TP2 (50%)" },
        { price: tp3, trimPct: 0.75, label: "TP3 (75%)" },
      ];
    }
    return [];
  }

  // Fuse raw TP candidates into a few "confluence" zones, then score those fused zones.
  // This prevents overreacting to noisy/clustered TP sets and yields more stable trim levels.
  const fusedTPs = fuseTPCandidates(
    validTPs,
    entryPrice,
    direction,
    risk,
    horizonConfig,
  );
  const baseForScoring = fusedTPs.length > 0 ? fusedTPs : validTPs;

  // Score all candidates (fused preferred; otherwise raw)
  const scoredTPs = baseForScoring.map((tpItem) => ({
    ...tpItem,
    score:
      tpItem && tpItem._fused && typeof tpItem._fused.score === "number"
        ? tpItem._fused.score
        : scoreTPLevel(tpItem, entryPrice, direction, validTPs, horizonConfig),
  }));

  // Prioritize HTF timeframes (Weekly/Daily) - these should be further away and more reliable
  // Sort by: HTF timeframe first, then by score
  scoredTPs.sort((a, b) => {
    const tfA = String(a.timeframe || "D").toUpperCase();
    const tfB = String(b.timeframe || "D").toUpperCase();

    // HTF priority: W > D > 4H > others
    const htfPriority = (tf) => {
      if (tf === "W") return 3;
      if (tf === "D") return 2;
      if (tf === "240" || tf === "4H") return 1;
      return 0;
    };

    const priorityA = htfPriority(tfA);
    const priorityB = htfPriority(tfB);

    // If same HTF priority, sort by score
    if (priorityA === priorityB) {
      return b.score - a.score;
    }

    // Higher HTF priority first
    return priorityB - priorityA;
  });

  // Build intelligent TP array with progressive trim levels
  // Strategy: Prioritize HTF timeframes (Weekly/Daily) and select 3-4 TPs that are well-spaced
  const selectedTPs = [];
  const minDistanceBetweenTPs = horizonConfig.minDistanceBetweenTPs;
  const maxTPs = horizonConfig.maxTPs;

  // First pass: Prioritize HTF timeframes (W, D) - these are more reliable and further away
  const htfTPs = scoredTPs.filter((tp) => {
    const tf = String(tp.timeframe || "D").toUpperCase();
    return tf === "W" || tf === "D";
  });

  // Second pass: If we don't have enough HTF TPs, add lower timeframe TPs
  const allTPsToConsider = htfTPs.length >= 3 ? htfTPs : scoredTPs;

  for (const tp of allTPsToConsider) {
    if (selectedTPs.length >= maxTPs) break;

    // Check if this TP is far enough from already selected TPs
    const tooClose = selectedTPs.some((selected) => {
      const distancePct = Math.abs(tp.price - selected.price) / entryPrice;
      return distancePct < minDistanceBetweenTPs;
    });

    if (!tooClose) {
      selectedTPs.push(tp);
    }
  }

  // If we don't have enough TPs, fill gaps intelligently
  if (selectedTPs.length < 3) {
    // Use top scored TPs and create intermediate levels
    const topTP = scoredTPs[0];
    if (topTP) {
      const baseDistance = Math.abs(topTP.price - entryPrice);
      const [m1, m2, m3] = horizonConfig.fallbackMultipliers || [0.6, 1.0, 1.5];

      // Create TP1 (closest)
      const tp1 = isLong
        ? entryPrice + baseDistance * m1
        : entryPrice - baseDistance * m1;

      // TP2 (middle) - use top scored TP
      const tp2 = topTP.price;

      // TP3 (farthest)
      const tp3 = isLong
        ? entryPrice + baseDistance * m3
        : entryPrice - baseDistance * m3;

      const trims = horizonConfig.trimLevels || [0.25, 0.5, 0.75];
      return [
        {
          price: tp1,
          trimPct: trims[0] || 0.25,
          label: `TP1 (${Math.round((trims[0] || 0.25) * 100)}%)`,
          source: topTP.source,
          timeframe: topTP.timeframe,
        },
        {
          price: tp2,
          trimPct: trims[1] || 0.5,
          label: `TP2 (${Math.round((trims[1] || 0.5) * 100)}%)`,
          source: topTP.source,
          timeframe: topTP.timeframe,
        },
        {
          price: tp3,
          trimPct: trims[2] || 0.75,
          label: `TP3 (${Math.round((trims[2] || 0.75) * 100)}%)`,
          source: topTP.source,
          timeframe: topTP.timeframe,
        },
      ];
    }
  }

  // Assign trim percentages to selected TPs
  // Closest TP = 25%, Middle = 50%, Farthest = 75%
  const sortedByDistance = [...selectedTPs].sort((a, b) => {
    const distA = Math.abs(a.price - entryPrice);
    const distB = Math.abs(b.price - entryPrice);
    return distA - distB;
  });

  const trimLevels = horizonConfig.trimLevels || [0.25, 0.5, 0.75];
  const tpArray = sortedByDistance.slice(0, 3).map((tp, idx) => ({
    price: tp.price,
    trimPct: trimLevels[idx] || 0.75,
    label: `TP${idx + 1} (${Math.round(trimLevels[idx] * 100)}%)`,
    source: tp.source,
    timeframe: tp.timeframe,
    confidence: tp.confidence,
  }));

  // If we have a 4th TP, add it as final exit
  if (sortedByDistance.length > 3 && trimLevels[3] != null) {
    const finalTP = sortedByDistance[3];
    tpArray.push({
      price: finalTP.price,
      trimPct: trimLevels[3],
      label: `TP4 (${Math.round(trimLevels[3] * 100)}%)`,
      source: finalTP.source,
      timeframe: finalTP.timeframe,
      confidence: finalTP.confidence,
    });
  }

  return tpArray;
}

// Helper: Get intelligent TP (best single or weighted blend) - for backward compatibility
function getIntelligentTP(tickerData, entryPrice, direction) {
  // Build TP array and return the first TP (25% trim level) as the primary TP
  const tpArray = buildIntelligentTPArray(tickerData, entryPrice, direction);
  if (tpArray.length > 0) {
    return tpArray[0].price;
  }

  // Fallback to original logic
  return getValidTP(tickerData, entryPrice, direction);
}

// Helper: Get valid TP based on direction and entry price (fallback)
function getValidTP(tickerData, entryPrice, direction) {
  const isLong = direction === "LONG";

  // Get TP from tickerData
  let tp = Number(tickerData.tp);

  // If tp_levels exists, extract all valid TP prices
  let tpPrices = [];
  if (
    tickerData.tp_levels &&
    Array.isArray(tickerData.tp_levels) &&
    tickerData.tp_levels.length > 0
  ) {
    tpPrices = tickerData.tp_levels
      .map((tpItem) => {
        if (
          typeof tpItem === "object" &&
          tpItem !== null &&
          tpItem.price != null
        ) {
          return Number(tpItem.price);
        }
        return typeof tpItem === "number" ? Number(tpItem) : null;
      })
      .filter((p) => Number.isFinite(p) && p > 0);
  }

  // Add the primary TP if it's valid
  if (Number.isFinite(tp) && tp > 0) {
    tpPrices.push(tp);
  }

  // Remove duplicates and sort
  tpPrices = [...new Set(tpPrices)].sort((a, b) => a - b);

  // Find first valid TP based on direction
  if (isLong) {
    // For LONG: TP must be above entry price
    const validTPs = tpPrices.filter((p) => p > entryPrice);
    if (validTPs.length > 0) {
      return validTPs[0]; // Return first (lowest) valid TP above entry
    }
    // If no valid TP found, check if primary TP is valid
    if (Number.isFinite(tp) && tp > entryPrice) {
      return tp;
    }
    // Fallback: use highest TP from levels (might still be invalid, but better than nothing)
    if (tpPrices.length > 0) {
      console.warn(
        `[TP VALIDATION] ⚠️ ${
          tickerData.ticker || "UNKNOWN"
        } LONG: No TP above entry $${entryPrice.toFixed(
          2,
        )}. Using highest TP: $${Math.max(...tpPrices).toFixed(2)}`,
      );
      return Math.max(...tpPrices);
    }
  } else {
    // For SHORT: TP must be below entry price
    const validTPs = tpPrices.filter((p) => p < entryPrice);
    if (validTPs.length > 0) {
      return validTPs[validTPs.length - 1]; // Return last (highest) valid TP below entry
    }
    // If no valid TP found, check if primary TP is valid
    if (Number.isFinite(tp) && tp < entryPrice) {
      return tp;
    }
    // Fallback: use lowest TP from levels
    if (tpPrices.length > 0) {
      console.warn(
        `[TP VALIDATION] ⚠️ ${
          tickerData.ticker || "UNKNOWN"
        } SHORT: No TP below entry $${entryPrice.toFixed(
          2,
        )}. Using lowest TP: $${Math.min(...tpPrices).toFixed(2)}`,
      );
      return Math.min(...tpPrices);
    }
  }

  // Last resort: return primary TP even if invalid
  if (Number.isFinite(tp) && tp > 0) {
    console.warn(
      `[TP VALIDATION] ⚠️ ${
        tickerData.ticker || "UNKNOWN"
      } ${direction}: Using invalid TP $${tp.toFixed(
        2,
      )} (entry: $${entryPrice.toFixed(2)})`,
    );
    return tp;
  }

  return null;
}

// Calculate RR at entry price (for trade creation) using intelligent TP array
function calculateRRAtEntry(tickerData, entryPrice) {
  const direction = getTradeDirection(tickerData.state);
  const sl = Number(tickerData.sl);

  if (!Number.isFinite(entryPrice) || !Number.isFinite(sl)) {
    return null;
  }

  // Build intelligent TP array and use max TP for RR calculation
  const tpArray = buildIntelligentTPArray(tickerData, entryPrice, direction);

  let maxTP = null;
  if (tpArray.length > 0) {
    // Use the highest TP from the array (farthest target)
    maxTP = Math.max(...tpArray.map((tp) => tp.price));
  } else {
    // Fallback to single TP
    const tp = getIntelligentTP(tickerData, entryPrice, direction);
    if (!Number.isFinite(tp)) return null;
    maxTP = tp;
  }

  const state = String(tickerData.state || "");
  const isLong = state.includes("BULL");
  const isShort = state.includes("BEAR");

  let risk, gain;

  if (isLong) {
    risk = entryPrice - sl; // Risk from entry to SL
    gain = maxTP - entryPrice; // Gain from entry to max TP
  } else if (isShort) {
    risk = sl - entryPrice; // Risk from entry to SL
    gain = entryPrice - maxTP; // Gain from entry to max TP
  } else {
    risk = Math.abs(entryPrice - sl);
    gain = Math.abs(maxTP - entryPrice);
  }

  if (risk <= 0 || gain <= 0) return null;
  return gain / risk;
}

// Calculate trade P&L and status with progressive TP trimming (25%, 50%, 75%)
function calculateTradePnl(tickerData, entryPrice, existingTrade = null) {
  const direction = getTradeDirection(tickerData.state);
  if (!direction) return null;

  const sl = Number(tickerData.sl);
  const currentPrice = Number(tickerData.price);

  if (!Number.isFinite(sl) || !Number.isFinite(currentPrice)) {
    return null;
  }

  // Market is closed on weekends — never execute TP trims/exits on Sat/Sun.
  // (We still allow SL evaluation to be conservative.)
  const weekendNow = isNyWeekend(Date.now());

  const ticker = String(tickerData.ticker || "").toUpperCase();
  const isFutures = FUTURES_SPECS[ticker] || ticker.endsWith("1!");

  // For futures: trade 1 contract, calculate P&L based on point value
  // For stocks: calculate shares based on dollar amount
  let shares;
  let pointValue = 1; // Default for stocks (price per share)

  if (isFutures && FUTURES_SPECS[ticker]) {
    // Futures: always trade 1 contract
    shares = 1;
    pointValue = FUTURES_SPECS[ticker].pointValue;
  } else {
    // Stocks: calculate shares from dollar amount
    shares = TRADE_SIZE / entryPrice;
  }

  // Get or build 3-tier TP array
  let tpArray = existingTrade?.tpArray || [];
  if (tpArray.length === 0) {
    // Build 3-tier TP array if not stored in trade
    tpArray = build3TierTPArray(tickerData, entryPrice, direction);
  }

  // Defensive: If an entry price was corrected after the trade was created,
  // an older stored tpArray may no longer be on the profit side (e.g. TP < entry for LONG),
  // which can cause "TP trims" at a loss. Filter + rebuild if needed.
  const isLong = direction === "LONG";
  const minDistancePct = 0.01; // keep consistent with build3TierTPArray
  const isProfitSide = (tpPrice) =>
    isLong
      ? tpPrice > entryPrice &&
        (tpPrice - entryPrice) / entryPrice >= minDistancePct
      : tpPrice < entryPrice &&
        (entryPrice - tpPrice) / entryPrice >= minDistancePct;

  const sanitizedTpArray = Array.isArray(tpArray)
    ? tpArray
        .map((tp) => ({
          ...tp,
          price: Number(tp?.price),
          trimPct: Number(tp?.trimPct),
          tier: tp?.tier,
          label: tp?.label,
        }))
        .filter(
          (tp) =>
            Number.isFinite(tp.price) &&
            Number.isFinite(tp.trimPct) &&
            tp.trimPct > 0 &&
            tp.trimPct <= 1 &&
            isProfitSide(tp.price),
        )
        .sort((a, b) => (a.trimPct || 0) - (b.trimPct || 0))
    : [];

  // If the stored TP plan becomes invalid after entry corrections, rebuild it.
  if (sanitizedTpArray.length === 0) {
    const rebuilt = build3TierTPArray(tickerData, entryPrice, direction);
    if (Array.isArray(rebuilt) && rebuilt.length > 0) {
      tpArray = rebuilt;
    } else {
      tpArray = [];
    }
  } else {
    tpArray = sanitizedTpArray;
  }

  // Fallback to single TP if array is empty
  const fallbackTP =
    existingTrade?.tp || getIntelligentTP(tickerData, entryPrice, direction);
  if (tpArray.length === 0 && Number.isFinite(fallbackTP)) {
    tpArray = [{ price: fallbackTP, trimPct: 0.5, label: "TP (50%)" }];
  }

  const trimmedPct = existingTrade ? existingTrade.trimmedPct || 0 : 0;

  // Check which TP levels have been hit (sorted by trim percentage)
  const hitTPLevels = [];
  for (const tpLevel of tpArray) {
    const tpPrice = Number(tpLevel.price);
    if (!Number.isFinite(tpPrice)) continue;

    const hit = isLong ? currentPrice >= tpPrice : currentPrice <= tpPrice;
    if (hit) {
      hitTPLevels.push({
        ...tpLevel,
        price: tpPrice,
      });
    }
  }

  // Sort hit TPs by trim percentage (ascending)
  hitTPLevels.sort((a, b) => (a.trimPct || 0) - (b.trimPct || 0));

  // Check SL hit
  const hitSL = isLong ? currentPrice <= sl : currentPrice >= sl;

  let pnl = 0;
  let pnlPct = 0;
  let status = "OPEN";
  let newTrimmedPct = trimmedPct;
  let realizedPnl = 0; // P&L from trimmed portions

  if (hitSL) {
    // Stop Loss hit - close entire remaining position
    const slDiff = isLong ? sl - entryPrice : entryPrice - sl;

    // Calculate realized P&L from any previous trims
    for (const tpLevel of hitTPLevels) {
      const levelTrimPct = tpLevel.trimPct || 0;
      if (levelTrimPct <= trimmedPct) {
        const tpDiff = isLong
          ? tpLevel.price - entryPrice
          : entryPrice - tpLevel.price;
        // Only count the portion that was actually trimmed
        const alreadyCountedPct = Math.min(levelTrimPct, trimmedPct);
        realizedPnl += tpDiff * shares * pointValue * alreadyCountedPct;
      }
    }

    // Final P&L = realized from trims + remaining position at SL
    const remainingPct = 1 - trimmedPct;
    const remainingPnl = slDiff * shares * pointValue * remainingPct;
    pnl = realizedPnl + remainingPnl;
    pnlPct = ((sl - entryPrice) / entryPrice) * 100;
    status = "LOSS";
    return {
      shares,
      pnl,
      pnlPct,
      status,
      currentPrice,
      trimmedPct: trimmedPct,
      tpArray,
      exitPrice: sl,
      exitReason: "SL",
      exitCategory: "INVALIDATION",
    };
  } else if (hitTPLevels.length > 0 && !weekendNow) {
    // One or more TP levels hit - determine next trim action
    // Find the highest TP level hit that we haven't trimmed yet
    let nextTrimTP = null;
    for (const tpLevel of hitTPLevels) {
      const levelTrimPct = tpLevel.trimPct || 0;
      if (levelTrimPct > trimmedPct) {
        nextTrimTP = tpLevel;
        break; // Take the first (lowest) untrimmed TP
      }
    }

    if (nextTrimTP) {
      // Need to trim at this TP level
      const targetTrimPct = nextTrimTP.trimPct || 0.5;
      const trimAmount = targetTrimPct - trimmedPct;
      const tpDiff = isLong
        ? nextTrimTP.price - entryPrice
        : entryPrice - nextTrimTP.price;

      // Calculate realized P&L from all previous trims (including intermediate levels)
      for (const tpLevel of hitTPLevels) {
        const levelTrimPct = tpLevel.trimPct || 0;
        if (levelTrimPct < targetTrimPct && levelTrimPct > trimmedPct) {
          // Intermediate TP hit - calculate P&L for the portion between previous trim and this level
          const levelTpDiff = isLong
            ? tpLevel.price - entryPrice
            : entryPrice - tpLevel.price;
          const intermediateTrimAmount = levelTrimPct - trimmedPct;
          realizedPnl +=
            levelTpDiff * shares * pointValue * intermediateTrimAmount;
        }
      }

      // Calculate P&L from this trim
      const trimPnl = tpDiff * shares * pointValue * trimAmount;
      const trimPnlPct = ((nextTrimTP.price - entryPrice) / entryPrice) * 100;

      // If we've trimmed 100%, close the trade
      if (targetTrimPct >= 1.0) {
        // Full exit - calculate total P&L
        const totalRealizedPnl = realizedPnl + trimPnl;
        return {
          shares,
          pnl: totalRealizedPnl,
          pnlPct: trimPnlPct,
          status: totalRealizedPnl >= 0 ? "WIN" : "LOSS",
          currentPrice,
          trimmedPct: 1.0,
          tpArray,
          exitPrice: nextTrimTP.price,
          exitReason: "TP_FULL",
          exitCategory: "PROFIT_MANAGEMENT",
          trimPrice: nextTrimTP.price,
          trimTargetPct: targetTrimPct,
          trimDeltaPct: trimAmount,
        };
      }

      // Partial trim - return with new trimmed percentage
      return {
        shares,
        pnl: realizedPnl + trimPnl,
        pnlPct: trimPnlPct,
        status: "TP_HIT_TRIM",
        currentPrice,
        trimmedPct: targetTrimPct,
        tpArray, // Store TP array for next check
        decisionCategory: "PROFIT_MANAGEMENT",
        trimPrice: nextTrimTP.price,
        trimTargetPct: targetTrimPct,
        trimDeltaPct: trimAmount,
      };
    } else {
      // Already trimmed at all hit TP levels - check if we should hold winners
      // Calculate current price vs entry
      const priceDiff = isLong
        ? currentPrice - entryPrice
        : entryPrice - currentPrice;
      const priceDiffPct = (priceDiff / entryPrice) * 100;

      // Calculate realized P&L from all trims
      for (const tpLevel of hitTPLevels) {
        const levelTrimPct = tpLevel.trimPct || 0;
        if (levelTrimPct <= trimmedPct) {
          const levelTpDiff = isLong
            ? tpLevel.price - entryPrice
            : entryPrice - tpLevel.price;
          // Count the portion that was actually trimmed
          const trimmedAtThisLevel = Math.min(levelTrimPct, trimmedPct);
          const prevTrimmedPct = hitTPLevels
            .filter((tp) => (tp.trimPct || 0) < levelTrimPct)
            .reduce((sum, tp) => Math.max(sum, tp.trimPct || 0), 0);
          const trimAmount = trimmedAtThisLevel - prevTrimmedPct;
          if (trimAmount > 0) {
            realizedPnl += levelTpDiff * shares * pointValue * trimAmount;
          }
        }
      }

      // Check if we should hold winners (price above 4H 8-13 EMA cloud)
      // Use 4H EMA cloud position if available, otherwise fallback to price momentum
      let shouldHold = false;
      const fourHEMACloud = tickerData.fourh_ema_cloud;

      if (fourHEMACloud && fourHEMACloud.position) {
        // Use 4H EMA cloud position for hold decision
        if (isLong) {
          // For LONG: hold if price is above the 4H EMA cloud
          shouldHold = fourHEMACloud.position === "above" && trimmedPct < 1.0;
        } else {
          // For SHORT: hold if price is below the 4H EMA cloud
          shouldHold = fourHEMACloud.position === "below" && trimmedPct < 1.0;
        }
      } else {
        // Fallback: use price momentum and profit threshold
        // Hold if: price is significantly above entry (>2%) and we haven't trimmed everything
        shouldHold = priceDiffPct > 2.0 && trimmedPct < 1.0;
      }

      if (shouldHold) {
        // Hold remaining position - calculate unrealized P&L
        const remainingPct = 1 - trimmedPct;
        const unrealizedPnl = priceDiff * shares * pointValue * remainingPct;

        return {
          shares,
          pnl: realizedPnl + unrealizedPnl,
          pnlPct: priceDiffPct,
          status: "OPEN", // Still holding
          currentPrice,
          trimmedPct,
          tpArray,
          exitReason: null,
          decisionCategory: "PROFIT_MANAGEMENT",
        };
      }

      // Not holding - calculate current P&L
      const remainingPct = 1 - trimmedPct;
      const currentPnl = priceDiff * shares * pointValue * remainingPct;

      return {
        shares,
        pnl: realizedPnl + currentPnl,
        pnlPct: priceDiffPct,
        status: "OPEN",
        currentPrice,
        trimmedPct,
        tpArray,
        exitReason: null,
        decisionCategory: "PROFIT_MANAGEMENT",
      };
    }
  } else {
    // No TP hit yet - calculate unrealized P&L
    const priceDiff = isLong
      ? currentPrice - entryPrice
      : entryPrice - currentPrice;
    const remainingPct = 1 - trimmedPct;
    pnl = priceDiff * shares * pointValue * remainingPct;
    pnlPct = ((currentPrice - entryPrice) / entryPrice) * 100;

    // Add realized P&L from any previous trims (shouldn't happen if no TP hit, but handle edge case)
    if (trimmedPct > 0 && hitTPLevels.length > 0) {
      // Estimate realized P&L based on highest TP hit
      const highestTP = hitTPLevels[hitTPLevels.length - 1];
      const tpDiff = isLong
        ? highestTP.price - entryPrice
        : entryPrice - highestTP.price;
      realizedPnl = tpDiff * shares * pointValue * trimmedPct;
      pnl += realizedPnl;
    }

    status = "OPEN";
  }

  return {
    shares,
    pnl,
    pnlPct,
    status,
    currentPrice,
    trimmedPct: newTrimmedPct,
    tpArray,
    exitReason: null,
  };
}

// Pattern Recognition: Analyze winning patterns from trade history
function analyzeWinningPatterns(tradeHistory, currentTickers) {
  if (!tradeHistory || tradeHistory.length === 0) {
    return { summary: "No trade history available for pattern analysis" };
  }

  const wins = tradeHistory.filter((t) => t.status === "WIN");
  const losses = tradeHistory.filter((t) => t.status === "LOSS");
  const winRate = wins.length / tradeHistory.length;

  // Analyze by rank ranges
  const rankPatterns = {};
  tradeHistory.forEach((t) => {
    const rank = Math.floor((t.rank || 0) / 10) * 10; // Group by 10s
    const key = `Rank ${rank}-${rank + 9}`;
    if (!rankPatterns[key]) {
      rankPatterns[key] = { wins: 0, losses: 0, totalPnl: 0 };
    }
    if (t.status === "WIN") rankPatterns[key].wins++;
    if (t.status === "LOSS") rankPatterns[key].losses++;
    rankPatterns[key].totalPnl += t.pnl || 0;
  });

  // Analyze by RR ranges
  const rrPatterns = {};
  tradeHistory.forEach((t) => {
    const rr = t.rr || 0;
    let range = "Unknown";
    if (rr >= 2.0) range = "RR ≥ 2.0";
    else if (rr >= 1.5) range = "RR 1.5-2.0";
    else if (rr >= 1.0) range = "RR 1.0-1.5";
    else if (rr > 0) range = "RR < 1.0";

    if (!rrPatterns[range]) {
      rrPatterns[range] = { wins: 0, losses: 0, totalPnl: 0 };
    }
    if (t.status === "WIN") rrPatterns[range].wins++;
    if (t.status === "LOSS") rrPatterns[range].losses++;
    rrPatterns[range].totalPnl += t.pnl || 0;
  });

  // Find best performing patterns
  const bestRankPattern = Object.entries(rankPatterns)
    .filter(([_, stats]) => stats.wins + stats.losses >= 3)
    .sort((a, b) => {
      const aRate = a[1].wins / (a[1].wins + a[1].losses || 1);
      const bRate = b[1].wins / (b[1].wins + b[1].losses || 1);
      return bRate - aRate;
    })[0];

  const bestRRPattern = Object.entries(rrPatterns)
    .filter(([_, stats]) => stats.wins + stats.losses >= 3)
    .sort((a, b) => {
      const aRate = a[1].wins / (a[1].wins + a[1].losses || 1);
      const bRate = b[1].wins / (b[1].wins + b[1].losses || 1);
      return bRate - aRate;
    })[0];

  // Match current tickers to winning patterns
  const matchingSetups = currentTickers.filter((t) => {
    if (!bestRankPattern || !bestRRPattern) return false;
    const rankRange = bestRankPattern[0];
    const rrRange = bestRRPattern[0];
    const tickerRank = Math.floor((t.rank || 0) / 10) * 10;
    const rankMatch = rankRange.includes(`Rank ${tickerRank}`);
    const rrMatch =
      (rrRange === "RR ≥ 2.0" && t.rr >= 2.0) ||
      (rrRange === "RR 1.5-2.0" && t.rr >= 1.5 && t.rr < 2.0) ||
      (rrRange === "RR 1.0-1.5" && t.rr >= 1.0 && t.rr < 1.5);
    return rankMatch && rrMatch;
  });

  return {
    summary: `Analyzed ${tradeHistory.length} trades. Win rate: ${(
      winRate * 100
    ).toFixed(1)}%. Best pattern: ${bestRankPattern?.[0] || "N/A"} with ${
      bestRRPattern?.[0] || "N/A"
    } RR. ${matchingSetups.length} current setups match winning patterns.`,
    bestRankPattern: bestRankPattern?.[0] || null,
    bestRRPattern: bestRRPattern?.[0] || null,
    matchingSetups: matchingSetups.slice(0, 5).map((t) => t.ticker),
    winRate: winRate,
  };
}

// Process trade simulation for a ticker (called on ingest)
// options.replayBatchContext: { allTrades } - use pre-loaded trades, skip KV reads/writes for trades+exec (replay perf)
async function processTradeSimulation(
  KV,
  ticker,
  tickerData,
  prevData,
  env = null,
  options = {},
) {
  const forceUseIngestTs = !!options?.forceUseIngestTs;
  const replayCtx = options?.replayBatchContext;
  const isReplay = !!replayCtx;
  // During replay, use ingest timestamp for all event timestamps (not Date.now())
  const asOfMsRaw = options?.asOfTs ?? tickerData?.ts ?? tickerData?.ingest_ts;
  const asOfMs = (isReplay && asOfMsRaw != null)
    ? (Number(asOfMsRaw) < 1e12 ? Number(asOfMsRaw) * 1000 : Number(asOfMsRaw))
    : null;
  const eventTs = () =>
    Number.isFinite(asOfMs) ? new Date(asOfMs).toISOString() : new Date().toISOString();

  // ── Execution Adapter: all trade mutations go through this ──
  // During replay, skip adapter (no D1 writes or Alpaca calls — trades are in-memory only)
  const adapter = (!isReplay && env) ? createExecutionAdapter(env, {
    d1UpsertTrade,
    d1InsertTradeEvent,
    d1InsertPosition,
    d1UpdatePosition,
    d1UpdatePositionSL,
    d1InsertExecutionAction,
    d1InsertLot,
  }) : null;

  try {
    const tradesKey = "timed:trades:all";
    let allTrades;
    if (isReplay) {
      allTrades = replayCtx.allTrades || [];
    } else if (env?.DB) {
      allTrades = (await d1LoadTradesForSimulation(env)) ?? (await kvGetJSON(KV, tradesKey)) ?? [];
    } else {
      allTrades = (await kvGetJSON(KV, tradesKey)) || [];
    }

    const sym = String(ticker || "").toUpperCase();
    
    // Skip futures contracts - they require special handling that's not implemented
    if (FUTURES_TICKERS.has(sym)) {
      return { skipped: true, reason: "futures_not_supported" };
    }
    // Skip non-equity instruments (VIX, commodities, leveraged ETFs)
    if (NON_EQUITY_BLOCKLIST.has(sym)) {
      return { skipped: true, reason: "non_equity_blocked" };
    }
    
    // ═══════════════════════════════════════════════════════════════════════════
    // VIX-BASED VOLATILITY FILTER: Block entries during extreme volatility
    // VIX > 25: Block new LONG entries (too risky for pullback plays)
    // VIX > 30: Block ALL new entries (market regime is broken)
    // ═══════════════════════════════════════════════════════════════════════════
    let vixLevel = null;
    let vixSkipReason = null;
    // Skip VIX KV read during replay (too many subrequests)
    if (!isReplay) {
      try {
        const vixData = await kvGetJSON(KV, "timed:latest:VIX");
        if (vixData && Number.isFinite(Number(vixData.price))) {
          vixLevel = Number(vixData.price);
          // Get trade direction early for VIX check
          const entryPathCheck = String(tickerData?.__entry_path || tickerData?.entry_path || "").toLowerCase();
          const isLongEntry = entryPathCheck.includes("long") || 
            (tickerData.state === "HTF_BULL_LTF_PULLBACK" && !entryPathCheck.includes("short"));
          
          if (vixLevel > 30) {
            vixSkipReason = `vix_extreme_${vixLevel.toFixed(1)}`;
          } else if (vixLevel > 25 && isLongEntry) {
            vixSkipReason = `vix_high_long_blocked_${vixLevel.toFixed(1)}`;
          }
        }
      } catch (vixErr) {
        // VIX data unavailable - continue without filtering
        console.warn("[VIX_CHECK] Failed to get VIX data:", String(vixErr?.message || vixErr));
      }
    }
    
    // Determine trade direction based on entry path (for mean-reversion entries like gold_short)
    // or fall back to state-based direction
    const entryPath = String(tickerData?.__entry_path || tickerData?.entry_path || "").toLowerCase();
    const stateDirection = getTradeDirection(tickerData.state); // BULL->LONG, BEAR->SHORT
    let direction;
    if (entryPath.includes("short")) {
      // gold_short, gold_short_medium: SHORT
      direction = "SHORT";
    } else if (entryPath.includes("long")) {
      // gold_long, gold_long_shallow: LONG
      direction = "LONG";
    } else {
      // Fall back to state-based direction (momentum, squeeze, etc.)
      direction = stateDirection;
    }
    if (!direction) return;
    
    // ─────────────────────────────────────────────────────────────────────────
    // DIRECTION VALIDATION: Allow intentional mean-reversion entries (gold_short)
    // Gold Short is a DELIBERATE counter-trend play on blow-off tops:
    //   HTF_BULL_LTF_BULL + high HTF/LTF = overextended → SHORT (mean reversion)
    // Only block mismatches that are NOT from a recognized entry path.
    // Data: 82.7% of big DOWN moves start from HTF_BULL_LTF_BULL (Historical Movers)
    // ─────────────────────────────────────────────────────────────────────────
    const isGoldShortEntry = entryPath.includes("gold_short");
    const isGoldLongEntry = entryPath.includes("gold_long");
    const hasIntentionalEntryPath = isGoldShortEntry || isGoldLongEntry;
    
    // Only block direction mismatches for entries WITHOUT a recognized entry path
    // (e.g., momentum/squeeze entries where direction must align with state)
    const directionMismatch = stateDirection && direction !== stateDirection && !hasIntentionalEntryPath;
    if (directionMismatch) {
      console.log(`[DIRECTION_MISMATCH] ${sym}: entryPath=${entryPath} suggests ${direction}, but state=${tickerData.state} suggests ${stateDirection}. Blocking entry.`);
      return { skipped: true, reason: `direction_mismatch: ${direction} vs ${stateDirection}` };
    }

    // Phase 3: Open position from D1 (single source of truth).
    // KV fallback ONLY when D1 is unavailable (local dev / replay).
    // Using KV as fallback when D1 exists caused phantom positions:
    // stale KV trades get "found", processed, and written back — never closing.
    let openTrade = null;
    let openPositionContext = null;  // D1 position with SL for stage classification
    if (env?.DB && !isReplay) {
      openPositionContext = await getPositionContext(env, sym);
      openTrade = await getOpenPositionAsTrade(env, sym, direction) ||
        await getOpenPositionAsTrade(env, sym, direction === "LONG" ? "SHORT" : "LONG");
    }
    if (openTrade == null && !(env?.DB)) {
      // KV fallback: only when D1 is not available (local dev, testing)
      openTrade = allTrades.find(
        (t) =>
          String(t?.ticker || "").toUpperCase() === sym &&
          isOpenTradeStatus(t?.status),
      ) || null;
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // FIX: Check for recent trades (ANY status) to prevent rapid re-entry.
    // Checks BOTH entry_ts AND exit_ts — a recently-closed trade blocks immediate
    // re-entry even if the entry was long ago.
    // ─────────────────────────────────────────────────────────────────────────
    const RECENT_TRADE_WINDOW_MS = 30 * 60 * 1000; // 30 minutes — safety net on top of 4h ENTER_COOLDOWN
    const recentTrade = allTrades.find((t) => {
      if (String(t?.ticker || "").toUpperCase() !== sym) return false;
      const nowForCheck = isReplay && Number.isFinite(asOfMs) ? asOfMs : Date.now();
      // Check entry age
      const entryTs = Number(t?.entry_ts) || isoToMs(t?.entryTime) || 0;
      const entryTsNorm = entryTs < 1e12 ? entryTs * 1000 : entryTs;
      const entryAge = nowForCheck - entryTsNorm;
      if (entryAge >= 0 && entryAge < RECENT_TRADE_WINDOW_MS) return true;
      // Check exit age — prevents immediate re-entry after close
      const exitTs = Number(t?.exit_ts) || 0;
      const exitTsNorm = exitTs > 0 && exitTs < 1e12 ? exitTs * 1000 : exitTs;
      if (exitTsNorm > 0) {
        const exitAge = nowForCheck - exitTsNorm;
        if (exitAge >= 0 && exitAge < RECENT_TRADE_WINDOW_MS) return true;
      }
      return false;
    }) || null;
    
    // ZOMBIE FIX: If trade is 100% trimmed but not formally closed, close it now.
    if (openTrade && clamp(Number(openTrade.trimmedPct || 0), 0, 1) >= 0.9999 && isOpenTradeStatus(openTrade.status)) {
      const zombiePnl = Number(openTrade.realizedPnl || openTrade.pnl || 0);
      openTrade.status = zombiePnl > 0 ? "WIN" : zombiePnl < 0 ? "LOSS" : "FLAT";
      openTrade.exitPrice = Number(openTrade.trim_price || openTrade.trimPrice || pxNow) || 0;
      openTrade.exitReason = "TP_FULL";
      openTrade.exit_ts = openTrade.trim_ts || Date.now();
      openTrade.pnl = zombiePnl;
      if (Number.isFinite(openTrade.entryPrice) && openTrade.entryPrice > 0) {
        openTrade.pnlPct = (zombiePnl / (openTrade.entryPrice * (Number(openTrade.shares) || 1))) * 100;
      }
      console.log(`[ZOMBIE FIX] ${sym} trade 100% trimmed but status was ${openTrade.status} — closed as ${openTrade.status}`);
      if (env?.DB) {
        try {
          await env.DB.prepare(`UPDATE trades SET status=?, exit_price=?, exit_reason=?, exit_ts=?, pnl=?, pnl_pct=? WHERE trade_id=?`)
            .bind(openTrade.status, openTrade.exitPrice, openTrade.exitReason, openTrade.exit_ts, openTrade.pnl, openTrade.pnlPct || 0, openTrade.trade_id || openTrade.id).run();
        } catch (e) { console.error(`[ZOMBIE FIX] D1 update failed for ${sym}:`, e); }
      }
      openTrade = null; // no longer open
    }

    // If we have an open trade from KV but no D1 context, try to use trade's SL
    if (openTrade && !openPositionContext && Number.isFinite(openTrade.sl)) {
      openPositionContext = {
        status: "OPEN",
        direction: openTrade.direction,
        sl: openTrade.sl,
        entryPrice: openTrade.entryPrice,
        avgEntry: openTrade.entryPrice,
      };
    }
    
    // ─────────────────────────────────────────────────────────────────────────
    // SECTOR ALIGNMENT: Refresh sector consensus cache (async, non-blocking).
    // This ensures qualifiesForEnter and classifyKanbanStage have fresh data.
    // During replay, skip (KV reads are expensive and sector data is stale).
    // ─────────────────────────────────────────────────────────────────────────
    if (!isReplay && KV) {
      try {
        // Fire-and-forget: compute sector alignment for this ticker's sector
        // Result is cached in _sectorAlignmentCache for sync access in pure functions
        await computeSectorAlignment(KV, sym);
      } catch { /* sector alignment is a boost, not a gate — never block on failure */ }
    }

    // ─────────────────────────────────────────────────────────────────────────
    // RE-COMPUTE KANBAN STAGE WITH POSITION CONTEXT
    // This ensures exit/trim detection uses the position's trailing SL
    // ─────────────────────────────────────────────────────────────────────────
    const storedStage = String(tickerData?.kanban_stage || "").trim().toLowerCase();
    // Always re-classify: position-aware when we have context, fresh discovery otherwise.
    // Never rely solely on stored stage — it may be stale from a prior scoring cycle.
    const recomputedStage = classifyKanbanStage(tickerData, openPositionContext || null);
    const stage = String(recomputedStage || storedStage || "").trim().toLowerCase();
    
    const prevStage = String(prevData?.kanban_stage || "")
      .trim()
      .toLowerCase();
    
    const openTradeDir =
      openTrade && String(openTrade.direction || "").toUpperCase();
    // CRITICAL: Use simulation time (asOfMs) during replay, not wall-clock time.
    // Without this, min hold timers are meaningless in replay because entries and exits
    // from different times of day are processed within milliseconds of each other.
    const now = (isReplay && Number.isFinite(asOfMs) && asOfMs > 0) ? asOfMs : Date.now();

    // Portfolio (cash gating + bookkeeping)
    let portfolio = isReplay
      ? { cash: 1e9 }
      : await getPortfolioState(KV);

    const stageTransition = stage && stage !== prevStage;
    // IMPORTANT:
    // Entering only on stage *transition* can miss entries if we don't ingest during the brief
    // window where a ticker first enters ENTER. If the ticker remains in ENTER and there
    // is still no open trade, we should re-attempt entry on subsequent ingests (cooldown + cycle guard
    // prevent churn / duplicate entries).
    // Support both new "enter" stage and legacy "enter_now" stage
    const isEnter = stage === "enter" || stage === "enter_now";
    // DEBUG: Log stage computation
    if (isReplay && (stage === "enter" || stage === "enter_now")) {
      console.log(`[REPLAY_ENTER_CHECK] ${sym} stage=${stage} storedStage=${storedStage} recomputedStage=${recomputedStage} isEnter=${isEnter} entryPath=${tickerData?.__entry_path}`);
    }
    // IMPORTANT:
    // Trimming only on stage *transition* can miss trims if we miss the first TRIM-lane ingest
    // (or if the TRIM lane persists). Use cooldown + trimmedPct guard to prevent churn.
    const isTrim = stage === "trim";
    // IMPORTANT:
    // Exiting only on stage *transition* can get stuck if we miss the first "enter exit lane"
    // ingest, or the exit is throttled by cooldown. If a ticker remains in the EXIT lane while
    // the ledger trade is still OPEN/TP_HIT_TRIM, we should re-attempt the exit on subsequent
    // ingests (cooldown prevents churn).
    const isExit = stage === "exit";

    // Idempotency / anti-flap guards (per ticker)
    // In replay mode: use in-memory Map from replayCtx.execStates (persists across intervals)
    // In live mode: use KV storage
    const execKey = `timed:exec:last:${sym}`;
    const execState = isReplay
      ? (replayCtx?.execStates?.get(sym) || {})
      : (await kvGetJSON(KV, execKey)) || {};
    const lastEnterMs = Number(execState.lastEnterMs);
    const lastTrimMs = Number(execState.lastTrimMs);
    const lastExitMs = Number(execState.lastExitMs);
    const lastEnterTriggerTs = Number(execState.lastEnterTriggerTs);
    const lastEnterSide =
      execState.lastEnterSide != null ? String(execState.lastEnterSide) : null;
    const curTriggerTs = Number(tickerData?.trigger_ts);
    // DATA: 66% of entries were within 1hr of previous on same ticker. Most were losers.
    // Increase cooldown from 10m to 4hrs to prevent rapid re-entry churn.
    const ENTER_COOLDOWN_MS = 4 * 60 * 60 * 1000; // 4 hours
    const enterCooldownOk =
      !Number.isFinite(lastEnterMs) || now - lastEnterMs >= ENTER_COOLDOWN_MS;
    const trimCooldownOk =
      !Number.isFinite(lastTrimMs) || now - lastTrimMs >= 5 * 60 * 1000; // 5m
    // Require position to be open at least N minutes before allowing first/next trim
    // DATA: Winner median hold = 3min for trims, so 10min gives room without blocking good trims
    const MIN_MINUTES_SINCE_ENTRY_BEFORE_TRIM = 10;
    // Require position to be open at least N minutes before exit
    // Phase 1b: Increased to 240min (4 hours) for swing-trade holds.
    // Swing trades need time to develop — intraday noise should not trigger exits.
    // Only exception: hard SL breach (handled separately by fuse exit logic)
    const MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT = 240;
    const entryMs =
      openTrade == null
        ? null
        : Number(openTrade.entry_ts) ||
          isoToMs(openTrade.entryTime) ||
          isoToMs(openTrade.entry_time) ||
          null;
    const entryMsNorm = entryMs != null && entryMs < 1e12 ? entryMs * 1000 : entryMs;
    const minEntryAgeMs = MIN_MINUTES_SINCE_ENTRY_BEFORE_TRIM * 60 * 1000;
    const trimMinAgeOk =
      openTrade == null ||
      !Number.isFinite(entryMsNorm) ||
      now - entryMsNorm >= minEntryAgeMs;
    // Exit minimum age: position must be open for at least 15 min before exit is allowed
    const minExitAgeMs = MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT * 60 * 1000;
    const exitMinAgeOk =
      openTrade == null ||
      !Number.isFinite(entryMsNorm) ||
      now - entryMsNorm >= minExitAgeMs;
    const exitCooldownOk =
      !Number.isFinite(lastExitMs) || now - lastExitMs >= 5 * 60 * 1000; // 5m
    const sameEnterCycle =
      Number.isFinite(curTriggerTs) &&
      curTriggerTs > 0 &&
      Number.isFinite(lastEnterTriggerTs) &&
      lastEnterTriggerTs > 0 &&
      lastEnterTriggerTs === curTriggerTs &&
      !!lastEnterSide &&
      lastEnterSide === direction;

    const pxNow = Number(tickerData?.price);
    // CRITICAL: For LIVE entries, always use the current market price.
    // tickerData.entry_price can be hours/days stale (set when signal first fired).
    // For REPLAY, use the stored entry_price since pxNow is the replay candle close.
    let entryPxCandidate;
    if (isReplay) {
      entryPxCandidate =
        Number(tickerData?.entry_price) ||
        Number(tickerData?.entry_ref) ||
        Number(tickerData?.trigger_price) ||
        pxNow ||
        null;
    } else {
      // Live mode: prefer current market price, with staleness guard
      const storedEntryPx = Number(tickerData?.entry_price);
      if (Number.isFinite(pxNow) && pxNow > 0) {
        entryPxCandidate = pxNow;
        // Log warning if stored entry_price diverges significantly from market
        if (Number.isFinite(storedEntryPx) && storedEntryPx > 0) {
          const divergePct = Math.abs(storedEntryPx - pxNow) / pxNow * 100;
          if (divergePct > 1) {
            console.warn(`[ENTRY_PRICE_STALE] ${sym}: stored entry_price=$${storedEntryPx.toFixed(2)} vs market=$${pxNow.toFixed(2)} (${divergePct.toFixed(1)}% divergence, using market)`);
          }
        }
      } else {
        entryPxCandidate = storedEntryPx || Number(tickerData?.trigger_price) || null;
      }
    }

    const move =
      tickerData?.move_status && typeof tickerData.move_status === "object"
        ? tickerData.move_status
        : null;
    const reasons = Array.isArray(move?.reasons) ? move.reasons : [];
    const reason =
      reasons.length > 0
        ? String(reasons[0])
        : stage
          ? `KANBAN_${stage.toUpperCase()}`
          : "KANBAN";

    const persistTrades = async () => {
      allTrades.sort((a, b) => {
        const timeA = new Date(a.entryTime || 0).getTime();
        const timeB = new Date(b.entryTime || 0).getTime();
        return timeB - timeA;
      });
      if (!isReplay) await kvPutJSON(KV, tradesKey, allTrades);
    };

    const upsertAlertSafe = async (alert) => {
      try {
        if (!env || isReplay) return; // Skip D1 alert writes during replay
        await d1UpsertAlert(env, alert);
      } catch (e) {
        console.error("[D1 LEDGER] alert upsert failed:", e);
      }
    };

    const closeTradeAtPrice = async (trade, closePrice, closeReason) => {
      const p = Number(closePrice);
      if (!Number.isFinite(p) || p <= 0) return;
      const trimmed = clamp(Number(trade.trimmedPct || 0), 0, 1);
      const remainingPct = Math.max(0, 1 - trimmed);
      const shares = Number(trade.shares);
      if (!Number.isFinite(shares)) return;
      const remainingShares = shares * remainingPct;

      const dirSign =
        String(trade.direction || "").toUpperCase() === "SHORT" ? -1 : 1;
      const pnlRemaining =
        (p - Number(trade.entryPrice)) *
        remainingShares *
        (Number(trade.pointValue) || 1) *
        dirSign;
      trade.realizedPnl = Number(trade.realizedPnl || 0) + pnlRemaining;

      const ev = {
        type: "EXIT",
        timestamp: eventTs(),
        price: p,
        shares: remainingShares,
        value: p * remainingShares,
        reason: closeReason,
        pnl_realized: pnlRemaining,
        note: `Exit at $${p.toFixed(2)} (${closeReason})`,
      };
      trade.history = Array.isArray(trade.history)
        ? [...trade.history, ev]
        : [ev];

      trade.exitReason = closeReason;
      trade.exitPrice = p;
      trade.exit_ts = Number.isFinite(asOfMs) ? asOfMs : (isoToMs(eventTs()) || Date.now());
      trade.status = trade.realizedPnl > 0 ? "WIN" : trade.realizedPnl < 0 ? "LOSS" : "FLAT";
      trade.pnl = trade.realizedPnl;
      trade.pnlPct =
        Number.isFinite(Number(trade.notional)) && Number(trade.notional) > 0
          ? (trade.pnl / Number(trade.notional)) * 100
          : (Number.isFinite(trade.entryPrice) && trade.entryPrice > 0
            ? (trade.pnl / (trade.entryPrice * (Number(trade.shares) || 1))) * 100
            : null);
      trade.lastUpdate = eventTs();

      // Portfolio cash increases by proceeds
      portfolio.cash = Number(portfolio.cash) + p * remainingShares;

      // Account ledger: record EXIT (cash inflow + realized P&L)
      if (!isReplay && env?.DB) {
        d1InsertLedgerEntry(env, {
          mode: "trader",
          ts: trade.exit_ts || Date.now(),
          event_type: "EXIT",
          position_id: trade.id,
          ticker: sym,
          direction: trade.direction,
          qty: remainingShares,
          price: p,
          cash_delta: p * remainingShares,
          realized_pnl: pnlRemaining,
          balance: portfolio.cash,
          note: `Exit ${sym} ${remainingShares}sh @$${p.toFixed(2)} (${closeReason}) PnL=$${pnlRemaining.toFixed(2)}`,
        }).catch(e => console.error("[LEDGER] EXIT insert failed:", e));
        d1UpdateDirectionOutcome(env, trade).catch(() => {});
      }

      // Persist via execution adapter (D1 source of truth), then Discord
      if (adapter) {
        await adapter.closePosition(sym, {
          _price: p,
          _reason: closeReason,
          _trade: trade,
          _event: ev,
          _remainingShares: remainingShares,
          _pnl: pnlRemaining,
          _isPartialClose: false,
        }).catch((e) => {
          console.error("[EXEC] closeTradeAtPrice adapter failed:", e);
        });
        
        // Clear entry state from ticker's KV record to prevent stale position showing in kanban
        // This ensures ticker returns to opportunity lanes after position closes
        try {
          const latestKey = `timed:latest:${sym}`;
          const existingPayload = await kvGetJSON(KV, latestKey);
          if (existingPayload) {
            existingPayload.entry_ts = null;
            existingPayload.entry_price = null;
            existingPayload.kanban_cycle_enter_now_ts = null;
            existingPayload.kanban_cycle_trigger_ts = null;
            existingPayload.kanban_cycle_side = null;
            // Recompute kanban stage now that position is closed
            existingPayload.move_status = computeMoveStatus(existingPayload);
            if (existingPayload.flags) {
              existingPayload.flags.move_invalidated = existingPayload.move_status?.status === "INVALIDATED";
              existingPayload.flags.move_completed = existingPayload.move_status?.status === "COMPLETED";
              existingPayload.flags.position_closed_cleared = true;
            }
            const newStage = classifyKanbanStage(existingPayload, null);
            existingPayload.kanban_stage = newStage;
            existingPayload.kanban_meta = deriveKanbanMeta(existingPayload, newStage);
            await kvPutJSON(KV, latestKey, existingPayload);
            console.log(`[TRADE SIM] ${sym} position closed: cleared entry state, stage → ${newStage}`);
          }
        } catch (clearErr) {
          console.error(`[TRADE SIM] ${sym} failed to clear entry state:`, clearErr);
        }
      }

      // Discord + D1 alert (best-effort, deduped)
      if (env && trade?.id) {
        try {
          const tsMs = Date.now();
          const dedupe = await shouldSendTradeDiscordEvent(KV, {
            tradeId: trade.id,
            type: "TRADE_EXIT",
            ts: tsMs,
          });
          if (!dedupe.deduped) {
            const embed = createTradeClosedEmbed(
              sym,
              String(trade.direction || "").toUpperCase(),
              String(trade.status || "").toUpperCase(),
              Number(trade.entryPrice),
              Number(trade.exitPrice),
              Number(trade.pnl || trade.realizedPnl || 0),
              Number(trade.pnlPct || 0),
              Number(trade.rank || 0),
              Number(trade.rr || 0),
              tickerData,
              trade,
              {
                qty: remainingShares,
                value: p * remainingShares,
                pnl: pnlRemaining,
              },
            );
            const allow = shouldSendDiscordAlert(env, "TRADE_EXIT", {
              ticker: sym,
              direction: trade.direction,
            });
            const sendRes = allow
              ? await notifyDiscord(env, embed).catch((err) => ({
                  ok: false,
                  error: String(err),
                }))
              : { ok: false, skipped: true, reason: "critical_only" };
            // In-app notification for trade exit
            ctx.waitUntil(d1InsertNotification(env, {
              email: null, type: "trade_exit",
              title: `EXIT: ${sym} ${String(trade.direction || "").toUpperCase()}`,
              body: `Closed ${sym} @ $${Number(trade.exitPrice).toFixed(2)} (P&L: ${Number(trade.pnlPct || 0) >= 0 ? "+" : ""}${Number(trade.pnlPct || 0).toFixed(1)}%, ${String(trade.status || "").toUpperCase()})`,
              link: `/simulation-dashboard.html`,
            }));
            await upsertAlertSafe({
              alert_id: buildAlertId(sym, tsMs, "TRADE_EXIT"),
              ticker: sym,
              ts: tsMs,
              side: String(trade.direction || "").toUpperCase(),
              state: tickerData?.state,
              rank: Number(trade.rank) || 0,
              rr_at_alert: Number(trade.rr) || 0,
              trigger_reason: closeReason || "TRADE_EXIT",
              dedupe_day: formatDedupDay(tsMs),
              discord_sent: !!sendRes?.ok,
              discord_status: sendRes?.status ?? null,
              discord_error: sendRes?.ok
                ? null
                : sendRes?.reason || sendRes?.statusText || sendRes?.error || null,
              payload_json: (() => {
                try {
                  return JSON.stringify(tickerData || null);
                } catch {
                  return null;
                }
              })(),
              meta_json: (() => {
                try {
                  return JSON.stringify({
                    type: "TRADE_EXIT",
                    trade_id: trade.id,
                    status: trade.status,
                    reason: closeReason,
                    exit_price: trade.exitPrice,
                  });
                } catch {
                  return null;
                }
              })(),
            });
          }
        } catch (e) {
          console.error("[KANBAN TRADE] exit discord error:", e);
        }
      }
    };

    const trimTradeToPct = async (
      trade,
      targetTrimPct,
      trimPrice,
      trimReason,
    ) => {
      const p = Number(trimPrice);
      if (!Number.isFinite(p) || p <= 0) return;
      const oldTrim = clamp(Number(trade.trimmedPct || 0), 0, 1);
      if (oldTrim >= 0.9999) return;
      const tgt = clamp(Number(targetTrimPct), 0, 1);
      if (tgt <= oldTrim + 1e-6) return;

      // Atomic CAS: verify D1 hasn't been trimmed by a parallel invocation.
      // Only proceed if D1's trimmed_pct still matches what we read.
      if (env?.DB && !isReplay && trade.trade_id) {
        try {
          const cas = await env.DB.prepare(
            `UPDATE trades SET trimmed_pct = ? WHERE trade_id = ? AND COALESCE(trimmed_pct, 0) < ?`
          ).bind(tgt, trade.trade_id, tgt - 1e-6).run();
          if (!cas?.meta?.changes) {
            console.log(`[TRIM CAS] ${sym} trim to ${(tgt * 100).toFixed(0)}% blocked — D1 already at or beyond target`);
            return;
          }
        } catch (e) {
          console.warn(`[TRIM CAS] ${sym} CAS check failed, proceeding:`, e?.message);
        }
      }
      const delta = tgt - oldTrim;
      const shares = Number(trade.shares);
      if (!Number.isFinite(shares)) return;
      const trimShares = shares * delta;

      const dirSign =
        String(trade.direction || "").toUpperCase() === "SHORT" ? -1 : 1;
      const pnlRealized =
        (p - Number(trade.entryPrice)) *
        trimShares *
        (Number(trade.pointValue) || 1) *
        dirSign;
      trade.realizedPnl = Number(trade.realizedPnl || 0) + pnlRealized;
      trade.trimmedPct = tgt;
      const isFullClose = tgt >= 0.9999 || trade.trimmedPct >= 0.9999;
      trade.status = isFullClose
        ? (trade.realizedPnl > 0 ? "WIN" : trade.realizedPnl < 0 ? "LOSS" : "FLAT")
        : tgt > 0
          ? "TP_HIT_TRIM"
          : "OPEN";
      if (isFullClose) {
        trade.exitPrice = p;
        trade.exitReason = "TP_FULL";
        trade.pnl = trade.realizedPnl;
        trade.pnlPct =
          Number.isFinite(Number(trade.notional)) && Number(trade.notional) > 0
            ? (trade.realizedPnl / Number(trade.notional)) * 100
            : (Number.isFinite(trade.entryPrice) && trade.entryPrice > 0
              ? (trade.realizedPnl / (trade.entryPrice * (Number(trade.shares) || 1))) * 100
              : null);
      }

      // ─────────────────────────────────────────────────────────────────────
      // 3-TIER SL ADJUSTMENT: Move SL based on which tier was just hit
      // ─────────────────────────────────────────────────────────────────────
      const entryPrice = Number(trade.entryPrice);
      const oldSl = Number(trade.sl);
      const dir = String(trade.direction || "").toUpperCase();
      const tpArray = Array.isArray(trade.tpArray) ? trade.tpArray : [];
      let slAdjusted = false;
      let slAdjustReason = null;

      // Update trimTiers tracking if present
      if (Array.isArray(trade.trimTiers)) {
        for (const tier of trade.trimTiers) {
          if (!tier.hit && tgt >= tier.pct) {
            tier.hit = true;
            tier.hitTs = eventTs();
          }
        }
      }

      // Tier 1: TRIM TP hit (60%) -> Move SL to Breakeven (entry price)
      if (tgt >= THREE_TIER_CONFIG.TRIM.trimPct && oldTrim < THREE_TIER_CONFIG.TRIM.trimPct) {
        if (Number.isFinite(entryPrice) && entryPrice > 0) {
          const beStop = entryPrice;
          // For LONG: only tighten if new SL is higher; for SHORT: only if lower
          const shouldTighten = dir === "LONG"
            ? beStop > oldSl || !Number.isFinite(oldSl)
            : beStop < oldSl || !Number.isFinite(oldSl);
          if (shouldTighten) {
            trade.sl = beStop;
            slAdjusted = true;
            slAdjustReason = "TRIM_TP_HIT_SL_TO_BE";
            console.log(`[3-TIER] ${sym} TRIM TP hit: SL moved to BE at $${beStop.toFixed(2)}`);
          }
        }
      }

      // Tier 2: EXIT TP hit (80%) -> Move SL to TRIM TP price
      if (tgt >= THREE_TIER_CONFIG.EXIT.trimPct && oldTrim < THREE_TIER_CONFIG.EXIT.trimPct) {
        const trimTpItem = tpArray.find(tp => tp.tier === "TRIM");
        const trimTpPrice = trimTpItem?.price;
        if (Number.isFinite(trimTpPrice) && trimTpPrice > 0) {
          // For LONG: only tighten if new SL is higher; for SHORT: only if lower
          const currentSl = Number(trade.sl);
          const shouldTighten = dir === "LONG"
            ? trimTpPrice > currentSl || !Number.isFinite(currentSl)
            : trimTpPrice < currentSl || !Number.isFinite(currentSl);
          if (shouldTighten) {
            trade.sl = trimTpPrice;
            slAdjusted = true;
            slAdjustReason = "EXIT_TP_HIT_SL_TO_TRIM_TP";
            console.log(`[3-TIER] ${sym} EXIT TP hit: SL moved to TRIM TP at $${trimTpPrice.toFixed(2)}`);
          }
        }
      }

      if (slAdjusted) {
        trade.sl_protect_reason = slAdjustReason;
        trade.sl_last_tighten_ts = eventTs();
      }

      const tsNow = eventTs();
      const ev = {
        type: "TRIM",
        timestamp: tsNow,
        price: p,
        shares: trimShares,
        value: p * trimShares,
        trimPct: tgt,
        trimDeltaPct: delta,
        reason: trimReason,
        pnl_realized: pnlRealized,
        sl_adjusted: slAdjusted,
        sl_adjust_reason: slAdjustReason,
        new_sl: slAdjusted ? trade.sl : null,
        note: `Trimmed ${Math.round(delta * 100)}% at $${p.toFixed(2)} (${trimReason})${slAdjusted ? ` - SL moved to $${trade.sl.toFixed(2)}` : ""}`,
      };
      trade.history = Array.isArray(trade.history)
        ? [...trade.history, ev]
        : [ev];
      if (isFullClose) {
        const exitEv = {
          type: "EXIT",
          timestamp: tsNow,
          price: p,
          shares: trimShares,
          value: p * trimShares,
          reason: "TP_FULL",
          pnl_realized: pnlRealized,
          note: `Closed at $${p.toFixed(2)} (TP_FULL)`,
        };
        trade.history.push(exitEv);
        trade.exit_ts = isoToMs(tsNow) || Date.now();
        if (trade.exit_ts < 1e12) trade.exit_ts = trade.exit_ts * 1000;
      }
      trade.lastUpdate = tsNow;
      trade.trim_ts = Number.isFinite(asOfMs) ? asOfMs : (isoToMs(tsNow) || null);

      // Portfolio cash increases by proceeds
      portfolio.cash = Number(portfolio.cash) + p * trimShares;

      // Account ledger: record TRIM (cash inflow + realized P&L)
      if (!isReplay && env?.DB) {
        d1InsertLedgerEntry(env, {
          mode: "trader",
          ts: ev.timestamp ? new Date(ev.timestamp).getTime() : Date.now(),
          event_type: isFullClose ? "EXIT" : "TRIM",
          position_id: trade.id,
          ticker: sym,
          direction: trade.direction,
          qty: trimShares,
          price: p,
          cash_delta: p * trimShares,
          realized_pnl: pnlRealized,
          balance: portfolio.cash,
          note: `${isFullClose ? "Exit" : "Trim"} ${sym} ${trimShares.toFixed(1)}sh @$${p.toFixed(2)} PnL=$${pnlRealized.toFixed(2)}`,
        }).catch(e => console.error("[LEDGER] TRIM insert failed:", e));
      }

      // Persist via execution adapter (D1 source of truth)
      if (adapter) {
        const exitEv = isFullClose ? trade.history.find((e) => e && e.type === "EXIT") : null;
        const tsTrim = ev.timestamp ? new Date(ev.timestamp).getTime() : Date.now();
        const newCostBasis = Number(trade.shares) * (1 - tgt) * Number(trade.entryPrice);
        await adapter.closePosition(sym, {
          _price: p,
          _reason: trimReason,
          _trade: trade,
          _event: ev,
          _exitEvent: exitEv,
          _trimShares: trimShares,
          _pnl: pnlRealized,
          _isPartialClose: true,
          _isFullClose: isFullClose,
          _positionUpdates: {
            total_qty: isFullClose ? 0 : Number(trade.shares) * (1 - tgt),
            cost_basis: isFullClose ? 0 : newCostBasis,
            updated_at: tsTrim,
            ...(isFullClose ? { status: "CLOSED", closed_at: tsTrim } : {}),
          },
        }).catch((e) => {
          console.error("[EXEC] trimTradeToPct adapter failed:", e);
        });
      }

      // Discord + D1 alert (best-effort, deduped)
      if (env && trade?.id) {
        try {
          const tsMs = Date.now();
          const dedupe = await shouldSendTradeDiscordEvent(KV, {
            tradeId: trade.id,
            type: "TRADE_TRIM",
            ts: tsMs,
          });
          if (!dedupe.deduped) {
            const dir = String(trade.direction || "").toUpperCase();
            const dirSign = dir === "SHORT" ? -1 : 1;
            const pnlPctAtTrim =
              Number.isFinite(Number(trade.entryPrice)) && Number(trade.entryPrice) > 0
                ? ((p - Number(trade.entryPrice)) / Number(trade.entryPrice)) *
                  100 *
                  dirSign
                : 0;
            const allow = shouldSendDiscordAlert(env, "TRADE_TRIM", {
              newTrimmedPct: tgt,
              trimDeltaPctRaw: delta,
            });
            const embed = createTradeTrimmedEmbed(
              sym,
              dir,
              Number(trade.entryPrice),
              Number(trade.currentPrice || p),
              Number(trade.tp || p),
              Number(pnlRealized || 0),
              Number(pnlPctAtTrim || 0),
              tgt,
              tickerData,
              trade,
              delta,
              { qty: trimShares, value: p * trimShares, pnl: pnlRealized },
            );
            const sendRes = allow
              ? await notifyDiscord(env, embed).catch((err) => ({
                  ok: false,
                  error: String(err),
                }))
              : { ok: false, skipped: true, reason: "critical_only" };
            // In-app notification for trade trim
            ctx.waitUntil(d1InsertNotification(env, {
              email: null, type: "trade_trim",
              title: `TRIM: ${sym} ${dir}`,
              body: `Trimmed ${sym} ${dir} to ${tgt}% (P&L: ${Number(pnlPctAtTrim || 0) >= 0 ? "+" : ""}${Number(pnlPctAtTrim || 0).toFixed(1)}%)`,
              link: `/index-react.html?ticker=${sym}`,
            }));
            await upsertAlertSafe({
              alert_id: buildAlertId(sym, tsMs, "TRADE_TRIM"),
              ticker: sym,
              ts: tsMs,
              side: dir,
              state: tickerData?.state,
              rank: Number(trade.rank) || 0,
              rr_at_alert: Number(trade.rr) || 0,
              trigger_reason: trimReason || "TRADE_TRIM",
              dedupe_day: formatDedupDay(tsMs),
              discord_sent: !!sendRes?.ok,
              discord_status: sendRes?.status ?? null,
              discord_error: sendRes?.ok
                ? null
                : sendRes?.reason || sendRes?.statusText || sendRes?.error || null,
              payload_json: (() => {
                try {
                  return JSON.stringify(tickerData || null);
                } catch {
                  return null;
                }
              })(),
              meta_json: (() => {
                try {
                  return JSON.stringify({
                    type: "TRADE_TRIM",
                    trade_id: trade.id,
                    trimmed_pct: tgt,
                    trim_delta_pct: delta,
                    trim_price: p,
                  });
                } catch {
                  return null;
                }
              })(),
            });
          }
        } catch (e) {
          console.error("[KANBAN TRADE] trim discord error:", e);
        }
      }
    };

    // Market is closed on weekends — never execute TP trims/exits on Sat/Sun.
    // (We still allow SL evaluation elsewhere to be conservative.)
    // During replay, use the simulation time (asOfMs) to check weekend, not wall-clock time.
    const weekendNow = isNyWeekend(isReplay && Number.isFinite(asOfMs) ? asOfMs : Date.now());

    // RTH guard: Regular Trading Hours = 9:30 AM - 4:00 PM ET.
    // ENTRIES: Restricted to RTH only.
    // EXITS/TRIMS outside RTH: Only allowed if PRICE-DRIVEN (SL breach, max-loss, TP hit).
    //   Signal-based exits (fuse, kanban, completion) are blocked outside RTH.
    //   This prevents premature trims/exits during thin pre-market/after-hours volume.
    // DEFEND (SL adjustment): SL tightening allowed outside RTH, but Discord notifications suppressed.
    // During replay, use the simulation time to check RTH.
    const entryTimeRef = isReplay && Number.isFinite(asOfMs) ? new Date(asOfMs) : new Date();
    const outsideRTH = !isNyRegularMarketOpen(entryTimeRef);

    // ═══════════════════════════════════════════════════════════════════════════
    // Phase 4a/4b/4c: FUSE EXIT ENGINE — Swing-adapted exit system
    // Fires independently of kanban stage, based on structural signals.
    // Hard fuse: extreme RSI on 1H+4H → close immediately
    // Soft fuse: arm on 1H RSI → confirm with Daily EMA break → close
    // Trailing: after TP1, trail SL using Daily EMA(21)
    // ═══════════════════════════════════════════════════════════════════════════
    let fuseExitFired = false;
    // FUSE EXITS are signal-based (RSI extremes), NOT price-driven — block outside RTH
    if (openTrade && isOpenTradeStatus(openTrade.status) && Number.isFinite(pxNow) && !weekendNow && !outsideRTH) {
      const tradeDir = String(openTrade.direction || "").toUpperCase();
      const isLong = tradeDir === "LONG";
      const entryPx = Number(openTrade.entryPrice);

      // Extract RSI values from tf_tech
      const rsi1H = tickerData?.tf_tech?.["1H"]?.rsi?.r5 ?? 50;
      const rsi4H = tickerData?.tf_tech?.["4H"]?.rsi?.r5 ?? 50;

      // Phase 4a: HARD FUSE — double confirmation extreme RSI
      const hardFuseLong = isLong && rsi1H >= 85 && rsi4H >= 80;
      const hardFuseShort = !isLong && rsi1H <= 15 && rsi4H <= 20;

      if (hardFuseLong || hardFuseShort) {
        console.log(`[FUSE EXIT] ${sym} HARD FUSE: ${isLong ? "LONG" : "SHORT"} rsi1H=${rsi1H} rsi4H=${rsi4H}`);
        tickerData.__exit_reason = `hard_fuse_rsi_extreme`;
        // Force exit regardless of kanban stage
        await closeTradeAtPrice(openTrade, pxNow, "HARD_FUSE_RSI_EXTREME");
        const fuseExecUpdate = { ...execState, lastExitMs: now };
        if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, fuseExecUpdate);
        else if (!isReplay) await kvPutJSON(KV, execKey, fuseExecUpdate);
        fuseExitFired = true;
      }

      // Phase 4b: SOFT FUSE — arm on moderate RSI, confirm with structure break
      if (!fuseExitFired) {
        const softArmLong = isLong && rsi1H >= 75;
        const softArmShort = !isLong && rsi1H <= 25;

        if (softArmLong || softArmShort) {
          // Check structural confirmation: Daily EMA(21) break or 4H SuperTrend flip
          const dailyEma21 = tickerData?.tf_tech?.D?.ema?.depth ?? 5;
          const st4HFlip = tickerData?.tf_tech?.["4H"]?.atr;
          const st4HBear = st4HFlip?.x === "bear" || st4HFlip?.xs === 1;
          const st4HBull = st4HFlip?.x === "bull" || st4HFlip?.xs === -1;
          const phaseOsc4H = tickerData?.tf_tech?.["4H"]?.ph?.v ?? 0;
          const phaseDot4H = Math.abs(phaseOsc4H) > 61.8;

          // Confirm for LONG: price broke below Daily EMA(21) OR 4H ST flipped bear OR phase leaving distribution
          const dEma21Break = isLong ? (dailyEma21 < 4) : (dailyEma21 > 6); // depth < 4 means below key EMAs
          const stConfirm = isLong ? st4HBear : st4HBull;

          if (dEma21Break || stConfirm || phaseDot4H) {
            console.log(`[FUSE EXIT] ${sym} SOFT FUSE: ${isLong ? "LONG" : "SHORT"} rsi1H=${rsi1H} dEma21Break=${dEma21Break} stConfirm=${stConfirm}`);
            tickerData.__exit_reason = `soft_fuse_rsi_confirmed`;
            await closeTradeAtPrice(openTrade, pxNow, "SOFT_FUSE_RSI_CONFIRMED");
            const fuseExecUpdate = { ...execState, lastExitMs: now };
            if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, fuseExecUpdate);
            else if (!isReplay) await kvPutJSON(KV, execKey, fuseExecUpdate);
            fuseExitFired = true;
          }
        }
      }

      // Phase 4c: DYNAMIC TRAILING STOP — trail using Daily EMA(21) after profit
      if (!fuseExitFired && Number.isFinite(entryPx) && entryPx > 0) {
        const pnlPct = isLong
          ? ((pxNow - entryPx) / entryPx) * 100
          : ((entryPx - pxNow) / entryPx) * 100;

        // Only trail after position is profitable (> 1%)
        if (pnlPct > 1.0) {
          const currentSL = Number(openTrade.sl);
          const atrD = Number(tickerData?.atr_d) || 0;

          // After TP1 hit (use completion as proxy): trail with Daily EMA(21)
          // Approximate Daily EMA(21) from tf_tech
          const dBundle = tickerData?.tf_tech?.D;
          const dEmaStructure = dBundle?.ema?.structure ?? 0;

          if (atrD > 0 && Number.isFinite(currentSL)) {
            let newSL;
            if (isLong) {
              // Trail: SL = price - 1x Daily ATR (gives room for pullbacks)
              newSL = Math.round((pxNow - 1.0 * atrD) * 100) / 100;
              // Only ratchet up, never down
              if (newSL > currentSL) {
                openTrade.sl = newSL;
                console.log(`[TRAILING SL] ${sym} LONG trail: SL ${currentSL.toFixed(2)} → ${newSL.toFixed(2)} (pnl=${pnlPct.toFixed(1)}%)`);
              }
            } else {
              // SHORT: trail SL downward
              newSL = Math.round((pxNow + 1.0 * atrD) * 100) / 100;
              if (newSL < currentSL) {
                openTrade.sl = newSL;
                console.log(`[TRAILING SL] ${sym} SHORT trail: SL ${currentSL.toFixed(2)} → ${newSL.toFixed(2)} (pnl=${pnlPct.toFixed(1)}%)`);
              }
            }
          }
        }
      }
    } else if (openTrade && isOpenTradeStatus(openTrade.status) && !weekendNow && outsideRTH) {
      // Log when fuse checks would have run but were blocked by RTH
      const rsi1H = tickerData?.tf_tech?.["1H"]?.rsi?.r5 ?? 50;
      const rsi4H = tickerData?.tf_tech?.["4H"]?.rsi?.r5 ?? 50;
      if (rsi1H >= 75 || rsi1H <= 25 || rsi4H >= 80 || rsi4H <= 20) {
        console.log(`[FUSE EXIT] ${sym} fuse check blocked: outside RTH (rsi1H=${rsi1H} rsi4H=${rsi4H}), signal-based exits wait for market open`);
        if (!isReplay && env?.DB) {
          const session = _cronCalendar ? _calGetSessionType(_calGetETMinutes()) : "CLOSED";
          d1QueueAction(env, { ticker: sym, action: "exit", direction: openTrade.direction, session, snapshot: { price: pxNow, exit_reason: `fuse_rsi_1h=${rsi1H}_4h=${rsi4H}` }, reason: "outside_RTH" });
        }
      }
    }

    // 1) EXIT: close any open trade while in EXIT lane
    // Guard: position must be open for at least MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT (4 hours)
    // to prevent rapid enter→exit churn from volatile price movements
    // CRITICAL: Verify trade is actually still open before executing (prevents ghost events on closed trades)
    // FLAT-PRICE GUARD: If exit price equals entry price (no movement), skip exit unless SL hit.
    // This prevents $0 P&L "WIN" trades from stale candle data during replay.
    const flatPriceExit = openTrade && Number.isFinite(pxNow) && Number.isFinite(Number(openTrade.entryPrice))
      && Math.abs(pxNow - Number(openTrade.entryPrice)) / Number(openTrade.entryPrice) < 0.001; // < 0.1% movement
    const exitReasonRaw = tickerData?.__exit_reason || reason || `KANBAN_EXIT`;
    const isSLExit = /\bSL\b|stop.?loss|max.?loss/i.test(String(exitReasonRaw));
    // Outside RTH: only allow price-driven exits (SL breach, max loss). Signal-based exits wait for RTH.
    const exitAllowedOutsideRTH = isSLExit;
    if (isExit && !weekendNow && (!outsideRTH || exitAllowedOutsideRTH) && exitCooldownOk && exitMinAgeOk && !fuseExitFired && openTrade && isOpenTradeStatus(openTrade.status) && clamp(Number(openTrade.trimmedPct || 0), 0, 1) < 0.9999) {
      if (flatPriceExit && !isSLExit) {
        // Price hasn't moved — keep holding instead of closing at $0 P&L
        console.log(`[TRADE SIM] ${sym} exit skipped: flat price (entry=$${Number(openTrade.entryPrice).toFixed(2)} exit=$${pxNow.toFixed(2)}), holding`);
      } else {
        await closeTradeAtPrice(openTrade, pxNow, exitReasonRaw);
        const exitExecUpdate = { ...execState, lastExitMs: now };
        if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, exitExecUpdate);
        else if (!isReplay) await kvPutJSON(KV, execKey, exitExecUpdate);
      }
    } else if (isExit && openTrade && outsideRTH && !exitAllowedOutsideRTH && !fuseExitFired) {
      console.log(`[TRADE SIM] ${sym} exit blocked: outside RTH (reason=${exitReasonRaw}), only SL/max-loss exits allowed pre/post-market`);
      if (!isReplay && env?.DB) {
        const session = _cronCalendar ? _calGetSessionType(_calGetETMinutes()) : "CLOSED";
        d1QueueAction(env, { ticker: sym, action: "exit", direction: openTrade.direction, session, snapshot: { price: pxNow, exit_reason: exitReasonRaw }, reason: weekendNow ? "weekend" : "outside_RTH" });
      }
    } else if (isExit && openTrade && !exitMinAgeOk && !fuseExitFired) {
      const ageMin = Number.isFinite(entryMsNorm) ? Math.round((now - entryMsNorm) / 60000) : 0;
      console.log(
        `[TRADE SIM] ${sym} exit blocked: position only ${ageMin}m old (min ${MIN_MINUTES_SINCE_ENTRY_BEFORE_EXIT}m)`
      );
    }

    // 2) DEFEND: Tighten SL to protect gains (warning signals, but not at extremes)
    // ─────────────────────────────────────────────────────────────────────────
    // DEFEND action: Move SL closer to entry to lock in gains or reduce loss
    // Does NOT trim - just protects the position
    // ─────────────────────────────────────────────────────────────────────────
    const isDefend = stage === "defend";
    const lastDefendMs = Number(execState.lastDefendMs);
    const defendCooldownOk = !Number.isFinite(lastDefendMs) || now - lastDefendMs >= 5 * 60 * 1000; // 5m
    
    if (isDefend && !weekendNow && defendCooldownOk && openTrade && Number.isFinite(pxNow) && clamp(Number(openTrade.trimmedPct || 0), 0, 1) < 0.9999) {
      const entryPx = Number(openTrade.entryPrice);
      const dir = String(openTrade.direction || "").toUpperCase();
      const isLong = dir === "LONG";
      const currentSL = Number(openTrade.sl);
      
      if (Number.isFinite(entryPx) && entryPx > 0) {
        // Calculate P&L to determine SL strategy
        const pnlPct = isLong
          ? ((pxNow - entryPx) / entryPx) * 100
          : ((entryPx - pxNow) / entryPx) * 100;
        
        let newSL = currentSL;
        let defendAction = null;
        
        // DATA-DRIVEN SL TIGHTENING:
        // Old thresholds (3%/1.5%) were too aggressive — avg winner was only 0.4%.
        // Widened to let winners develop before locking in breakeven.
        if (pnlPct >= 5) {
          // Strong profit >= 5%: Move SL to breakeven + 1% buffer
          // This protects meaningful gains while allowing normal retracement
          const buffer = entryPx * 0.01; // 1% buffer above breakeven
          newSL = isLong ? entryPx + buffer : entryPx - buffer;
          defendAction = "BREAKEVEN_PLUS";
        } else if (pnlPct >= 3) {
          // Good profit (3-5%): Move SL to breakeven
          // Only move to breakeven when we have a meaningful cushion
          newSL = entryPx;
          defendAction = "BREAKEVEN";
        }
        // NOTE: Removed the -2% to -5% "LIMIT_LOSS" tightening.
        // Data shows this causes premature exits. The original SL from entry
        // should handle risk management. Don't tighten on losses.
        
        // Only update if new SL is tighter (more protective)
        const slImproved = Number.isFinite(newSL) && (
          !Number.isFinite(currentSL) ||
          (isLong ? newSL > currentSL : newSL < currentSL)
        );
        
        if (slImproved && defendAction) {
          openTrade.sl = newSL;
          openTrade.lastUpdate = eventTs();
          
          // Persist SL update via execution adapter
          if (adapter) {
            await adapter.replaceOrder(`${openTrade.id}-SL`, {
              stop_price: newSL,
              _trade: openTrade,
              _reason: defendAction,
            }).catch(e => {
              console.error(`[DEFEND] ${sym} adapter.replaceOrder failed:`, e);
            });
          }
          
          console.log(
            `[DEFEND] ${sym} SL tightened: ${defendAction}, ` +
            `P&L ${pnlPct.toFixed(2)}%, SL ${currentSL?.toFixed(2) || 'none'} → $${newSL.toFixed(2)}`
          );
          
          // Discord alert for DEFEND action (daily dedup — max 1 per trade per day)
          // Suppress outside RTH for equity tickers (after-hours scoring is noisy)
          if (env && !outsideRTH) {
            try {
              const tsMs = Date.now();
              // Use date-based bucket (86400000ms = 1 day) to prevent repeated alerts
              const dedupe = await shouldSendTradeDiscordEvent(KV, {
                tradeId: openTrade.id,
                type: "TRADE_DEFEND",
                ts: tsMs,
                bucketMs: 24 * 60 * 60 * 1000,
              });
              if (!dedupe.deduped) {
                // Use unified kanban stage embed for DEFEND (replaces inline embed)
                const embed = createKanbanStageEmbed(sym, "defend", "hold", tickerData, openTrade);
                const allow = shouldSendDiscordAlert(env, "KANBAN_DEFEND", { ticker: sym });
                if (allow) {
                  await notifyDiscord(env, embed).catch(() => {});
                }
              }
            } catch (e) {
              console.error("[DEFEND] discord error:", e);
            }
          }
          
          const defendExecUpdate = { ...execState, lastDefendMs: now };
          if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, defendExecUpdate);
          else if (!isReplay) await kvPutJSON(KV, execKey, defendExecUpdate);
        }
      }
    }

    // 3) TRIM: apply progressive trim on transition into TRIM lane (only after position has been open long enough)
    // ─────────────────────────────────────────────────────────────────────────
    // 3-TIER SYSTEM: TRIM TP (60%), EXIT TP (80%), RUNNER TP (100%)
    // Trim targets are based on which TP level price has reached
    // ─────────────────────────────────────────────────────────────────────────
    // CRITICAL: Verify trade is actually still open before trimming (prevents ghost events on closed trades)
    if (isTrim && !weekendNow && trimCooldownOk && trimMinAgeOk && openTrade && isOpenTradeStatus(openTrade.status) && Number.isFinite(pxNow) && clamp(Number(openTrade.trimmedPct || 0), 0, 1) < 0.9999) {
      const tpArray = Array.isArray(openTrade.tpArray) ? openTrade.tpArray : [];
      const entryPx = Number(openTrade.entryPrice);
      const dir = String(openTrade.direction || "").toUpperCase();
      const isLong = dir === "LONG";
      
      // Find which TP level price has reached
      let target = THREE_TIER_CONFIG.TRIM.trimPct; // Default to TRIM (60%)
      let trimIsPriceDriven = false; // Track if trim is TP-hit (allowed outside RTH)
      
      if (tpArray.length > 0 && Number.isFinite(entryPx)) {
        // Check if price has reached each tier's TP
        const trimTp = tpArray.find(tp => tp.tier === "TRIM");
        const exitTp = tpArray.find(tp => tp.tier === "EXIT");
        const runnerTp = tpArray.find(tp => tp.tier === "RUNNER");
        
        const reachedTp = (tp) => {
          if (!tp || !Number.isFinite(tp.price)) return false;
          return isLong ? pxNow >= tp.price : pxNow <= tp.price;
        };
        
        if (reachedTp(runnerTp)) {
          target = THREE_TIER_CONFIG.RUNNER.trimPct; // 100%
          trimIsPriceDriven = true;
          console.log(`[3-TIER] ${sym} price $${pxNow.toFixed(2)} reached RUNNER TP $${runnerTp?.price?.toFixed(2)}`);
        } else if (reachedTp(exitTp)) {
          target = THREE_TIER_CONFIG.EXIT.trimPct; // 80%
          trimIsPriceDriven = true;
          console.log(`[3-TIER] ${sym} price $${pxNow.toFixed(2)} reached EXIT TP $${exitTp?.price?.toFixed(2)}`);
        } else if (reachedTp(trimTp)) {
          target = THREE_TIER_CONFIG.TRIM.trimPct; // 60%
          trimIsPriceDriven = true;
          console.log(`[3-TIER] ${sym} price $${pxNow.toFixed(2)} reached TRIM TP $${trimTp?.price?.toFixed(2)}`);
        } else {
          // Price hasn't reached TRIM TP yet - use completion-based approach as fallback
          // GUARD: Only allow completion-based trims when the position is actually profitable.
          // Without this, indicator signals (RSI extreme, fuel critical) can classify a position
          // as "trim" stage even when underwater, and completion >= 60% would execute the trim
          // at a loss — producing a misleading "Taking Profit" notification.
          const dirSign = isLong ? 1 : -1;
          const positionPnlPct = Number.isFinite(entryPx) && entryPx > 0
            ? ((pxNow - entryPx) / entryPx) * 100 * dirSign
            : 0;
          if (positionPnlPct <= 0) {
            console.log(`[TRADE SIM] ${sym} completion-based trim blocked: position P&L ${positionPnlPct.toFixed(2)}% (not profitable)`);
            target = 0;
          } else {
            const comp = Number(tickerData?.completion);
            const phase = Number(tickerData?.phase_pct);
            // Progressive: start with 60% trim at 90% completion to TRIM TP
            const completionToTrim = computeCompletionToTier(tickerData, "TRIM");
            if (completionToTrim >= 0.9 || (Number.isFinite(comp) && comp >= 0.6)) {
              target = THREE_TIER_CONFIG.TRIM.trimPct; // 60%
              // Completion-based trim is NOT price-driven — block outside RTH
            } else {
              // Don't trim yet if we're not close to TRIM TP
              target = 0;
            }
          }
        }
      }
      
      // Outside RTH: only allow price-driven trims (TP actually hit). Signal/completion-based trims wait for RTH.
      if (target > 0 && outsideRTH && !trimIsPriceDriven) {
        console.log(`[TRADE SIM] ${sym} trim blocked: outside RTH, non-price-driven trim (completion/signal-based), waiting for market open`);
        if (!isReplay && env?.DB) {
          const session = _cronCalendar ? _calGetSessionType(_calGetETMinutes()) : "CLOSED";
          d1QueueAction(env, { ticker: sym, action: "trim", direction: openTrade?.direction, session, snapshot: { price: pxNow, target_pct: target }, reason: weekendNow ? "weekend" : "outside_RTH" });
        }
        target = 0;
      }
      
      if (target > 0) {
        await trimTradeToPct(openTrade, target, pxNow, reason);
        const trimExecUpdate = { ...execState, lastTrimMs: now };
        if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, trimExecUpdate);
        else if (!isReplay) await kvPutJSON(KV, execKey, trimExecUpdate);
      }
    }

    // 3) ENTER: open trade while in ENTER_NOW lane
    // Entries restricted to regular market hours (9:30 AM - 4:00 PM ET)
    if (isEnter && !weekendNow && !outsideRTH && enterCooldownOk && !sameEnterCycle) {
      // If we already have an open trade in the opposite direction, close it first (flip).
      if (
        openTrade &&
        openTradeDir &&
        openTradeDir !== direction &&
        exitCooldownOk
      ) {
        await closeTradeAtPrice(openTrade, pxNow, `FLIP_${reason}`);
        const flipExecUpdate = { ...execState, lastExitMs: now };
        if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, flipExecUpdate);
        else if (!isReplay) await kvPutJSON(KV, execKey, flipExecUpdate);
        openTrade = null;
      }
    }

    // ─────────────────────────────────────────────────────────────────────────
    // SMART ENTRY GATES: Concentration, correlation, and daily safety net
    // ─────────────────────────────────────────────────────────────────────────
    // Instead of a hard MAX_OPEN_POSITIONS cap, we use intelligent gates:
    //   Gate 1: Sector concentration — max 3 positions per sector
    //   Gate 2: Directional concentration — max 5 same-direction positions
    //   Gate 3: Correlation guard — block if highly correlated with existing
    //   Safety net: MAX_DAILY_ENTRIES to prevent runaway crons
    const MAX_PER_SECTOR = 5;           // max open positions in one sector
    const MAX_SAME_DIRECTION = 12;      // max positions in same direction (long/short)
    const CORRELATION_SECTOR_THRESHOLD = 3; // if 3+ positions already in same sector, require higher quality
    const MAX_DAILY_ENTRIES = 10;       // safety net (up from 5)
    
    let smartGateBlocked = false;
    let smartGateReason = null;
    const db = env?.DB;
    // Skip smart gates during replay (processing historical data)
    if (isEnter && !weekendNow && !outsideRTH && enterCooldownOk && !sameEnterCycle && !openTrade && db && !isReplay) {
      try {
        // Query all open positions with their direction and ticker for sector lookup
        const openPosResult = await db.prepare(
          `SELECT ticker, direction FROM positions WHERE status = 'OPEN'`
        ).all();
        const openPositions = openPosResult?.results || [];
        
        // Determine candidate's direction and sector
        const entryPath = String(tickerData?.__entry_path || tickerData?.entry_path || "").toLowerCase();
        const candidateDir = entryPath.includes("short") ? "SHORT" : "LONG";
        const candidateSector = getSector(sym) || "UNKNOWN";
        
        // Gate 1: Sector concentration
        let sectorCount = 0;
        for (const pos of openPositions) {
          const posSector = getSector(String(pos.ticker).toUpperCase()) || "UNKNOWN";
          if (posSector === candidateSector && candidateSector !== "UNKNOWN") sectorCount++;
        }
        if (sectorCount >= MAX_PER_SECTOR) {
          smartGateBlocked = true;
          smartGateReason = `sector_full:${sectorCount}/${MAX_PER_SECTOR} ${candidateSector}`;
          console.log(`[SMART_GATE] Blocked ${sym}: ${smartGateReason}`);
        }
        
        // Gate 2: Directional concentration
        if (!smartGateBlocked) {
          let dirCount = 0;
          for (const pos of openPositions) {
            if (String(pos.direction).toUpperCase() === candidateDir) dirCount++;
          }
          if (dirCount >= MAX_SAME_DIRECTION) {
            smartGateBlocked = true;
            smartGateReason = `direction_full:${dirCount}/${MAX_SAME_DIRECTION} ${candidateDir}`;
            console.log(`[SMART_GATE] Blocked ${sym}: ${smartGateReason}`);
          }
        }
        
        // Gate 3: Correlation guard (sector proxy)
        // If 2+ positions already in same sector, require higher entry quality
        if (!smartGateBlocked && sectorCount >= CORRELATION_SECTOR_THRESHOLD) {
          const eqScore = Number(tickerData?.entry_quality?.score || tickerData?.__entry_quality) || 0;
          const requiredQuality = 75; // higher bar when sector is already represented
          if (eqScore > 0 && eqScore < requiredQuality) {
            smartGateBlocked = true;
            smartGateReason = `correlated:${sectorCount} in ${candidateSector}, need quality>=${requiredQuality} (got ${eqScore})`;
            console.log(`[SMART_GATE] Blocked ${sym}: ${smartGateReason}`);
          }
        }
        
        // Safety net: daily entry count
        if (!smartGateBlocked) {
          const today = new Date().toISOString().slice(0, 10);
          const dailyResult = await db.prepare(
            `SELECT COUNT(*) as cnt FROM execution_actions WHERE type = 'ENTRY' AND day = ?`
          ).bind(today).first();
          const dailyCount = Number(dailyResult?.cnt) || 0;
          if (dailyCount >= MAX_DAILY_ENTRIES) {
            smartGateBlocked = true;
            smartGateReason = `daily_limit:${dailyCount}/${MAX_DAILY_ENTRIES}`;
            console.log(`[SMART_GATE] Blocked ${sym}: ${smartGateReason}`);
          }
        }
      } catch (e) {
        console.error(`[SMART_GATE] Error checking gates: ${e.message}`);
      }
    }

    // Check VIX filter before creating new trade
    if (vixSkipReason && !openTrade) {
      console.log(`[VIX_FILTER] Skipping ${sym} entry: ${vixSkipReason}`);
      return { skipped: true, reason: vixSkipReason };
    }

    // DEBUG: Capture condition values for enter-stage tickers during replay
    const storedStageDebug = String(tickerData?.kanban_stage || "").trim().toLowerCase();
    if (isReplay && (storedStageDebug === "enter" || storedStageDebug === "enter_now") && replayCtx?.processDebug && replayCtx.processDebug.length < 5) {
      replayCtx.processDebug.push({
        ts: options?.asOfTs,
        sym,
        storedStage: storedStageDebug,
        stage,
        isEnter,
        weekendNow,
        enterCooldownOk,
        sameEnterCycle,
        openTrade: !!openTrade,
        openTradeId: openTrade?.id,
        positionLimitBlocked,
        direction,
        entryPath: tickerData?.__entry_path,
      });
    }

    // Return early if conditions not met, with debug info
    // Block if there's a recent trade (prevents rapid re-entry after immediate WIN/LOSS)
    const recentTradeBlocked = !openTrade && !!recentTrade;
    if (recentTradeBlocked) {
      console.log(`[RECENT_TRADE_BLOCKED] ${sym}: Found recent trade ${recentTrade?.id} (status=${recentTrade?.status}), blocking new entry`);
    }
    
    if (isEnter && (weekendNow || outsideRTH || !enterCooldownOk || sameEnterCycle || openTrade || recentTradeBlocked || smartGateBlocked)) {
      // ── KANBAN STAGE CORRECTION ──
      // Entry signal is valid but execution gates blocked. Downgrade the stored
      // kanban_stage from "enter" → "setup" so the UI accurately reflects that
      // the system cannot act yet.  Include the reason so the card can show why.
      const blockReasons = [];
      if (weekendNow) blockReasons.push("weekend");
      if (outsideRTH) blockReasons.push("outside_RTH");
      if (!enterCooldownOk) blockReasons.push("cooldown");
      if (sameEnterCycle) blockReasons.push("same_cycle");
      if (openTrade) blockReasons.push("existing_position");
      if (recentTradeBlocked) blockReasons.push("recent_trade");
      if (smartGateBlocked) blockReasons.push(smartGateReason || "smart_gate");
      const blockReason = blockReasons.join("+");
      console.log(`[ENTRY_BLOCKED→SETUP] ${sym} downgrading enter→setup: ${blockReason}`);
      
      // Update the live KV payload so UI sees "setup" instead of stale "enter"
      if (!isReplay && KV) {
        try {
          const latestKey = `timed:latest:${sym}`;
          const currentPayload = await kvGetJSON(KV, latestKey);
          if (currentPayload && String(currentPayload.kanban_stage).toLowerCase() === "enter") {
            currentPayload.kanban_stage = "setup";
            currentPayload.__setup_reason = `entry_qualified_but_blocked:${blockReason}`;
            currentPayload.__entry_block_reason = blockReason;
            currentPayload.kanban_meta = deriveKanbanMeta(currentPayload, "setup");
            await kvPutJSON(KV, latestKey, currentPayload);
          }
        } catch (e) {
          console.error(`[ENTRY_BLOCKED→SETUP] ${sym} KV update failed: ${e.message}`);
        }
      }

      // Queue entry for market open if blocked by time-based reasons
      if (!isReplay && env?.DB && (weekendNow || outsideRTH)) {
        const session = _cronCalendar ? _calGetSessionType(_calGetETMinutes()) : "CLOSED";
        d1QueueAction(env, {
          ticker: sym,
          action: "enter",
          direction: direction || null,
          session,
          snapshot: { price: Number(tickerData?.price), sl: Number(tickerData?.sl), tp: Number(tickerData?.tp), rank: Number(tickerData?.rank), state: tickerData?.state, entry_path: tickerData?.__entry_path },
          reason: weekendNow ? "weekend" : outsideRTH ? "outside_RTH" : "holiday",
        });
      }
    }
    if (isEnter && !weekendNow && !outsideRTH && enterCooldownOk && !sameEnterCycle && !openTrade && !recentTradeBlocked && !smartGateBlocked) {
      // Clear stale block reason from KV so UI shows "ready" immediately
      if (!isReplay && KV) {
        try {
          const latestKey = `timed:latest:${sym}`;
          const cur = await kvGetJSON(KV, latestKey);
          if (cur && (cur.__entry_block_reason || cur.__setup_reason)) {
            delete cur.__entry_block_reason;
            delete cur.__setup_reason;
            cur.__execution_ready = true;
            await kvPutJSON(KV, latestKey, cur);
          }
        } catch (_) { /* non-critical */ }
      }
      console.log(`[ENTRY_CREATE_START] ${sym} passed all gates, attempting trade creation`);
      const entryPx = Number(entryPxCandidate);
      let slCandidate = Number(tickerData?.sl ?? tickerData?.sl_price ?? tickerData?.stop_loss);
      let tpCandidate = Number(tickerData?.tp ?? tickerData?.tp_max_price ?? tickerData?.tp_target_price ?? tickerData?.tp_target);
      
      // Fallback TP calculation if missing
      if (!Number.isFinite(tpCandidate) || tpCandidate <= 0) {
        const tpFromLevels = computeTpMaxFromLevels(tickerData);
        tpCandidate = Number.isFinite(tpFromLevels) ? tpFromLevels : 0;
      }
      
      // Fallback SL calculation when TradingView doesn't provide one
      // DATA: Trades need room to breathe. 1.0x ATR was too tight (62/80 exited in <15min).
      // Using 1.5x ATR gives enough room for normal intraday noise.
      if (!Number.isFinite(slCandidate) || slCandidate <= 0) {
        const atr = Number(tickerData?.atr);
        if (Number.isFinite(atr) && atr > 0 && Number.isFinite(entryPx)) {
          slCandidate = direction === "LONG" 
            ? entryPx - (atr * 1.5) 
            : entryPx + (atr * 1.5);
        } else if (Number.isFinite(entryPx) && entryPx > 0) {
          // Fallback: 2.5% from entry (gives room for normal retracements)
          slCandidate = direction === "LONG" 
            ? entryPx * 0.975 
            : entryPx * 1.025;
        }
      }
      
      // Fallback TP if still missing: 6% from entry (2:1 R:R with 3% SL)
      if (!Number.isFinite(tpCandidate) || tpCandidate <= 0) {
        if (Number.isFinite(entryPx) && entryPx > 0) {
          tpCandidate = direction === "LONG" 
            ? entryPx * 1.06 
            : entryPx * 0.94;
        }
      }
      
      // Debug: log why trades might not be created
      const allValid = 
        Number.isFinite(entryPx) && entryPx > 0 &&
        Number.isFinite(pxNow) && pxNow > 0 &&
        Number.isFinite(slCandidate) && slCandidate > 0 &&
        Number.isFinite(tpCandidate) && tpCandidate > 0;
      
      // Capture debug for replay
      if (isReplay && replayCtx?.processDebug && replayCtx.processDebug.length < 3) {
        replayCtx.processDebug.push({
          sym,
          dir: direction,
          entryPx,
          pxNow,
          slCandidate,
          tpCandidate,
          atr: tickerData?.atr,
          allValid,
        });
      }
      if (!allValid) {
        console.log(`[TRADE ENTRY BLOCKED] ${sym} direction=${direction}:`, {
          entryPx: { value: entryPx, valid: Number.isFinite(entryPx) && entryPx > 0 },
          pxNow: { value: pxNow, valid: Number.isFinite(pxNow) && pxNow > 0 },
          slCandidate: { value: slCandidate, valid: Number.isFinite(slCandidate) && slCandidate > 0 },
          tpCandidate: { value: tpCandidate, valid: Number.isFinite(tpCandidate) && tpCandidate > 0 },
          atr: tickerData?.atr,
        });
      }
      
      if (
        Number.isFinite(entryPx) &&
        entryPx > 0 &&
        Number.isFinite(pxNow) &&
        pxNow > 0
        // Require valid SL/TP to avoid creating "unmanaged" trades
        && Number.isFinite(slCandidate) &&
        slCandidate > 0 &&
        Number.isFinite(tpCandidate) &&
        tpCandidate > 0
      ) {
        // ── Step 1: Compute SL first (needed for risk-based sizing) ──
        // Build 3-tier TP array for this trade
        const tpArray = build3TierTPArray(tickerData, entryPx, direction);
        const validTP = tpArray.length > 0 ? tpArray[0].price : tpCandidate;
        const runnerTp = tpArray.find(tp => tp.tier === "RUNNER");

        // Ensure SL is on the correct side of entry price
        if (direction === "SHORT" && Number.isFinite(slCandidate) && slCandidate < entryPx) {
          const atr = Number(tickerData?.atr);
          const slDist = entryPx - slCandidate;
          slCandidate = entryPx + slDist;
          if (Number.isFinite(atr) && atr > 0) {
            slCandidate = Math.max(slCandidate, entryPx + atr * 1.5);
          }
          console.log(`[SL_FLIP] ${sym} SHORT: flipped SL from below entry to $${slCandidate.toFixed(2)} (entry=$${entryPx.toFixed(2)})`);
        }
        if (direction === "LONG" && Number.isFinite(slCandidate) && slCandidate > entryPx) {
          const atr = Number(tickerData?.atr);
          const slDist = slCandidate - entryPx;
          slCandidate = entryPx - slDist;
          if (Number.isFinite(atr) && atr > 0) {
            slCandidate = Math.min(slCandidate, entryPx - atr * 1.5);
          }
          console.log(`[SL_FLIP] ${sym} LONG: flipped SL from above entry to $${slCandidate.toFixed(2)} (entry=$${entryPx.toFixed(2)})`);
        }

        // Apply direction-specific SL adjustment based on gold standard patterns
        const slAdjustment = computeDirectionAwareSL(tickerData, slCandidate, direction, entryPx);
        const finalSL = slAdjustment.sl;
        if (slAdjustment.adjusted) {
          console.log(`[GOLD_STANDARD_SL] ${sym} ${direction} SL adjusted: ${slCandidate.toFixed(2)} → ${finalSL.toFixed(2)} (${slAdjustment.reason})`);
        }

        const calculatedRR = (() => {
          if (!runnerTp || !Number.isFinite(finalSL) || !Number.isFinite(entryPx)) {
            return Number(tickerData?.rr) || 0;
          }
          const risk = Math.abs(entryPx - finalSL);
          const reward = Math.abs(runnerTp.price - entryPx);
          return risk > 0 ? reward / risk : 0;
        })();

        // ── Step 2: Gather sizing signals and compute confidence ──
        const sizingSignals = isReplay
          ? { mlConfidence: 0.5, winRate: 0.5, sectorAlignmentScore: 0.5, vixScore: 0.5, vixLevel: 0, sector: getSector(sym) || "UNKNOWN" }
          : await gatherSizingSignals(env, sym, tickerData, allTrades);
        const { confidence, breakdown: confidenceBreakdown } = computeTradeConfidence(tickerData, sizingSignals);

        // ── Step 3: Risk-based position sizing ──
        const cash = Number(portfolio.cash);
        const cfg = getSizingConfig(env);
        const isFuturesSym = FUTURES_SPECS[sym] || sym.endsWith("1!");
        let shares, pointValue, notional, sizingMeta;

        if (isFuturesSym && FUTURES_SPECS[sym]) {
          // Futures: always 1 contract
          shares = 1;
          pointValue = FUTURES_SPECS[sym].pointValue;
          notional = entryPx; // nominal
          sizingMeta = { method: "futures_fixed", riskPct: 0, maxDollarRisk: 0, riskPerShare: 0, vixMultiplier: 1 };
        } else if (Number.isFinite(cash) && cash >= cfg.MIN_NOTIONAL) {
          // Stocks/crypto: risk-based sizing
          const accountValue = Number(portfolio.startCash || PORTFOLIO_START_CASH) +
            (allTrades || []).filter(t => t.status === "WIN" || t.status === "LOSS").reduce((sum, t) => sum + (Number(t.realizedPnl) || 0), 0);
          const sizing = computeRiskBasedSize(confidence, accountValue, entryPx, finalSL, sizingSignals.vixLevel, env);
          // Cap by available cash
          notional = Math.min(sizing.notional, cash);
          shares = notional / entryPx;
          pointValue = 1;
          sizingMeta = sizing;
        } else {
          shares = null;
          notional = null;
          pointValue = 1;
          sizingMeta = { method: "insufficient_cash" };
        }

        if (Number.isFinite(shares) && shares > 0 && notional != null) {
            const tradeId = `${sym}-${now}-${Math.random().toString(36).substr(2, 9)}`;
            const entryTime = eventTs();
            const entryTsMs = Number.isFinite(asOfMs) ? asOfMs : (entryTime ? new Date(entryTime).getTime() : null);
            const ev = {
              type: "ENTRY",
              timestamp: entryTime,
              price: entryPx,
              shares: shares,
              value: entryPx * shares,
              reason: reason,
              note: `Entry from ENTER_NOW at $${entryPx.toFixed(2)} (${sizingMeta.method}, risk=${((sizingMeta.riskPct || 0) * 100).toFixed(1)}%)`,
            };

            const trade = {
              id: tradeId,
              ticker: sym,
              direction,
              entryPath: entryPath || null,
              entryPrice: entryPx,
              entryTime,
              entry_ts: entryTsMs || undefined,
              triggerTimestamp: Number(tickerData?.trigger_ts) || null,
              sl: finalSL,
              sl_original: slCandidate,
              sl_gs_adjusted: slAdjustment.adjusted,
              sl_gs_reason: slAdjustment.reason,
              tp: validTP,
              tpArray: tpArray,
              trimTiers: [
                { tier: "TRIM", pct: THREE_TIER_CONFIG.TRIM.trimPct, hit: false, hitTs: null },
                { tier: "EXIT", pct: THREE_TIER_CONFIG.EXIT.trimPct, hit: false, hitTs: null },
                { tier: "RUNNER", pct: THREE_TIER_CONFIG.RUNNER.trimPct, hit: false, hitTs: null },
              ],
              rr: calculatedRR,
              rank: Number(tickerData?.rank) || 0,
              state: tickerData?.state,
              flags: tickerData?.flags || {},
              scriptVersion: tickerData?.script_version || "unknown",
              status: "OPEN",
              trimmedPct: 0,
              history: [ev],
              notional: notional,
              confidence: confidence,
              confidenceBreakdown: confidenceBreakdown,
              sizing: {
                method: sizingMeta.method,
                riskPct: sizingMeta.riskPct || 0,
                maxDollarRisk: sizingMeta.maxDollarRisk || 0,
                riskPerShare: sizingMeta.riskPerShare || 0,
                vixAtEntry: sizingSignals.vixLevel || 0,
                vixMultiplier: sizingMeta.vixMultiplier || 1,
              },
              shares: shares,
              pointValue: pointValue,
              realizedPnl: 0,
              currentPrice: pxNow,
              lastUpdate: eventTs(),
              source: "KANBAN_ENTER_NOW",
              sectorAtEntry: (() => {
                const sa = getSectorAlignmentCached(sym);
                return sa ? { sector: sa.sector, aligned: sa.aligned, direction: sa.direction, strength: sa.strength } : null;
              })(),
            };

            // Portfolio cash decreases by cost
            portfolio.cash = Number(portfolio.cash) - entryPx * shares;

            // Account ledger: record ENTRY (cash outflow)
            if (!isReplay && env?.DB) {
              d1InsertLedgerEntry(env, {
                mode: "trader",
                ts: entryTsMs || Date.now(),
                event_type: "ENTRY",
                position_id: tradeId,
                ticker: sym,
                direction,
                qty: shares,
                price: entryPx,
                cash_delta: -(entryPx * shares),
                realized_pnl: 0,
                balance: portfolio.cash,
                note: `Entry ${direction} ${sym} ${shares}sh @$${entryPx.toFixed(2)}`,
              }).catch(e => console.error("[LEDGER] ENTRY insert failed:", e));
            }

            allTrades.push(trade);
            console.log(`[ENTRY_CREATED] ${sym} dir=${direction} entry=${entryPx} sl=${finalSL} tp=${validTP} shares=${shares.toFixed(2)} notional=$${notional.toFixed(0)} conf=${confidence.toFixed(2)} method=${sizingMeta.method} risk=${((sizingMeta.riskPct || 0) * 100).toFixed(1)}% isReplay=${isReplay}`);
            d1LogDirectionAccuracy(env, trade, tickerData, entryPath).catch(() => {});
            const entryExecUpdate = {
              ...execState,
              lastEnterMs: now,
              lastEnterTriggerTs:
                Number.isFinite(curTriggerTs) && curTriggerTs > 0
                  ? curTriggerTs
                  : null,
              lastEnterSide: direction,
            };
            if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, entryExecUpdate);
            else if (!isReplay) await kvPutJSON(KV, execKey, entryExecUpdate);
            // Persist via execution adapter (trade + position + lot + execution_action)
            if (adapter) {
              const tsPos = entryTsMs != null && Number.isFinite(entryTsMs) ? entryTsMs : Date.now();
              await adapter.submitOrder({
                symbol: sym,
                qty: shares,
                side: direction === "LONG" ? "buy" : "sell",
                type: "market",
                time_in_force: "gtc",
                order_class: "bracket",
                take_profit: { limit_price: validTP },
                stop_loss: { stop_price: finalSL },
                client_order_id: tradeId,
                _meta: {
                  trade,
                  position: {
                    position_id: tradeId,
                    ticker: sym,
                    direction,
                    status: "OPEN",
                    total_qty: shares,
                    cost_basis: entryPx * shares,
                    created_at: tsPos,
                    updated_at: tsPos,
                    script_version: trade.scriptVersion,
                    stop_loss: finalSL,
                    take_profit: validTP,
                  },
                },
              }).catch((e) => {
                console.error("[EXEC] ENTRY adapter.submitOrder failed:", e);
              });
            }

            // Discord + D1 alert (best-effort, deduped)
            if (env) {
              try {
                const tsMs = Date.now();
                const dedupe = await shouldSendTradeDiscordEvent(KV, {
                  tradeId,
                  type: "TRADE_ENTRY",
                  ts: tsMs,
                });
                if (!dedupe.deduped) {
                  const allow = shouldSendDiscordAlert(env, "TRADE_ENTRY", {
                    ticker: sym,
                    rr: Number(trade.rr || 0),
                    rank: Number(trade.rank || 0),
                    momentumElite: !!trade.flags?.momentum_elite,
                  });
                  const embed = createTradeEntryEmbed(
                    sym,
                    direction,
                    Number(entryPx),
                    Number(slCandidate),
                    Number(tpCandidate),
                    Number(trade.rr || 0),
                    Number(trade.rank || 0),
                    trade.state,
                    Number(pxNow),
                    false,
                    tickerData,
                    {
                      qty: Number(trade.shares),
                      value: Number(entryPx) * Number(trade.shares),
                      pnl: 0,
                    },
                  );
                  const sendRes = allow
                    ? await notifyDiscord(env, embed).catch((err) => ({
                        ok: false,
                        error: String(err),
                      }))
                    : { ok: false, skipped: true, reason: "critical_only" };
                  // In-app notification for trade entry
                  ctx.waitUntil(d1InsertNotification(env, {
                    email: null, type: "trade_entry",
                    title: `ENTRY: ${sym} ${direction}`,
                    body: `Entered ${sym} ${direction} @ $${Number(entryPx).toFixed(2)} (Rank: ${Number(trade.rank || 0)}, R:R: ${Number(trade.rr || 0).toFixed(1)})`,
                    link: `/index-react.html?ticker=${sym}`,
                  }));
                  await upsertAlertSafe({
                    alert_id: buildAlertId(sym, tsMs, "TRADE_ENTRY"),
                    ticker: sym,
                    ts: tsMs,
                    side: direction,
                    state: tickerData?.state,
                    rank: Number(trade.rank) || 0,
                    rr_at_alert: Number(trade.rr) || 0,
                    trigger_reason: reason || "TRADE_ENTRY",
                    dedupe_day: formatDedupDay(tsMs),
                    discord_sent: !!sendRes?.ok,
                    discord_status: sendRes?.status ?? null,
                    discord_error: sendRes?.ok
                      ? null
                      : sendRes?.reason ||
                        sendRes?.statusText ||
                        sendRes?.error ||
                        null,
                    payload_json: (() => {
                      try {
                        return JSON.stringify(tickerData || null);
                      } catch {
                        return null;
                      }
                    })(),
                    meta_json: (() => {
                      try {
                        return JSON.stringify({
                          type: "TRADE_ENTRY",
                          trade_id: tradeId,
                          entry_price: entryPx,
                          sl: slCandidate,
                          tp: tpCandidate,
                        });
                      } catch {
                        return null;
                      }
                    })(),
                  });
                }
              } catch (e) {
                console.error("[KANBAN TRADE] entry discord error:", e);
              }
            }

            // ── Instant transition: Enter → just_entered ──
            // Update kanban_stage immediately so the UI reflects the trade within
            // seconds (instead of waiting up to 5 min for the next scoring cron).
            if (!isReplay) {
              try {
                const latestPayload = await kvGetJSON(KV, `timed:latest:${sym}`);
                if (latestPayload && typeof latestPayload === "object") {
                  latestPayload.prev_kanban_stage = latestPayload.kanban_stage;
                  latestPayload.prev_kanban_stage_ts = Date.now();
                  latestPayload.kanban_stage = "just_entered";
                  latestPayload.entry_price = entryPx;
                  latestPayload.entry_ts = Date.now();
                  await kvPutJSON(KV, `timed:latest:${sym}`, latestPayload);
                  console.log(`[INSTANT TRANSITION] ${sym} enter → just_entered @ $${entryPx}`);
                }
              } catch (e) {
                // Non-critical — next scoring cycle will correct
                console.warn(`[INSTANT TRANSITION] ${sym} failed:`, String(e).slice(0, 100));
              }
            }
        } else {
          tickerData.flags =
            tickerData.flags && typeof tickerData.flags === "object"
              ? tickerData.flags
              : {};
          tickerData.flags.portfolio_no_cash = true;
        }
      }
    } // end of entry block

    // 4) Mark-to-market open trade (no auto TP/SL execution; Kanban lanes drive executions)
    if (openTrade && isOpenTradeStatus(openTrade.status)) {
      openTrade.currentPrice = Number.isFinite(pxNow)
        ? pxNow
        : openTrade.currentPrice;
      const mtm = computeTradePnlComponents(openTrade, tickerData);
      if (mtm.pnl != null) openTrade.pnl = mtm.pnl;
      if (mtm.pnlPct != null) openTrade.pnlPct = mtm.pnlPct;

      // Gain protection: tighten stale SL once trade is meaningfully in profit.
      // We DO NOT loosen stops; only tighten in the trade's favor.
      // ─────────────────────────────────────────────────────────────────────────
      // 3-TIER SL TRAILING: After EXIT TP (80% trimmed), use ATR-based trailing
      // ─────────────────────────────────────────────────────────────────────────
      try {
        const dir = String(openTrade.direction || "").toUpperCase();
        const entry = Number(openTrade.entryPrice);
        const mark = Number(openTrade.currentPrice);
        const oldSl = Number(openTrade.sl);
        const trimmedPct = clamp(Number(openTrade.trimmedPct || 0), 0, 1);
        const completion = Number(tickerData?.completion);
        const tpArray = Array.isArray(openTrade.tpArray) ? openTrade.tpArray : [];

        const sign = dir === "SHORT" ? -1 : 1;
        const pnlPct =
          Number.isFinite(entry) && entry > 0 && Number.isFinite(mark) && mark > 0
            ? ((mark - entry) / entry) * 100 * sign
            : NaN;

        const lastSlTightenMs = Number(execState.lastSlTightenMs);
        const slCooldownOk =
          !Number.isFinite(lastSlTightenMs) || now - lastSlTightenMs >= 15 * 60 * 1000; // 15m

        // Check if we're in RUNNER phase (80%+ trimmed)
        const isRunnerPhase = trimmedPct >= THREE_TIER_CONFIG.EXIT.trimPct;

        const shouldProtect =
          slCooldownOk &&
          !weekendNow &&
          Number.isFinite(pnlPct) &&
          (pnlPct >= 4.0 ||                           // was 2.0 — give winners more room
            trimmedPct > 0 ||
            (Number.isFinite(completion) && completion >= 0.6));

        if (shouldProtect && (dir === "LONG" || dir === "SHORT")) {
          let candidate = null;
          let slReason = "PROTECT_GAINS";

          // ─────────────────────────────────────────────────────────────────────
          // RUNNER PHASE: ATR-based trailing stop (2.5x ATR below current high)
          // ─────────────────────────────────────────────────────────────────────
          if (isRunnerPhase) {
            // Get ATR from ticker data or infer from TP levels
            let atr = Number(tickerData?.atr);
            if (!Number.isFinite(atr) || atr <= 0) {
              atr = inferAtrFromTPLevels(tickerData, entry);
            }
            if (!Number.isFinite(atr) || atr <= 0) {
              // Fallback: use 2% of entry as ATR proxy
              atr = entry * 0.02;
            }

            // ATR trailing: 2.5x ATR from current price (was 1.5x — too tight for normal volatility)
            const atrMultiplier = 2.5;
            const trailStop = dir === "LONG"
              ? mark - (atr * atrMultiplier)
              : mark + (atr * atrMultiplier);

            // Only use ATR trail if it's better than current SL
            if (dir === "LONG" && trailStop > oldSl) {
              candidate = trailStop;
              slReason = "ATR_TRAILING_RUNNER";
              console.log(`[3-TIER] ${sym} RUNNER ATR trail: $${trailStop.toFixed(2)} (2.5x ATR=$${(atr * atrMultiplier).toFixed(2)})`);
            } else if (dir === "SHORT" && trailStop < oldSl) {
              candidate = trailStop;
              slReason = "ATR_TRAILING_RUNNER";
              console.log(`[3-TIER] ${sym} RUNNER ATR trail: $${trailStop.toFixed(2)} (2.5x ATR=$${(atr * atrMultiplier).toFixed(2)})`);
            }
          }

          // ─────────────────────────────────────────────────────────────────────
          // NON-RUNNER: Standard protection logic
          // ─────────────────────────────────────────────────────────────────────
          if (!isRunnerPhase || candidate == null) {
            // Candidate 1: break-even once +5% (or after trim with gains)
            // DATA: Breakeven at +3% was too aggressive — winners need room to develop.
            // Only move to breakeven when we have a significant cushion.
            if (pnlPct >= 5.0 || (trimmedPct > 0 && pnlPct >= 2.0)) {
              candidate = entry;
            }

            // Candidate 2: use Daily EMA cloud boundary when available (acts as dynamic support/resistance)
            const dailyCloud =
              tickerData?.daily_ema_cloud && typeof tickerData.daily_ema_cloud === "object"
                ? tickerData.daily_ema_cloud
                : null;
            if (dailyCloud) {
              const upper = Number(dailyCloud.upper);
              const lower = Number(dailyCloud.lower);
              if (dir === "LONG" && Number.isFinite(lower) && lower > 0) {
                candidate = candidate == null ? lower : Math.max(candidate, lower);
              }
              if (dir === "SHORT" && Number.isFinite(upper) && upper > 0) {
                candidate = candidate == null ? upper : Math.min(candidate, upper);
              }
            }
          }

          // Bound the candidate so it remains a valid protective stop relative to current price
          let newSl = null;
          if (candidate != null && Number.isFinite(candidate) && candidate > 0) {
            if (dir === "LONG") {
              // Stop must be below current price; cap at 99.5% of mark.
              newSl = Math.min(candidate, mark * 0.995);
              // Only tighten if it moves up meaningfully.
              if (Number.isFinite(oldSl) && oldSl > 0) {
                if (newSl <= oldSl + entry * 0.0005) newSl = null;
              }
            } else if (dir === "SHORT") {
              // Stop must be above current price; floor at 100.5% of mark.
              newSl = Math.max(candidate, mark * 1.005);
              if (Number.isFinite(oldSl) && oldSl > 0) {
                if (newSl >= oldSl - entry * 0.0005) newSl = null;
              }
            }
          }

          if (newSl != null && Number.isFinite(newSl) && newSl > 0) {
            const prev = Number.isFinite(oldSl) ? oldSl : null;
            openTrade.sl = newSl;
            openTrade.sl_protect_reason = slReason;
            openTrade.sl_last_tighten_ts = eventTs();

            const ev = {
              type: "SL_TIGHTEN",
              timestamp: eventTs(),
              price: mark,
              oldSl: prev,
              newSl,
              pnlPct,
              reason: slReason,
              isRunnerPhase,
              note: isRunnerPhase
                ? `ATR trailing SL for RUNNER (${pnlPct.toFixed(2)}% unrealized)`
                : `Tightened SL to protect gains (${pnlPct.toFixed(2)}% unrealized)`,
            };
            openTrade.history = Array.isArray(openTrade.history)
              ? [...openTrade.history, ev]
              : [ev];

            // Persist SL tighten via execution adapter
            if (adapter && openTrade?.id) {
              await adapter.replaceOrder(`${openTrade.id}-SL`, {
                stop_price: newSl,
                _trade: openTrade,
                _event: ev,
                _reason: slReason,
              }).catch((e) => {
                console.error("[EXEC] SL_TIGHTEN adapter.replaceOrder failed:", e);
              });
            }
            const slExecUpdate = { ...execState, lastSlTightenMs: now };
            if (isReplay && replayCtx?.execStates) replayCtx.execStates.set(sym, slExecUpdate);
            else if (!isReplay) await kvPutJSON(KV, execKey, slExecUpdate);
          }
        }
      } catch (e) {
        console.error("[KANBAN TRADE] gain-protection SL tighten error:", e);
      }

      openTrade.lastUpdate = eventTs();
      if (env && !isReplay) {
        await d1UpsertTrade(env, openTrade).catch((e) => {
          console.error("[D1 LEDGER] mark-to-market upsert failed:", e);
        });
      }
    }

    if (!isReplay) portfolio = await putPortfolioState(KV, portfolio);
    await persistTrades();

    // Legacy price-based simulation path removed from Kanban-driven execution.
    // Keep the function returning successfully for callers.
    return;

    if (false) {
      // Check if entry price needs correction (was incorrectly set from trigger_price)
      let correctedEntryPrice = existingOpenTrade.entryPrice;
      const entryPriceCorrected =
        existingOpenTrade.entryPriceCorrected || false;

      if (!entryPriceCorrected && tickerData.price) {
        const currentEntryPrice = Number(existingOpenTrade.entryPrice);
        const currentPrice = Number(tickerData.price);
        const triggerPrice = tickerData.trigger_price
          ? Number(tickerData.trigger_price)
          : null;

        // Check if price is available and entry price differs significantly
        const priceAvailable = currentPrice > 0;
        const entryPriceDiffers =
          Math.abs(currentEntryPrice - currentPrice) / currentPrice > 0.01; // More than 1% difference

        console.log(
          `[TRADE SIM] Checking ${ticker} ${direction} entry price correction: entry=$${currentEntryPrice.toFixed(
            2,
          )}, current=$${currentPrice.toFixed(2)}, trigger=${
            triggerPrice ? "$" + triggerPrice.toFixed(2) : "null"
          }, differs=${entryPriceDiffers}, corrected=${entryPriceCorrected}`,
        );

        if (priceAvailable && entryPriceDiffers) {
          // Check if trade is old (backfill) - use entry time from trade
          const entryTime = existingOpenTrade.entryTime
            ? new Date(existingOpenTrade.entryTime).getTime()
            : null;
          const now = Date.now();
          const isOldTrade = entryTime && now - entryTime > 60 * 60 * 1000; // More than 1 hour old

          // Also check trigger timestamp if available
          const triggerTimestamp =
            tickerData.trigger_ts != null
              ? new Date(Number(tickerData.trigger_ts)).toISOString()
              : tickerData.ts != null
                ? new Date(Number(tickerData.ts)).toISOString()
                : null;
          const triggerTime = triggerTimestamp
            ? new Date(triggerTimestamp).getTime()
            : null;
          const isBackfill = triggerTime && now - triggerTime > 60 * 60 * 1000;

          // Determine if entry price was likely set incorrectly
          // Check if entry price matches trigger_price (if available) or if trade is old
          const entryMatchesTrigger =
            triggerPrice &&
            Math.abs(currentEntryPrice - triggerPrice) / triggerPrice < 0.001;

          console.log(
            `[TRADE SIM] ${ticker} correction check: isOldTrade=${isOldTrade}, isBackfill=${isBackfill}, entryMatchesTrigger=${entryMatchesTrigger}, entryTime=${existingOpenTrade.entryTime}`,
          );

          // For old trades: ALWAYS use current price (entry was likely wrong)
          // For trades where entry matches trigger_price: use current price (entry was likely wrong)
          // If entry differs significantly from current price, it's likely wrong
          if (isOldTrade || entryMatchesTrigger || entryPriceDiffers) {
            // For old trades or mismatched prices: ALWAYS use current price, never trigger_price
            correctedEntryPrice = currentPrice;
            console.log(
              `[TRADE SIM] 🔧 Correcting ${ticker} ${direction} entry price: $${currentEntryPrice.toFixed(
                2,
              )} -> $${correctedEntryPrice.toFixed(2)} (reason: ${
                isOldTrade
                  ? "old trade"
                  : entryMatchesTrigger
                    ? "matches trigger_price"
                    : "differs from current price"
              }, using current price)`,
            );
          } else if (isBackfill && triggerPrice) {
            // For backfills only (not old trades): use trigger_price if significantly different
            const priceDiff =
              Math.abs(triggerPrice - currentPrice) / currentPrice;
            if (priceDiff > 0.01) {
              // More than 1% difference - use trigger_price for backfill
              correctedEntryPrice = triggerPrice;
              console.log(
                `[TRADE SIM] 🔧 Correcting ${ticker} ${direction} entry price: $${currentEntryPrice.toFixed(
                  2,
                )} -> $${correctedEntryPrice.toFixed(
                  2,
                )} (backfill, using trigger_price)`,
              );
            } else {
              // Price is close - use current price even for backfills
              correctedEntryPrice = currentPrice;
              console.log(
                `[TRADE SIM] 🔧 Correcting ${ticker} ${direction} entry price: $${currentEntryPrice.toFixed(
                  2,
                )} -> $${correctedEntryPrice.toFixed(
                  2,
                )} (backfill, trigger_price close, using current price)`,
              );
            }
          }
        }
      }

      // Recalculate shares if entry price was corrected — uses original trade's notional or risk-based sizing
      let correctedShares = existingOpenTrade.shares;
      if (
        correctedEntryPrice !== existingOpenTrade.entryPrice &&
        !entryPriceCorrected
      ) {
        const tickerUpper = String(ticker || "").toUpperCase();
        const isFutures =
          FUTURES_SPECS[tickerUpper] || tickerUpper.endsWith("1!");
        if (isFutures && FUTURES_SPECS[tickerUpper]) {
          correctedShares = 1;
        } else {
          // Preserve the original notional value from the trade
          const originalNotional = Number(existingOpenTrade.notional) || (Number(existingOpenTrade.shares) * Number(existingOpenTrade.entryPrice)) || TRADE_SIZE;
          correctedShares = originalNotional / correctedEntryPrice;
        }
        console.log(
          `[TRADE SIM] 🔧 Recalculating ${ticker} ${direction} shares: ${existingOpenTrade.shares?.toFixed(
            4,
          )} -> ${correctedShares.toFixed(4)} (due to entry price correction)`,
        );
      }

      // Check TD Sequential exit signals BEFORE calculating P&L
      // TD Sequential only relevant on D/W/M — ignore intraday (4H and below)
      const tdSeq = tickerData.td_sequential || {};
      const tdExitTf = String(tdSeq.timeframe || tdSeq.tf || "D").toUpperCase();
      const tdExitIsHTF = ["D", "W", "M", "1D", "1W", "1M", "DAILY", "WEEKLY", "MONTHLY"].includes(tdExitTf);
      const tdSeqExitLong = tdExitIsHTF &&
        (tdSeq.exit_long === true || tdSeq.exit_long === "true");
      const tdSeqExitShort = tdExitIsHTF &&
        (tdSeq.exit_short === true || tdSeq.exit_short === "true");

      // Check if TD Sequential signals an exit for this trade direction
      let shouldExitFromTDSeq =
        (direction === "LONG" && tdSeqExitLong) ||
        (direction === "SHORT" && tdSeqExitShort);

      let tradeCalc;
      if (shouldExitFromTDSeq) {
        // Market is closed on weekends — do not exit/defend based on TDSEQ on Sat/Sun.
        if (isNyWeekend(Date.now())) {
          shouldExitFromTDSeq = false;
        }
      }

      // Avoid instant churn: ignore TDSEQ exits shortly after entry.
      if (shouldExitFromTDSeq) {
        const entryMs =
          isoToMs(existingOpenTrade?.entryTime) ||
          Number(existingOpenTrade?.entryTs) ||
          Number(existingOpenTrade?.entry_ts) ||
          isoToMs(existingOpenTrade?.entry_time) ||
          null;
        const nowMs = Number(tickerData?.ts) || Date.now();
        const ageMs = Number.isFinite(entryMs) ? nowMs - entryMs : null;
        const MIN_TDSEQ_HOLD_MS = 4 * 60 * 60 * 1000; // 4 hours (TD9 is usually a pullback; don't flinch early)
        if (Number.isFinite(ageMs) && ageMs >= 0 && ageMs < MIN_TDSEQ_HOLD_MS) {
          shouldExitFromTDSeq = false;
          // Breadcrumb for debugging / review
          await appendActivity(KV, {
            ticker,
            type: "tdseq_ignored_early",
            direction,
            age_min: Math.round(ageMs / 60000),
            min_age_min: Math.round(MIN_TDSEQ_HOLD_MS / 60000),
            td9_bullish:
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
            td9_bearish:
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
            td13_bullish:
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
            td13_bearish:
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
          });
        }
      }

      // TDSEQ should protect gains, not force exits at a loss.
      // Require (a) some profit buffer and (b) meaningful progress (phase/completion/TP progress) before allowing a TDSEQ exit.
      if (shouldExitFromTDSeq) {
        const priceNow = Number(tickerData?.price);
        const entryPx =
          Number(existingOpenTrade?.entryPrice) ||
          Number(existingOpenTrade?.entry_price) ||
          Number(tickerData?.trigger_price) ||
          Number(tickerData?.price);
        const tpPx =
          Number(existingOpenTrade?.tp) ||
          Number(existingOpenTrade?.tp_price) ||
          Number(tickerData?.tp);
        const completion = Number(tickerData?.completion);
        const phasePct = Number(tickerData?.phase_pct);

        const pnlPctNow =
          Number.isFinite(priceNow) && Number.isFinite(entryPx) && entryPx > 0
            ? direction === "LONG"
              ? ((priceNow - entryPx) / entryPx) * 100
              : ((entryPx - priceNow) / entryPx) * 100
            : null;

        let tpProgress = null;
        if (
          Number.isFinite(priceNow) &&
          Number.isFinite(entryPx) &&
          Number.isFinite(tpPx) &&
          tpPx !== entryPx
        ) {
          const raw =
            direction === "LONG"
              ? (priceNow - entryPx) / (tpPx - entryPx)
              : (entryPx - priceNow) / (entryPx - tpPx);
          tpProgress = Number.isFinite(raw)
            ? Math.max(0, Math.min(1, raw))
            : null;
        }

        const hasProfitBuffer = Number.isFinite(pnlPctNow)
          ? pnlPctNow >= 0.35
          : false; // ~35 bps
        const hasMeaningfulProgress =
          (Number.isFinite(completion) && completion >= 0.7) ||
          (Number.isFinite(phasePct) && phasePct >= 0.7) ||
          (Number.isFinite(tpProgress) && tpProgress >= 0.35);

        if (!(hasProfitBuffer && hasMeaningfulProgress)) {
          shouldExitFromTDSeq = false;
          await appendActivity(KV, {
            ticker,
            type: "tdseq_ignored_not_ready",
            direction,
            pnl_pct: Number.isFinite(pnlPctNow) ? pnlPctNow : null,
            completion: Number.isFinite(completion) ? completion : null,
            phase_pct: Number.isFinite(phasePct) ? phasePct : null,
            tp_progress: Number.isFinite(tpProgress) ? tpProgress : null,
            td9_bullish:
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
            td9_bearish:
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
            td13_bullish:
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
            td13_bearish:
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
          });
        }
      }

      if (shouldExitFromTDSeq) {
        // Higher-TF confirmation: only allow TDSEQ exits when DAILY structure confirms.
        // If DAILY doesn't confirm (or is missing), defend by tightening SL and keep holding.
        const daily = tickerData?.daily_ema_cloud || null;
        const fourH = tickerData?.fourh_ema_cloud || null;

        const dailyPos = String(daily?.position || "").toLowerCase();
        const dailyUpper = Number(daily?.upper);
        const dailyLower = Number(daily?.lower);

        const fourHPos = String(fourH?.position || "").toLowerCase();
        const fourHUpper = Number(fourH?.upper);
        const fourHLower = Number(fourH?.lower);

        const priceNow = Number(tickerData.price || 0);

        const dailyExists =
          dailyPos ||
          (Number.isFinite(dailyUpper) && dailyUpper > 0) ||
          (Number.isFinite(dailyLower) && dailyLower > 0);

        const dailyConfirmsExit =
          direction === "LONG"
            ? dailyExists &&
              (dailyPos === "below" ||
                (Number.isFinite(dailyLower) &&
                  dailyLower > 0 &&
                  priceNow < dailyLower))
            : dailyExists &&
              (dailyPos === "above" ||
                (Number.isFinite(dailyUpper) &&
                  dailyUpper > 0 &&
                  priceNow > dailyUpper));

        // If daily doesn't confirm the reversal, prefer defending (tighten SL) over exiting.
        const shouldDefend = !dailyConfirmsExit;

        const defendUpper =
          dailyExists && Number.isFinite(dailyUpper) && dailyUpper > 0
            ? dailyUpper
            : Number.isFinite(fourHUpper) && fourHUpper > 0
              ? fourHUpper
              : null;
        const defendLower =
          dailyExists && Number.isFinite(dailyLower) && dailyLower > 0
            ? dailyLower
            : Number.isFinite(fourHLower) && fourHLower > 0
              ? fourHLower
              : null;

        const canDefendLong =
          direction === "LONG" &&
          shouldDefend &&
          (dailyPos ? dailyPos !== "below" : true) &&
          Number.isFinite(defendLower) &&
          defendLower > 0;
        const canDefendShort =
          direction === "SHORT" &&
          shouldDefend &&
          (dailyPos ? dailyPos !== "above" : true) &&
          Number.isFinite(defendUpper) &&
          defendUpper > 0;

        if (canDefendLong || canDefendShort) {
          const suggestedSl = canDefendLong ? defendLower : defendUpper;
          const oldSlRaw =
            existingOpenTrade?.sl != null
              ? Number(existingOpenTrade.sl)
              : Number(tickerData?.sl);
          const oldSl = Number.isFinite(oldSlRaw) ? oldSlRaw : null;

          const tighten =
            oldSl == null
              ? true
              : direction === "LONG"
                ? suggestedSl > oldSl
                : suggestedSl < oldSl;

          if (tighten) {
            existingOpenTrade.sl = suggestedSl;
          }

          // Add activity feed event (even if no tighten, it documents the decision)
          await appendActivity(KV, {
            ticker,
            type: "tdseq_defense",
            direction,
            price: priceNow,
            old_sl: oldSl,
            new_sl: tighten ? suggestedSl : oldSl,
            cloud_pos: dailyPos || fourHPos || null,
            cloud_upper: Number.isFinite(defendUpper) ? defendUpper : null,
            cloud_lower: Number.isFinite(defendLower) ? defendLower : null,
            td9_bullish:
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
            td9_bearish:
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
            td13_bullish:
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
            td13_bearish:
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
          });

          // Discord + D1 alert — unified dedup with kanban DEFEND path
          // Only notify if the SL was actually tightened (avoids repeated alerts for same state).
          // Suppress outside RTH for equity tickers (after-hours scoring is noisy).
          // Uses daily dedup bucket (max 1 alert per trade per day).
          if (tighten && !outsideRTH) {
            try {
              const nowMs = Date.now();
              const tradeId = existingOpenTrade?.id || `${ticker}-${direction}`;
              const dedupe = await shouldSendTradeDiscordEvent(KV, {
                tradeId,
                type: "TRADE_DEFEND",
                ts: nowMs,
                bucketMs: 24 * 60 * 60 * 1000,
              });

              if (!dedupe.deduped) {
                const allow = shouldSendDiscordAlert(env, "KANBAN_DEFEND", { ticker, direction });
                if (allow) {
                  const embed = createKanbanStageEmbed(ticker, "defend", "hold", tickerData, existingOpenTrade);
                  const sendRes = await notifyDiscord(env, embed).catch((err) => {
                    console.error(`[TRADE SIM] Failed to send TDSEQ defense alert for ${ticker}:`, err);
                    return { ok: false, error: String(err) };
                  });

                  d1UpsertAlert(env, {
                    alert_id: buildAlertId(ticker, nowMs, "TDSEQ_DEFENSE"),
                    ticker,
                    ts: nowMs,
                    side: direction,
                    state: tickerData.state,
                    rank: Number(existingOpenTrade.rank) || 0,
                    rr_at_alert: Number(existingOpenTrade.rr) || 0,
                    trigger_reason: "TDSEQ_DEFENSE",
                    dedupe_day: formatDedupDay(nowMs),
                    discord_sent: !!sendRes?.ok,
                    discord_status: sendRes?.status ?? null,
                    discord_error: sendRes?.ok ? null : sendRes?.reason || sendRes?.statusText || sendRes?.error || "discord_send_failed",
                    payload_json: JSON.stringify({
                      ticker, direction, price: priceNow,
                      old_sl: oldSl, new_sl: suggestedSl,
                      cloud: dailyExists ? daily : fourH, td_sequential: tdSeq,
                    }),
                    meta_json: JSON.stringify({ kind: "tdseq_defense" }),
                  }).catch((e) => {
                    console.error(`[D1 LEDGER] Failed to upsert TDSEQ defense alert:`, e);
                  });
                }
              }
            } catch (e) {
              console.error(`[TRADE SIM] TDSEQ defense alert error:`, e);
            }
          }

          // Do not exit; continue with normal TP/SL evaluation using updated SL.
          shouldExitFromTDSeq = false;
        }

        // If DAILY doesn't confirm, do not exit (even if we couldn't tighten).
        if (shouldDefend && shouldExitFromTDSeq) {
          shouldExitFromTDSeq = false;
        }
      }

      if (shouldExitFromTDSeq) {
        console.log(
          `[TRADE SIM] 🚨 TD Sequential exit signal for ${ticker} ${direction}: ` +
            `TD9/TD13 ${
              direction === "LONG" ? "bearish" : "bullish"
            } reversal detected`,
        );

        // Force exit at current price (TD Sequential exhaustion signal)
        const currentPrice = Number(tickerData.price || 0);
        const shares = correctedShares || existingOpenTrade.shares || 0;
        let pnl = 0;
        let pnlPct = 0;

        if (direction === "LONG") {
          pnl = (currentPrice - correctedEntryPrice) * shares;
          pnlPct =
            ((currentPrice - correctedEntryPrice) / correctedEntryPrice) * 100;
        } else {
          pnl = (correctedEntryPrice - currentPrice) * shares;
          pnlPct =
            ((correctedEntryPrice - currentPrice) / correctedEntryPrice) * 100;
        }

        const tdSeqStatus = pnl >= 0 ? "WIN" : "LOSS";
        tradeCalc = {
          shares,
          pnl,
          pnlPct,
          status: tdSeqStatus,
          currentPrice,
          trimmedPct: existingOpenTrade.trimmedPct || 0,
          exitPrice: currentPrice,
          exitReason: "TDSEQ",
          exitCategory: "INVALIDATION",
        };

        // Add activity feed event for TD9 exit
        await appendActivity(KV, {
          ticker,
          type: "td9_exit",
          direction,
          side: direction === "LONG" ? "bearish" : "bullish",
          entryPrice: correctedEntryPrice,
          exitPrice: currentPrice,
          pnl,
          pnlPct,
          status: tdSeqStatus,
          td9_bullish:
            tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true",
          td9_bearish:
            tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true",
          td13_bullish:
            tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true",
          td13_bearish:
            tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true",
        });
      } else {
        // Normal TP/SL calculation
        tradeCalc = calculateTradePnl(tickerData, correctedEntryPrice, {
          ...existingOpenTrade,
          shares: correctedShares,
        });
      }

      if (tradeCalc) {
        // Ensure status matches actual P&L (fix for trades marked WIN with negative P&L)
        let newStatus =
          tradeCalc.status === "TP_HIT_TRIM" ? "TP_HIT_TRIM" : tradeCalc.status;
        if (
          (newStatus === "WIN" || newStatus === "LOSS") &&
          tradeCalc.pnl !== undefined
        ) {
          // Double-check: WIN must have positive P&L, LOSS must have negative P&L
          if (newStatus === "WIN" && tradeCalc.pnl < 0) {
            console.log(
              `[TRADE SIM] ⚠️ Correcting ${ticker} ${direction}: WIN with negative P&L (${tradeCalc.pnl.toFixed(
                2,
              )}) -> LOSS`,
            );
            newStatus = "LOSS";
          } else if (newStatus === "LOSS" && tradeCalc.pnl > 0) {
            console.log(
              `[TRADE SIM] ⚠️ Correcting ${ticker} ${direction}: LOSS with positive P&L (${tradeCalc.pnl.toFixed(
                2,
              )}) -> WIN`,
            );
            newStatus = "WIN";
          }
        }

        // Update history for trade lifecycle events (ENTRY / TRIM / EXIT)
        const history = Array.isArray(existingOpenTrade.history)
          ? [...existingOpenTrade.history]
          : [];
        const newHistoryEvents = [];

        const ensureEntryInHistory = () => {
          const hasEntry = history.some((e) => e && e.type === "ENTRY");
          if (hasEntry) return;
          history.unshift({
            type: "ENTRY",
            timestamp: existingOpenTrade.entryTime,
            price: existingOpenTrade.entryPrice,
            shares: existingOpenTrade.shares || 0,
            value:
              existingOpenTrade.entryPrice * (existingOpenTrade.shares || 0),
            note: `Initial entry at $${Number(
              existingOpenTrade.entryPrice,
            ).toFixed(2)}`,
            positionPct: 1.0,
          });
        };

        ensureEntryInHistory();

        // Add history entry if entry price was corrected
        if (
          correctedEntryPrice !== existingOpenTrade.entryPrice &&
          !entryPriceCorrected
        ) {
          const ev = {
            type: "ENTRY_CORRECTION",
            timestamp: eventTs(),
            price: correctedEntryPrice,
            shares: correctedShares,
            value: correctedEntryPrice * correctedShares,
            note: `Entry price corrected from $${existingOpenTrade.entryPrice.toFixed(
              2,
            )} to $${correctedEntryPrice.toFixed(
              2,
            )} (was incorrectly using trigger_price)`,
          };
          history.push(ev);
          newHistoryEvents.push(ev);
        }

        const oldStatus = existingOpenTrade.status || "OPEN";
        const oldTrimmedPct = Number(existingOpenTrade.trimmedPct || 0);
        const newTrimmedPct = Number(
          tradeCalc.trimmedPct != null ? tradeCalc.trimmedPct : oldTrimmedPct,
        );
        const trimDeltaPctRaw = newTrimmedPct - oldTrimmedPct;
        const EPS = 1e-6;
        const didTrim = trimDeltaPctRaw > EPS;

        // Determine prices/reasons used by the calc
        const currentPrice = Number(
          tickerData.price || tradeCalc.currentPrice || 0,
        );
        const trimPrice = Number(
          tradeCalc.trimPrice != null
            ? tradeCalc.trimPrice
            : tickerData.tp != null
              ? Number(tickerData.tp)
              : existingOpenTrade.tp,
        );
        const exitPrice = Number(
          tradeCalc.exitPrice != null ? tradeCalc.exitPrice : currentPrice,
        );
        const exitReason =
          tradeCalc.exitReason ||
          (shouldExitFromTDSeq
            ? "TDSEQ"
            : newStatus === "LOSS"
              ? "SL"
              : "TP_FULL");
        const exitCategory =
          tradeCalc.exitCategory ||
          (exitReason === "SL" || exitReason === "TDSEQ"
            ? "INVALIDATION"
            : exitReason === "TP_FULL"
              ? "PROFIT_MANAGEMENT"
              : null);

        // Add TRIM event whenever trimmedPct increases (supports progressive trims)
        if (didTrim) {
          const alreadyLogged = history.some((e) => {
            if (!e || e.type !== "TRIM") return false;
            const ePct = Number(
              e.trimPct != null
                ? e.trimPct
                : e.trimmedPct != null
                  ? e.trimmedPct
                  : 0,
            );
            return Math.abs(ePct - newTrimmedPct) < EPS;
          });

          if (!alreadyLogged) {
            const trimShares =
              (correctedShares || existingOpenTrade.shares || 0) *
              trimDeltaPctRaw; // Allow fractional shares
            const ev = {
              type: "TRIM",
              timestamp: eventTs(),
              price: Number.isFinite(trimPrice) ? trimPrice : null,
              shares: trimShares,
              value:
                Number.isFinite(trimPrice) && Number.isFinite(trimShares)
                  ? trimPrice * trimShares
                  : null,
              trimPct: newTrimmedPct, // total trimmed
              trimDeltaPct: trimDeltaPctRaw, // this trim step
              remainingPct: Math.max(0, 1 - newTrimmedPct),
              category:
                tradeCalc.decisionCategory ||
                tradeCalc.exitCategory ||
                "PROFIT_MANAGEMENT",
              note: `Trimmed ${Math.round(trimDeltaPctRaw * 100)}% at TP ${
                Number.isFinite(trimPrice)
                  ? `$${Number(trimPrice).toFixed(2)}`
                  : "—"
              } (total trimmed: ${Math.round(newTrimmedPct * 100)}%)`,
            };
            history.push(ev);
            newHistoryEvents.push(ev);
          }
        }

        // Add history entry for close
        if (
          (newStatus === "WIN" || newStatus === "LOSS") &&
          oldStatus !== "WIN" &&
          oldStatus !== "LOSS"
        ) {
          const remainingShares =
            (correctedShares || existingOpenTrade.shares || 0) *
            Math.max(0, 1 - oldTrimmedPct);
          const ev = {
            type: "EXIT",
            timestamp: eventTs(),
            price: exitPrice,
            shares: remainingShares,
            value: exitPrice * remainingShares,
            reason: exitReason,
            category: exitCategory,
            note: `Closed ${
              newStatus === "WIN" ? "profitably" : "at loss"
            } at $${Number(exitPrice).toFixed(2)} (${exitReason})`,
          };
          history.push(ev);
          newHistoryEvents.push(ev);
        }

        const updatedTrade = {
          ...existingOpenTrade,
          ...tradeCalc,
          entryPrice: correctedEntryPrice, // Use corrected entry price if it was corrected
          shares: correctedShares, // Use corrected shares if entry price was corrected
          entryPriceCorrected:
            correctedEntryPrice !== existingOpenTrade.entryPrice ||
            entryPriceCorrected, // Mark as corrected
          status: newStatus,
          trimmedPct: tradeCalc.trimmedPct || existingOpenTrade.trimmedPct || 0,
          lastUpdate: eventTs(),
          // Prefer the trade's current SL (may be tightened defensively)
          sl: Number.isFinite(Number(existingOpenTrade.sl))
            ? Number(existingOpenTrade.sl)
            : Number(tickerData.sl) || existingOpenTrade.sl,
          // Prefer the trade's TP plan (may be rebuilt after entry corrections)
          tpArray:
            tradeCalc.tpArray && Array.isArray(tradeCalc.tpArray)
              ? tradeCalc.tpArray
              : existingOpenTrade.tpArray,
          tp: (() => {
            const arr =
              tradeCalc.tpArray && Array.isArray(tradeCalc.tpArray)
                ? tradeCalc.tpArray
                : existingOpenTrade.tpArray;
            const first =
              Array.isArray(arr) && arr.length > 0
                ? arr
                    .map((x) => ({
                      price: Number(x?.price),
                      trimPct: Number(x?.trimPct),
                    }))
                    .filter(
                      (x) =>
                        Number.isFinite(x.price) && Number.isFinite(x.trimPct),
                    )
                    .sort((a, b) => a.trimPct - b.trimPct)[0]?.price
                : null;
            return Number.isFinite(first)
              ? first
              : Number(tickerData.tp) || existingOpenTrade.tp;
          })(),
          rr: (() => {
            const slVal = Number.isFinite(Number(existingOpenTrade.sl))
              ? Number(existingOpenTrade.sl)
              : Number(tickerData.sl) || existingOpenTrade.sl;
            const risk = Math.abs(correctedEntryPrice - Number(slVal));
            const arr =
              tradeCalc.tpArray && Array.isArray(tradeCalc.tpArray)
                ? tradeCalc.tpArray
                : existingOpenTrade.tpArray;
            const prices = Array.isArray(arr)
              ? arr
                  .map((x) => Number(x?.price))
                  .filter((p) => Number.isFinite(p))
              : [];
            const exitTp =
              prices.length > 0
                ? direction === "LONG"
                  ? Math.max(...prices)
                  : Math.min(...prices)
                : null;
            const gain =
              Number.isFinite(exitTp) && risk > 0
                ? direction === "LONG"
                  ? exitTp - correctedEntryPrice
                  : correctedEntryPrice - exitTp
                : null;
            const rrCalc =
              risk > 0 && gain != null && gain > 0 ? gain / risk : null;
            return rrCalc || Number(tickerData.rr) || existingOpenTrade.rr || 0;
          })(),
          rank: Number(tickerData.rank) || existingOpenTrade.rank,
          history: history,
          trim_ts: (() => {
            const trimEv = Array.isArray(newHistoryEvents) ? newHistoryEvents.find((e) => e && e.type === "TRIM") : null;
            if (trimEv) return Number.isFinite(asOfMs) ? asOfMs : (isoToMs(trimEv.timestamp) || null);
            return existingOpenTrade.trim_ts ?? null;
          })(),
          exitReason:
            newStatus === "WIN" || newStatus === "LOSS" ? exitReason : null,
          exitCategory:
            newStatus === "WIN" || newStatus === "LOSS" ? exitCategory : null,
          exitPrice:
            newStatus === "WIN" || newStatus === "LOSS" ? exitPrice : null,
          exit_ts:
            newStatus === "WIN" || newStatus === "LOSS"
              ? (Number.isFinite(asOfMs) ? asOfMs : (isoToMs(eventTs()) || Date.now()))
              : (existingOpenTrade.exit_ts ?? null),
        };

        const tradeIndex = allTrades.findIndex(
          (t) => t.id === existingOpenTrade.id,
        );
        if (tradeIndex >= 0) {
          allTrades[tradeIndex] = updatedTrade;

          // D1 first (source of truth), then KV — skip during replay (in-memory only)
          if (env && !isReplay) {
            await d1UpsertTrade(env, updatedTrade).catch((e) => {
              console.error(
                `[D1 LEDGER] Failed to upsert trade ${updatedTrade?.id}:`,
                e,
              );
            });
            if (
              updatedTrade?.id &&
              Array.isArray(newHistoryEvents) &&
              newHistoryEvents.length > 0
            ) {
              for (const ev of newHistoryEvents) {
                await d1InsertTradeEvent(env, updatedTrade.id, ev).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to insert trade event for ${updatedTrade.id}:`,
                    e,
                  );
                });
              }
            }
            if (newStatus === "WIN" || newStatus === "LOSS" || newStatus === "FLAT") {
              d1UpdateDirectionOutcome(env, updatedTrade).catch(() => {});
            }
          }
          await kvPutJSON(KV, tradesKey, allTrades);
          console.log(
            `[TRADE SIM] Updated trade ${ticker} ${direction}: ${oldStatus} -> ${newStatus}`,
          );

          // Send Discord notifications for status changes
          if (env) {
            const pnl = updatedTrade.pnl || 0;
            const pnlPct = updatedTrade.pnlPct || 0;
            const findHistoryTs = (type) => {
              if (!Array.isArray(newHistoryEvents)) return Date.now();
              for (let i = newHistoryEvents.length - 1; i >= 0; i--) {
                const ev = newHistoryEvents[i];
                if (!ev || !ev.type) continue;
                if (String(ev.type).toUpperCase() === type) {
                  const ts =
                    isoToMs(ev.timestamp) || Number(ev.ts) || Date.now();
                  return Number.isFinite(ts) ? ts : Date.now();
                }
              }
              return Date.now();
            };

            // Send TRIM alert whenever a new TRIM event was created
            if (didTrim) {
              console.log(
                `[TRADE SIM] 📢 Preparing trim alert for ${ticker} ${direction} (trimmedPct ${oldTrimmedPct} -> ${newTrimmedPct})`,
              );
              const alertTs = findHistoryTs("TRIM");
              const dedupe = await shouldSendTradeDiscordEvent(KV, {
                tradeId: updatedTrade.id,
                type: "TRADE_TRIM",
                ts: alertTs,
              });
              if (dedupe.deduped) {
                console.log(
                  `[TRADE SIM] 🔁 Deduped TRIM alert for ${ticker} ${direction} (${dedupe.key})`,
                );
              } else if (
                shouldSendDiscordAlert(env, "TRADE_TRIM", {
                  newTrimmedPct,
                  trimDeltaPctRaw,
                })
              ) {
                const trimQtySim = Number(updatedTrade.shares) * Number(trimDeltaPctRaw || 0);
                const trimPriceSim = Number.isFinite(trimPrice) ? trimPrice : Number(updatedTrade.tp);
                const embed = createTradeTrimmedEmbed(
                  ticker,
                  direction,
                  updatedTrade.entryPrice,
                  currentPrice,
                  trimPriceSim,
                  pnl,
                  pnlPct,
                  newTrimmedPct,
                  tickerData,
                  updatedTrade,
                  trimDeltaPctRaw,
                  { qty: trimQtySim, value: trimPriceSim * trimQtySim, pnl },
                );
                const sendRes = await notifyDiscord(env, embed).catch((err) => {
                  console.error(
                    `[TRADE SIM] ❌ Failed to send trim alert for ${ticker}:`,
                    err,
                  );
                  return { ok: false, error: String(err) };
                }); // Don't let Discord errors break trade updates
                // persist alert (best-effort)
                const alertPayloadJson = (() => {
                  try {
                    return JSON.stringify(tickerData);
                  } catch {
                    return null;
                  }
                })();
                const alertMetaJson = (() => {
                  try {
                    return JSON.stringify({
                      type: "TRADE_TRIM",
                      trade_id: updatedTrade.id,
                      trimmed_pct: newTrimmedPct,
                      trim_delta_pct: trimDeltaPctRaw,
                    });
                  } catch {
                    return null;
                  }
                })();
                d1UpsertAlert(env, {
                  alert_id: buildAlertId(ticker, alertTs, "TRADE_TRIM"),
                  ticker,
                  ts: alertTs,
                  side: direction,
                  state: tickerData.state,
                  rank: updatedTrade.rank,
                  rr_at_alert: updatedTrade.rr,
                  trigger_reason: "TRADE_TRIM",
                  dedupe_day: formatDedupDay(alertTs),
                  discord_sent: !!sendRes?.ok,
                  discord_status: sendRes?.status ?? null,
                  discord_error: sendRes?.ok
                    ? null
                    : sendRes?.reason ||
                      sendRes?.statusText ||
                      sendRes?.error ||
                      "discord_send_failed",
                  payload_json: alertPayloadJson,
                  meta_json: alertMetaJson,
                }).catch((e) => {
                  console.error(`[D1 LEDGER] Failed to upsert trim alert:`, e);
                });
              } else {
                console.log(
                  `[TRADE SIM] (critical-only) Skipping TRIM discord for ${ticker} (${newTrimmedPct}% total trimmed)`,
                );
              }
            }

            // EXIT Discord alert is already sent by closeTradeAtPrice() above.
            // Only send additional TD9/TD13 alert here if applicable (separate alert type).
            if (
              (newStatus === "WIN" || newStatus === "LOSS") &&
              oldStatus !== "WIN" &&
              oldStatus !== "LOSS"
            ) {
              console.log(
                `[TRADE SIM] 📢 Exit alert for ${ticker} ${direction} (${newStatus}) — handled by closeTradeAtPrice`,
              );

              // If this was a TD exit, send additional TD9/TD13 alert (separate type, not duplicate)
              if (
                shouldExitFromTDSeq &&
                shouldSendDiscordAlert(env, "TD9_EXIT", { ticker, direction })
              ) {
                console.log(
                  `[TRADE SIM] 📢 Preparing TD9 exit alert for ${ticker} ${direction}`,
                );
                const exitTs = findHistoryTs("EXIT");
                const td9Dedupe = await shouldSendTradeDiscordEvent(KV, {
                  tradeId: updatedTrade.id,
                  type: "TD9_EXIT",
                  ts: exitTs,
                });
                if (td9Dedupe.deduped) {
                  console.log(
                    `[TRADE SIM] 🔁 Deduped TD9_EXIT alert for ${ticker} ${direction} (${td9Dedupe.key})`,
                  );
                } else {
                  const td9Embed = createTradeClosedEmbed(
                    ticker,
                    direction,
                    newStatus,
                    updatedTrade.entryPrice,
                    exitPrice,
                    pnl,
                    pnlPct,
                    updatedTrade.rank || existingOpenTrade.rank || 0,
                    updatedTrade.rr || existingOpenTrade.rr || 0,
                    tickerData,
                    updatedTrade,
                  );
                  const td9Res = await notifyDiscord(env, td9Embed).catch(
                    (err) => {
                      console.error(
                        `[TRADE SIM] ❌ Failed to send TD9 exit alert for ${ticker}:`,
                        err,
                      );
                      return { ok: false, error: String(err) };
                    },
                  );
                  const exitPayloadJson = (() => { try { return JSON.stringify(tickerData); } catch { return null; } })();
                  const exitMetaJson = (() => { try { return JSON.stringify({ type: "TD9_EXIT", trade_id: updatedTrade.id, status: newStatus }); } catch { return null; } })();
                  d1UpsertAlert(env, {
                    alert_id: buildAlertId(ticker, exitTs, "TD9_EXIT"),
                    ticker,
                    ts: exitTs,
                    side: direction,
                    state: tickerData.state,
                    rank: updatedTrade.rank,
                    rr_at_alert: updatedTrade.rr,
                    trigger_reason: "TDSEQ_EXIT",
                    dedupe_day: formatDedupDay(exitTs),
                    discord_sent: !!td9Res?.ok,
                    discord_status: td9Res?.status ?? null,
                    discord_error: td9Res?.ok ? null : td9Res?.reason || td9Res?.statusText || td9Res?.error || "discord_send_failed",
                    payload_json: exitPayloadJson,
                    meta_json: exitMetaJson,
                  }).catch((e) => {
                    console.error(`[D1 LEDGER] Failed to upsert TD9 exit alert:`, e);
                  });
                }
              }
            }
          } else {
            console.log(
              `[TRADE SIM] ⚠️ Skipping Discord alert for ${ticker} ${direction} status change (${oldStatus} -> ${newStatus}) - env not available`,
            );
          }
        }
      }
    } else {
      // Check if we should create a new trade
      // ALWAYS prefer price field from TradingView for entry price
      // Only use trigger_price as fallback if price is missing or invalid
      const currentPrice = tickerData.price ? Number(tickerData.price) : null;
      const triggerPrice = tickerData.trigger_price
        ? Number(tickerData.trigger_price)
        : null;

      // Detect backfill: if trigger_ts is significantly older
      const triggerTimestamp =
        tickerData.trigger_ts != null
          ? new Date(Number(tickerData.trigger_ts)).toISOString()
          : tickerData.ts != null
            ? new Date(Number(tickerData.ts)).toISOString()
            : null;
      const now = Date.now();
      const triggerTime = triggerTimestamp
        ? new Date(triggerTimestamp).getTime()
        : null;
      const isBackfill = triggerTime && now - triggerTime > 60 * 60 * 1000; // More than 1 hour old

      let entryPrice;
      let priceSource;

      // ALWAYS use current price if available and valid (> 0)
      // For new trades, we want the entry price to reflect the CURRENT market price,
      // not a historical trigger_price, so traders see accurate entry levels
      if (currentPrice && currentPrice > 0) {
        entryPrice = currentPrice;
        priceSource = isBackfill ? "price (backfill, using current)" : "price";
        console.log(
          `[TRADE SIM] Using current price $${currentPrice.toFixed(
            2,
          )} as entry price${
            isBackfill
              ? " (backfill detected, but using current price for accuracy)"
              : " (real-time)"
          }`,
        );
      } else if (triggerPrice && triggerPrice > 0) {
        // Fallback: only use trigger_price if price is not available
        entryPrice = triggerPrice;
        priceSource = "trigger_price (fallback)";
        console.log(
          `[TRADE SIM] ⚠️ Using trigger_price $${triggerPrice.toFixed(
            2,
          )} as fallback (price not available)`,
        );
      } else {
        // No valid price available - cannot create trade
        console.log(
          `[TRADE SIM] ⚠️ Cannot create trade for ${ticker}: no valid price or trigger_price`,
        );
        return; // Exit early if no valid price
      }

      console.log(
        `[TRADE SIM] ${ticker} entry price: $${entryPrice.toFixed(
          2,
        )} (from ${priceSource}${
          isBackfill ? ", BACKFILL" : ""
        }), current price: $${Number(tickerData.price || 0).toFixed(
          2,
        )}, trigger_price: ${
          tickerData.trigger_price
            ? "$" + Number(tickerData.trigger_price).toFixed(2)
            : "null"
        }`,
      );
      const entryRR = calculateRRAtEntry(tickerData, entryPrice);

      // Create a temporary tickerData with entry RR for checking conditions
      const tickerDataForCheck = {
        ...tickerData,
        rr: entryRR, // Use entry RR instead of current RR
      };

      const shouldTrigger = shouldTriggerTradeSimulation(
        ticker,
        tickerDataForCheck,
        prevData,
      );

      // Log detailed check results for debugging
      const h = Number(tickerData.htf_score);
      const l = Number(tickerData.ltf_score);
      const state = String(tickerData.state || "");
      const alignedLong = state === "HTF_BULL_LTF_BULL";
      const alignedShort = state === "HTF_BEAR_LTF_BEAR";
      const inCorridor =
        Number.isFinite(h) &&
        Number.isFinite(l) &&
        ((h > 0 && l >= -10 && l <= 22) || (h < 0 && l >= -12 && l <= 10));
      const side =
        h > 0 && l >= -10 && l <= 22
          ? "LONG"
          : h < 0 && l >= -12 && l <= 10
            ? "SHORT"
            : null;
      const corridorAlignedOK =
        (side === "LONG" && alignedLong) || (side === "SHORT" && alignedShort);

      const flags = tickerData.flags || {};
      const momentumElite = !!flags.momentum_elite;
      const baseMinRR = 1.5;
      const minRR = momentumElite ? Math.max(1.2, baseMinRR * 0.9) : baseMinRR;

      const rrOk = (entryRR || 0) >= minRR;
      const compOk =
        (Number(tickerData.completion) || 0) <= (momentumElite ? 0.5 : 0.4);
      const phaseOk =
        (Number(tickerData.phase_pct) || 0) <= (momentumElite ? 0.7 : 0.6);

      console.log(
        `[TRADE SIM] ${ticker} ${direction}: shouldTrigger=${shouldTrigger}, entryRR=${
          entryRR?.toFixed(2) || "null"
        }, currentRR=${tickerData.rr?.toFixed(2) || "null"}, rank=${
          tickerData.rank || 0
        }, state=${state}`,
      );
      console.log(
        `[TRADE SIM] ${ticker} checks: inCorridor=${inCorridor}, corridorAlignedOK=${corridorAlignedOK}, rrOk=${rrOk} (${
          entryRR?.toFixed(2) || "null"
        } >= ${minRR}), compOk=${compOk}, phaseOk=${phaseOk}`,
      );

      if (!shouldTrigger) {
        console.log(
          `[TRADE SIM] ❌ ${ticker} ${direction}: Trade creation BLOCKED - conditions not met`,
        );
        return; // Exit early - do not create trade
      }

      if (shouldTrigger) {
        const now = Date.now();
        const recentCloseWindow = 5 * 60 * 1000; // 5 minutes

        // Check for recently closed trade (prevent rapid re-entry)
        const recentlyClosedTrade = allTrades.find(
          (t) =>
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "WIN" || t.status === "LOSS") &&
            t.entryTime &&
            now - new Date(t.entryTime).getTime() < recentCloseWindow,
        );

        // Check for existing open trade
        // Allow new position if entry price is significantly different (>5%) - enables scaling in
        const anyOpenTrade = allTrades.find(
          (t) =>
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM"),
        );

        // If open trade exists, check if entry price is significantly different
        let shouldBlockOpenTrade = false;
        if (anyOpenTrade && anyOpenTrade.entryPrice) {
          const existingEntryPrice = Number(anyOpenTrade.entryPrice);
          const priceDiffPct =
            Math.abs(entryPrice - existingEntryPrice) / existingEntryPrice;
          // Block only if entry prices are within 5% of each other (too similar to be scaling in)
          shouldBlockOpenTrade = priceDiffPct < 0.05; // 5% threshold

          if (shouldBlockOpenTrade) {
            console.log(
              `[TRADE SIM] ⚠️ ${ticker} ${direction}: Open trade exists with similar entry price (${existingEntryPrice.toFixed(
                2,
              )} vs ${entryPrice.toFixed(2)}, diff: ${(
                priceDiffPct * 100
              ).toFixed(2)}%)`,
            );
          } else {
            // Scaling in - merge into existing trade
            console.log(
              `[TRADE SIM] ℹ️ ${ticker} ${direction}: Scaling in - entry price differs significantly (${existingEntryPrice.toFixed(
                2,
              )} vs ${entryPrice.toFixed(2)}, diff: ${(
                priceDiffPct * 100
              ).toFixed(2)}%)`,
            );

            // Calculate new average entry price and total shares (risk-based sizing for scale-in)
            const existingShares = anyOpenTrade.shares || 0;
            const existingValue = existingEntryPrice * existingShares;
            const tickerUpper = String(ticker || "").toUpperCase();
            const isFutures =
              FUTURES_SPECS[tickerUpper] || tickerUpper.endsWith("1!");
            let newShares;
            if (isFutures && FUTURES_SPECS[tickerUpper]) {
              newShares = 1;
            } else {
              // Use risk-based sizing for the scale-in portion
              const scaleConfidence = anyOpenTrade.confidence || 0.5;
              const scaleSL = anyOpenTrade.sl;
              const scaleAccountVal = Number(portfolio?.startCash || PORTFOLIO_START_CASH);
              const scaleVix = anyOpenTrade.sizing?.vixAtEntry || 0;
              const scaleSizing = computeRiskBasedSize(scaleConfidence, scaleAccountVal, entryPrice, scaleSL, scaleVix, env);
              // Scale-in gets half the risk-based size (conservative add-on)
              newShares = (scaleSizing.notional / entryPrice) * 0.5;
              if (!Number.isFinite(newShares) || newShares <= 0) {
                newShares = TRADE_SIZE / entryPrice; // fallback
              }
            }
            const newValue = entryPrice * newShares;
            const totalShares = existingShares + newShares;
            const totalValue = existingValue + newValue;
            const avgEntryPrice =
              totalShares > 0 ? totalValue / totalShares : entryPrice;

            // Update existing trade with scaled-in position
            const tradeCalc = calculateTradePnl(
              tickerData,
              avgEntryPrice,
              anyOpenTrade,
            );
            if (tradeCalc) {
              // Add history entry for scaling in
              const history = anyOpenTrade.history || [
                {
                  type: "ENTRY",
                  timestamp: anyOpenTrade.entryTime,
                  price: existingEntryPrice,
                  shares: existingShares,
                  value: existingValue,
                  note: `Initial entry at $${existingEntryPrice.toFixed(2)}`,
                },
              ];

              history.push({
                type: "SCALE_IN",
                timestamp: eventTs(),
                price: entryPrice,
                shares: newShares,
                value: newValue,
                note: `Scaled in at $${entryPrice.toFixed(
                  2,
                )} (avg entry now $${avgEntryPrice.toFixed(2)})`,
              });

              const updatedTrade = {
                ...anyOpenTrade,
                entryPrice: avgEntryPrice, // Update to average entry price
                shares: totalShares,
                ...tradeCalc,
                history: history,
                lastUpdate: eventTs(),
              };

              const tradeIndex = allTrades.findIndex(
                (t) => t.id === anyOpenTrade.id,
              );
              if (tradeIndex >= 0) {
                allTrades[tradeIndex] = updatedTrade;

                // D1 first (source of truth), then KV — skip during replay
                if (env && !isReplay) {
                  await d1UpsertTrade(env, updatedTrade).catch((e) => {
                    console.error(
                      `[D1 LEDGER] Failed to upsert scaled-in trade:`,
                      e,
                    );
                  });
                  const scaleEvent = history[history.length - 1];
                  if (scaleEvent && updatedTrade?.id) {
                    await d1InsertTradeEvent(env, updatedTrade.id, scaleEvent).catch(
                      (e) => {
                        console.error(
                          `[D1 LEDGER] Failed to insert SCALE_IN event:`,
                          e,
                        );
                      },
                    );
                  }
                  // Phase 2: ADD_ENTRY (new lot + action, update position)
                  const posId = anyOpenTrade.id;
                  const tsScale = scaleEvent?.timestamp ? new Date(scaleEvent.timestamp).getTime() : Date.now();
                  const lotIdScale = `${posId}-lot-${tsScale}`;
                  const actionIdScale = `${posId}-ADD_ENTRY-${tsScale}`;
                  await d1InsertLot(env, {
                    lot_id: lotIdScale,
                    position_id: posId,
                    ts: tsScale,
                    qty: newShares,
                    price: entryPrice,
                    value: newValue,
                    remaining_qty: newShares,
                  }).catch(() => {});
                  await d1InsertExecutionAction(env, {
                    action_id: actionIdScale,
                    position_id: posId,
                    ts: tsScale,
                    action_type: "ADD_ENTRY",
                    qty: newShares,
                    price: entryPrice,
                    value: newValue,
                    pnl_realized: null,
                    reason: "SCALE_IN",
                  }).catch(() => {});
                  await d1UpdatePosition(env, posId, {
                    total_qty: totalShares,
                    cost_basis: totalShares * avgEntryPrice,
                    updated_at: tsScale,
                  }).catch(() => {});
                }
                await kvPutJSON(KV, tradesKey, allTrades);
                console.log(
                  `[TRADE SIM] ✅ Scaled in ${ticker} ${direction} - Avg Entry: $${avgEntryPrice.toFixed(
                    2,
                  )}, Total Shares: ${totalShares}`,
                );

                // Send Discord notification for scaling in
                if (env) {
                  const scalePnlLabel = (tradeCalc.pnl ?? 0) >= 0 ? `+$${(tradeCalc.pnl ?? 0).toFixed(2)}` : `-$${Math.abs(tradeCalc.pnl ?? 0).toFixed(2)}`;
                  const scalePctLabel = `${(tradeCalc.pnlPct ?? 0) >= 0 ? "+" : ""}${(tradeCalc.pnlPct ?? 0).toFixed(2)}%`;
                  const embed = {
                    title: `📈  Scaled In: ${ticker} ${direction}`,
                    description: `Added to position at **$${entryPrice.toFixed(2)}**. Average entry now **$${avgEntryPrice.toFixed(2)}** with **${totalShares}** shares.`,
                    color: 0x3b82f6,
                    fields: [
                      {
                        name: "Position",
                        value: `New Entry:  **$${entryPrice.toFixed(2)}**\nAvg Entry:  **$${avgEntryPrice.toFixed(2)}**\nShares:  **${totalShares}**`,
                        inline: false,
                      },
                      {
                        name: "Current",
                        value: `Price:  **$${Number(tickerData.price).toFixed(2)}**\nP&L:  **${scalePnlLabel}** (${scalePctLabel})`,
                        inline: false,
                      },
                    ],
                    footer: {
                      text: "Timed Trading Simulator",
                    },
                    timestamp: new Date().toISOString(),
                  };
                  if (
                    shouldSendDiscordAlert(env, "SYSTEM", {
                      ticker,
                      kind: "trade_merge",
                    })
                  ) {
                    await notifyDiscord(env, embed).catch(() => {});
                  }
                }
              }
            }

            // Don't create a new trade - we've merged into existing
            return;
          }
        } else if (anyOpenTrade) {
          // Open trade exists but no entry price - block to be safe
          shouldBlockOpenTrade = true;
        }

        // Check for closed trades on subsequent days with similar entry price
        // Allow scaling/pyramiding if price differs significantly (>2%), but block if price is nearly the same
        const priceThreshold = entryPrice * 0.02; // 2% threshold for "nearly the same"
        const today = new Date(now);
        today.setHours(0, 0, 0, 0);
        const todayStart = today.getTime();

        // Find closed trades from previous days (not today) with similar entry price
        const similarPriceClosedTrade = allTrades.find((t) => {
          if (
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "WIN" || t.status === "LOSS") &&
            t.entryPrice &&
            t.entryTime
          ) {
            const entryDate = new Date(t.entryTime);
            entryDate.setHours(0, 0, 0, 0);
            const entryDayStart = entryDate.getTime();

            // Only check trades from previous days (not today)
            const isPreviousDay = entryDayStart < todayStart;

            // Check if price is nearly the same (within 2%)
            const priceDiff = Math.abs(Number(t.entryPrice) - entryPrice);
            const isSimilarPrice = priceDiff < priceThreshold;

            return isPreviousDay && isSimilarPrice;
          }
          return false;
        });

        // Check for open trades with similar price (existing logic - keep this)
        const similarPriceOpenTrade = allTrades.find(
          (t) =>
            t.ticker === ticker &&
            t.direction === direction &&
            (t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM") &&
            t.entryPrice &&
            Math.abs(Number(t.entryPrice) - entryPrice) < priceThreshold,
        );

        // Log why trade was rejected if applicable
        if (recentlyClosedTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - recently closed trade (within 5 min)`,
          );
        } else if (shouldBlockOpenTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - open trade already exists with similar entry price`,
          );
        } else if (similarPriceOpenTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - open trade exists with similar entry price (${Number(
              similarPriceOpenTrade.entryPrice,
            ).toFixed(2)} vs ${entryPrice.toFixed(2)}, diff: ${(
              (Math.abs(Number(similarPriceOpenTrade.entryPrice) - entryPrice) /
                entryPrice) *
              100
            ).toFixed(2)}%)`,
          );
        } else if (similarPriceClosedTrade) {
          console.log(
            `[TRADE SIM] ⚠️ ${ticker} ${direction}: Skipping - closed trade from previous day with similar entry price (${Number(
              similarPriceClosedTrade.entryPrice,
            ).toFixed(2)} vs ${entryPrice.toFixed(2)}, diff: ${(
              (Math.abs(
                Number(similarPriceClosedTrade.entryPrice) - entryPrice,
              ) /
                entryPrice) *
              100
            ).toFixed(2)}%, closed: ${similarPriceClosedTrade.entryTime})`,
          );
        } else {
          // Price differs significantly or no similar trade found - allow scaling/pyramiding
          if (similarPriceClosedTrade === undefined && anyOpenTrade) {
            console.log(
              `[TRADE SIM] ℹ️ ${ticker} ${direction}: Price differs significantly from previous day's closed trade - allowing scaling/pyramiding`,
            );
          }
        }

        if (
          !recentlyClosedTrade &&
          !shouldBlockOpenTrade &&
          !similarPriceOpenTrade &&
          !similarPriceClosedTrade
        ) {
          const tradeCalc = calculateTradePnl(tickerData, entryPrice);

          if (tradeCalc) {
            console.log(
              `[TRADE SIM] ✅ Creating new trade ${ticker} ${direction} - Entry: $${entryPrice.toFixed(
                2,
              )}, RR: ${entryRR?.toFixed(2) || "N/A"}`,
            );
            // Determine entry time: use ingest ts when reprocessing/replay (not replay run time)
            const entryTsMs =
              Number.isFinite(asOfMs)
                ? asOfMs
                : forceUseIngestTs && tickerData?.ts != null
                  ? (Number(tickerData.ts) < 1e12 ? Number(tickerData.ts) * 1000 : Number(tickerData.ts))
                  : forceUseIngestTs && triggerTimestamp
                    ? new Date(triggerTimestamp).getTime()
                    : isBackfill && triggerTimestamp
                      ? new Date(triggerTimestamp).getTime()
                      : Date.now();
            const entryTime = new Date(entryTsMs).toISOString();

            // ─────────────────────────────────────────────────────────────────────
            // BUILD 3-TIER TP ARRAY (TRIM 60%, EXIT 80%, RUNNER 100%)
            // ─────────────────────────────────────────────────────────────────────
            const tpArray = build3TierTPArray(
              tickerData,
              entryPrice,
              direction,
            );
            if (tpArray.length === 0) {
              console.error(
                `[TRADE SIM] ❌ ${ticker} ${direction}: Cannot create trade - no valid TP array found`,
              );
              return; // Exit early if no valid TP array
            }

            // Use first TP (TRIM level, 60%) as primary TP for backward compatibility
            const validTP = tpArray[0].price;

            // Calculate RR using RUNNER TP (max/furthest) from array
            const runnerTp = tpArray.find(tp => tp.tier === "RUNNER");
            const maxTP = runnerTp?.price || Math.max(...tpArray.map((tp) => tp.price));
            const baseSL = Number(tickerData.sl);
            
            // Apply direction-specific SL adjustment based on gold standard patterns
            const slAdjustment = computeDirectionAwareSL(tickerData, baseSL, direction, entryPrice);
            const finalSL = slAdjustment.sl;
            if (slAdjustment.adjusted) {
              console.log(`[GOLD_STANDARD_SL] ${ticker} ${direction} SL adjusted: ${baseSL.toFixed(2)} → ${finalSL.toFixed(2)} (${slAdjustment.reason})`);
            }
            
            const risk = Math.abs(entryPrice - finalSL);
            const gain =
              direction === "LONG" ? maxTP - entryPrice : entryPrice - maxTP;
            const calculatedRR = risk > 0 && gain > 0 ? gain / risk : null;

            // Log the 3-tier TP array for debugging
            console.log(`[3-TIER] ${ticker} ${direction} TP array:`, tpArray.map(tp => 
              `${tp.tier} $${tp.price.toFixed(2)} (${Math.round(tp.trimPct * 100)}%)`
            ).join(", "));

            const trade = {
              id: `${ticker}-${now}-${Math.random().toString(36).substr(2, 9)}`,
              ticker,
              direction,
              entryPath: entryPath || null,  // Track which entry criteria was used
              entryPrice,
              entryTime, // When trade was actually created (ingest time in replay)
              entry_ts: entryTsMs, // Numeric ms for D1/display (ingest time, not replay run time)
              triggerTimestamp: triggerTimestamp, // When signal was generated (for reference)
              sl: finalSL,
              sl_original: baseSL,
              sl_gs_adjusted: slAdjustment.adjusted,
              sl_gs_reason: slAdjustment.reason,
              tp: validTP, // Primary TP (TRIM level, 60% off)
              tpArray: tpArray, // Store full 3-tier TP array
              // Track which tiers have been hit
              trimTiers: [
                { tier: "TRIM", pct: THREE_TIER_CONFIG.TRIM.trimPct, hit: false, hitTs: null },
                { tier: "EXIT", pct: THREE_TIER_CONFIG.EXIT.trimPct, hit: false, hitTs: null },
                { tier: "RUNNER", pct: THREE_TIER_CONFIG.RUNNER.trimPct, hit: false, hitTs: null },
              ],
              rr: calculatedRR || entryRR || Number(tickerData.rr) || 0, // Use calculated RR from RUNNER TP
              rank: Number(tickerData.rank) || 0,
              state: tickerData.state,
              flags: tickerData.flags || {},
              scriptVersion: tickerData.script_version || "unknown",
              trimmedPct: 0, // Start with 0% trimmed
              // Trade history/audit trail
              history: [
                {
                  type: "ENTRY",
                  timestamp: entryTime,
                  price: entryPrice,
                  shares: tradeCalc.shares || 0,
                  value: entryPrice * (tradeCalc.shares || 0),
                  note: `Initial entry at $${entryPrice.toFixed(2)}${
                    triggerTimestamp
                      ? ` (signal: ${new Date(
                          triggerTimestamp,
                        ).toLocaleString()})`
                      : ""
                  }`,
                },
              ],
              ...tradeCalc,
            };

            allTrades.push(trade);
            allTrades.sort((a, b) => {
              const timeA = new Date(a.entryTime || 0).getTime();
              const timeB = new Date(b.entryTime || 0).getTime();
              return timeB - timeA;
            });

            // CRITICAL: Save trade to KV with retry logic to ensure it persists
            // This ensures the trade is saved even if the request is canceled
            // Use retry with verification to handle race conditions
            const saveResult = await kvPutJSONWithRetry(
              KV,
              tradesKey,
              allTrades,
            );
            if (saveResult.success) {
              console.log(
                `[TRADE SIM] ✅ Created new trade ${ticker} ${direction} (Rank ${
                  trade.rank
                }, Entry RR ${trade.rr.toFixed(2)}) - Saved to KV (attempt ${
                  saveResult.attempt
                }${saveResult.note ? `, ${saveResult.note}` : ""})`,
              );
            } else {
              console.error(
                `[TRADE SIM] ❌ Failed to save trade ${ticker} ${direction} after ${saveResult.attempts} attempts:`,
                saveResult.error,
              );
              // Still log the trade creation even if save failed
              // The trade will be recreated on next ingestion if conditions are met
              console.log(
                `[TRADE SIM] ⚠️ Trade ${ticker} ${direction} created but NOT saved - will retry on next ingestion`,
              );
            }

            // Persist new trade + ENTRY event to D1 ledger (best-effort) — skip during replay
            if (!isReplay) {
              d1UpsertTrade(env, trade).catch((e) => {
                console.error(
                  `[D1 LEDGER] Failed to upsert new trade ${ticker}:`,
                  e,
                );
              });
              d1LogDirectionEntry(env, trade, tickerData).catch(() => {});
              const entryEvent =
                Array.isArray(trade.history) && trade.history.length > 0
                  ? trade.history[0]
                  : null;
              if (entryEvent && trade?.id) {
                d1InsertTradeEvent(env, trade.id, entryEvent).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to insert ENTRY event for ${ticker}:`,
                    e,
                  );
                });
              }
            }

            // Send Discord notification for new trade entry
            // Only send alert if this is a real-time trade (not a backfill)
            // Backfills can have misleading entry prices and confuse traders
            if (env && !isBackfill) {
              console.log(
                `[TRADE SIM] 📢 Preparing entry alert for ${ticker} ${direction}`,
              );

              // CRITICAL: If we're sending a Discord alert, ensure the trade is saved
              // Retry KV write if it failed, since we have enough confidence to alert
              if (!saveResult.success) {
                console.log(
                  `[TRADE SIM] 🔄 Retrying KV save for ${ticker} ${direction} before sending alert`,
                );
                const retryResult = await kvPutJSONWithRetry(
                  KV,
                  tradesKey,
                  allTrades,
                  null,
                  5,
                );
                if (retryResult.success) {
                  console.log(
                    `[TRADE SIM] ✅ Trade ${ticker} ${direction} saved on retry (attempt ${retryResult.attempt})`,
                  );
                } else {
                  console.error(
                    `[TRADE SIM] ❌ Trade ${ticker} ${direction} STILL not saved after retry - alerting anyway but trade may be lost`,
                  );
                }
              }

              const allowDiscord = shouldSendDiscordAlert(env, "TRADE_ENTRY", {
                ticker,
                rank: trade.rank || 0,
                rr: entryRR || 0,
                momentumElite: !!tickerData?.flags?.momentum_elite,
              });

              const embed = allowDiscord
                ? createTradeEntryEmbed(
                    ticker,
                    direction,
                    entryPrice,
                    Number(tickerData.sl),
                    validTP, // Use validated TP
                    entryRR || 0,
                    trade.rank || 0,
                    tickerData.state || "N/A",
                    Number(tickerData.price), // Current price for comparison
                    isBackfill,
                    tickerData, // Pass full ticker data for comprehensive embed
                  )
                : null;
              const sendRes = allowDiscord
                ? await notifyDiscord(env, embed).catch((err) => {
                    console.error(
                      `[TRADE SIM] ❌ Failed to send entry alert for ${ticker}:`,
                      err,
                    );
                    return { ok: false, error: String(err) };
                  }) // Don't let Discord errors break trade creation
                : {
                    ok: false,
                    skipped: true,
                    reason: "suppressed_critical_only",
                  };

              const entryTs =
                isoToMs(trade.entryTime) ||
                Number(trade.entry_ts) ||
                Date.now();
              const entryPayloadJson = (() => {
                try {
                  return JSON.stringify(tickerData);
                } catch {
                  return null;
                }
              })();
              const entryMetaJson = (() => {
                try {
                  return JSON.stringify({
                    type: "TRADE_ENTRY",
                    trade_id: trade.id,
                    entry_price: entryPrice,
                    sl: Number(tickerData.sl),
                    tp: validTP,
                  });
                } catch {
                  return null;
                }
              })();
              d1UpsertAlert(env, {
                alert_id: buildAlertId(ticker, entryTs, "TRADE_ENTRY"),
                ticker,
                ts: entryTs,
                side: direction,
                state: tickerData.state,
                rank: trade.rank || 0,
                rr_at_alert: entryRR || 0,
                trigger_reason: "TRADE_ENTRY",
                dedupe_day: formatDedupDay(entryTs),
                discord_sent: !!sendRes?.ok,
                discord_status: sendRes?.status ?? null,
                discord_error: sendRes?.ok
                  ? null
                  : sendRes?.reason ||
                    sendRes?.statusText ||
                    sendRes?.error ||
                    "discord_send_failed",
                payload_json: entryPayloadJson,
                meta_json: entryMetaJson,
              }).catch((e) => {
                console.error(`[D1 LEDGER] Failed to upsert entry alert:`, e);
              });

              // Log trade entry to activity feed
              try {
                await appendActivity(KV, {
                  ticker,
                  type: "trade_entry",
                  direction: direction,
                  action: "entry",
                  entryPrice: entryPrice,
                  sl: Number(tickerData.sl),
                  tp: validTP,
                  maxTP:
                    tickerData.tp_levels &&
                    Array.isArray(tickerData.tp_levels) &&
                    tickerData.tp_levels.length > 0
                      ? Math.max(
                          ...tickerData.tp_levels
                            .map((tp) =>
                              typeof tp === "object" && tp.price
                                ? Number(tp.price)
                                : Number(tp),
                            )
                            .filter((p) => Number.isFinite(p)),
                        )
                      : validTP,
                  rr: entryRR || 0,
                  rank: trade.rank || 0,
                  state: tickerData.state || "N/A",
                  htf_score: tickerData.htf_score,
                  ltf_score: tickerData.ltf_score,
                  completion: tickerData.completion,
                  phase_pct: tickerData.phase_pct,
                  price: Number(tickerData.price),
                  tradeId: trade.id,
                });
              } catch (activityErr) {
                console.error(
                  `[TRADE SIM] Failed to log trade entry to activity feed for ${ticker}:`,
                  activityErr,
                );
              }
            } else if (env && isBackfill) {
              console.log(
                `[TRADE SIM] ⚠️ Skipping Discord alert for ${ticker} ${direction} - backfill trade (entry: $${entryPrice.toFixed(
                  2,
                )}, current: $${Number(tickerData.price).toFixed(2)})`,
              );
            } else if (!env) {
              console.log(
                `[TRADE SIM] ⚠️ Skipping Discord alert for ${ticker} ${direction} - env not available`,
              );
            }
          } else {
            console.log(
              `[TRADE SIM] ⚠️ ${ticker} ${direction}: tradeCalc returned null`,
            );
          }
        }
      } else {
        // Log why trade wasn't created
        const rr = entryRR || Number(tickerData.rr) || 0;
        const comp = Number(tickerData.completion) || 0;
        const phase = Number(tickerData.phase_pct) || 0;
        const rank = Number(tickerData.rank) || 0;
        const h = Number(tickerData.htf_score);
        const l = Number(tickerData.ltf_score);
        const hFinite = Number.isFinite(h);
        const lFinite = Number.isFinite(l);
        const inCorridor =
          hFinite &&
          lFinite &&
          ((h > 0 && l >= -8 && l <= 12) || (h < 0 && l >= -12 && l <= 8));
        const aligned =
          tickerData.state === "HTF_BULL_LTF_BULL" ||
          tickerData.state === "HTF_BEAR_LTF_BEAR";

        // Determine why inCorridor is false
        let corridorReason = "";
        if (!hFinite || !lFinite) {
          corridorReason = `HTF/LTF scores invalid (HTF: ${
            hFinite ? h.toFixed(2) : "invalid"
          }, LTF: ${lFinite ? l.toFixed(2) : "invalid"})`;
        } else if (h > 0) {
          // LONG corridor check
          if (l < -8) {
            corridorReason = `LTF too low for LONG corridor (LTF: ${l.toFixed(
              2,
            )} < -8)`;
          } else if (l > 12) {
            corridorReason = `LTF too high for LONG corridor (LTF: ${l.toFixed(
              2,
            )} > 12)`;
          } else {
            corridorReason = `Should be in LONG corridor (HTF: ${h.toFixed(
              2,
            )} > 0, LTF: ${l.toFixed(2)} in [-8, 12])`;
          }
        } else if (h < 0) {
          // SHORT corridor check
          if (l < -12) {
            corridorReason = `LTF too low for SHORT corridor (LTF: ${l.toFixed(
              2,
            )} < -12)`;
          } else if (l > 8) {
            corridorReason = `LTF too high for SHORT corridor (LTF: ${l.toFixed(
              2,
            )} > 8)`;
          } else {
            corridorReason = `Should be in SHORT corridor (HTF: ${h.toFixed(
              2,
            )} < 0, LTF: ${l.toFixed(2)} in [-12, 8])`;
          }
        } else {
          corridorReason = `HTF is zero (HTF: ${h.toFixed(
            2,
          )}, neither LONG nor SHORT corridor)`;
        }

        // Check shouldTriggerTradeSimulation conditions
        const shouldTrigger = shouldTriggerTradeSimulation(
          ticker,
          tickerData,
          prevData,
        );

        console.log(
          `[TRADE SIM] ❌ ${ticker} ${direction}: Conditions not met`,
          {
            entryRR: entryRR?.toFixed(2),
            currentRR: tickerData.rr?.toFixed(2),
            comp,
            phase,
            rank,
            state: tickerData.state,
            htf_score: hFinite ? h.toFixed(2) : "invalid",
            ltf_score: lFinite ? l.toFixed(2) : "invalid",
            inCorridor,
            corridorReason,
            aligned,
            shouldTrigger,
            // Show what shouldTriggerTradeSimulation checks
            hasPrice: !!tickerData.price,
            hasSL: !!tickerData.sl,
            hasTP: !!tickerData.tp,
            trigger_reason: tickerData.trigger_reason || "none",
            sq30_release: !!(tickerData.flags && tickerData.flags.sq30_release),
            momentum_elite: !!(
              tickerData.flags && tickerData.flags.momentum_elite
            ),
          },
        );
      }
    }
  } catch (err) {
    console.error(`[TRADE SIM ERROR] ${ticker}:`, err);
  }
}

//─────────────────────────────────────────────────────────────────────────────
// Momentum Elite Calculation (Worker-Based with Caching)
//─────────────────────────────────────────────────────────────────────────────

// Fetch market cap from external API (placeholder - implement with your preferred API)
async function fetchMarketCap(ticker) {
  // TODO: Implement with Alpha Vantage, Yahoo Finance, or other API
  // For now, return null to skip market cap check
  // Example: const response = await fetch(`https://api.example.com/marketcap/${ticker}`);
  return null; // Will be implemented with actual API
}

// Calculate Average Daily Range (ADR) from price data
function calculateADR(price, high, low) {
  if (!price || price <= 0) return null;
  const dailyRange = (high - low) / price;
  return dailyRange;
}

// Calculate percentage change over period
function calculatePctChange(current, previous) {
  if (!previous || previous <= 0) return null;
  return (current - previous) / previous;
}

// Check if ticker meets Momentum Elite criteria
async function computeMomentumElite(KV, ticker, payload) {
  const cacheKey = `timed:momentum:${ticker}`;
  const now = Date.now();

  // Check cache (5 minute TTL for final status)
  const cached = await kvGetJSON(KV, cacheKey);
  if (cached && now - cached.timestamp < 5 * 60 * 1000) {
    return cached;
  }

  const price = Number(payload.price) || 0;

  // All base criteria must be true:
  // 1. Price > $4
  const priceOver4 = price >= 4.0;

  // 2. Market Cap > $1B (cached for 24 hours)
  // NOTE: Market cap is not enforced for Momentum Elite in this build (UI expectation),
  // but we still compute it for informational/debug purposes.
  const marketCapKey = `timed:momentum:marketcap:${ticker}`;
  let marketCapOver1B = true; // Default to true if we can't check
  const marketCapCache = await kvGetJSON(KV, marketCapKey);
  if (marketCapCache && now - marketCapCache.timestamp < 24 * 60 * 60 * 1000) {
    marketCapOver1B = marketCapCache.value;
  } else {
    // Fetch fresh market cap
    const marketCap = await fetchMarketCap(ticker);
    if (marketCap !== null) {
      marketCapOver1B = marketCap >= 1000000000;
      await kvPutJSON(
        KV,
        marketCapKey,
        { value: marketCapOver1B, timestamp: now },
        24 * 60 * 60,
      );
    }
  }

  // 3. Average Daily Range (ADR) (looser, cached for 1 hour)
  // Prefer TradingView heartbeat fields when present.
  const adrKey = `timed:momentum:adr:${ticker}`;
  let adrOk = true; // Looser: if we can't compute ADR, don't block
  const adrCache = await kvGetJSON(KV, adrKey);
  if (adrCache && now - adrCache.timestamp < 60 * 60 * 1000) {
    adrOk = !!adrCache.value;
  } else {
    // Prefer ADR from payload:
    // - Heartbeat sends `adr_14` as an absolute $ range
    // - Some sources may provide `adr_pct_14` as a fraction (0.02 == 2%)
    const adrAbs = Number(payload.adr_14);
    const adrPctDirect = Number(payload.adr_pct_14);

    const priceForAdr = price > 0 ? price : Number(payload.price) || 0;
    const adrPct =
      Number.isFinite(adrPctDirect) && adrPctDirect > 0
        ? adrPctDirect
        : Number.isFinite(adrAbs) && adrAbs > 0 && priceForAdr > 0
          ? adrAbs / priceForAdr
          : null;

    if (Number.isFinite(adrAbs) && adrAbs > 0) {
      // Looser than $2: treat >= $1 as "OK"
      adrOk = adrAbs >= 1.0;
    } else if (Number.isFinite(adrPct) && adrPct > 0) {
      // Looser than 2%: treat >= 1.5% as "OK"
      adrOk = adrPct >= 0.015;
    } else {
      // Fallback: if only OHLC is available, estimate ADR as a percent of price (legacy).
      const high = Number(payload.high ?? payload.h) || price;
      const low = Number(payload.low ?? payload.l) || price;
      const adrPct = calculateADR(price, high, low); // fraction of price
      // Looser: accept >= 1.5% if computed
      adrOk = adrPct != null && Number.isFinite(adrPct) && adrPct >= 0.015;
    }
    await kvPutJSON(KV, adrKey, { value: adrOk, timestamp: now }, 60 * 60);
  }

  // 4. Average Volume (30 days) > 2M (cached for 1 hour)
  // Prefer TradingView heartbeat fields when present (most accurate).
  const volumeKey = `timed:momentum:volume:${ticker}`;
  let volumeOver2M = false;
  const volumeCache = await kvGetJSON(KV, volumeKey);
  if (volumeCache && now - volumeCache.timestamp < 60 * 60 * 1000) {
    volumeOver2M = volumeCache.value;
  } else {
    const avgVol30 = Number(payload.avg_vol_30);
    const avgVol50 = Number(payload.avg_vol_50);
    const avgVol =
      Number.isFinite(avgVol30) && avgVol30 > 0
        ? avgVol30
        : Number.isFinite(avgVol50) && avgVol50 > 0
          ? avgVol50
          : Number(payload.volume) || 0;
    volumeOver2M = avgVol >= 2000000;
    await kvPutJSON(
      KV,
      volumeKey,
      { value: volumeOver2M, timestamp: now },
      60 * 60,
    );
  }

  // All base criteria (looser ADR gate)
  const allBaseCriteria = priceOver4 && adrOk && volumeOver2M;

  // Any momentum criteria (cached for 15 minutes):
  // Prefer TradingView payload data (most accurate), fallback to trail history
  const momentumKey = `timed:momentum:changes:${ticker}`;
  let anyMomentumCriteria = false;
  const momentumCache = await kvGetJSON(KV, momentumKey);
  if (momentumCache && now - momentumCache.timestamp < 15 * 60 * 1000) {
    anyMomentumCriteria = momentumCache.value;
  } else {
    // First, try to use momentum_pct from TradingView payload (most accurate)
    const momentumPct = payload.momentum_pct || {};
    const weekPct = momentumPct.week != null ? Number(momentumPct.week) : null;
    const monthPct =
      momentumPct.month != null ? Number(momentumPct.month) : null;
    const threeMonthsPct =
      momentumPct.three_months != null
        ? Number(momentumPct.three_months)
        : null;
    const sixMonthsPct =
      momentumPct.six_months != null ? Number(momentumPct.six_months) : null;

    if (monthPct != null) {
      // Align to TradingView screener-style filter: 1M change >= 25%
      anyMomentumCriteria = Number.isFinite(monthPct) && monthPct >= 25.0;
    } else {
      // Fallback: Calculate from trail history (for older data or if TradingView doesn't send it)
      const trailKey = `timed:trail:${ticker}`;
      const trail = (await kvGetJSON(KV, trailKey)) || [];

      if (trail.length > 0 && price > 0) {
        const currentPrice = price;
        const now = Date.now();

        // Time periods in milliseconds
        const oneWeekAgo = now - 7 * 24 * 60 * 60 * 1000;
        const oneMonthAgo = now - 30 * 24 * 60 * 60 * 1000;
        const threeMonthsAgo = now - 90 * 24 * 60 * 60 * 1000;
        const sixMonthsAgo = now - 180 * 24 * 60 * 60 * 1000;

        // Find closest trail points to these times (by timestamp)
        const findClosestPrice = (targetTime) => {
          let closest = null;
          let minDiff = Infinity;
          for (const point of trail) {
            if (!point.ts) continue;
            const diff = Math.abs(point.ts - targetTime);
            if (diff < minDiff) {
              minDiff = diff;
              // Try to get price from point (might be in different fields)
              const pointPrice =
                Number(point.price) || Number(point.close) || null;
              if (pointPrice && pointPrice > 0) {
                closest = pointPrice;
              }
            }
          }
          return closest;
        };

        const priceWeekAgo = findClosestPrice(oneWeekAgo);
        const priceMonthAgo = findClosestPrice(oneMonthAgo);
        const price3MonthsAgo = findClosestPrice(threeMonthsAgo);
        const price6MonthsAgo = findClosestPrice(sixMonthsAgo);

        // Calculate percentage changes
        const monthOver25Pct =
          priceMonthAgo && priceMonthAgo > 0
            ? (currentPrice - priceMonthAgo) / priceMonthAgo >= 0.25
            : false;
        anyMomentumCriteria = !!monthOver25Pct;
      } else {
        // No trail data yet, default to false
        anyMomentumCriteria = false;
      }
    }

    // Cache result
    await kvPutJSON(
      KV,
      momentumKey,
      { value: anyMomentumCriteria, timestamp: now },
      15 * 60,
    );
  }

  const momentumElite = allBaseCriteria && anyMomentumCriteria;

  // Store result with metadata
  const result = {
    momentum_elite: momentumElite,
    criteria: {
      priceOver4,
      marketCapOver1B,
      // Back-compat name: still called adrOver2 in UI, but now means "ADR gate passed (looser)".
      adrOver2: adrOk,
      volumeOver2M,
      allBaseCriteria,
      anyMomentumCriteria,
    },
    timestamp: now,
  };

  // Check for status change and log history
  const prevStatus = cached ? cached.momentum_elite : false;
  if (momentumElite !== prevStatus) {
    const historyKey = `timed:momentum:history:${ticker}`;
    const history = (await kvGetJSON(KV, historyKey)) || [];
    history.push({
      status: momentumElite,
      timestamp: now,
      criteria: result.criteria,
    });
    // Keep last 100 status changes
    const trimmedHistory = history.slice(-100);
    await kvPutJSON(KV, historyKey, trimmedHistory);
  }

  // Cache result (keep long enough for UI filtering between bar closes)
  await kvPutJSON(KV, cacheKey, result, 6 * 60 * 60);

  return result;
}

function computeRank(d) {
  const htf = Number(d.htf_score);
  const ltf = Number(d.ltf_score);
  const comp = completionForSize(d);
  const phase = Number(d.phase_pct);
  const rr = d.rr != null ? Number(d.rr) : computeRR(d);

  const flags = d.flags || {};
  const sqRel = !!flags.sq30_release;
  const sqOn = !!flags.sq30_on;
  const phaseZoneChange = !!flags.phase_zone_change;
  const momentumElite = !!flags.momentum_elite;
  const emaCross1H1348 = !!flags.ema_cross_1h_13_48;
  const buyableDip1H1348 = !!flags.buyable_dip_1h_13_48;

  const state = String(d.state || "");
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  const setup =
    state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK";

  // ADJUSTED SCORING: More discriminating, lower base
  let score = 30; // Reduced from 50 to make scoring more selective

  // Data completeness: slightly down-rank incomplete payloads so “Today/Prime” stays sane.
  const completeness = d?.data_completeness || computeDataCompleteness(d);
  if (completeness && typeof completeness === "object") {
    if (completeness.score < 70) score -= 10;
    else if (completeness.score < 85) score -= 5;
    else if (completeness.score < 95) score -= 2;
  }

  // Per-TF technical structure alignment (bonus/penalty).
  const tfAlign = d?.tf_summary || tfTechAlignmentSummary(d);
  if (
    tfAlign &&
    typeof tfAlign === "object" &&
    Number.isFinite(tfAlign.score)
  ) {
    score += tfAlign.score;
  }

  // Explicit triggers[] “why now” boost.
  const trig = d?.trigger_summary || triggerSummaryAndScore(d);
  if (trig && typeof trig === "object" && Number.isFinite(trig.score)) {
    score += trig.score;
  }

  // Move status: invalidate/completed moves should fall out of “best setups”
  const ms = d?.move_status || computeMoveStatus(d);
  if (ms && typeof ms === "object") {
    if (ms.status === "INVALIDATED") score -= 25;
    else if (ms.status === "COMPLETED") score -= 15;
  }

  // State bonuses (reduced)
  if (aligned) score += 12; // Reduced from 15
  if (setup) score += 4; // Reduced from 5

  // HTF/LTF contributions (more selective - require stronger signals)
  if (Number.isFinite(htf)) {
    const htfAbs = Math.abs(htf);
    // Only give full credit for strong HTF signals (>= 25)
    if (htfAbs >= 25) score += Math.min(10, htfAbs * 0.4);
    else if (htfAbs >= 15)
      score += Math.min(7, htfAbs * 0.35); // Reduced for moderate signals
    else score += Math.min(4, htfAbs * 0.25); // Minimal for weak signals
  }

  if (Number.isFinite(ltf)) {
    const ltfAbs = Math.abs(ltf);
    // Only give full credit for strong LTF signals (>= 20)
    if (ltfAbs >= 20) score += Math.min(10, ltfAbs * 0.3);
    else if (ltfAbs >= 12)
      score += Math.min(6, ltfAbs * 0.25); // Reduced for moderate signals
    else score += Math.min(3, ltfAbs * 0.2); // Minimal for weak signals
  }

  // Completion bonus (reduced and more selective)
  if (Number.isFinite(comp)) {
    // Early completion gets more points, but cap reduced
    if (comp <= 0.2)
      score += 15; // Excellent (0-20% completion)
    else if (comp <= 0.4)
      score += 10; // Good (20-40% completion)
    else if (comp <= 0.6) score += 5; // Moderate (40-60% completion)
    // No bonus for completion > 60%
  }

  // Phase penalty (starts earlier, more aggressive)
  if (Number.isFinite(phase)) {
    if (phase > 0.5) score -= Math.max(0, (phase - 0.5) * 30); // Penalty starts at 50% instead of 60%
    // Early phase (< 50%) gets small bonus
    if (phase <= 0.3) score += 3; // Early phase bonus
  }

  // Squeeze bonuses — DATA-DRIVEN adjustment (Phase 1 analysis: squeeze_releases
  // have -33.7% lift toward DOWN moves, the #1 predictive bearish feature).
  // Squeeze Release (Bull context): 70.2% DOWN, EV -10.6
  // Squeeze Release (Bear context): 65.5% DOWN, EV -14.4
  // In-squeeze (sq30_on) is more predictive of a pending move than release.
  if (sqRel) {
    // State-conditional: release in pullback can be a reversal catalyst,
    // but in aligned states it often precedes reversals (mean reversion).
    if (setup) score += 6;       // Pullback + squeeze release = potential reversal catalyst
    else if (aligned) score += 2; // Aligned + release = often precedes mean reversion
    else score -= 2;              // Bear/neutral + release = bearish expansion
  } else if (sqOn) {
    score += 5; // Squeeze building is more predictive than release (per entry quality analysis)
  }

  // Phase zone change bonus (reduced)
  if (phaseZoneChange) score += 2; // Reduced from 3

  // RR contribution (more selective - requires better RR)
  if (Number.isFinite(rr)) {
    if (rr >= 2.0)
      score += 10; // Excellent RR (2.0+)
    else if (rr >= 1.5)
      score += 7; // Good RR (1.5-2.0)
    else if (rr >= 1.2) score += 4; // Acceptable RR (1.2-1.5)
    // No bonus for RR < 1.2
  }

  // Momentum Elite boost (reduced but still significant)
  if (momentumElite) score += 15; // Reduced from 20

  // 1H 13/48 cross + buyable-dip nuance
  // - Cross is a strong pivot/confirmation marker
  // - Dip-after-cross is a premium pullback entry opportunity
  if (emaCross1H1348) score += 5;
  if (buyableDip1H1348) score += 7;

  // HTF/LTF divergence penalty — DATA-DRIVEN (Phase 1 analysis: htf_ltf_diverging
  // has -28.2% lift toward DOWN moves, the #3 predictive bearish feature).
  // When HTF and LTF disagree on direction, setups are unreliable.
  const htfBull = htf > 5;
  const htfBear = htf < -5;
  const ltfBull = ltf > 5;
  const ltfBear = ltf < -5;
  if ((htfBull && ltfBear) || (htfBear && ltfBull)) {
    score -= 5; // HTF/LTF divergence: setup reliability drops significantly
  }

  // Sector bias adjustment — DATA-DRIVEN (Phase 1 analysis: massive sector skew).
  // Basic Materials 86.4% UP, Precious Metals 83.3% UP, Energy 100% UP
  // Financials 13.6% UP (86.4% bearish), Crypto 43.9% UP
  const ticker = String(d?.ticker || "").toUpperCase();
  const sector = SECTOR_MAP[ticker] || "";
  if (sector === "Basic Materials" || sector === "Precious Metals" || sector === "Energy") {
    score += 3; // Strong historical bullish bias
  } else if (sector === "Financials") {
    score -= 4; // Strong historical bearish bias (only 13.6% UP)
  } else if (sector === "Crypto") {
    score -= 2; // Moderate bearish bias (43.9% UP)
  }

  // RSI Divergence boost/penalty
  const rsi = d.rsi;
  if (rsi && rsi.divergence) {
    const divType = String(rsi.divergence.type || "none");
    const divStrength = Number(rsi.divergence.strength || 0);
    if (divType === "bullish") {
      score += 3 + Math.min(2, divStrength * 0.1); // Boost for bullish divergence
    } else if (divType === "bearish") {
      score -= 3 - Math.min(2, divStrength * 0.1); // Penalty for bearish divergence
    }
  }

  // TD Sequential boost/penalty — only relevant on Daily/Weekly/Monthly timeframes.
  // Ignore TD Sequential from 4H and below (intraday noise).
  const tdSeq = d.td_sequential || {};
  const tdTf = String(tdSeq.timeframe || tdSeq.tf || d.tf || "D").toUpperCase();
  const tdIsHigherTF = ["D", "W", "M", "1D", "1W", "1M", "DAILY", "WEEKLY", "MONTHLY"].includes(tdTf);
  const tdSeqBoost = tdIsHigherTF ? (Number(tdSeq.boost) || 0) : 0;
  if (Number.isFinite(tdSeqBoost) && tdSeqBoost !== 0) {
    score += tdSeqBoost;
  }

  score = Math.max(0, Math.min(100, score));
  return Math.round(score);
}

// ─────────────────────────────────────────────────────────────
// Live Thesis features (seq + deltas) computed from trail
// Mirrors feature families used in scripts/analyze-best-setups.js
// ─────────────────────────────────────────────────────────────

function clamp01(x) {
  const n = Number(x);
  if (!Number.isFinite(n)) return 0;
  return Math.max(0, Math.min(1, n));
}

function flagOn(flags, k) {
  if (!flags || typeof flags !== "object") return false;
  const v = flags[k];
  return v === true || v === 1 || v === "true";
}

function orderedWithin(a, b, maxMs) {
  if (!Number.isFinite(a) || !Number.isFinite(b) || !Number.isFinite(maxMs))
    return false;
  return b >= a && b - a <= maxMs;
}

function normalizeTrailPoint(p) {
  if (!p || typeof p !== "object") return null;
  const ts = Number(p.ts ?? p.timestamp ?? p.ingest_ts ?? p.ingest_time);
  const price = Number(p.price ?? p.__price);
  return {
    __ts: Number.isFinite(ts) ? ts : null,
    __price: Number.isFinite(price) ? price : null,
    htf_score: p.htf_score != null ? Number(p.htf_score) : null,
    ltf_score: p.ltf_score != null ? Number(p.ltf_score) : null,
    completion: p.completion != null ? Number(p.completion) : null,
    phase_pct: p.phase_pct != null ? Number(p.phase_pct) : null,
    state: p.state != null ? String(p.state) : "",
    rank: p.rank != null ? Number(p.rank) : null,
    trigger_reason: p.trigger_reason != null ? String(p.trigger_reason) : null,
    trigger_dir:
      p.trigger_dir != null ? String(p.trigger_dir).trim().toUpperCase() : null,
    __flags: p.flags && typeof p.flags === "object" ? p.flags : {},
  };
}

function directionForThesis(p, fallbackPayload = null) {
  const fromTrig =
    (fallbackPayload && fallbackPayload.trigger_dir) || (p && p.trigger_dir);
  const td = String(fromTrig || "")
    .trim()
    .toUpperCase();
  if (td === "LONG" || td === "SHORT") return td;

  const st = String(
    (fallbackPayload && fallbackPayload.state) || (p && p.state) || "",
  );
  if (st.includes("BEAR")) return "SHORT";
  if (st.includes("BULL")) return "LONG";

  const htf = Number(
    (fallbackPayload && fallbackPayload.htf_score) || (p && p.htf_score),
  );
  if (Number.isFinite(htf) && htf < 0) return "SHORT";
  if (Number.isFinite(htf) && htf > 0) return "LONG";
  return null;
}

function lowerBoundTs(points, tsTarget, idxHiExclusive) {
  let lo = 0;
  let hi = Math.max(
    0,
    Number.isFinite(idxHiExclusive) ? idxHiExclusive : points.length,
  );
  while (lo < hi) {
    const mid = (lo + hi) >> 1;
    const ts = Number(points[mid]?.__ts);
    if (!Number.isFinite(ts) || ts < tsTarget) lo = mid + 1;
    else hi = mid;
  }
  return lo;
}

function lookbackDeltas(points, idx0, lookbackMs) {
  const p0 = points[idx0];
  const t0 = Number(p0?.__ts);
  if (!Number.isFinite(t0) || !Number.isFinite(lookbackMs) || lookbackMs <= 0)
    return null;
  const idxHi = Math.max(0, idx0);
  if (idxHi <= 0) return null;
  const tsTarget = t0 - lookbackMs;
  const idx = lowerBoundTs(points, tsTarget, idxHi);
  const p1 = points[Math.min(idx, idxHi - 1)];
  if (!p1) return null;

  const htf0 = Number(p0?.htf_score);
  const ltf0 = Number(p0?.ltf_score);
  const px0 = Number(p0?.__price);
  const t1 = Number(p1?.__ts);
  const htf1 = Number(p1?.htf_score);
  const ltf1 = Number(p1?.ltf_score);
  const px1 = Number(p1?.__price);

  const dtMs = Number.isFinite(t1) ? t0 - t1 : null;
  const dHtf =
    Number.isFinite(htf0) && Number.isFinite(htf1) ? htf0 - htf1 : null;
  const dLtf =
    Number.isFinite(ltf0) && Number.isFinite(ltf1) ? ltf0 - ltf1 : null;
  const dPxPct =
    Number.isFinite(px0) && Number.isFinite(px1) && px1 > 0
      ? (px0 - px1) / px1
      : null;

  return {
    lookbackMs,
    t1: Number.isFinite(t1) ? t1 : null,
    dtMs,
    deltaHtf: dHtf,
    deltaLtf: dLtf,
    deltaPricePct: dPxPct,
  };
}

function isWinnerSignatureSnapshotForThesis(p) {
  const flags = p?.__flags || {};
  const state = String(p?.state || "");
  const isSetup = state.includes("PULLBACK");
  const inCorridor = corridorSide(p) != null;
  const completion = clamp01(p?.completion);
  const phasePct = clamp01(p?.phase_pct);
  const inSqueeze = flagOn(flags, "sq30_on") && !flagOn(flags, "sq30_release");
  return (
    isSetup && inCorridor && completion < 0.15 && (phasePct < 0.6 || inSqueeze)
  );
}

function isPrimeLikeSnapshotForThesis(p) {
  const flags = p?.__flags || {};
  const state = String(p?.state || "");
  const inCorridor = corridorSide(p) != null;
  const rank = Number(p?.rank);
  const completion = clamp01(p?.completion);
  const phase = clamp01(p?.phase_pct);
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
  const sqRel = flagOn(flags, "sq30_release");
  const phaseZoneChange = flagOn(flags, "phase_zone_change");
  return (
    inCorridor &&
    (Number.isFinite(rank) ? rank >= 75 : false) &&
    completion < 0.4 &&
    phase < 0.6 &&
    (aligned || sqRel || phaseZoneChange)
  );
}

function computeLiveThesisFeaturesFromTrail(trailPoints, payload) {
  const H1 = 60 * 60 * 1000;
  const LOOKBACK_4H = 4 * H1;
  const LOOKBACK_1D = 24 * H1;

  const raw = Array.isArray(trailPoints) ? trailPoints : [];
  const pts = raw
    .map(normalizeTrailPoint)
    .filter((x) => x && Number.isFinite(x.__ts))
    .sort((a, b) => Number(a.__ts) - Number(b.__ts));

  const empty = {
    seq: {
      recentSqueezeRelease_6h: false,
      recentSqueezeOn_6h: false,
      corridorEntry_60m: false,
      pattern: {
        squeezeReleaseToMomentum_6h: false,
        squeezeOnToRelease_24h: false,
      },
    },
    deltas: { htf_4h: null, ltf_4h: null, htf_1d: null },
    flags: {
      htf_improving_4h: false,
      htf_improving_1d: false,
      htf_move_4h_ge_5: false,
      thesis_match: false,
    },
  };
  if (pts.length < 2) return empty;

  let lastCorridorEntryTs = null;
  let lastSqueezeOnTs = null;
  let lastSqueezeReleaseTs = null;
  let lastSetupToMomentumTs = null;

  for (let i = 1; i < pts.length; i++) {
    const p = pts[i];
    const prev = pts[i - 1];
    const ts = Number(p.__ts);
    if (!Number.isFinite(ts)) continue;

    const ent = corridorSide(p) != null;
    const entPrev = corridorSide(prev) != null;

    const flags = p.__flags || {};
    const flagsPrev = prev.__flags || {};

    const st = String(p.state || "");
    const stPrev = String(prev.state || "");
    const isPullback = st.includes("PULLBACK");
    const wasPullback = stPrev.includes("PULLBACK");
    const isMomentum =
      (st.includes("LTF_BULL") || st.includes("LTF_BEAR")) && !isPullback;

    if (!entPrev && ent) lastCorridorEntryTs = ts;
    if (flagOn(flags, "sq30_on") && !flagOn(flagsPrev, "sq30_on"))
      lastSqueezeOnTs = ts;
    if (flagOn(flags, "sq30_release") && !flagOn(flagsPrev, "sq30_release"))
      lastSqueezeReleaseTs = ts;
    if (wasPullback && isMomentum) lastSetupToMomentumTs = ts;
  }

  const latest = pts[pts.length - 1];
  const nowTs = Number(latest.__ts);
  const since = {
    corridorEntryMs: Number.isFinite(lastCorridorEntryTs)
      ? Math.max(0, nowTs - lastCorridorEntryTs)
      : null,
    squeezeOnMs: Number.isFinite(lastSqueezeOnTs)
      ? Math.max(0, nowTs - lastSqueezeOnTs)
      : null,
    squeezeReleaseMs: Number.isFinite(lastSqueezeReleaseTs)
      ? Math.max(0, nowTs - lastSqueezeReleaseTs)
      : null,
  };

  const deltas4h = lookbackDeltas(pts, pts.length - 1, LOOKBACK_4H);
  const deltas1d = lookbackDeltas(pts, pts.length - 1, LOOKBACK_1D);

  const dir = directionForThesis(latest, payload);
  const htf_4h = deltas4h ? deltas4h.deltaHtf : null;
  const ltf_4h = deltas4h ? deltas4h.deltaLtf : null;
  const htf_1d = deltas1d ? deltas1d.deltaHtf : null;

  const htf_improving_4h =
    !!dir &&
    Number.isFinite(htf_4h) &&
    ((dir === "LONG" && htf_4h > 0) || (dir === "SHORT" && htf_4h < 0));
  const htf_improving_1d =
    !!dir &&
    Number.isFinite(htf_1d) &&
    ((dir === "LONG" && htf_1d > 0) || (dir === "SHORT" && htf_1d < 0));
  const htf_move_4h_ge_5 = Number.isFinite(htf_4h) && Math.abs(htf_4h) >= 5;

  const seq = {
    recentSqueezeRelease_6h:
      since.squeezeReleaseMs != null && since.squeezeReleaseMs <= 6 * H1,
    recentSqueezeOn_6h:
      since.squeezeOnMs != null && since.squeezeOnMs <= 6 * H1,
    corridorEntry_60m:
      since.corridorEntryMs != null && since.corridorEntryMs <= 60 * 60 * 1000,
    pattern: {
      squeezeReleaseToMomentum_6h: orderedWithin(
        lastSqueezeReleaseTs,
        lastSetupToMomentumTs,
        6 * H1,
      ),
      squeezeOnToRelease_24h: orderedWithin(
        lastSqueezeOnTs,
        lastSqueezeReleaseTs,
        24 * H1,
      ),
    },
  };

  const primeLike = isPrimeLikeSnapshotForThesis(latest);
  const winnerSignature = isWinnerSignatureSnapshotForThesis(latest);

  const rank = Number(payload?.rank ?? latest?.rank);
  const completion = clamp01(payload?.completion ?? latest?.completion);
  const phase = clamp01(payload?.phase_pct ?? latest?.phase_pct);
  const rr = (() => {
    const n = Number(payload?.rr);
    if (Number.isFinite(n)) return n;
    const v = computeRR(payload);
    return Number.isFinite(v) ? Number(v) : null;
  })();

  const baseGate =
    Number.isFinite(rank) &&
    rank >= 74 &&
    Number.isFinite(rr) &&
    rr >= 1.5 &&
    Number.isFinite(completion) &&
    completion <= 0.6 + 1e-9 &&
    Number.isFinite(phase) &&
    phase <= 0.6 + 1e-9;

  const A = seq.pattern.squeezeReleaseToMomentum_6h && htf_move_4h_ge_5;
  const B = seq.recentSqueezeRelease_6h && htf_improving_4h;
  const C =
    (primeLike && htf_move_4h_ge_5) || (winnerSignature && htf_improving_4h);
  const thesis_match = !!baseGate && (A || B || C);

  return {
    seq,
    deltas: { htf_4h, ltf_4h, htf_1d },
    flags: {
      htf_improving_4h,
      htf_improving_1d,
      htf_move_4h_ge_5,
      thesis_match,
    },
  };
}

async function appendTrail(KV, ticker, point, maxN = 8) {
  const key = `timed:trail:${ticker}`;
  const cur = (await kvGetJSON(KV, key)) || [];
  cur.push(point);
  const keep = cur.length > maxN ? cur.slice(cur.length - maxN) : cur;
  await kvPutJSON(KV, key, keep);
  return keep;
}

async function appendCaptureTrail(KV, ticker, point, maxN = 48) {
  const key = `timed:capture:trail:${ticker}`;
  const cur = (await kvGetJSON(KV, key)) || [];
  cur.push(point);
  const keep = cur.length > maxN ? cur.slice(cur.length - maxN) : cur;
  await kvPutJSON(KV, key, keep);
}

/** Per-ticker KV key prefixes to clean when a ticker is removed. */
const TICKER_KV_PREFIXES = [
  "timed:latest:", "timed:trail:", "timed:sector_map:",
  "timed:momentum:", "timed:momentum:marketcap:", "timed:momentum:adr:",
  "timed:momentum:volume:", "timed:momentum:changes:", "timed:momentum:history:",
  "timed:context:", "timed:heartbeat:",
  "timed:prevstate:", "timed:prevcorridor:", "timed:prevsqueeze:",
  "timed:prevsqueezerel:", "timed:prevmomentumelite:",
  "timed:prev_close:", "timed:prev_flip_watch:",
  "timed:fundamentals:", "timed:pe_history:",
  "timed:capture:latest:", "timed:capture:trail:", "timed:capture:raw:",
  "timed:ingest:raw:", "timed:ingest:missing:",
];

/** Data lifecycle: aggregate timed_trail older than 48h into trail_5m_facts, then purge old raw data. */
const DATA_LIFECYCLE_48H_MS = 48 * 60 * 60 * 1000;
const DATA_LIFECYCLE_7D_MS = 7 * 24 * 60 * 60 * 1000;
const DATA_LIFECYCLE_30D_MS = 30 * 24 * 60 * 60 * 1000;
const DATA_LIFECYCLE_60D_MS = 60 * 24 * 60 * 60 * 1000;
const DATA_LIFECYCLE_90D_MS = 90 * 24 * 60 * 60 * 1000;
const DATA_LIFECYCLE_180D_MS = 180 * 24 * 60 * 60 * 1000;
const PURGE_BATCH = 5000;

/** Tiered candle retention: shorter TFs expire sooner, D/W/M kept forever.
 *  1m and 3m entries removed — no longer written, existing rows purged by one-time cleanup.
 *  5m/10m increased to 90 days to support 6-12 month model training data. */
const CANDLE_RETENTION_DAYS = {
  "5": 90,
  "10": 90,
  "10m": 90,
  "30": 90,
  "30m": 90,
  "60": 180,
  "1h": 180,
  "240": 365,
  "4h": 365,
  // "D", "W", and "M" are intentionally omitted → kept forever
};

async function runDataLifecycle(env, opts = {}) {
  const db = env?.DB;
  if (!db) {
    console.error("[DATA LIFECYCLE] No DB binding");
    return;
  }
  const now = Date.now();
  // Allow override for manual backfill scenarios (e.g., force recent data through)
  const cutoff48h = opts.cutoffMs != null && Number.isFinite(opts.cutoffMs)
    ? opts.cutoffMs
    : now - DATA_LIFECYCLE_48H_MS;
  const cutoff7d = now - DATA_LIFECYCLE_7D_MS;

  try {
    // 1. Aggregate timed_trail (ts < 48h) into trail_5m_facts
    // Uses subqueries for first/last values per bucket (kanban_stage, price open/close)
    const agg = await db
      .prepare(
        `INSERT OR REPLACE INTO trail_5m_facts
         (ticker, bucket_ts, price_open, price_high, price_low, price_close,
          htf_score_avg, htf_score_min, htf_score_max,
          ltf_score_avg, ltf_score_min, ltf_score_max,
          state, rank, completion, phase_pct,
          had_squeeze_release, had_ema_cross, had_st_flip, had_momentum_elite, had_flip_watch,
          kanban_stage_start, kanban_stage_end, kanban_changed,
          sample_count, created_at)
         SELECT
          t.ticker,
          (t.ts / 300000) * 300000 AS bucket,
          -- Price OHLC: first price in bucket = open, last = close
          (SELECT price FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND price IS NOT NULL ORDER BY ts ASC LIMIT 1),
          MAX(t.price),
          MIN(t.price),
          (SELECT price FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND price IS NOT NULL ORDER BY ts DESC LIMIT 1),
          ROUND(AVG(t.htf_score), 2), MIN(t.htf_score), MAX(t.htf_score),
          ROUND(AVG(t.ltf_score), 2), MIN(t.ltf_score), MAX(t.ltf_score),
          -- End-of-bucket state: last row's state
          (SELECT state FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND state IS NOT NULL ORDER BY ts DESC LIMIT 1),
          MAX(t.rank), MAX(t.completion), MAX(t.phase_pct),
          -- Flags: check flags_json for any occurrence (1 if any row had it)
          MAX(CASE WHEN t.flags_json LIKE '%squeeze_release%' OR t.flags_json LIKE '%sq30_release%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%ema_cross%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%st_flip%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%momentum_elite%' THEN 1 ELSE 0 END),
          MAX(CASE WHEN t.flags_json LIKE '%flip_watch%' THEN 1 ELSE 0 END),
          -- Kanban: first and last kanban_stage in the bucket
          (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts ASC LIMIT 1),
          (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts DESC LIMIT 1),
          -- kanban_changed: 1 if first != last kanban_stage in bucket
          CASE WHEN
            (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts ASC LIMIT 1)
            IS NOT
            (SELECT kanban_stage FROM timed_trail WHERE ticker = t.ticker AND (ts / 300000) * 300000 = (t.ts / 300000) * 300000 AND ts < ?1 AND kanban_stage IS NOT NULL ORDER BY ts DESC LIMIT 1)
          THEN 1 ELSE 0 END,
          COUNT(*),
          (strftime('%s', 'now') * 1000)
         FROM timed_trail t
         WHERE t.ts < ?1
         GROUP BY t.ticker, (t.ts / 300000) * 300000`,
      )
      .bind(cutoff48h)
      .run();
    console.log("[DATA LIFECYCLE] Aggregated trail → 5m facts:", agg?.meta?.changes ?? "ok");

    // 2. Purge timed_trail in batches to avoid D1 overload
    let trailDeleted = 0;
    for (;;) {
      const del = await db
        .prepare(
          `DELETE FROM timed_trail WHERE rowid IN (SELECT rowid FROM timed_trail WHERE ts < ?1 LIMIT ?2)`,
        )
        .bind(cutoff48h, PURGE_BATCH)
        .run();
      const n = del?.meta?.changes ?? 0;
      trailDeleted += n;
      if (n < PURGE_BATCH) break;
    }
    console.log("[DATA LIFECYCLE] Purged timed_trail rows:", trailDeleted);

    // 3. Purge ingest_receipts older than 7 days in batches
    let receiptsDeleted = 0;
    for (;;) {
      const del = await db
        .prepare(
          `DELETE FROM ingest_receipts WHERE rowid IN (SELECT rowid FROM ingest_receipts WHERE received_ts < ?1 LIMIT ?2)`,
        )
        .bind(cutoff7d, PURGE_BATCH)
        .run();
      const n = del?.meta?.changes ?? 0;
      receiptsDeleted += n;
      if (n < PURGE_BATCH) break;
    }
    console.log("[DATA LIFECYCLE] Purged ingest_receipts rows:", receiptsDeleted);

    // 4. Roll up trail_5m_facts into trail_daily_summary (permanent archive)
    // Only roll up complete days (yesterday and older, not today's partial data)
    const yesterday = new Date(now - 24 * 60 * 60 * 1000);
    const yesterdayStr = yesterday.toISOString().slice(0, 10); // YYYY-MM-DD
    // Convert to ET for market-day alignment (9:30 AM ET to 4:00 PM ET)
    // Bucket_ts is UTC ms; a market day in ET spans ~14:30 UTC to ~21:00 UTC
    try {
      const dailyAgg = await db
        .prepare(
          `INSERT OR REPLACE INTO trail_daily_summary
           (ticker, date, price_open, price_high, price_low, price_close, price_change_pct,
            htf_score_avg, ltf_score_avg,
            minutes_bull_bull, minutes_bull_pullback, minutes_bear_bear, minutes_bear_pullback,
            squeeze_releases, ema_crosses, st_flips,
            enter_now_count,
            trades_opened, trades_closed, trade_pnl,
            sample_count, created_at)
           SELECT
            f.ticker,
            ?2,
            -- OHLC: first/last bucket's open/close
            (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1),
            MAX(f.price_high),
            MIN(f.price_low),
            (SELECT price_close FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts DESC LIMIT 1),
            CASE WHEN
              (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1) > 0
            THEN ROUND(
              ((SELECT price_close FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts DESC LIMIT 1)
               - (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1))
              / (SELECT price_open FROM trail_5m_facts WHERE ticker = f.ticker AND bucket_ts >= ?3 AND bucket_ts < ?4 ORDER BY bucket_ts ASC LIMIT 1) * 100, 2)
            ELSE NULL END,
            ROUND(AVG(f.htf_score_avg), 2),
            ROUND(AVG(f.ltf_score_avg), 2),
            -- State distribution: each 5m bucket = 5 minutes
            SUM(CASE WHEN f.state LIKE '%BULL%BULL%' THEN 5 ELSE 0 END),
            SUM(CASE WHEN f.state LIKE '%BULL%PULLBACK%' OR f.state LIKE '%BULL%BEAR%' THEN 5 ELSE 0 END),
            SUM(CASE WHEN f.state LIKE '%BEAR%BEAR%' THEN 5 ELSE 0 END),
            SUM(CASE WHEN f.state LIKE '%BEAR%PULLBACK%' OR f.state LIKE '%BEAR%BULL%' THEN 5 ELSE 0 END),
            -- Signal counts
            SUM(f.had_squeeze_release),
            SUM(f.had_ema_cross),
            SUM(f.had_st_flip),
            -- Kanban enter_now count
            SUM(CASE WHEN f.kanban_stage_end = 'enter_now' AND f.kanban_changed = 1 THEN 1 ELSE 0 END),
            -- Trade activity (placeholder - filled from trades table below)
            0, 0, 0,
            SUM(f.sample_count),
            (strftime('%s', 'now') * 1000)
           FROM trail_5m_facts f
           WHERE f.bucket_ts >= ?3 AND f.bucket_ts < ?4
           GROUP BY f.ticker`,
        )
        .bind(
          cutoff48h,
          yesterdayStr,
          // Yesterday's market day: 9:30 AM ET = 14:30 UTC, 4:00 PM ET = 21:00 UTC
          // Use broad window: start of day UTC to end of day UTC to catch all buckets
          new Date(yesterdayStr + "T00:00:00Z").getTime(),
          new Date(yesterdayStr + "T23:59:59Z").getTime(),
        )
        .run();
      console.log("[DATA LIFECYCLE] Daily summary roll-up:", dailyAgg?.meta?.changes ?? "ok");

      // Backfill trade counts from trades table for yesterday
      try {
        await db
          .prepare(
            `UPDATE trail_daily_summary SET
              trades_opened = COALESCE((SELECT COUNT(*) FROM trades WHERE ticker = trail_daily_summary.ticker AND entry_ts >= ?1 AND entry_ts < ?2), 0),
              trades_closed = COALESCE((SELECT COUNT(*) FROM trades WHERE ticker = trail_daily_summary.ticker AND exit_ts >= ?1 AND exit_ts < ?2), 0),
              trade_pnl = COALESCE((SELECT SUM(pnl_pct) FROM trades WHERE ticker = trail_daily_summary.ticker AND exit_ts >= ?1 AND exit_ts < ?2), 0)
            WHERE date = ?3`,
          )
          .bind(
            new Date(yesterdayStr + "T00:00:00Z").getTime(),
            new Date(yesterdayStr + "T23:59:59Z").getTime(),
            yesterdayStr,
          )
          .run();
      } catch (tradeErr) {
        console.error("[DATA LIFECYCLE] Daily trade backfill error:", tradeErr);
      }
    } catch (dailyErr) {
      console.error("[DATA LIFECYCLE] Daily summary error:", dailyErr);
    }

    // 5. Tiered candle purge: short TFs expire sooner, D/W kept forever
    let totalCandlesPurged = 0;
    for (const [tf, retentionDays] of Object.entries(CANDLE_RETENTION_DAYS)) {
      const cutoffMs = now - retentionDays * 24 * 60 * 60 * 1000;
      try {
        let tfPurged = 0;
        for (;;) {
          const del = await db
            .prepare(
              `DELETE FROM ticker_candles WHERE rowid IN (
                SELECT rowid FROM ticker_candles WHERE tf = ?1 AND ts < ?2 LIMIT ?3
              )`,
            )
            .bind(tf, cutoffMs, PURGE_BATCH)
            .run();
          const n = del?.meta?.changes ?? 0;
          tfPurged += n;
          if (n < PURGE_BATCH) break;
        }
        if (tfPurged > 0) {
          console.log(`[DATA LIFECYCLE] Purged ${tf} candles: ${tfPurged} (>${retentionDays}d old)`);
          totalCandlesPurged += tfPurged;
        }
      } catch (candleErr) {
        console.error(`[DATA LIFECYCLE] Candle purge error for ${tf}:`, candleErr);
      }
    }
    // One-time purge: delete ALL remaining 1m and 3m candles (no longer written as of Phase 2).
    for (const deadTf of ["1", "3m"]) {
      try {
        let deadPurged = 0;
        for (;;) {
          const del = await db
            .prepare(`DELETE FROM ticker_candles WHERE rowid IN (SELECT rowid FROM ticker_candles WHERE tf = ?1 LIMIT ?2)`)
            .bind(deadTf, PURGE_BATCH)
            .run();
          const n = del?.meta?.changes ?? 0;
          deadPurged += n;
          if (n < PURGE_BATCH) break;
        }
        if (deadPurged > 0) {
          console.log(`[DATA LIFECYCLE] Purged ALL ${deadTf} candles: ${deadPurged} (deprecated TF)`);
          totalCandlesPurged += deadPurged;
        }
      } catch (e) {
        console.error(`[DATA LIFECYCLE] ${deadTf} purge error:`, e);
      }
    }
    if (totalCandlesPurged > 0) {
      console.log(`[DATA LIFECYCLE] Total candles purged: ${totalCandlesPurged}`);
    }

    // 6. Retention purges for secondary D1 tables
    const retentionPurges = [
      { table: "alerts", col: "ts", cutoff: now - DATA_LIFECYCLE_90D_MS, where: null },
      { table: "model_predictions", col: "ts", cutoff: now - DATA_LIFECYCLE_180D_MS, where: "AND resolved = 1" },
      { table: "model_outcomes", col: "resolution_ts", cutoff: now - DATA_LIFECYCLE_180D_MS, where: null },
      { table: "ml_v1_queue", col: "created_at", cutoff: now - DATA_LIFECYCLE_30D_MS, where: null },
      { table: "user_notifications", col: "created_at", cutoff: now - DATA_LIFECYCLE_60D_MS, where: "AND read_at IS NOT NULL" },
      { table: "trail_5m_facts", col: "bucket_ts", cutoff: now - DATA_LIFECYCLE_180D_MS, where: null },
      { table: "queued_actions", col: "resolved_at", cutoff: now - DATA_LIFECYCLE_7D_MS, where: "AND status != 'PENDING'" },
      { table: "queued_actions", col: "queued_at", cutoff: now - 24 * 60 * 60 * 1000, where: "AND status = 'PENDING'" },
    ];
    for (const { table, col, cutoff, where } of retentionPurges) {
      try {
        let purged = 0;
        const whereClause = where ? ` ${where}` : "";
        for (;;) {
          const del = await db
            .prepare(`DELETE FROM ${table} WHERE rowid IN (SELECT rowid FROM ${table} WHERE ${col} < ?1${whereClause} LIMIT ?2)`)
            .bind(cutoff, PURGE_BATCH)
            .run();
          const n = del?.meta?.changes ?? 0;
          purged += n;
          if (n < PURGE_BATCH) break;
        }
        if (purged > 0) {
          console.log(`[DATA LIFECYCLE] Purged ${table}: ${purged} rows`);
        }
      } catch (e) {
        if (!String(e?.message || "").includes("no such table")) {
          console.error(`[DATA LIFECYCLE] ${table} purge error:`, e);
        }
      }
    }

    // 7. Purge ALL D1 + KV data for tickers on the removal blocklist
    try {
      const KV = env?.KV_TIMED || null;
      const removedList = KV ? await KV.get("timed:removed", "json") : null;
      if (Array.isArray(removedList) && removedList.length > 0) {
        let totalRemoved = 0;
        for (const ticker of removedList) {
          for (const table of ["ticker_candles", "ticker_index", "ticker_latest", "timed_trail", "trail_5m_facts", "trail_daily_summary"]) {
            try {
              for (;;) {
                const del = await db
                  .prepare(`DELETE FROM ${table} WHERE rowid IN (SELECT rowid FROM ${table} WHERE ticker = ?1 LIMIT ?2)`)
                  .bind(ticker, PURGE_BATCH)
                  .run();
                const n = del?.meta?.changes ?? 0;
                totalRemoved += n;
                if (n < PURGE_BATCH) break;
              }
            } catch (_) { /* table may not exist */ }
          }
          // Clean orphaned per-ticker KV keys
          if (KV) {
            for (const prefix of TICKER_KV_PREFIXES) {
              try { await KV.delete(`${prefix}${ticker}`); } catch (_) {}
            }
          }
        }
        if (totalRemoved > 0) {
          console.log(`[DATA LIFECYCLE] Purged ${totalRemoved} D1 rows for ${removedList.length} removed tickers`);
        }
      }
    } catch (removedErr) {
      console.error("[DATA LIFECYCLE] Removed-ticker purge error:", removedErr);
    }
  } catch (err) {
    console.error("[DATA LIFECYCLE] Error:", err);
  }
}

// ─────────────────────────────────────────────────────────────
// D1 Latest Snapshot Storage (fast reads for UI)
// ─────────────────────────────────────────────────────────────

async function d1EnsureLatestSchema(env) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  // Throttle schema checks to ~once/day
  const KV = env?.KV_TIMED;
  const throttleKey = "timed:d1:latest:schema_ok_ms";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 24 * 60 * 60 * 1000) {
        return { ok: true, skipped: true, reason: "throttled" };
      }
    }
  } catch {
    // ignore
  }

  try {
    // Index of tickers we know about (baseline)
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ticker_index (
          ticker TEXT PRIMARY KEY,
          first_seen_ts INTEGER NOT NULL,
          last_seen_ts INTEGER NOT NULL
        )`,
      )
      .run();

    // Latest snapshot per ticker (for UI reads)
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ticker_latest (
          ticker TEXT PRIMARY KEY,
          ts INTEGER NOT NULL,
          updated_at INTEGER NOT NULL,
          kanban_stage TEXT,
          prev_kanban_stage TEXT,
          payload_json TEXT NOT NULL
        )`,
      )
      .run();

    // Best-effort schema migration for existing deployments (D1/SQLite doesn't support IF NOT EXISTS for ADD COLUMN)
    try {
      await db
        .prepare(`ALTER TABLE ticker_latest ADD COLUMN prev_kanban_stage TEXT`)
        .run();
    } catch {
      // ignore (already exists)
    }

    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ticker_latest_ts ON ticker_latest (ts)`,
      )
      .run();
    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ticker_latest_kanban_stage ON ticker_latest (kanban_stage)`,
      )
      .run();
    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ticker_latest_prev_kanban_stage ON ticker_latest (prev_kanban_stage)`,
      )
      .run();

    try {
      if (KV)
        await KV.put(throttleKey, String(Date.now()), {
          expirationTtl: 7 * 24 * 60 * 60,
        });
    } catch {
      // ignore
    }

    return { ok: true };
  } catch (err) {
    console.error("[D1 LATEST] Schema ensure failed:", err);
    return { ok: false, error: String(err) };
  }
}

// ─────────────────────────────────────────────────────────────
// D1 Candle Storage (multi-timeframe OHLCV)
// ─────────────────────────────────────────────────────────────

async function d1EnsureCandleSchema(env) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  // Throttle schema checks to ~once/hour (reduced from 24h to ensure migrations run promptly)
  const KV = env?.KV_TIMED;
  const throttleKey = "timed:d1:candles:schema_ok_ms";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 60 * 60 * 1000) {
        return { ok: true, skipped: true, reason: "throttled" };
      }
    }
  } catch {
    // ignore
  }

  try {
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ticker_candles (
          ticker TEXT NOT NULL,
          tf TEXT NOT NULL,
          ts INTEGER NOT NULL,
          o REAL,
          h REAL,
          l REAL,
          c REAL,
          v REAL,
          updated_at INTEGER NOT NULL,
          PRIMARY KEY (ticker, tf, ts)
        )`,
      )
      .run();

    // COST OPTIMIZATION: The old idx_ticker_candles_ticker_tf_ts index was redundant
    // with the PRIMARY KEY (ticker, tf, ts). SQLite B-trees support both ASC/DESC scans.
    // Replaced with idx_candles_tf_ts which enables the GROUP BY prev_close query
    // to use an index instead of a full table scan.
    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_candles_tf_ts
         ON ticker_candles (tf, ts)`,
      )
      .run();

    // Drop the redundant index (reduces write amplification on every INSERT/UPDATE)
    try { await db.prepare(`DROP INDEX IF EXISTS idx_ticker_candles_ticker_tf_ts`).run(); } catch { /* ignore */ }

    // Add session column for extended-hours tagging (PM/RTH/AH/CLOSED)
    // Uses ALTER TABLE which is idempotent — silently fails if column exists
    try {
      await db.prepare(`ALTER TABLE ticker_candles ADD COLUMN session TEXT`).run();
    } catch {
      // Column already exists — expected on subsequent runs
    }

    // ── COST OPTIMIZATION: Missing indexes (one-time creation, zero ongoing cost) ──
    // These indexes were identified in the D1 audit as missing but needed by
    // frequently-executed queries.
    const missingIndexes = [
      // ingest_receipts: retention DELETE needs to scan by received_ts
      `CREATE INDEX IF NOT EXISTS idx_ingest_receipts_received_ts ON ingest_receipts (received_ts)`,
      // trades: daily summary aggregation and exit-time queries
      `CREATE INDEX IF NOT EXISTS idx_trades_ticker_entry_ts ON trades (ticker, entry_ts)`,
      `CREATE INDEX IF NOT EXISTS idx_trades_ticker_exit_ts ON trades (ticker, exit_ts)`,
      // trade_events: type-filtered time queries
      `CREATE INDEX IF NOT EXISTS idx_trade_events_type_ts ON trade_events (type, ts)`,
      // positions: status-filtered ordering
      `CREATE INDEX IF NOT EXISTS idx_positions_status_created_at ON positions (status, created_at)`,
      // investor_positions: composite lookups + ordering
      `CREATE INDEX IF NOT EXISTS idx_inv_pos_ticker_status ON investor_positions (ticker, status)`,
      `CREATE INDEX IF NOT EXISTS idx_inv_pos_status_updated ON investor_positions (status, updated_at DESC)`,
      // users: Stripe webhook lookups
      `CREATE INDEX IF NOT EXISTS idx_users_stripe ON users (stripe_customer_id)`,
      // model_predictions: unresolved prediction lookups
      `CREATE INDEX IF NOT EXISTS idx_mp_ticker_resolved_ts ON model_predictions (ticker, resolved, ts)`,
      // investor_lots: position-level time ordering
      `CREATE INDEX IF NOT EXISTS idx_inv_lots_pos_ts ON investor_lots (position_id, ts DESC)`,
      // lots: position-level time ordering
      `CREATE INDEX IF NOT EXISTS idx_lots_position_ts ON lots (position_id, ts)`,
      // daily_briefs: date + type queries
      `CREATE INDEX IF NOT EXISTS idx_daily_briefs_date_type ON daily_briefs (date DESC, type ASC)`,
      // ml_v1_queue: resolution queries
      `CREATE INDEX IF NOT EXISTS idx_ml_v1_queue_y_due ON ml_v1_queue (y, label_due_ts)`,
      // pattern_library: active patterns sorted by expected value
      `CREATE INDEX IF NOT EXISTS idx_pl_status_ev ON pattern_library (status, expected_value DESC)`,
    ];
    for (const sql of missingIndexes) {
      try { await db.prepare(sql).run(); } catch { /* table may not exist yet */ }
    }

    try {
      if (KV)
        await KV.put(throttleKey, String(Date.now()), {
          expirationTtl: 7 * 24 * 60 * 60,
        });
    } catch {
      // ignore
    }

    return { ok: true };
  } catch (err) {
    console.error("[D1 CANDLES] Schema ensure failed:", err);
    return { ok: false, error: String(err) };
  }
}

// ─────────────────────────────────────────────────────────────
// Investor Positions & DCA — D1 schema
// ─────────────────────────────────────────────────────────────

async function ensureInvestorPositionsSchema(db, KV) {
  const throttleKey = "timed:schema:investor_positions:v1";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 24 * 60 * 60 * 1000) {
        return { ok: true, skipped: true };
      }
    }
  } catch {}

  try {
    // Long-term investor positions (separate from short-term trading positions)
    await db.prepare(`CREATE TABLE IF NOT EXISTS investor_positions (
      id TEXT PRIMARY KEY,
      ticker TEXT NOT NULL,
      status TEXT NOT NULL DEFAULT 'OPEN',
      total_shares REAL NOT NULL DEFAULT 0,
      cost_basis REAL NOT NULL DEFAULT 0,
      avg_entry REAL NOT NULL DEFAULT 0,
      first_entry_ts INTEGER,
      last_entry_ts INTEGER,
      thesis TEXT,
      thesis_invalidation TEXT,
      investor_stage TEXT,
      target_alloc_pct REAL,
      notes TEXT,
      dca_enabled INTEGER NOT NULL DEFAULT 0,
      dca_amount REAL DEFAULT 0,
      dca_frequency TEXT DEFAULT 'monthly',
      dca_next_ts INTEGER,
      dca_total_invested REAL DEFAULT 0,
      dca_num_buys INTEGER DEFAULT 0,
      created_at INTEGER NOT NULL,
      updated_at INTEGER NOT NULL,
      closed_at INTEGER
    )`).run();

    await db.prepare(`CREATE INDEX IF NOT EXISTS idx_inv_pos_ticker ON investor_positions (ticker)`).run();
    await db.prepare(`CREATE INDEX IF NOT EXISTS idx_inv_pos_status ON investor_positions (status)`).run();
    await db.prepare(`CREATE INDEX IF NOT EXISTS idx_inv_pos_dca ON investor_positions (dca_enabled, dca_next_ts)`).run();

    // Transaction log for each buy/sell in an investor position
    await db.prepare(`CREATE TABLE IF NOT EXISTS investor_lots (
      id TEXT PRIMARY KEY,
      position_id TEXT NOT NULL,
      ticker TEXT NOT NULL,
      action TEXT NOT NULL,
      shares REAL NOT NULL,
      price REAL NOT NULL,
      value REAL NOT NULL,
      ts INTEGER NOT NULL,
      reason TEXT,
      created_at INTEGER NOT NULL
    )`).run();

    await db.prepare(`CREATE INDEX IF NOT EXISTS idx_inv_lots_pos ON investor_lots (position_id)`).run();
    await db.prepare(`CREATE INDEX IF NOT EXISTS idx_inv_lots_ticker ON investor_lots (ticker, ts)`).run();

    try {
      if (KV) await KV.put(throttleKey, String(Date.now()), { expirationTtl: 7 * 24 * 60 * 60 });
    } catch {}

    return { ok: true };
  } catch (err) {
    console.error("[D1 INVESTOR] Schema ensure failed:", err);
    return { ok: false, error: String(err) };
  }
}

// DCA frequency → milliseconds between buys
function dcaFrequencyMs(freq) {
  switch (freq) {
    case "weekly": return 7 * 24 * 60 * 60 * 1000;
    case "biweekly": return 14 * 24 * 60 * 60 * 1000;
    case "monthly": return 30 * 24 * 60 * 60 * 1000;
    default: return 30 * 24 * 60 * 60 * 1000;
  }
}

// ─────────────────────────────────────────────────────────────
// ML v1 (online, lightweight) — schema + model utils
// ─────────────────────────────────────────────────────────────

// Keep KV key stable for admin reset + migrations.
const ML_V1_MODEL_KEY = "timed:model:ml_v1";
let ML_V1_CACHE = { model: null, loadedAt: 0 };

function mlV1Sigmoid(z) {
  const n = Number(z);
  if (!Number.isFinite(n)) return 0.5;
  // Clamp to avoid overflow
  const x = Math.max(-30, Math.min(30, n));
  return 1 / (1 + Math.exp(-x));
}

function mlV1DefaultModel() {
  // Keep this small + stable; we can expand later once backfill exists.
  const featureNames = [
    "bias",
    "rank_n",
    "rr_n",
    "completion",
    "phase",
    "abs_htf_n",
    "abs_ltf_n",
    "aligned",
    "setup",
    "sq_rel",
    "in_corridor",
    "momentum_elite",
  ];
  return {
    version: 1,
    featureNames,
    w: featureNames.map(() => 0),
    n: 0,
    lr: 0.05,
    l2: 0.001,
    updated_at: Date.now(),
  };
}

async function mlV1GetModel(KV) {
  const now = Date.now();
  if (ML_V1_CACHE.model && now - ML_V1_CACHE.loadedAt < 60 * 1000) {
    return ML_V1_CACHE.model;
  }
  let model = null;
  try {
    model = KV ? await kvGetJSON(KV, ML_V1_MODEL_KEY) : null;
  } catch {
    model = null;
  }
  if (!model || typeof model !== "object" || !Array.isArray(model.w)) {
    model = mlV1DefaultModel();
  }
  ML_V1_CACHE = { model, loadedAt: now };
  return model;
}

async function mlV1PutModel(KV, model) {
  if (!KV) return;
  const out =
    model && typeof model === "object" ? { ...model, updated_at: Date.now() } : null;
  if (!out) return;
  await kvPutJSON(KV, ML_V1_MODEL_KEY, out);
  ML_V1_CACHE = { model: out, loadedAt: Date.now() };
}

function mlV1ExtractX(d) {
  const flags = d?.flags && typeof d.flags === "object" ? d.flags : {};
  const state = String(d?.state || "");
  const rank = Number(d?.rank);
  const rr = Number(d?.rr);
  const completion = clamp01(d?.completion);
  const phase = clamp01(d?.phase_pct);
  const htf = Number(d?.htf_score);
  const ltf = Number(d?.ltf_score);
  const aligned =
    state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR" ? 1 : 0;
  const setup =
    state === "HTF_BULL_LTF_PULLBACK" || state === "HTF_BEAR_LTF_PULLBACK"
      ? 1
      : 0;

  // Normalize to roughly [-1,1] where possible.
  const rank_n = Number.isFinite(rank) ? (rank - 50) / 50 : 0;
  const rr_n = Number.isFinite(rr) ? Math.max(0, Math.min(4, rr)) / 4 : 0;
  const abs_htf_n = Number.isFinite(htf) ? Math.min(1, Math.abs(htf) / 100) : 0;
  const abs_ltf_n = Number.isFinite(ltf) ? Math.min(1, Math.abs(ltf) / 100) : 0;

  const inCorridor = (() => {
    try {
      return entryType(d)?.corridor ? 1 : 0;
    } catch {
      return 0;
    }
  })();

  return [
    1,
    rank_n,
    rr_n,
    completion,
    phase,
    abs_htf_n,
    abs_ltf_n,
    aligned,
    setup,
    flagOn(flags, "sq30_release") ? 1 : 0,
    inCorridor,
    flagOn(flags, "momentum_elite") ? 1 : 0,
  ];
}

function mlV1PredictProba(model, x) {
  const w = Array.isArray(model?.w) ? model.w : [];
  const n = Math.min(w.length, Array.isArray(x) ? x.length : 0);
  let z = 0;
  for (let i = 0; i < n; i++) z += Number(w[i] || 0) * Number(x[i] || 0);
  return mlV1Sigmoid(z);
}

function mlV1AttachScore(d, model) {
  const x = mlV1ExtractX(d);
  const p = mlV1PredictProba(model, x);
  const rr = Number(d?.rr);
  const rrUnit = Number.isFinite(rr) && rr > 0 ? Math.min(4, rr) : 1;
  // EV in "R units" (treat loss as -1R, win as +RR R). Expose as percent-ish for UI.
  const evUnits = p * rrUnit - (1 - p) * 1;
  const out = {
    v: 1,
    p_win_4h: p,
    ev_4h: evUnits * 100,
    p_win_1d: p,
    ev_1d: evUnits * 100,
    n: Number(model?.n) || 0,
    updated_at: model?.updated_at || null,
  };
  d.ml_v1 = out;
  // Back-compat alias used by UI snippets
  if (d.ml == null) d.ml = out;
  if (d.model == null) d.model = out;
  return out;
}

// Back-compat helper used by ingest/latest/all to attach model fields.
async function mlV1AttachToPayload(KV, payload) {
  if (!payload || typeof payload !== "object") return payload;
  const model = await mlV1GetModel(KV);
  mlV1AttachScore(payload, model);
  return payload;
}

async function d1EnsureMlV1Schema(env) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  try {
    await db
      .prepare(
        `CREATE TABLE IF NOT EXISTS ml_v1_queue (
          id TEXT PRIMARY KEY,
          ticker TEXT NOT NULL,
          ts INTEGER NOT NULL,
          horizon_ms INTEGER NOT NULL,
          dir TEXT,
          entry_price REAL,
          features_json TEXT,
          label_due_ts INTEGER NOT NULL,
          y INTEGER,
          labeled_at INTEGER,
          created_at INTEGER NOT NULL
        )`,
      )
      .run();
    await db
      .prepare(
        `CREATE INDEX IF NOT EXISTS idx_ml_v1_queue_due ON ml_v1_queue (label_due_ts)`,
      )
      .run();
    return { ok: true };
  } catch (e) {
    console.error("[D1 ML] Schema ensure failed:", e);
    return { ok: false, error: String(e) };
  }
}

// ═══════════════════════════════════════════════════════════════════════
// Notification Center — D1 Schema & Helpers
// ═══════════════════════════════════════════════════════════════════════

let _notifSchemaReady = false;
async function d1EnsureNotificationSchema(env) {
  if (_notifSchemaReady) return;
  const db = env?.DB;
  if (!db) return;
  try {
    await db.prepare(`
      CREATE TABLE IF NOT EXISTS push_subscriptions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        email TEXT NOT NULL,
        endpoint TEXT NOT NULL,
        p256dh TEXT NOT NULL,
        auth TEXT NOT NULL,
        created_at INTEGER NOT NULL,
        UNIQUE(email, endpoint)
      )
    `).run();
    await db.prepare(`
      CREATE TABLE IF NOT EXISTS user_notifications (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        email TEXT,
        type TEXT NOT NULL,
        title TEXT NOT NULL,
        body TEXT,
        link TEXT,
        read_at INTEGER,
        created_at INTEGER NOT NULL
      )
    `).run();
    await db.prepare(`
      CREATE INDEX IF NOT EXISTS idx_user_notif_email ON user_notifications(email, created_at DESC)
    `).run();
    _notifSchemaReady = true;
  } catch (e) {
    console.error("[NOTIF] Schema init failed:", String(e).slice(0, 200));
  }
}

// ═══════════════════════════════════════════════════════════════════════
// Action Queue — D1 Schema & Helpers
// Captures signals blocked by outsideRTH/weekend for drain at market open.
// ═══════════════════════════════════════════════════════════════════════

let _queueSchemaReady = false;
async function d1EnsureQueueSchema(env) {
  if (_queueSchemaReady) return;
  const db = env?.DB;
  if (!db) return;
  try {
    await db.prepare(`
      CREATE TABLE IF NOT EXISTS queued_actions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        ticker TEXT NOT NULL,
        action TEXT NOT NULL,
        direction TEXT,
        session TEXT,
        snapshot_json TEXT,
        reason TEXT,
        status TEXT NOT NULL DEFAULT 'PENDING',
        resolution TEXT,
        queued_at INTEGER NOT NULL,
        resolved_at INTEGER
      )
    `).run();
    await db.prepare(`
      CREATE UNIQUE INDEX IF NOT EXISTS idx_queued_actions_pending
      ON queued_actions(ticker, action) WHERE status = 'PENDING'
    `).run();
    await db.prepare(`
      CREATE INDEX IF NOT EXISTS idx_queued_actions_status
      ON queued_actions(status, queued_at)
    `).run();
    _queueSchemaReady = true;
  } catch (e) {
    console.error("[QUEUE] Schema init failed:", String(e).slice(0, 200));
  }
}

async function d1QueueAction(env, { ticker, action, direction, session, snapshot, reason }) {
  const db = env?.DB;
  if (!db) return;
  try {
    await d1EnsureQueueSchema(env);
    const snapshotStr = snapshot ? JSON.stringify(snapshot) : null;
    await db.prepare(`
      INSERT INTO queued_actions (ticker, action, direction, session, snapshot_json, reason, status, queued_at)
      VALUES (?1, ?2, ?3, ?4, ?5, ?6, 'PENDING', ?7)
      ON CONFLICT(ticker, action) WHERE status = 'PENDING'
      DO UPDATE SET direction=excluded.direction, session=excluded.session,
                    snapshot_json=excluded.snapshot_json, reason=excluded.reason,
                    queued_at=excluded.queued_at
    `).bind(ticker, action, direction || null, session || null, snapshotStr, reason || null, Date.now()).run();
    console.log(`[QUEUE] Queued ${ticker}/${action} (reason=${reason}, session=${session})`);
  } catch (e) {
    console.error(`[QUEUE] Insert failed for ${ticker}/${action}:`, String(e).slice(0, 200));
  }
}

async function d1ResolveQueuedAction(env, { ticker, action, status, resolution }) {
  const db = env?.DB;
  if (!db) return;
  try {
    await db.prepare(`
      UPDATE queued_actions SET status = ?3, resolution = ?4, resolved_at = ?5
      WHERE ticker = ?1 AND action = ?2 AND status = 'PENDING'
    `).bind(ticker, action, status, resolution || null, Date.now()).run();
  } catch (e) {
    console.error(`[QUEUE] Resolve failed for ${ticker}/${action}:`, String(e).slice(0, 200));
  }
}

/**
 * Drain queued actions at market open. Called once per day at first RTH scoring cycle.
 * Re-evaluates each PENDING action against fresh data. Executes if still valid, expires if stale.
 */
async function drainQueuedActions(env) {
  const db = env?.DB;
  const KV = env?.KV_TIMED;
  if (!db || !KV) return { executed: 0, expired: 0 };

  const throttleKey = `timed:queue:drained:${_calGetETDateStr()}`;
  const alreadyDrained = await KV.get(throttleKey);
  if (alreadyDrained) return { executed: 0, expired: 0, skipped: true };

  try {
    await d1EnsureQueueSchema(env);
    const rows = await db.prepare(
      `SELECT id, ticker, action, direction, snapshot_json, reason FROM queued_actions WHERE status = 'PENDING' ORDER BY queued_at ASC`
    ).all();
    const pending = rows?.results || [];
    if (pending.length === 0) {
      await KV.put(throttleKey, "1", { expirationTtl: 24 * 3600 });
      return { executed: 0, expired: 0 };
    }

    console.log(`[QUEUE DRAIN] Processing ${pending.length} pending actions at market open`);
    let executed = 0, expired = 0;

    for (const row of pending) {
      const { ticker, action, direction } = row;
      try {
        const latestData = await kvGetJSON(KV, `timed:latest:${ticker}`);
        if (!latestData) {
          await d1ResolveQueuedAction(env, { ticker, action, status: "EXPIRED", resolution: "no_latest_data" });
          expired++;
          continue;
        }

        const currentStage = String(latestData.kanban_stage || "").toLowerCase();

        if (action === "enter") {
          const stillEnter = currentStage === "enter" || currentStage === "enter_now";
          if (stillEnter) {
            await processTradeSimulation(KV, ticker, latestData, null, env);
            await d1ResolveQueuedAction(env, { ticker, action, status: "EXECUTED", resolution: "still_qualifies" });
            executed++;
          } else {
            await d1ResolveQueuedAction(env, { ticker, action, status: "EXPIRED", resolution: `stage_changed_to_${currentStage}` });
            expired++;
          }
        } else if (action === "exit") {
          const stillExit = currentStage === "exit";
          if (stillExit) {
            await processTradeSimulation(KV, ticker, latestData, null, env);
            await d1ResolveQueuedAction(env, { ticker, action, status: "EXECUTED", resolution: "still_qualifies" });
            executed++;
          } else {
            await d1ResolveQueuedAction(env, { ticker, action, status: "EXPIRED", resolution: `stage_changed_to_${currentStage}` });
            expired++;
          }
        } else if (action === "trim") {
          const stillTrim = currentStage === "trim";
          if (stillTrim) {
            await processTradeSimulation(KV, ticker, latestData, null, env);
            await d1ResolveQueuedAction(env, { ticker, action, status: "EXECUTED", resolution: "still_qualifies" });
            executed++;
          } else {
            await d1ResolveQueuedAction(env, { ticker, action, status: "EXPIRED", resolution: `stage_changed_to_${currentStage}` });
            expired++;
          }
        } else {
          await d1ResolveQueuedAction(env, { ticker, action, status: "EXPIRED", resolution: "unknown_action" });
          expired++;
        }
      } catch (e) {
        console.error(`[QUEUE DRAIN] Error processing ${ticker}/${action}:`, String(e).slice(0, 200));
        await d1ResolveQueuedAction(env, { ticker, action, status: "EXPIRED", resolution: `error:${String(e).slice(0, 100)}` });
        expired++;
      }
    }

    await KV.put(throttleKey, "1", { expirationTtl: 24 * 3600 });
    console.log(`[QUEUE DRAIN] Complete: ${executed} executed, ${expired} expired`);

    if ((executed > 0 || expired > 0) && shouldSendDiscordAlert(env, "SYSTEM")) {
      const details = pending.map(r => `${r.ticker} ${r.action} → ${r.ticker === r.ticker ? "" : ""}`).slice(0, 10);
      notifyDiscord(env, {
        embeds: [{
          title: "📋 Queue Drain Summary",
          description: `Processed **${pending.length}** queued actions at market open.\n✅ Executed: **${executed}** | ❌ Expired: **${expired}**`,
          color: executed > 0 ? 0x00e676 : 0xffa726,
          timestamp: new Date().toISOString(),
        }],
      }).catch(() => {});
    }

    return { executed, expired };
  } catch (e) {
    console.error("[QUEUE DRAIN] Fatal error:", e);
    return { executed: 0, expired: 0, error: String(e) };
  }
}

/** Insert a notification for a user (or broadcast if email is null) */
async function d1InsertNotification(env, { email, type, title, body, link }) {
  const db = env?.DB;
  if (!db) return;
  try {
    await d1EnsureNotificationSchema(env);
    await db.prepare(`
      INSERT INTO user_notifications (email, type, title, body, link, created_at)
      VALUES (?1, ?2, ?3, ?4, ?5, ?6)
    `).bind(email || null, type, title, body || null, link || null, Date.now()).run();

    // Fire Web Push to all matching subscriptions (non-blocking)
    try {
      await sendWebPushForNotification(env, { email, type, title, body, link });
    } catch (pushErr) {
      console.warn("[PUSH] sendWebPush failed:", String(pushErr).slice(0, 200));
    }
  } catch (e) {
    console.warn("[NOTIF] Insert failed:", String(e).slice(0, 100));
  }
}

// ═══════════════════════════════════════════════════════════════════════
// Web Push — VAPID + RFC 8291 (aes128gcm) using Web Crypto API
// ═══════════════════════════════════════════════════════════════════════

/**
 * Send Web Push notifications for a notification event.
 * If email is null (broadcast), sends to ALL subscriptions.
 * If email is set, sends only to that user's subscriptions.
 */
async function sendWebPushForNotification(env, { email, type, title, body, link }) {
  const db = env?.DB;
  const vapidPrivateKey = env?.VAPID_PRIVATE_KEY;
  const vapidSubject = env?.VAPID_SUBJECT || "mailto:legal@timed-trading.com";
  if (!db || !vapidPrivateKey) return;

  try {
    await d1EnsureNotificationSchema(env);
    let subs;
    if (email) {
      subs = await db.prepare(
        `SELECT endpoint, p256dh, auth FROM push_subscriptions WHERE email = ?1`
      ).bind(email.toLowerCase()).all();
    } else {
      // Broadcast: send to all subscriptions
      subs = await db.prepare(
        `SELECT endpoint, p256dh, auth FROM push_subscriptions`
      ).all();
    }
    const rows = subs?.results || [];
    if (rows.length === 0) return;

    const payload = JSON.stringify({
      title: title || "Timed Trading",
      body: body || "",
      type: type || "system",
      link: link || "/index-react.html",
      tag: `timed-${type}-${Date.now()}`,
    });

    const vapidKeys = await importVapidKeys(vapidPrivateKey);

    let sent = 0, failed = 0, cleaned = 0;
    for (const sub of rows) {
      try {
        const response = await sendWebPush({
          endpoint: sub.endpoint,
          p256dh: sub.p256dh,
          auth: sub.auth,
          payload,
          vapidKeys,
          vapidSubject,
        });
        if (response.status === 201 || response.status === 200) {
          sent++;
        } else if (response.status === 404 || response.status === 410) {
          // Subscription expired/unsubscribed — clean up
          await db.prepare(
            `DELETE FROM push_subscriptions WHERE endpoint = ?1`
          ).bind(sub.endpoint).run();
          cleaned++;
        } else {
          failed++;
          console.warn(`[PUSH] ${response.status} for ${sub.endpoint.slice(0, 60)}...`);
        }
      } catch (err) {
        failed++;
        console.warn(`[PUSH] Error for endpoint: ${String(err).slice(0, 100)}`);
      }
    }
    if (sent > 0 || cleaned > 0 || failed > 0) {
      console.log(`[PUSH] sent=${sent} cleaned=${cleaned} failed=${failed} type=${type}`);
    }
  } catch (e) {
    console.warn("[PUSH] sendWebPushForNotification error:", String(e).slice(0, 200));
  }
}

// ── Base64url helpers ──────────────────────────────────────────────────

function base64urlToUint8Array(base64url) {
  const base64 = base64url.replace(/-/g, "+").replace(/_/g, "/");
  const pad = (4 - (base64.length % 4)) % 4;
  const padded = base64 + "=".repeat(pad);
  const binary = atob(padded);
  const bytes = new Uint8Array(binary.length);
  for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
  return bytes;
}

function uint8ArrayToBase64url(bytes) {
  let binary = "";
  for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);
  return btoa(binary).replace(/\+/g, "-").replace(/\//g, "_").replace(/=+$/, "");
}

// ── VAPID JWT ──────────────────────────────────────────────────────────

/**
 * Import the VAPID private key (base64url-encoded raw 32-byte scalar)
 * and derive the public key for the JWT header.
 *
 * Strategy: wrap the raw 32-byte scalar into a PKCS8 DER envelope and import.
 * CF Workers' Web Crypto will derive the public point automatically on export.
 */
async function importVapidKeys(privateKeyBase64url) {
  const rawPrivateKey = base64urlToUint8Array(privateKeyBase64url);

  // Build minimal PKCS8 DER for EC P-256 private key (RFC 5958 / SEC 1)
  // Structure: SEQUENCE { version(0), AlgorithmIdentifier(EC, P-256), OCTET STRING { ECPrivateKey { version(1), privateKey } } }
  const ecPrivateKey = buildDerSequence([
    buildDerInteger(new Uint8Array([1])),          // version = 1
    buildDerOctetString(rawPrivateKey),             // 32-byte private scalar
  ]);
  const algorithmId = buildDerSequence([
    new Uint8Array([0x06, 0x07, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x02, 0x01]), // OID 1.2.840.10045.2.1 (EC)
    new Uint8Array([0x06, 0x08, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x03, 0x01, 0x07]), // OID 1.2.840.10045.3.1.7 (P-256)
  ]);
  const pkcs8 = buildDerSequence([
    buildDerInteger(new Uint8Array([0])),           // version = 0
    algorithmId,
    buildDerOctetString(ecPrivateKey),
  ]);

  const privateKey = await crypto.subtle.importKey(
    "pkcs8",
    pkcs8,
    { name: "ECDSA", namedCurve: "P-256" },
    true,
    ["sign"],
  );

  // Export as JWK to get x,y coords, then build the 65-byte uncompressed public key
  const jwk = await crypto.subtle.exportKey("jwk", privateKey);
  const x = base64urlToUint8Array(jwk.x);
  const y = base64urlToUint8Array(jwk.y);
  const publicKeyBytes = new Uint8Array(65);
  publicKeyBytes[0] = 0x04;
  publicKeyBytes.set(x, 1);
  publicKeyBytes.set(y, 33);

  return { privateKey, publicKeyBytes };
}

// ── Minimal DER helpers (just enough for PKCS8 wrapping) ───────────────

function buildDerLength(length) {
  if (length < 0x80) return new Uint8Array([length]);
  if (length < 0x100) return new Uint8Array([0x81, length]);
  return new Uint8Array([0x82, (length >> 8) & 0xff, length & 0xff]);
}

function buildDerSequence(items) {
  let totalLen = 0;
  for (const item of items) totalLen += item.length;
  const lenBytes = buildDerLength(totalLen);
  const out = new Uint8Array(1 + lenBytes.length + totalLen);
  out[0] = 0x30; // SEQUENCE tag
  out.set(lenBytes, 1);
  let offset = 1 + lenBytes.length;
  for (const item of items) { out.set(item, offset); offset += item.length; }
  return out;
}

function buildDerOctetString(data) {
  const lenBytes = buildDerLength(data.length);
  const out = new Uint8Array(1 + lenBytes.length + data.length);
  out[0] = 0x04; // OCTET STRING tag
  out.set(lenBytes, 1);
  out.set(data, 1 + lenBytes.length);
  return out;
}

function buildDerInteger(value) {
  // Prepend 0x00 if high bit set (to keep positive)
  const needPad = value[0] & 0x80;
  const len = value.length + (needPad ? 1 : 0);
  const lenBytes = buildDerLength(len);
  const out = new Uint8Array(1 + lenBytes.length + len);
  out[0] = 0x02; // INTEGER tag
  out.set(lenBytes, 1);
  if (needPad) { out[1 + lenBytes.length] = 0x00; out.set(value, 2 + lenBytes.length); }
  else out.set(value, 1 + lenBytes.length);
  return out;
}

/**
 * Create a signed VAPID JWT for the given push endpoint audience.
 */
async function createVapidJwt(endpoint, vapidKeys, vapidSubject) {
  const audience = new URL(endpoint).origin;
  const expiry = Math.floor(Date.now() / 1000) + 12 * 3600; // 12 hours

  const header = { typ: "JWT", alg: "ES256" };
  const payload = { aud: audience, exp: expiry, sub: vapidSubject };

  const encoder = new TextEncoder();
  const headerB64 = uint8ArrayToBase64url(encoder.encode(JSON.stringify(header)));
  const payloadB64 = uint8ArrayToBase64url(encoder.encode(JSON.stringify(payload)));
  const unsignedToken = `${headerB64}.${payloadB64}`;

  const signature = await crypto.subtle.sign(
    { name: "ECDSA", hash: { name: "SHA-256" } },
    vapidKeys.privateKey,
    encoder.encode(unsignedToken),
  );

  // Convert DER signature to raw r||s (64 bytes) for JWT ES256
  const sigBytes = new Uint8Array(signature);
  const rawSig = derToRaw(sigBytes);

  const signatureB64 = uint8ArrayToBase64url(rawSig);
  return `${unsignedToken}.${signatureB64}`;
}

/**
 * Convert DER-encoded ECDSA signature to raw r||s (64 bytes).
 * Handles leading zeros properly.
 */
function derToRaw(der) {
  // DER: 0x30 [len] 0x02 [rLen] [r...] 0x02 [sLen] [s...]
  if (der[0] === 0x30) {
    let offset = 2;
    const rLen = der[offset + 1];
    const r = der.slice(offset + 2, offset + 2 + rLen);
    offset = offset + 2 + rLen;
    const sLen = der[offset + 1];
    const s = der.slice(offset + 2, offset + 2 + sLen);

    const raw = new Uint8Array(64);
    // Right-align r and s to 32 bytes each (strip leading 0x00 padding)
    const rTrim = r[0] === 0 && r.length > 32 ? r.slice(1) : r;
    const sTrim = s[0] === 0 && s.length > 32 ? s.slice(1) : s;
    raw.set(rTrim, 32 - rTrim.length);
    raw.set(sTrim, 64 - sTrim.length);
    return raw;
  }
  // Already raw (64 bytes)
  if (der.length === 64) return der;
  throw new Error("Unexpected ECDSA signature format");
}

// ── RFC 8291 Payload Encryption (aes128gcm) ────────────────────────────

/**
 * Encrypt a push notification payload per RFC 8291 + RFC 8188 (aes128gcm).
 *
 * @param {string} payload - The plaintext payload
 * @param {string} p256dhBase64url - Client's P-256 public key (base64url)
 * @param {string} authBase64url - Client's auth secret (base64url, 16 bytes)
 * @returns {Object} { encrypted: Uint8Array, localPublicKey: Uint8Array }
 */
async function encryptPushPayload(payload, p256dhBase64url, authBase64url) {
  const clientPublicKeyBytes = base64urlToUint8Array(p256dhBase64url);
  const authSecret = base64urlToUint8Array(authBase64url);
  const plaintext = new TextEncoder().encode(payload);

  // Generate ephemeral ECDH key pair
  const localKeyPair = await crypto.subtle.generateKey(
    { name: "ECDH", namedCurve: "P-256" },
    true,
    ["deriveBits"],
  );

  // Export local public key as uncompressed point
  const localPublicKeyRaw = await crypto.subtle.exportKey("raw", localKeyPair.publicKey);
  const localPublicKey = new Uint8Array(localPublicKeyRaw);

  // Import client's public key
  const clientPublicKey = await crypto.subtle.importKey(
    "raw",
    clientPublicKeyBytes,
    { name: "ECDH", namedCurve: "P-256" },
    false,
    [],
  );

  // ECDH shared secret
  const sharedSecretBits = await crypto.subtle.deriveBits(
    { name: "ECDH", public: clientPublicKey },
    localKeyPair.privateKey,
    256,
  );
  const sharedSecret = new Uint8Array(sharedSecretBits);

  // RFC 8291 §3.4: IKM = HKDF(auth_secret, ecdh_secret, "WebPush: info\0" || client_pub || server_pub, 32)
  const encoder = new TextEncoder();
  const infoPrefix = encoder.encode("WebPush: info\0");
  const keyInfo = new Uint8Array(infoPrefix.length + clientPublicKeyBytes.length + localPublicKey.length);
  keyInfo.set(infoPrefix, 0);
  keyInfo.set(clientPublicKeyBytes, infoPrefix.length);
  keyInfo.set(localPublicKey, infoPrefix.length + clientPublicKeyBytes.length);

  const ikm = await hkdf(authSecret, sharedSecret, keyInfo, 32);

  // Generate 16-byte salt
  const salt = crypto.getRandomValues(new Uint8Array(16));

  // Derive Content-Encryption Key (CEK) and nonce
  const cekInfo = encoder.encode("Content-Encoding: aes128gcm\0");
  const nonceInfo = encoder.encode("Content-Encoding: nonce\0");

  const cek = await hkdf(salt, ikm, cekInfo, 16);
  const nonce = await hkdf(salt, ikm, nonceInfo, 12);

  // Pad plaintext: payload || 0x02 (delimiter for final record)
  const padded = new Uint8Array(plaintext.length + 1);
  padded.set(plaintext, 0);
  padded[plaintext.length] = 0x02; // Final record padding delimiter

  // AES-128-GCM encrypt
  const aesKey = await crypto.subtle.importKey(
    "raw", cek, { name: "AES-GCM" }, false, ["encrypt"],
  );
  const ciphertext = await crypto.subtle.encrypt(
    { name: "AES-GCM", iv: nonce },
    aesKey,
    padded,
  );
  const encryptedBytes = new Uint8Array(ciphertext);

  // Build aes128gcm header: salt(16) || rs(4) || idlen(1) || keyid(65) || ciphertext
  const rs = plaintext.length + 1 + 16 + 1; // record size (padded plaintext + tag overhead + delimiter... use 4096 as safe default)
  const recordSize = 4096;
  const header = new Uint8Array(16 + 4 + 1 + localPublicKey.length);
  header.set(salt, 0);
  // Record size as 4-byte big-endian
  const rsView = new DataView(header.buffer, 16, 4);
  rsView.setUint32(0, recordSize, false);
  header[20] = localPublicKey.length; // idlen
  header.set(localPublicKey, 21);

  // Combine header + ciphertext
  const encrypted = new Uint8Array(header.length + encryptedBytes.length);
  encrypted.set(header, 0);
  encrypted.set(encryptedBytes, header.length);

  return { encrypted, localPublicKey };
}

/**
 * HKDF-SHA256 extract + expand (single output block, length ≤ 32 bytes for most, ≤ 255*32 total).
 */
async function hkdf(salt, ikm, info, length) {
  // Extract: PRK = HMAC-SHA256(salt, ikm)
  const extractKey = await crypto.subtle.importKey(
    "raw", salt, { name: "HMAC", hash: "SHA-256" }, false, ["sign"],
  );
  const prk = new Uint8Array(await crypto.subtle.sign("HMAC", extractKey, ikm));

  // Expand: T(1) = HMAC-SHA256(PRK, info || 0x01)
  const expandKey = await crypto.subtle.importKey(
    "raw", prk, { name: "HMAC", hash: "SHA-256" }, false, ["sign"],
  );
  const expandInput = new Uint8Array(info.length + 1);
  expandInput.set(info, 0);
  expandInput[info.length] = 1;
  const output = new Uint8Array(await crypto.subtle.sign("HMAC", expandKey, expandInput));

  return output.slice(0, length);
}

// ── Send a single Web Push message ─────────────────────────────────────

/**
 * Send a Web Push notification to a single subscription endpoint.
 *
 * @param {Object} opts
 * @param {string} opts.endpoint - Push service endpoint URL
 * @param {string} opts.p256dh - Client public key (base64url)
 * @param {string} opts.auth - Client auth secret (base64url)
 * @param {string} opts.payload - JSON string to send
 * @param {Object} opts.vapidKeys - { privateKey: CryptoKey, publicKeyBytes: Uint8Array }
 * @param {string} opts.vapidSubject - VAPID subject (mailto: URL)
 * @returns {Response}
 */
async function sendWebPush({ endpoint, p256dh, auth, payload, vapidKeys, vapidSubject }) {
  // 1. Encrypt payload using RFC 8291
  const { encrypted } = await encryptPushPayload(payload, p256dh, auth);

  // 2. Create VAPID authorization
  const jwt = await createVapidJwt(endpoint, vapidKeys, vapidSubject);
  const vapidPublicKeyB64 = uint8ArrayToBase64url(vapidKeys.publicKeyBytes);

  // 3. POST to push service
  return fetch(endpoint, {
    method: "POST",
    headers: {
      "Content-Type": "application/octet-stream",
      "Content-Encoding": "aes128gcm",
      "Content-Length": String(encrypted.length),
      "TTL": "86400",
      "Urgency": "normal",
      "Authorization": `vapid t=${jwt}, k=${vapidPublicKeyB64}`,
    },
    body: encrypted,
  });
}

// ═══════════════════════════════════════════════════════════════════════
// Subscription / Stripe — D1 Schema Helpers
// ═══════════════════════════════════════════════════════════════════════

let _stripeSchemaReady = false;
async function d1EnsureStripeSchema(env) {
  if (_stripeSchemaReady) return;
  const db = env?.DB;
  if (!db) return;
  try {
    // Add Stripe columns to users table (idempotent ALTER TABLE)
    const cols = [
      ["stripe_customer_id", "TEXT"],
      ["stripe_subscription_id", "TEXT"],
      ["subscription_status", "TEXT DEFAULT 'none'"],
      ["trial_end", "INTEGER"],
    ];
    for (const [col, type] of cols) {
      try {
        await db.prepare(`ALTER TABLE users ADD COLUMN ${col} ${type}`).run();
      } catch {
        // Column already exists — ignore
      }
    }
    _stripeSchemaReady = true;
  } catch (e) {
    console.error("[STRIPE] Schema migration failed:", String(e).slice(0, 200));
  }
}

// ═══════════════════════════════════════════════════════════════════════
// Admin — D1 Schema Helpers (login_count, login_days tracking)
// ═══════════════════════════════════════════════════════════════════════

let _adminSchemaReady = false;
async function d1EnsureAdminSchema(env) {
  if (_adminSchemaReady) return;
  const db = env?.DB;
  if (!db) return;
  try {
    const cols = [
      ["login_count", "INTEGER DEFAULT 0"],
      ["login_days", "INTEGER DEFAULT 0"],
      ["last_login_day", "TEXT"],
    ];
    for (const [col, type] of cols) {
      try {
        await db.prepare(`ALTER TABLE users ADD COLUMN ${col} ${type}`).run();
      } catch {
        // Column already exists — ignore
      }
    }
    _adminSchemaReady = true;
  } catch (e) {
    console.error("[ADMIN] Schema migration failed:", String(e).slice(0, 200));
  }
}

// ═══════════════════════════════════════════════════════════════════════
// Phase 5 — User-Added Tickers
// ═══════════════════════════════════════════════════════════════════════

let _userTickersSchemaReady = false;
async function d1EnsureUserTickersSchema(env) {
  if (_userTickersSchemaReady) return;
  const db = env?.DB;
  if (!db) return;
  try {
    await db.prepare(
      `CREATE TABLE IF NOT EXISTS user_tickers (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_email TEXT NOT NULL,
        ticker TEXT NOT NULL,
        added_at INTEGER NOT NULL,
        deleted_at INTEGER,
        UNIQUE(user_email, ticker)
      )`
    ).run();
    try {
      await db.prepare(`CREATE INDEX IF NOT EXISTS idx_ut_email ON user_tickers(user_email)`).run();
      await db.prepare(`CREATE INDEX IF NOT EXISTS idx_ut_ticker ON user_tickers(ticker)`).run();
    } catch { /* indexes may already exist */ }
    _userTickersSchemaReady = true;
  } catch (e) {
    console.error("[USER_TICKERS] Schema migration failed:", String(e).slice(0, 200));
  }
}

// ═══════════════════════════════════════════════════════════════════════
// Learning Loop Schema — direction accuracy, path performance, model config
// ═══════════════════════════════════════════════════════════════════════

let _learningSchemaReady = false;
async function d1EnsureLearningSchema(env) {
  if (_learningSchemaReady) return;
  const db = env?.DB;
  if (!db) return;
  try {
    await db.batch([
      db.prepare(`CREATE TABLE IF NOT EXISTS direction_accuracy (
        trade_id TEXT PRIMARY KEY, ticker TEXT NOT NULL, ts INTEGER NOT NULL,
        traded_direction TEXT NOT NULL, consensus_direction TEXT, htf_score_direction TEXT,
        state_direction TEXT, direction_source TEXT,
        htf_score REAL, ltf_score REAL, regime_daily TEXT, regime_weekly TEXT, regime_combined TEXT,
        bullish_count INTEGER, bearish_count INTEGER, tf_stack_json TEXT,
        entry_path TEXT, rank INTEGER, rr REAL, entry_price REAL,
        exit_ts INTEGER, exit_price REAL, pnl REAL, pnl_pct REAL,
        direction_correct INTEGER, max_favorable_excursion REAL, max_adverse_excursion REAL,
        status TEXT, signal_snapshot_json TEXT
      )`),
      db.prepare(`CREATE TABLE IF NOT EXISTS path_performance (
        entry_path TEXT PRIMARY KEY, total_trades INTEGER NOT NULL DEFAULT 0,
        wins INTEGER NOT NULL DEFAULT 0, losses INTEGER NOT NULL DEFAULT 0, flats INTEGER NOT NULL DEFAULT 0,
        win_rate REAL, avg_pnl REAL, avg_pnl_pct REAL, avg_hold_minutes REAL,
        avg_mfe REAL, avg_mae REAL, recent_win_rate REAL, recent_trades INTEGER DEFAULT 0,
        enabled INTEGER NOT NULL DEFAULT 1, disable_reason TEXT,
        quality_gate_adj REAL DEFAULT 0, last_updated INTEGER NOT NULL
      )`),
      db.prepare(`CREATE TABLE IF NOT EXISTS model_config (
        config_key TEXT PRIMARY KEY, config_value TEXT NOT NULL, description TEXT,
        updated_at INTEGER NOT NULL, updated_by TEXT DEFAULT 'system'
      )`),
    ]);
    try {
      await db.batch([
        db.prepare(`CREATE INDEX IF NOT EXISTS idx_da_ticker_ts ON direction_accuracy (ticker, ts)`),
        db.prepare(`CREATE INDEX IF NOT EXISTS idx_da_direction_source ON direction_accuracy (direction_source)`),
        db.prepare(`CREATE INDEX IF NOT EXISTS idx_da_entry_path ON direction_accuracy (entry_path)`),
        db.prepare(`CREATE INDEX IF NOT EXISTS idx_da_status ON direction_accuracy (status)`),
        db.prepare(`CREATE INDEX IF NOT EXISTS idx_pp_enabled ON path_performance (enabled)`),
      ]);
    } catch { /* indexes may already exist */ }
    try {
      await db.prepare(`ALTER TABLE direction_accuracy ADD COLUMN signal_snapshot_json TEXT`).run();
    } catch { /* column may already exist */ }
    _learningSchemaReady = true;
  } catch (e) {
    console.error("[LEARNING] Schema migration failed:", String(e).slice(0, 200));
  }
}

// ═══════════════════════════════════════════════════════════════════════
// Calibration Pipeline — Analysis Engine
// ═══════════════════════════════════════════════════════════════════════

function percentile(arr, p) {
  if (!arr.length) return 0;
  const sorted = [...arr].sort((a, b) => a - b);
  const idx = (p / 100) * (sorted.length - 1);
  const lo = Math.floor(idx), hi = Math.ceil(idx);
  return lo === hi ? sorted[lo] : sorted[lo] + (sorted[hi] - sorted[lo]) * (idx - lo);
}

function spearmanCorrelation(x, y) {
  const n = x.length;
  if (n < 5) return 0;
  const rank = arr => {
    const sorted = arr.map((v, i) => ({ v, i })).sort((a, b) => a.v - b.v);
    const ranks = new Array(n);
    for (let i = 0; i < n; i++) ranks[sorted[i].i] = i + 1;
    return ranks;
  };
  const rx = rank(x), ry = rank(y);
  let d2 = 0;
  for (let i = 0; i < n; i++) d2 += (rx[i] - ry[i]) ** 2;
  return 1 - (6 * d2) / (n * (n * n - 1));
}

function computeATR14(candles) {
  const atrs = new Array(candles.length).fill(0);
  for (let i = 1; i < candles.length; i++) {
    const tr = Math.max(candles[i].h - candles[i].l, Math.abs(candles[i].h - candles[i - 1].c), Math.abs(candles[i].l - candles[i - 1].c));
    atrs[i] = i < 14 ? atrs[i - 1] + (tr - atrs[i - 1]) / i : atrs[i - 1] + (tr - atrs[i - 1]) / 14;
  }
  return atrs;
}

async function harvestMovesServerSide(env) {
  const db = env?.DB;
  const MIN_ATR = 1.5, MIN_DUR = 3;

  const { results: rawCandles } = await db.prepare(
    `SELECT ticker, ts, o, h, l, c FROM ticker_candles WHERE tf='D' ORDER BY ticker, ts`
  ).all();
  if (!rawCandles.length) return 0;

  const byTicker = {};
  for (const c of rawCandles) {
    const t = String(c.ticker).toUpperCase();
    (byTicker[t] = byTicker[t] || []).push({ ts: Number(c.ts), o: Number(c.o), h: Number(c.h), l: Number(c.l), c: Number(c.c) });
  }
  for (const arr of Object.values(byTicker)) arr.sort((a, b) => a.ts - b.ts);

  const { results: trailRows } = await db.prepare(
    `SELECT ticker, bucket_ts, htf_score_avg, ltf_score_avg, state, rank,
            had_squeeze_release, had_ema_cross, had_st_flip, had_momentum_elite
     FROM trail_5m_facts ORDER BY ticker, bucket_ts`
  ).all();
  const trailByTicker = {};
  for (const r of trailRows) { const t = String(r.ticker).toUpperCase(); (trailByTicker[t] = trailByTicker[t] || []).push(r); }

  const { results: daRows } = await db.prepare(
    `SELECT ticker, ts, signal_snapshot_json, regime_daily, regime_weekly, regime_combined
     FROM direction_accuracy WHERE signal_snapshot_json IS NOT NULL ORDER BY ticker, ts`
  ).all();
  const daByTicker = {};
  for (const r of daRows) { const t = String(r.ticker).toUpperCase(); (daByTicker[t] = daByTicker[t] || []).push(r); }

  let allMoves = [];
  for (const [ticker, candles] of Object.entries(byTicker)) {
    if (candles.length < 30) continue;
    const atrs = computeATR14(candles);

    for (let i = MIN_DUR; i < candles.length; i++) {
      const atr = atrs[i] || atrs[i - 1];
      if (!atr || atr <= 0) continue;
      for (let lb = MIN_DUR; lb <= Math.min(40, i); lb++) {
        const si = i - lb;
        const startAtr = atrs[si] || atr;
        if (startAtr <= 0) continue;
        const sp = candles[si].c, ep = candles[i].c;
        const movePct = ((ep - sp) / sp) * 100;
        const moveAtr = Math.abs(ep - sp) / startAtr;
        if (moveAtr < MIN_ATR || lb < MIN_DUR) continue;
        const dir = movePct > 0 ? "UP" : "DOWN";
        let maxExt = 0, maxPull = 0;
        const mfes = [], maes = [];
        for (let j = si + 1; j <= i; j++) {
          const fav = dir === "UP" ? (candles[j].h - sp) / startAtr : (sp - candles[j].l) / startAtr;
          const adv = dir === "UP" ? (sp - candles[j].l) / startAtr : (candles[j].h - sp) / startAtr;
          maxExt = Math.max(maxExt, fav); maxPull = Math.max(maxPull, adv);
          mfes.push(fav); maes.push(adv > 0 ? adv : 0);
        }
        let signalsJson = null, regimeJson = null;
        const trail = trailByTicker[ticker];
        if (trail) {
          const startTs = candles[si].ts;
          let closest = null, minDist = Infinity;
          for (const r of trail) { const d = Math.abs(Number(r.bucket_ts) - startTs); if (d < minDist) { minDist = d; closest = r; } }
          if (closest && minDist < 2 * 86400000) {
            signalsJson = JSON.stringify({ htf_score: Number(closest.htf_score_avg) || 0, ltf_score: Number(closest.ltf_score_avg) || 0, state: closest.state, rank: Number(closest.rank) || 0, squeeze_release: closest.had_squeeze_release ? 1 : 0, ema_cross: closest.had_ema_cross ? 1 : 0, st_flip: closest.had_st_flip ? 1 : 0, momentum_elite: closest.had_momentum_elite ? 1 : 0 });
          }
        }
        const da = daByTicker[ticker];
        if (da) {
          const startTs = candles[si].ts;
          let closest = null, minDist = Infinity;
          for (const r of da) { const d = Math.abs(Number(r.ts) - startTs); if (d < minDist) { minDist = d; closest = r; } }
          if (closest && minDist < 3 * 86400000) {
            signalsJson = closest.signal_snapshot_json || signalsJson;
            regimeJson = JSON.stringify({ daily: closest.regime_daily, weekly: closest.regime_weekly, combined: closest.regime_combined });
          }
        }
        allMoves.push({
          move_id: `${ticker}_${dir}_${candles[si].ts}`, ticker, direction: dir,
          start_ts: candles[si].ts, end_ts: candles[i].ts, duration_days: lb,
          move_pct: Math.round(movePct * 100) / 100, move_atr: Math.round(moveAtr * 100) / 100,
          max_ext_atr: Math.round(maxExt * 100) / 100, pullback_atr: Math.round(maxPull * 100) / 100,
          sl_optimal_atr: Math.round(percentile(maes.filter(v => v > 0), 75) * 100) / 100,
          tp_p50_atr: Math.round(percentile(mfes, 50) * 100) / 100,
          tp_p75_atr: Math.round(percentile(mfes, 75) * 100) / 100,
          tp_p90_atr: Math.round(percentile(mfes, 90) * 100) / 100,
          signals_json: signalsJson, regime_json: regimeJson,
        });
        break;
      }
    }
  }

  allMoves.sort((a, b) => b.move_atr - a.move_atr);
  const seen = new Set(), deduped = [];
  for (const m of allMoves) {
    const bucket = Math.floor(m.start_ts / (3 * 86400000));
    const key = `${m.ticker}:${m.direction}:${bucket}`;
    if (seen.has(key)) continue;
    seen.add(key); seen.add(`${m.ticker}:${m.direction}:${bucket - 1}`); seen.add(`${m.ticker}:${m.direction}:${bucket + 1}`);
    deduped.push(m);
  }

  await db.prepare(`DELETE FROM calibration_moves`).run();
  for (let i = 0; i < deduped.length; i += 50) {
    const chunk = deduped.slice(i, i + 50);
    await db.batch(chunk.map(m => db.prepare(
      `INSERT OR REPLACE INTO calibration_moves (move_id,ticker,direction,start_ts,end_ts,duration_days,move_pct,move_atr,max_ext_atr,pullback_atr,sl_optimal_atr,tp_p50_atr,tp_p75_atr,tp_p90_atr,signals_json,regime_json,created_at) VALUES (?1,?2,?3,?4,?5,?6,?7,?8,?9,?10,?11,?12,?13,?14,?15,?16,?17)`
    ).bind(m.move_id, m.ticker, m.direction, m.start_ts, m.end_ts, m.duration_days, m.move_pct, m.move_atr, m.max_ext_atr, m.pullback_atr, m.sl_optimal_atr, m.tp_p50_atr, m.tp_p75_atr, m.tp_p90_atr, m.signals_json, m.regime_json, Date.now())));
  }
  return deduped.length;
}

async function autopsyTradesServerSide(env) {
  const db = env?.DB;

  const { results: rawTrades } = await db.prepare(
    `SELECT t.trade_id, t.ticker, t.direction, t.entry_ts, t.exit_ts, t.entry_price, t.exit_price,
            t.pnl_pct, t.rank, t.rr, t.status,
            da.signal_snapshot_json, da.regime_daily, da.regime_weekly, da.regime_combined,
            da.entry_path AS da_entry_path
     FROM trades t LEFT JOIN direction_accuracy da ON da.trade_id = t.trade_id
     WHERE t.status IN ('CLOSED','TP_HIT','SL_HIT','MANUAL_EXIT','TP_HIT_TRIM')
     ORDER BY t.entry_ts`
  ).all();
  if (!rawTrades.length) return 0;

  const tickersNeeded = [...new Set(rawTrades.map(t => String(t.ticker).toUpperCase()))];

  const fiveMinByTicker = {};
  const dailyByTicker = {};
  for (const ticker of tickersNeeded) {
    const [fiveRes, dayRes] = await db.batch([
      db.prepare(`SELECT ts, h, l, c FROM ticker_candles WHERE tf='5' AND ticker=?1 ORDER BY ts`).bind(ticker),
      db.prepare(`SELECT ts, o, h, l, c FROM ticker_candles WHERE tf='D' AND ticker=?1 ORDER BY ts`).bind(ticker),
    ]);
    if (fiveRes.results?.length) fiveMinByTicker[ticker] = fiveRes.results;
    if (dayRes.results?.length) {
      const candles = dayRes.results.map(r => ({ ts: Number(r.ts), o: Number(r.o), h: Number(r.h), l: Number(r.l), c: Number(r.c) }));
      dailyByTicker[ticker] = { candles, atrs: computeATR14(candles) };
    }
  }

  const results = [];
  for (const trade of rawTrades) {
    const ticker = String(trade.ticker).toUpperCase();
    const entryTs = Number(trade.entry_ts), exitTs = Number(trade.exit_ts);
    const entryPrice = Number(trade.entry_price), exitPrice = Number(trade.exit_price);
    const direction = String(trade.direction).toUpperCase();
    const isLong = direction === "LONG";
    if (!entryTs || !exitTs || !entryPrice || !exitPrice) continue;

    let atrAtEntry = 0;
    const daily = dailyByTicker[ticker];
    if (daily) {
      let ci = 0, md = Infinity;
      for (let i = 0; i < daily.candles.length; i++) { const d = Math.abs(daily.candles[i].ts - entryTs); if (d < md) { md = d; ci = i; } }
      atrAtEntry = daily.atrs[ci] || 0;
    }
    if (atrAtEntry <= 0) atrAtEntry = entryPrice * 0.02;

    const estRisk = atrAtEntry * 1.5;
    const slPrice = isLong ? entryPrice - estRisk : entryPrice + estRisk;
    const initialRisk = Math.abs(entryPrice - slPrice) || atrAtEntry;
    const actualPnl = isLong ? exitPrice - entryPrice : entryPrice - exitPrice;
    const rMultiple = actualPnl / initialRisk;
    const pnlPct = Number(trade.pnl_pct) || 0;

    let mfePct = 0, maePct = 0, mfeAtr = 0, maeAtr = 0, timeToMfeMin = 0, slHitBeforeMfe = false;
    const candles5m = fiveMinByTicker[ticker];
    if (candles5m) {
      const during = candles5m.filter(c => { const ts = Number(c.ts); return ts >= entryTs && ts <= exitTs; });
      let maxFav = 0, maxAdv = 0, mfeTs = entryTs;
      for (const c of during) {
        const high = Number(c.h), low = Number(c.l);
        const fav = isLong ? (high - entryPrice) / entryPrice * 100 : (entryPrice - low) / entryPrice * 100;
        const adv = isLong ? (entryPrice - low) / entryPrice * 100 : (high - entryPrice) / entryPrice * 100;
        if (fav > maxFav) { maxFav = fav; mfeTs = Number(c.ts); }
        maxAdv = Math.max(maxAdv, adv);
      }
      mfePct = Math.round(maxFav * 100) / 100;
      maePct = Math.round(maxAdv * 100) / 100;
      mfeAtr = atrAtEntry > 0 ? Math.round((maxFav / 100 * entryPrice / atrAtEntry) * 100) / 100 : 0;
      maeAtr = atrAtEntry > 0 ? Math.round((maxAdv / 100 * entryPrice / atrAtEntry) * 100) / 100 : 0;
      timeToMfeMin = Math.round((mfeTs - entryTs) / 60000);
      slHitBeforeMfe = maxAdv > (estRisk / entryPrice * 100) && mfeTs > entryTs;
    }

    const exitEfficiency = mfePct > 0 ? Math.round((Math.max(0, pnlPct) / mfePct) * 100) / 100 : 0;
    let classification = "noise_trade";
    if (mfeAtr < 0.5 && maeAtr < 0.5) classification = "noise_trade";
    else if (maePct > mfePct && pnlPct <= 0) classification = "bad_entry";
    else if (pnlPct > 0 && exitEfficiency >= 0.7) classification = "optimal";
    else if (pnlPct > 0 && exitEfficiency < 0.5) classification = "left_money";
    else if (mfePct > 1 && pnlPct <= 0) classification = "gave_back";
    else if (pnlPct <= 0) classification = "bad_entry";
    else classification = "left_money";

    results.push({
      trade_id: trade.trade_id, ticker, direction, entry_ts: entryTs, exit_ts: exitTs,
      entry_price: entryPrice, exit_price: exitPrice, sl_price: Math.round(slPrice * 100) / 100,
      pnl_pct: pnlPct, r_multiple: Math.round(rMultiple * 100) / 100,
      mfe_pct: mfePct, mfe_atr: mfeAtr, mae_pct: maePct, mae_atr: maeAtr,
      exit_efficiency: exitEfficiency, sl_hit_before_mfe: slHitBeforeMfe ? 1 : 0,
      time_to_mfe_min: timeToMfeMin, optimal_hold_min: timeToMfeMin,
      classification, entry_signals_json: trade.signal_snapshot_json || null,
      entry_path: trade.da_entry_path || "unknown",
      rank_at_entry: Number(trade.rank) || 0,
      regime_at_entry: trade.regime_combined || trade.regime_daily || "unknown",
    });
  }

  await db.prepare(`DELETE FROM calibration_trade_autopsy`).run();
  for (let i = 0; i < results.length; i += 50) {
    const chunk = results.slice(i, i + 50);
    await db.batch(chunk.map(t => db.prepare(
      `INSERT OR REPLACE INTO calibration_trade_autopsy (trade_id,ticker,direction,entry_ts,exit_ts,entry_price,exit_price,sl_price,pnl_pct,r_multiple,mfe_pct,mfe_atr,mae_pct,mae_atr,exit_efficiency,sl_hit_before_mfe,time_to_mfe_min,optimal_hold_min,classification,entry_signals_json,entry_path,rank_at_entry,regime_at_entry,created_at) VALUES (?1,?2,?3,?4,?5,?6,?7,?8,?9,?10,?11,?12,?13,?14,?15,?16,?17,?18,?19,?20,?21,?22,?23,?24)`
    ).bind(t.trade_id, t.ticker, t.direction, t.entry_ts, t.exit_ts, t.entry_price, t.exit_price, t.sl_price, t.pnl_pct, t.r_multiple, t.mfe_pct, t.mfe_atr, t.mae_pct, t.mae_atr, t.exit_efficiency, t.sl_hit_before_mfe, t.time_to_mfe_min, t.optimal_hold_min, t.classification, t.entry_signals_json, t.entry_path, t.rank_at_entry, t.regime_at_entry, Date.now())));
  }
  return results.length;
}

async function runCalibrationAnalysis(env) {
  const db = env?.DB;
  if (!db) throw new Error("no_db");

  const { results: moves } = await db.prepare(`SELECT * FROM calibration_moves`).all();
  const { results: trades } = await db.prepare(`SELECT * FROM calibration_trade_autopsy`).all();
  if (!trades.length) throw new Error("no_trade_data");

  const splitIdx = Math.floor(trades.length * 0.75);
  const tradeSorted = [...trades].sort((a, b) => (a.entry_ts || 0) - (b.entry_ts || 0));
  const inSample = tradeSorted.slice(0, splitIdx);
  const outSample = tradeSorted.slice(splitIdx);

  function computeMetrics(subset) {
    if (!subset.length) return { n: 0, win_rate: 0, expectancy: 0, sqn: 0, avg_r: 0, profit_factor: 0 };
    let wins = 0, totalWinPnl = 0, totalLossPnl = 0;
    const rMultiples = [];
    for (const t of subset) {
      const r = t.r_multiple ?? (t.pnl_pct || 0);
      rMultiples.push(r);
      if ((t.pnl_pct || 0) > 0) { wins++; totalWinPnl += Math.abs(t.pnl_pct || 0); }
      else { totalLossPnl += Math.abs(t.pnl_pct || 0); }
    }
    const n = subset.length;
    const winRate = wins / n;
    const avgWin = wins > 0 ? totalWinPnl / wins : 0;
    const losses = n - wins;
    const avgLoss = losses > 0 ? totalLossPnl / losses : 0;
    const expectancy = (winRate * avgWin) - ((1 - winRate) * avgLoss);
    const profitFactor = totalLossPnl > 0 ? totalWinPnl / totalLossPnl : totalWinPnl > 0 ? Infinity : 0;
    const meanR = rMultiples.reduce((a, b) => a + b, 0) / n;
    const stdR = Math.sqrt(rMultiples.reduce((a, b) => a + (b - meanR) ** 2, 0) / n) || 1;
    const sqn = (meanR / stdR) * Math.sqrt(n);
    return {
      n, win_rate: Math.round(winRate * 1000) / 10, expectancy: Math.round(expectancy * 100) / 100,
      sqn: Math.round(sqn * 100) / 100, avg_r: Math.round(meanR * 100) / 100,
      profit_factor: profitFactor === Infinity ? 999 : Math.round(profitFactor * 100) / 100,
    };
  }

  // A. System Health
  const systemHealth = {
    overall: computeMetrics(trades),
    in_sample: computeMetrics(inSample),
    out_sample: computeMetrics(outSample),
  };
  const byRegime = {};
  for (const t of trades) {
    const reg = t.regime_at_entry || "unknown";
    (byRegime[reg] = byRegime[reg] || []).push(t);
  }
  systemHealth.by_regime = {};
  for (const [reg, arr] of Object.entries(byRegime)) {
    systemHealth.by_regime[reg] = computeMetrics(arr);
  }

  // B. Entry Path Report Card
  const byPath = {};
  for (const t of trades) {
    const p = t.entry_path || "unknown";
    (byPath[p] = byPath[p] || []).push(t);
  }
  const pathReport = {};
  const pathAdjustments = {};
  for (const [path, arr] of Object.entries(byPath)) {
    const m = computeMetrics(arr);
    const isArr = arr.filter(t => inSample.includes(t));
    const osArr = arr.filter(t => outSample.includes(t));
    const mfeAvg = arr.reduce((s, t) => s + (t.mfe_atr || 0), 0) / arr.length;
    const winRate = m.win_rate / 100;
    const avgWinR = arr.filter(t => (t.pnl_pct||0) > 0).reduce((s,t) => s + (t.r_multiple||0), 0) / (arr.filter(t => (t.pnl_pct||0) > 0).length || 1);
    const avgLossR = Math.abs(arr.filter(t => (t.pnl_pct||0) <= 0).reduce((s,t) => s + (t.r_multiple||0), 0) / (arr.filter(t => (t.pnl_pct||0) <= 0).length || 1)) || 1;
    const kellyPct = avgLossR > 0 ? (winRate * avgWinR / avgLossR - (1 - winRate)) / (avgWinR / avgLossR) : 0;
    const halfKelly = Math.max(0, Math.round(kellyPct * 50 * 100) / 100);
    let action = "KEEP";
    if (m.expectancy < 0 && arr.length >= 5) action = "DISABLE";
    else if (m.expectancy < 0.2 && arr.length >= 5) action = "RESTRICT";
    else if (m.expectancy > 0.5) action = "BOOST";
    pathReport[path] = {
      ...m, avg_mfe_atr: Math.round(mfeAvg * 100) / 100,
      half_kelly_pct: halfKelly, action,
      in_sample: computeMetrics(isArr), out_sample: computeMetrics(osArr),
    };
    if (action === "DISABLE") {
      pathAdjustments[path] = { action: "DISABLE" };
    } else if (action === "RESTRICT") {
      pathAdjustments[path] = { action: "RESTRICT", quality_gate_adj: 0.5 };
    }
  }

  // C. Signal Information Coefficients
  const signalNames = ["ema_cross", "supertrend", "ema_structure", "ema_depth", "rsi"];
  const signalIC = {};
  const newSignalWeights = {};
  for (const sig of signalNames) {
    const xs = [], ys = [];
    for (const t of trades) {
      if (!t.entry_signals_json) continue;
      try {
        const snap = JSON.parse(t.entry_signals_json);
        const tfs = snap.tf || snap;
        let sigVal = null;
        for (const tfData of Object.values(tfs)) {
          const signals = tfData.signals || tfData;
          if (signals[sig] != null) { sigVal = Number(signals[sig]); break; }
        }
        if (sigVal != null && isFinite(sigVal) && t.pnl_pct != null) {
          xs.push(sigVal);
          ys.push(t.pnl_pct);
        }
      } catch { /* skip bad json */ }
    }
    const ic = spearmanCorrelation(xs, ys);
    signalIC[sig] = { ic: Math.round(ic * 1000) / 1000, n: xs.length };
  }
  const totalAbsIC = Object.values(signalIC).reduce((s, v) => s + Math.abs(v.ic), 0) || 1;
  for (const sig of signalNames) {
    newSignalWeights[sig] = Math.round((Math.abs(signalIC[sig].ic) / totalAbsIC) * 100) / 100;
  }

  // D. SL/TP Calibration (Sweeney MFE/MAE)
  const winnerMAEs = trades.filter(t => (t.pnl_pct || 0) > 0).map(t => t.mae_atr || 0);
  const allMFEs = trades.map(t => t.mfe_atr || 0);
  const moveMFEs = moves.map(m => m.move_atr || 0);
  const slTP = {
    winner_mae: { p50: percentile(winnerMAEs, 50), p75: percentile(winnerMAEs, 75), p90: percentile(winnerMAEs, 90) },
    trade_mfe: { p50: percentile(allMFEs, 50), p75: percentile(allMFEs, 75), p90: percentile(allMFEs, 90) },
    move_mfe: moves.length ? { p50: percentile(moveMFEs, 50), p75: percentile(moveMFEs, 75), p90: percentile(moveMFEs, 90) } : null,
    recommended_sl_atr: Math.round(percentile(winnerMAEs, 75) * 100) / 100,
    recommended_tp_trim_atr: Math.round(percentile(allMFEs, 50) * 100) / 100,
    recommended_tp_exit_atr: Math.round(percentile(allMFEs, 75) * 100) / 100,
    recommended_tp_runner_atr: Math.round(percentile(allMFEs, 90) * 100) / 100,
  };

  // E. Regime-Conditional Filters
  const regimeFilters = {};
  for (const [reg, arr] of Object.entries(byRegime)) {
    const m = computeMetrics(arr);
    regimeFilters[reg] = {
      ...m,
      block_entries: m.expectancy < 0 && arr.length >= 5,
      min_rank_adj: m.expectancy < 0.2 ? 10 : 0,
    };
  }

  // F. Rank Threshold Optimization
  const rankDeciles = {};
  for (let d = 0; d < 100; d += 10) {
    const label = `${d}-${d + 10}`;
    const subset = trades.filter(t => {
      const r = t.rank_at_entry ?? 0;
      return r >= d && r < d + 10;
    });
    rankDeciles[label] = computeMetrics(subset);
  }
  let bestRankSQN = -Infinity, bestRankCutoff = 0;
  for (let cut = 10; cut <= 90; cut += 10) {
    const above = trades.filter(t => (t.rank_at_entry ?? 0) >= cut);
    if (above.length < 5) continue;
    const m = computeMetrics(above);
    if (m.sqn > bestRankSQN) { bestRankSQN = m.sqn; bestRankCutoff = cut; }
  }

  // G. Position Sizing (overall Kelly)
  const overallWR = systemHealth.overall.win_rate / 100;
  const overallAvgWinR = trades.filter(t => (t.pnl_pct||0) > 0).reduce((s,t) => s + (t.r_multiple||0), 0) / (trades.filter(t => (t.pnl_pct||0) > 0).length || 1);
  const overallAvgLossR = Math.abs(trades.filter(t => (t.pnl_pct||0) <= 0).reduce((s,t) => s + (t.r_multiple||0), 0) / (trades.filter(t => (t.pnl_pct||0) <= 0).length || 1)) || 1;
  const kellyFull = overallAvgLossR > 0 ? (overallWR * overallAvgWinR / overallAvgLossR - (1 - overallWR)) / (overallAvgWinR / overallAvgLossR) : 0;
  const positionSizing = {
    kelly_full_pct: Math.round(kellyFull * 10000) / 100,
    half_kelly_pct: Math.round(Math.max(0, kellyFull / 2) * 10000) / 100,
    current_sizing_pct: "5-7% fixed",
  };

  // H. Missed Opportunity Analysis
  let missedMoves = 0, missedSignals = {};
  if (moves.length) {
    const tradeTickers = new Set(trades.map(t => `${t.ticker}:${t.direction}`));
    for (const m of moves) {
      const key = `${m.ticker}:${m.direction}`;
      const tradeNearby = trades.some(t => t.ticker === m.ticker && t.direction === m.direction &&
        Math.abs((t.entry_ts || 0) - m.start_ts) < 5 * 86400000);
      if (!tradeNearby) {
        missedMoves++;
        if (m.signals_json) {
          try {
            const sigs = JSON.parse(m.signals_json);
            for (const [k, v] of Object.entries(sigs)) {
              missedSignals[k] = (missedSignals[k] || 0) + 1;
            }
          } catch {}
        }
      }
    }
  }

  // I. Walk-Forward Validation
  const wfoSummary = {
    in_sample_sqn: systemHealth.in_sample.sqn,
    out_sample_sqn: systemHealth.out_sample.sqn,
    degradation_pct: systemHealth.in_sample.sqn > 0
      ? Math.round((1 - systemHealth.out_sample.sqn / systemHealth.in_sample.sqn) * 100)
      : 0,
    verdict: systemHealth.out_sample.sqn >= systemHealth.in_sample.sqn * 0.7 ? "PASS" : "WARNING",
  };

  // Build recommendations
  const recommendations = {
    signal_weights: newSignalWeights,
    sl_atr: slTP.recommended_sl_atr,
    tp_tiers: {
      trim: slTP.recommended_tp_trim_atr,
      exit: slTP.recommended_tp_exit_atr,
      runner: slTP.recommended_tp_runner_atr,
    },
    rank_threshold: bestRankCutoff,
    path_adjustments: pathAdjustments,
    wfo_verdict: wfoSummary.verdict,
  };

  const reportJson = {
    system_health: systemHealth,
    entry_paths: pathReport,
    signal_ic: signalIC,
    sl_tp_calibration: slTP,
    regime_filters: regimeFilters,
    rank_optimization: { deciles: rankDeciles, best_cutoff: bestRankCutoff, best_sqn: bestRankSQN },
    position_sizing: positionSizing,
    missed_opportunities: { count: missedMoves, total_moves: moves.length, common_signals: missedSignals },
    wfo_summary: wfoSummary,
  };

  const reportId = `cal_${Date.now()}`;
  await db.prepare(
    `INSERT INTO calibration_report (report_id, run_ts, lookback_days, trade_count, move_count, report_json, recommendations_json)
     VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)`
  ).bind(
    reportId, Date.now(), 400, trades.length, moves.length,
    JSON.stringify(reportJson), JSON.stringify(recommendations)
  ).run();

  return { report_id: reportId, ...reportJson, recommendations };
}

// ═══════════════════════════════════════════════════════════════════════
// Calibration Pipeline Schema — moves, trade autopsy, reports
// ═══════════════════════════════════════════════════════════════════════

let _calibSchemaReady = false;
async function d1EnsureCalibrationSchema(env) {
  if (_calibSchemaReady) return;
  const db = env?.DB;
  if (!db) return;
  try {
    await db.batch([
      db.prepare(`CREATE TABLE IF NOT EXISTS calibration_moves (
        move_id TEXT PRIMARY KEY,
        ticker TEXT NOT NULL,
        direction TEXT NOT NULL,
        start_ts INTEGER NOT NULL,
        end_ts INTEGER NOT NULL,
        duration_days INTEGER,
        move_pct REAL,
        move_atr REAL,
        max_ext_atr REAL,
        pullback_atr REAL,
        sl_optimal_atr REAL,
        tp_p50_atr REAL,
        tp_p75_atr REAL,
        tp_p90_atr REAL,
        signals_json TEXT,
        regime_json TEXT,
        created_at INTEGER NOT NULL DEFAULT (unixepoch())
      )`),
      db.prepare(`CREATE TABLE IF NOT EXISTS calibration_trade_autopsy (
        trade_id TEXT PRIMARY KEY,
        ticker TEXT NOT NULL,
        direction TEXT NOT NULL,
        entry_ts INTEGER,
        exit_ts INTEGER,
        entry_price REAL,
        exit_price REAL,
        sl_price REAL,
        pnl_pct REAL,
        r_multiple REAL,
        mfe_pct REAL,
        mfe_atr REAL,
        mae_pct REAL,
        mae_atr REAL,
        exit_efficiency REAL,
        sl_hit_before_mfe INTEGER,
        time_to_mfe_min REAL,
        optimal_hold_min REAL,
        classification TEXT,
        entry_signals_json TEXT,
        entry_path TEXT,
        rank_at_entry INTEGER,
        regime_at_entry TEXT,
        created_at INTEGER NOT NULL DEFAULT (unixepoch())
      )`),
      db.prepare(`CREATE TABLE IF NOT EXISTS calibration_report (
        report_id TEXT PRIMARY KEY,
        run_ts INTEGER NOT NULL,
        lookback_days INTEGER,
        trade_count INTEGER,
        move_count INTEGER,
        report_json TEXT,
        recommendations_json TEXT,
        applied_at INTEGER,
        applied_by TEXT
      )`),
    ]);
    await db.batch([
      db.prepare(`CREATE INDEX IF NOT EXISTS idx_cm_ticker ON calibration_moves (ticker)`),
      db.prepare(`CREATE INDEX IF NOT EXISTS idx_cm_dir ON calibration_moves (direction)`),
      db.prepare(`CREATE INDEX IF NOT EXISTS idx_cta_ticker ON calibration_trade_autopsy (ticker)`),
      db.prepare(`CREATE INDEX IF NOT EXISTS idx_cta_class ON calibration_trade_autopsy (classification)`),
      db.prepare(`CREATE INDEX IF NOT EXISTS idx_cr_run ON calibration_report (run_ts)`),
    ]);
    _calibSchemaReady = true;
  } catch (e) {
    console.error("[CALIBRATION] Schema migration failed:", String(e).slice(0, 200));
  }
}

/** Runs full calibration pipeline (harvest + autopsy + analysis). Used by cron when timed:calibration:requested is set. */
async function runCalibrationInCron(env) {
  const KV = env?.KV_TIMED;
  if (!KV) return;
  const requested = await KV.get("timed:calibration:requested");
  if (!requested) return;
  try {
    await d1EnsureCalibrationSchema(env);
    await d1EnsureLearningSchema(env);
    const moveCount = await harvestMovesServerSide(env);
    const tradeCount = await autopsyTradesServerSide(env);
    const report = await runCalibrationAnalysis(env);
    console.log(`[CALIBRATION] Cron run complete: moves=${moveCount} trades=${tradeCount} report_id=${report?.report_id || "?"}`);
  } catch (e) {
    console.error("[CALIBRATION] Cron run error:", String(e?.message || e).slice(0, 300));
    return; // keep key so next run retries
  }
  await KV.delete("timed:calibration:requested");
}

// Log direction accuracy entry on trade creation
async function d1LogDirectionEntry(env, trade, tickerData) {
  const db = env?.DB;
  if (!db) return;
  try {
    await d1EnsureLearningSchema(env);
    const sc = tickerData?.swing_consensus || {};
    const regime = tickerData?.regime || {};
    const htfScore = Number(tickerData?.htf_score) || 0;
    const stateStr = String(tickerData?.state || "");

    let signalSnapshot = null;
    if (Array.isArray(sc.tf_stack)) {
      const snap = { avg_bias: sc.avg_bias ?? null, tf: {} };
      for (const entry of sc.tf_stack) {
        if (entry.bias === "unknown") continue;
        snap.tf[entry.tf] = {
          bias: entry.biasScore ?? null,
          signals: entry.signals || {},
        };
      }
      signalSnapshot = JSON.stringify(snap);
    }

    await db.prepare(
      `INSERT OR IGNORE INTO direction_accuracy
       (trade_id, ticker, ts, traded_direction, consensus_direction, htf_score_direction,
        state_direction, direction_source, htf_score, ltf_score, regime_daily, regime_weekly,
        regime_combined, bullish_count, bearish_count, tf_stack_json, entry_path,
        rank, rr, entry_price, signal_snapshot_json, status)
       VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)`
    ).bind(
      trade.id, trade.ticker, trade.entry_ts || Date.now(),
      trade.direction,
      sc.direction || null,
      htfScore >= 0 ? "LONG" : "SHORT",
      stateStr.includes("BULL") ? "LONG" : stateStr.includes("BEAR") ? "SHORT" : null,
      tickerData?.direction_source || null,
      htfScore, Number(tickerData?.ltf_score) || 0,
      regime.daily || null, regime.weekly || null, regime.combined || null,
      sc.bullish_count ?? null, sc.bearish_count ?? null,
      sc.tf_stack ? JSON.stringify(sc.tf_stack) : null,
      trade.entryPath || null,
      Number(trade.rank) || 0, Number(trade.rr) || 0, Number(trade.entryPrice) || 0,
      signalSnapshot,
      "OPEN"
    ).run();
  } catch (e) {
    console.warn("[LEARNING] Failed to log direction entry:", String(e).slice(0, 150));
  }
}

// Update direction accuracy on trade close
async function d1UpdateDirectionOutcome(env, trade) {
  const db = env?.DB;
  if (!db || !trade?.id) return;
  try {
    await d1EnsureLearningSchema(env);
    const isLong = trade.direction === "LONG";
    const entryPx = Number(trade.entryPrice) || 0;
    const exitPx = Number(trade.exitPrice) || 0;
    const pnl = Number(trade.pnl) || Number(trade.realizedPnl) || 0;
    const pnlPct = Number(trade.pnlPct) || 0;
    const dirCorrect = pnl > 0 ? 1 : pnl < 0 ? 0 : null;
    const mfe = Number(trade.maxFavorableExcursion) || null;
    const mae = Number(trade.maxAdverseExcursion) || null;
    const status = String(trade.status || "");
    await db.prepare(
      `UPDATE direction_accuracy SET exit_ts=?, exit_price=?, pnl=?, pnl_pct=?,
       direction_correct=?, max_favorable_excursion=?, max_adverse_excursion=?, status=?
       WHERE trade_id=?`
    ).bind(
      trade.exit_ts || Date.now(), exitPx, pnl, pnlPct,
      dirCorrect, mfe, mae, status, trade.id
    ).run();
  } catch (e) {
    console.warn("[LEARNING] Failed to update direction outcome:", String(e).slice(0, 150));
  }
}

async function d1LogDirectionAccuracy(env, trade, tickerData, entryPath) {
  const db = env?.DB;
  if (!db) return;
  try {
    await d1EnsureLearningSchema(env);
    const sc = tickerData?.swing_consensus || {};
    const regime = tickerData?.regime || {};
    const htfScore = Number(tickerData?.htf_score) || 0;
    const state = String(tickerData?.state || "");

    // Build per-signal snapshot from the enriched tf_stack
    let signalSnapshot = null;
    if (Array.isArray(sc.tf_stack)) {
      const snap = { avg_bias: sc.avg_bias ?? null, tf: {} };
      for (const entry of sc.tf_stack) {
        if (entry.bias === "unknown") continue;
        snap.tf[entry.tf] = {
          bias: entry.biasScore ?? null,
          signals: entry.signals || {},
        };
      }
      signalSnapshot = JSON.stringify(snap);
    }

    await db.prepare(
      `INSERT OR IGNORE INTO direction_accuracy
       (trade_id, ticker, ts, traded_direction, consensus_direction, htf_score_direction,
        state_direction, direction_source, htf_score, ltf_score,
        regime_daily, regime_weekly, regime_combined,
        bullish_count, bearish_count, tf_stack_json, entry_path,
        rank, rr, entry_price, signal_snapshot_json, status)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18, ?19, ?20, ?21, 'OPEN')`
    ).bind(
      trade.id,
      trade.ticker,
      trade.entry_ts || Date.now(),
      trade.direction,
      sc.direction || null,
      htfScore >= 0 ? "LONG" : "SHORT",
      state.includes("BULL") ? "LONG" : state.includes("BEAR") ? "SHORT" : null,
      tickerData?.direction_source || null,
      htfScore,
      Number(tickerData?.ltf_score) || 0,
      regime.daily || null,
      regime.weekly || null,
      regime.combined || null,
      sc.bullish_count ?? null,
      sc.bearish_count ?? null,
      sc.tf_stack ? JSON.stringify(sc.tf_stack) : null,
      entryPath || null,
      Number(trade.rank) || 0,
      Number(trade.rr) || 0,
      Number(trade.entryPrice) || 0,
      signalSnapshot,
    ).run();
  } catch (e) {
    console.warn("[LEARNING] d1LogDirectionAccuracy failed:", String(e).slice(0, 150));
  }
}

async function d1UpdateDirectionAccuracyOnExit(env, trade) {
  const db = env?.DB;
  if (!db) return;
  try {
    await d1EnsureLearningSchema(env);
    const isLong = trade.direction === "LONG";
    const entryPx = Number(trade.entryPrice);
    const exitPx = Number(trade.exitPrice);
    if (!Number.isFinite(entryPx) || !Number.isFinite(exitPx)) return;

    const priceMoved = isLong ? exitPx - entryPx : entryPx - exitPx;
    const directionCorrect = priceMoved > 0 ? 1 : 0;

    const pnl = Number(trade.pnl) || Number(trade.realizedPnl) || 0;
    const pnlPct = Number(trade.pnlPct) || (entryPx > 0 ? (pnl / (entryPx * (trade.shares || 1))) * 100 : 0);

    await db.prepare(
      `UPDATE direction_accuracy SET
         exit_ts = ?1, exit_price = ?2, pnl = ?3, pnl_pct = ?4,
         direction_correct = ?5, status = ?6
       WHERE trade_id = ?7`
    ).bind(
      trade.exit_ts || Date.now(),
      exitPx,
      pnl,
      pnlPct,
      directionCorrect,
      trade.status || (pnl > 0 ? "WIN" : pnl < 0 ? "LOSS" : "FLAT"),
      trade.id,
    ).run();
  } catch (e) {
    console.warn("[LEARNING] d1UpdateDirectionAccuracyOnExit failed:", String(e).slice(0, 150));
  }
}

const USER_TICKER_SLOT_LIMITS = { free: 3, member: 3, pro: 10, vip: 10, admin: 50 };
const USER_TICKER_SYSTEM_CAP = 200;
const USER_TICKER_HOLD_DAYS = 7;
const USER_TICKER_DAILY_SWAPS = 1;

async function d1GetActiveUserTickers(env) {
  const db = env?.DB;
  if (!db) return [];
  try {
    await d1EnsureUserTickersSchema(env);
    const rows = await db.prepare(
      `SELECT DISTINCT ticker FROM user_tickers WHERE deleted_at IS NULL`
    ).all();
    return (rows?.results || []).map(r => r.ticker);
  } catch (e) {
    console.warn("[USER_TICKERS] Failed to fetch active tickers:", String(e?.message || e).slice(0, 200));
    return [];
  }
}

let _userTickersCache = null;
let _userTickersCacheTs = 0;
async function d1GetActiveUserTickersCached(env) {
  const now = Date.now();
  if (_userTickersCache && (now - _userTickersCacheTs) < 60_000) return _userTickersCache;
  _userTickersCache = await d1GetActiveUserTickers(env);
  _userTickersCacheTs = now;
  return _userTickersCache;
}

function getUserSlotLimit(user) {
  const tier = String(user?.tier || user?.role || "free").toLowerCase();
  return USER_TICKER_SLOT_LIMITS[tier] || USER_TICKER_SLOT_LIMITS.free;
}

async function d1GetUserSlots(env, email) {
  const db = env?.DB;
  if (!db) return [];
  await d1EnsureUserTickersSchema(env);
  const rows = await db.prepare(
    `SELECT * FROM user_tickers WHERE user_email = ? ORDER BY added_at DESC`
  ).bind(email).all();
  const now = Date.now();
  return (rows?.results || []).map(r => ({
    ...r,
    active: r.deleted_at == null,
    held: r.deleted_at != null && (now - r.deleted_at) < USER_TICKER_HOLD_DAYS * 86400000,
  }));
}

async function d1CountUniqueNewUserTickers(env) {
  const db = env?.DB;
  if (!db) return 0;
  try {
    await d1EnsureUserTickersSchema(env);
    const coreSet = new Set(Object.keys(SECTOR_MAP));
    const rows = await db.prepare(
      `SELECT DISTINCT ticker FROM user_tickers WHERE deleted_at IS NULL`
    ).all();
    let count = 0;
    for (const r of rows?.results || []) {
      if (!coreSet.has(r.ticker)) count++;
    }
    return count;
  } catch { return 0; }
}

async function d1CountUserSwapsToday(env, email) {
  const db = env?.DB;
  if (!db) return 0;
  const todayStart = new Date();
  todayStart.setUTCHours(0, 0, 0, 0);
  try {
    const row = await db.prepare(
      `SELECT COUNT(*) as cnt FROM user_tickers WHERE user_email = ? AND deleted_at >= ?`
    ).bind(email, todayStart.getTime()).first();
    return row?.cnt || 0;
  } catch { return 0; }
}

async function d1TickerHasCandles(env, ticker) {
  const db = env?.DB;
  if (!db) return false;
  try {
    const row = await db.prepare(
      `SELECT 1 FROM ticker_candles WHERE ticker = ? LIMIT 1`
    ).bind(ticker).first();
    return !!row;
  } catch { return false; }
}

async function d1EnqueueMlV1(env, ticker, payload, horizonsMs) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const ts = Number(payload?.ts);
  const price = Number(payload?.price);
  if (!Number.isFinite(ts) || !Number.isFinite(price) || price <= 0)
    return { ok: false, skipped: true, reason: "bad_ts_or_price" };
  await d1EnsureMlV1Schema(env);

  const dir = sideFromStateOrScores(payload);
  const x = mlV1ExtractX(payload);
  const createdAt = Date.now();

  const sym = String(ticker || "").toUpperCase();
  const hs = Array.isArray(horizonsMs) ? horizonsMs : [];
  for (const h of hs) {
    const hm = Number(h);
    if (!Number.isFinite(hm) || hm <= 0) continue;
    const due = ts + hm;
    const id = `${sym}:${ts}:${hm}`;
    try {
      await db
        .prepare(
          `INSERT OR IGNORE INTO ml_v1_queue
           (id, ticker, ts, horizon_ms, dir, entry_price, features_json, label_due_ts, y, labeled_at, created_at)
           VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, NULL, NULL, ?9)`,
        )
        .bind(
          id,
          sym,
          ts,
          hm,
          dir != null ? String(dir) : null,
          price,
          JSON.stringify({ x }),
          due,
          createdAt,
        )
        .run();
    } catch (e) {
      console.error(`[D1 ML] enqueue failed for ${id}:`, String(e));
    }
  }
  return { ok: true };
}

async function d1NearestClose(env, ticker, tsTarget) {
  const db = env?.DB;
  if (!db) return null;
  const sym = String(ticker || "").toUpperCase();
  const t = Number(tsTarget);
  if (!sym || !Number.isFinite(t)) return null;
  
  // Query timed_trail for ingest data (has price from TradingView scripts)
  try {
    const row = await db
      .prepare(
        `SELECT ts, payload_json FROM timed_trail
         WHERE ticker=?1 AND ts>=?2
         ORDER BY ts ASC LIMIT 1`,
      )
      .bind(sym, t)
      .first();
    if (row && row.payload_json) {
      try {
        const p = JSON.parse(row.payload_json);
        const price = Number(p?.price || p?.close);
        if (Number.isFinite(price) && price > 0) return price;
      } catch {
        // ignore parse error
      }
    }
  } catch (e) {
    console.error(`[ML LABEL] Failed to get exit price for ${sym}:`, String(e));
  }
  
  // Fallback to ticker_candles if available (for chart backfill data)
  const tfs = ["3", "10", "30"];
  for (const tf of tfs) {
    try {
      const row = await db
        .prepare(
          `SELECT ts, c FROM ticker_candles
           WHERE ticker=?1 AND tf=?2 AND ts>=?3
           ORDER BY ts ASC LIMIT 1`,
        )
        .bind(sym, tf, t)
        .first();
      if (row && Number.isFinite(Number(row.c))) return Number(row.c);
    } catch {
      // ignore
    }
  }
  // Fallback to last known <= target
  for (const tf of tfs) {
    try {
      const row = await db
        .prepare(
          `SELECT ts, c FROM ticker_candles
           WHERE ticker=?1 AND tf=?2 AND ts<=?3
           ORDER BY ts DESC LIMIT 1`,
        )
        .bind(sym, tf, t)
        .first();
      if (row && Number.isFinite(Number(row.c))) return Number(row.c);
    } catch {
      // ignore
    }
  }
  return null;
}

function mlV1LabelFromHorizon(entryPrice, exitPrice, dir) {
  const ep = Number(entryPrice);
  const xp = Number(exitPrice);
  if (!Number.isFinite(ep) || !Number.isFinite(xp) || ep <= 0) return null;
  const side = String(dir || "").toUpperCase();
  const ret = (xp - ep) / ep;
  if (side === "SHORT") return ret < 0 ? 1 : 0;
  if (side === "LONG") return ret > 0 ? 1 : 0;
  // If direction unknown, just ask "up?"
  return ret > 0 ? 1 : 0;
}

async function mlV1TrainFromQueue(env, KV, maxN = 75, force = false) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  await d1EnsureMlV1Schema(env);
  const now = Date.now();
  
  // Force mode: ignore label_due_ts check (for backfilling old data)
  const query = force
    ? `SELECT id, ticker, ts, horizon_ms, dir, entry_price, features_json, label_due_ts
       FROM ml_v1_queue
       WHERE y IS NULL
       ORDER BY ts ASC
       LIMIT ?1`
    : `SELECT id, ticker, ts, horizon_ms, dir, entry_price, features_json, label_due_ts
       FROM ml_v1_queue
       WHERE y IS NULL AND label_due_ts <= ?1
       ORDER BY label_due_ts ASC
       LIMIT ?2`;
  
  const rows = force
    ? await db.prepare(query).bind(Math.max(1, Math.min(250, Number(maxN) || 75))).all()
    : await db.prepare(query).bind(now, Math.max(1, Math.min(250, Number(maxN) || 75))).all();
  const due = Array.isArray(rows?.results) ? rows.results : [];
  console.log(`[ML TRAIN] Found ${due.length} entries to process (force=${force})`);
  if (due.length === 0) return { ok: true, trained: 0 };

  let model = await mlV1GetModel(KV);
  let trained = 0;
  let skipped = { no_exit: 0, no_label: 0, no_features: 0 };

  for (const r of due) {
    const exit = await d1NearestClose(env, r.ticker, Number(r.label_due_ts));
    if (exit == null) {
      skipped.no_exit++;
      continue;
    }
    const y = mlV1LabelFromHorizon(r.entry_price, exit, r.dir);
    if (y == null) {
      skipped.no_label++;
      continue;
    }
    let x = null;
    try {
      const fj = r.features_json ? JSON.parse(String(r.features_json)) : null;
      x = Array.isArray(fj?.x) ? fj.x : null;
    } catch {
      x = null;
    }
    if (!Array.isArray(x)) continue;

    const p = mlV1PredictProba(model, x);
    const err = Number(y) - p;
    const lr = Number(model?.lr) || 0.05;
    const l2 = Number(model?.l2) || 0.001;
    const w = Array.isArray(model?.w) ? model.w.slice() : mlV1DefaultModel().w;

    for (let i = 0; i < Math.min(w.length, x.length); i++) {
      const wi = Number(w[i] || 0);
      const xi = Number(x[i] || 0);
      w[i] = wi + lr * (err * xi - l2 * wi);
    }
    model = { ...model, w, n: (Number(model?.n) || 0) + 1 };

    try {
      await db
        .prepare(
          `UPDATE ml_v1_queue SET y=?2, labeled_at=?3 WHERE id=?1`,
        )
        .bind(String(r.id), Number(y), now)
        .run();
      trained++;
    } catch {
      // ignore
    }
  }

  if (trained > 0) {
    await mlV1PutModel(KV, model);
  }
  console.log(`[ML TRAIN] Result: trained=${trained}, skipped=${JSON.stringify(skipped)}`);
  return { ok: true, trained, model_n: model.n, skipped, checked: due.length };
}

async function d1UpsertCandle(env, ticker, tf, candle) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const tfKey = normalizeTfKey(tf);
  if (!sym || !tfKey) return { ok: false, error: "bad_params" };

  const ts = Number(candle?.ts);
  if (!Number.isFinite(ts)) return { ok: false, error: "bad_ts" };
  const o = Number(candle?.o);
  const h = Number(candle?.h);
  const l = Number(candle?.l);
  const c = Number(candle?.c);
  const v = candle?.v != null ? Number(candle?.v) : null;
  if (![o, h, l, c].every((x) => Number.isFinite(x))) {
    return { ok: false, error: "bad_ohlc" };
  }
  const updatedAt = Date.now();
  try {
    await d1EnsureCandleSchema(env);
    // Try INSERT with session column first; fall back to without if column doesn't exist yet
    try {
      const session = candle?.session || null; // PM / RTH / AH / CLOSED (set by alpacaBarToCandle)
      await db
        .prepare(
          `INSERT INTO ticker_candles (ticker, tf, ts, o, h, l, c, v, session, updated_at)
           VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)
           ON CONFLICT(ticker, tf, ts) DO UPDATE SET
             o=excluded.o, h=excluded.h, l=excluded.l, c=excluded.c, v=excluded.v,
             session=excluded.session, updated_at=excluded.updated_at`,
        )
        .bind(sym, tfKey, ts, o, h, l, c, v, session, updatedAt)
        .run();
    } catch (sessionErr) {
      // Session column may not exist yet — fallback without it
      if (String(sessionErr).includes("no such column: session")) {
        await db
          .prepare(
            `INSERT INTO ticker_candles (ticker, tf, ts, o, h, l, c, v, updated_at)
             VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)
             ON CONFLICT(ticker, tf, ts) DO UPDATE SET
               o=excluded.o, h=excluded.h, l=excluded.l, c=excluded.c, v=excluded.v,
               updated_at=excluded.updated_at`,
          )
          .bind(sym, tfKey, ts, o, h, l, c, v, updatedAt)
          .run();
      } else {
        throw sessionErr;
      }
    }
    return { ok: true };
  } catch (err) {
    console.error(`[D1 CANDLES] Upsert failed for ${sym} ${tfKey}:`, err);
    return { ok: false, error: String(err) };
  }
}

/**
 * Upsert a candle from ingest price data. Unlike d1UpsertCandle (which overwrites
 * all OHLCV), this merges the price into an existing candle:
 *   - If no candle exists: creates one with o=h=l=c=price
 *   - If candle exists: updates h=MAX(h,price), l=MIN(l,price), c=price
 *     (preserves original open and Alpaca volume)
 */
async function d1UpsertIngestCandle(env, ticker, tf, price, tsMs) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true };
  const sym = String(ticker || "").toUpperCase();
  const tfKey = normalizeTfKey(tf);
  if (!sym || !tfKey || !Number.isFinite(price) || price <= 0 || !Number.isFinite(tsMs)) return { ok: false };
  try {
    await d1EnsureCandleSchema(env);
    await db.prepare(
      `INSERT INTO ticker_candles (ticker, tf, ts, o, h, l, c, v, updated_at)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, NULL, ?8)
       ON CONFLICT(ticker, tf, ts) DO UPDATE SET
         h = MAX(ticker_candles.h, excluded.h),
         l = MIN(ticker_candles.l, excluded.l),
         c = excluded.c,
         updated_at = excluded.updated_at`
    ).bind(sym, tfKey, tsMs, price, price, price, price, Date.now()).run();
    return { ok: true };
  } catch (err) {
    console.warn(`[INGEST CANDLE] ${sym} ${tfKey} upsert failed:`, String(err).slice(0, 100));
    return { ok: false };
  }
}

async function d1GetCandles(env, ticker, tf, limit = 200) {
  const db = env?.DB;
  if (!db) return { ok: false, error: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const tfKey = normalizeTfKey(tf);
  const n = Math.max(10, Math.min(3000, Number(limit) || 200));
  if (!sym || !tfKey) return { ok: false, error: "bad_params" };

  try {
    await d1EnsureCandleSchema(env);
    const rows = await db
      .prepare(
        `SELECT ts, o, h, l, c, v
         FROM ticker_candles
         WHERE ticker = ?1 AND tf = ?2
         ORDER BY ts DESC
         LIMIT ?3`,
      )
      .bind(sym, tfKey, n)
      .all();
    const out = (rows?.results || [])
      .map((r) => ({
        ts: Number(r?.ts),
        o: Number(r?.o),
        h: Number(r?.h),
        l: Number(r?.l),
        c: Number(r?.c),
        v: r?.v != null ? Number(r?.v) : null,
      }))
      .filter((x) => Number.isFinite(x.ts) && Number.isFinite(x.o))
      .sort((a, b) => a.ts - b.ts);
    return { ok: true, ticker: sym, tf: tfKey, candles: out };
  } catch (err) {
    console.error(`[D1 CANDLES] Read failed for ${sym} ${tfKey}:`, err);
    return { ok: false, error: String(err) };
  }
}

/**
 * Batch-fetch candles for ALL timeframes of a single ticker in ONE D1 batch call.
 * Returns a Map<tf, {ok, candles}> — same shape as d1GetCandles per TF.
 * This reduces 9 D1 subrequests to 1, critical for staying under the 1000/invocation limit.
 */
async function d1GetCandlesAllTfs(env, ticker, tfConfigs) {
  const db = env?.DB;
  if (!db) return {};
  const sym = String(ticker || "").toUpperCase();
  if (!sym) return {};

  const stmts = [];
  const tfKeys = [];
  for (const { tf, limit } of tfConfigs) {
    const tfKey = normalizeTfKey(tf);
    if (!tfKey) continue;
    const n = Math.max(10, Math.min(3000, Number(limit) || 200));
    stmts.push(
      db.prepare(
        `SELECT ts, o, h, l, c, v FROM ticker_candles
         WHERE ticker = ?1 AND tf = ?2 ORDER BY ts DESC LIMIT ?3`
      ).bind(sym, tfKey, n)
    );
    tfKeys.push(tfKey);
  }
  if (stmts.length === 0) return {};

  try {
    const batchResults = await db.batch(stmts);
    const out = {};
    for (let i = 0; i < tfKeys.length; i++) {
      const rows = batchResults[i]?.results || [];
      const candles = rows
        .map(r => ({
          ts: Number(r?.ts), o: Number(r?.o), h: Number(r?.h),
          l: Number(r?.l), c: Number(r?.c), v: r?.v != null ? Number(r?.v) : null,
        }))
        .filter(x => Number.isFinite(x.ts) && Number.isFinite(x.o))
        .sort((a, b) => a.ts - b.ts);
      out[tfKeys[i]] = { ok: true, ticker: sym, tf: tfKeys[i], candles };
    }
    return out;
  } catch (err) {
    console.error(`[D1 CANDLES] Batch read failed for ${sym}:`, String(err).slice(0, 150));
    return {};
  }
}

// "As-of" variant: only returns candles with ts <= asOfTs (for historical replay)
async function d1GetCandlesAsOf(env, ticker, tf, limit = 200, asOfTs = null) {
  if (!asOfTs || !Number.isFinite(asOfTs)) return d1GetCandles(env, ticker, tf, limit);
  const db = env?.DB;
  if (!db) return { ok: false, error: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const tfKey = normalizeTfKey(tf);
  const n = Math.max(10, Math.min(3000, Number(limit) || 200));
  if (!sym || !tfKey) return { ok: false, error: "bad_params" };
  try {
    await d1EnsureCandleSchema(env);
    const rows = await db
      .prepare(
        `SELECT ts, o, h, l, c, v
         FROM ticker_candles
         WHERE ticker = ?1 AND tf = ?2 AND ts <= ?4
         ORDER BY ts DESC
         LIMIT ?3`,
      )
      .bind(sym, tfKey, n, asOfTs)
      .all();
    const out = (rows?.results || [])
      .map((r) => ({
        ts: Number(r?.ts),
        o: Number(r?.o),
        h: Number(r?.h),
        l: Number(r?.l),
        c: Number(r?.c),
        v: r?.v != null ? Number(r?.v) : null,
      }))
      .filter((x) => Number.isFinite(x.ts) && Number.isFinite(x.o))
      .sort((a, b) => a.ts - b.ts);
    return { ok: true, ticker: sym, tf: tfKey, candles: out };
  } catch (err) {
    console.error(`[D1 CANDLES AS-OF] Read failed for ${sym} ${tfKey}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1UpsertTickerIndex(env, ticker, ts) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  if (_removedTickersCache && _removedTickersCache.has(sym)) return { ok: false, skipped: true, reason: "removed" };
  const nowTs = Number(ts) || Date.now();

  try {
    await d1EnsureLatestSchema(env);
    await db
      .prepare(
        `INSERT INTO ticker_index (ticker, first_seen_ts, last_seen_ts)
         VALUES (?1, ?2, ?3)
         ON CONFLICT(ticker) DO UPDATE SET last_seen_ts = excluded.last_seen_ts`,
      )
      .bind(sym, nowTs, nowTs)
      .run();
    return { ok: true };
  } catch (err) {
    console.error(`[D1 LATEST] Index upsert failed for ${sym}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1UpsertTickerLatest(env, ticker, payload) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  const ts = Number(payload?.ts) || Date.now();
  const updatedAt = Date.now();
  const stage =
    payload?.kanban_stage != null ? String(payload.kanban_stage) : null;
  const prevStage =
    payload?.prev_kanban_stage != null
      ? String(payload.prev_kanban_stage)
      : null;

  const D1_MAX = 50000;
  let payloadJson = null;
  try {
    let slim = slimPayloadForD1(payload);
    let s = JSON.stringify(slim);
    if (s.length > D1_MAX) {
      slim = minimalPayloadForD1(payload);
      s = JSON.stringify(slim);
    }
    payloadJson = s.length <= D1_MAX ? s : null;
  } catch {
    payloadJson = null;
  }
  if (!payloadJson)
    return { ok: false, skipped: true, reason: "payload_json_failed" };

  try {
    await d1EnsureLatestSchema(env);
    await db
      .prepare(
        `INSERT INTO ticker_latest (ticker, ts, updated_at, kanban_stage, prev_kanban_stage, payload_json)
         VALUES (?1, ?2, ?3, ?4, ?5, ?6)
         ON CONFLICT(ticker) DO UPDATE SET
           ts = excluded.ts,
           updated_at = excluded.updated_at,
           kanban_stage = excluded.kanban_stage,
           prev_kanban_stage = excluded.prev_kanban_stage,
           payload_json = excluded.payload_json`,
      )
      .bind(sym, ts, updatedAt, stage, prevStage, payloadJson)
      .run();
    return { ok: true };
  } catch (err) {
    console.error(`[D1 LATEST] Latest upsert failed for ${sym}:`, err);
    return { ok: false, error: String(err) };
  }
}

// Patch selected fields inside ticker_latest.payload_json without rewriting the whole row.
// Uses SQLite JSON1 `json_set` to avoid a read+merge cycle.
async function d1PatchTickerLatestFields(env, ticker, patch) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const sym = String(ticker || "").toUpperCase();
  if (!sym) return { ok: false, skipped: true, reason: "bad_ticker" };
  if (!patch || typeof patch !== "object")
    return { ok: false, skipped: true, reason: "bad_patch" };

  const pairs = [];
  const binds = [];
  const add = (k, v) => {
    if (v == null) return;
    // Keep numbers as numbers; booleans as 1/0; strings as strings.
    let val = v;
    if (typeof v === "boolean") val = v ? 1 : 0;
    pairs.push(`'$.${k}', ?${binds.length + 1}`);
    binds.push(val);
  };

  add("prev_close", patch.prev_close);
  add("day_change", patch.day_change);
  add("day_change_pct", patch.day_change_pct);
  add("change", patch.change);
  add("change_pct", patch.change_pct);
  add("session", patch.session);
  add("is_rth", patch.is_rth);

  if (pairs.length === 0)
    return { ok: false, skipped: true, reason: "no_fields" };

  try {
    await d1EnsureLatestSchema(env);
    const sql = `UPDATE ticker_latest
                 SET payload_json = json_set(payload_json, ${pairs.join(", ")})
                 WHERE ticker = ?${binds.length + 1} AND payload_json IS NOT NULL`;
    binds.push(sym);
    await db
      .prepare(sql)
      .bind(...binds)
      .run();
    return { ok: true };
  } catch (err) {
    console.error(`[D1 LATEST] Patch failed for ${sym}:`, err);
    return { ok: false, error: String(err) };
  }
}

/**
 * Freshness heartbeat: merge live price + ingest_ts into timed:latest for all tickers.
 * Runs every minute from the price feed cron. Guarantees ingest_ts stays fresh even when
 * scoring fails (insufficient candles) or is skipped. Preserves scores; only updates
 * price, prev_close, day_change, day_change_pct, ingest_ts, ingest_time.
 */
async function mergeFreshnessIntoLatest(KV, prices) {
  const tickers = Object.keys(prices || {}).filter((s) => Number(prices[s]?.p) > 0);
  if (tickers.length === 0) return { merged: 0 };
  const now = Date.now();
  const ingestTime = new Date(now).toISOString();
  const BATCH = 50;
  let merged = 0;
  for (let i = 0; i < tickers.length; i += BATCH) {
    const batch = tickers.slice(i, i + BATCH);
    const results = await Promise.allSettled(
      batch.map(async (sym) => {
        const snap = prices[sym];
        if (!snap || !(Number(snap.p) > 0)) return;
        const existing = await kvGetJSON(KV, `timed:latest:${sym}`);
        if (!existing || typeof existing !== "object") return;
        // CRITICAL: Don't overwrite existing non-zero day_change with 0.
        // When market is closed or prevClose is unavailable, the price feed
        // computes dc=0/dp=0, which would erase the last known good values.
        // Only update if the new value is meaningfully non-zero, OR if existing is missing.
        const newDc = Number.isFinite(snap.dc) ? snap.dc : null;
        const newDp = Number.isFinite(snap.dp) ? snap.dp : null;
        const existDc = existing.day_change;
        const existDp = existing.day_change_pct;
        const updatedPrice = Number(snap.p);
        const updatedPc = Number(snap.pc) || existing.prev_close || 0;

        // If existing day_change is 0 (stale) but we have valid price + prev_close,
        // recompute from scratch so the UI shows a real value.
        let finalDc, finalDp;
        if (newDc !== null && newDc !== 0) {
          // Fresh non-zero value from the price feed — use it
          finalDc = newDc;
          finalDp = newDp;
        } else if (Number.isFinite(existDc) && existDc !== 0) {
          // Existing non-zero value — preserve it
          finalDc = existDc;
          finalDp = existDp;
        } else if (updatedPrice > 0 && updatedPc > 0 && updatedPc !== updatedPrice) {
          // Both existing and new are 0/null, but we have price + prev_close — recompute
          finalDc = Math.round((updatedPrice - updatedPc) * 100) / 100;
          finalDp = Math.round(((updatedPrice - updatedPc) / updatedPc) * 10000) / 100;
        } else {
          finalDc = existDc ?? newDc ?? 0;
          finalDp = existDp ?? newDp ?? 0;
        }

        const updated = {
          ...existing,
          price: updatedPrice,
          prev_close: updatedPc || existing.prev_close,
          day_change: finalDc,
          day_change_pct: finalDp,
          ingest_ts: now,
          ingest_time: ingestTime,
        };
        await kvPutJSON(KV, `timed:latest:${sym}`, updated);
        return 1;
      }),
    );
    merged += results.filter((r) => r.status === "fulfilled" && r.value === 1).length;
  }
  if (merged > 0) {
    console.log(`[FRESHNESS] Merged price+ingest_ts into ${merged}/${tickers.length} tickers`);
  }
  return { merged };
}

// Periodic KV → D1 latest sync (batched) to bootstrap /timed/all quickly after deploy.
async function d1SyncLatestBatchFromKV(env, ctx, batchSize = 50) {
  const KV = env?.KV_TIMED;
  const db = env?.DB;
  if (!KV || !db)
    return { ok: false, skipped: true, reason: "missing_kv_or_db" };

  try {
    await d1EnsureLatestSchema(env);
  } catch {
    // ignore
  }

  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
  if (!Array.isArray(tickers) || tickers.length === 0) {
    return { ok: false, skipped: true, reason: "no_tickers_index" };
  }

  const cursorKey = "timed:d1:latest_sync_cursor";
  let cursor = 0;
  try {
    cursor = Number(await KV.get(cursorKey)) || 0;
    if (!Number.isFinite(cursor) || cursor < 0) cursor = 0;
  } catch {
    cursor = 0;
  }

  const start = Date.now();
  const end = Math.min(cursor + batchSize, tickers.length);
  const slice = tickers.slice(cursor, end);

  for (const t of slice) {
    const sym = String(t || "").toUpperCase();
    if (!sym) continue;
    try {
      // Always index the ticker (even if no latest yet)
      await d1UpsertTickerIndex(env, sym, Date.now());
      const latest = await kvGetJSON(KV, `timed:latest:${sym}`);
      if (latest && typeof latest === "object") {
        // Attach ML predictions before syncing to D1
        try {
          await mlV1AttachToPayload(KV, latest);
        } catch (e) {
          console.warn(`[D1 SYNC] ML attach failed for ${sym}:`, String(e));
        }
        
        // Ensure stage exists for D1 consumers
        try {
          if (latest.kanban_stage == null) {
            const stage = classifyKanbanStage(latest);
            if (stage) latest.kanban_stage = stage;
          }
        } catch {
          // ignore
        }
        await d1UpsertTickerLatest(env, sym, latest);
      }
    } catch (e) {
      console.error(`[D1 SYNC] Failed for ${sym}:`, String(e));
    }
  }

  const nextCursor = end >= tickers.length ? 0 : end;
  try {
    await KV.put(cursorKey, String(nextCursor), {
      expirationTtl: 7 * 24 * 60 * 60,
    });
  } catch {
    // ignore
  }

  const ms = Date.now() - start;
  console.log(
    `[D1 SYNC] Synced ${slice.length}/${tickers.length} tickers in ${ms}ms (cursor ${cursor}→${nextCursor})`,
  );
  return {
    ok: true,
    synced: slice.length,
    total: tickers.length,
    ms,
    cursor,
    nextCursor,
  };
}

async function d1CleanupOldTrail(env, ttlDays = 35) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  const KV = env?.KV_TIMED;
  // throttle cleanup to at most once per hour
  const throttleKey = "timed:d1:trail:last_cleanup_ms";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 60 * 60 * 1000) {
        return { ok: true, skipped: true, reason: "throttled" };
      }
    }
  } catch {
    // ignore throttle failures
  }

  const cutoff = Date.now() - Number(ttlDays) * 24 * 60 * 60 * 1000;
  try {
    const r = await db
      .prepare(`DELETE FROM timed_trail WHERE ts < ?1`)
      .bind(cutoff)
      .run();

    if (KV) {
      await KV.put(throttleKey, String(Date.now()), {
        expirationTtl: 2 * 60 * 60, // 2 hours
      });
    }

    return { ok: true, deleted: r?.meta?.changes || 0, cutoff };
  } catch (err) {
    console.error(`[D1 TRAIL] Cleanup failed:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1GetTrailRange(env, ticker, sinceTs = null, limit = 5000, includeKanban = false) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const t = String(ticker || "").toUpperCase();
  const lim = Math.max(1, Math.min(20000, Number(limit) || 5000));

  try {
    // Always include kanban_stage column (lightweight). Include payload_json only when full kanban data is requested.
    const cols = includeKanban
      ? `ts, price, htf_score, ltf_score, completion, phase_pct, state, rank, flags_json, trigger_reason, trigger_dir, kanban_stage, payload_json`
      : `ts, price, htf_score, ltf_score, completion, phase_pct, state, rank, flags_json, trigger_reason, trigger_dir, kanban_stage`;
    
    let stmt;
    if (sinceTs != null && Number.isFinite(Number(sinceTs))) {
      stmt = db
        .prepare(
          `SELECT ${cols}
           FROM timed_trail
           WHERE ticker = ?1 AND ts >= ?2
           ORDER BY ts ASC
           LIMIT ?3`,
        )
        .bind(t, Number(sinceTs), lim);
    } else {
      stmt = db
        .prepare(
          `SELECT ${cols}
           FROM timed_trail
           WHERE ticker = ?1
           ORDER BY ts DESC
           LIMIT ?2`,
        )
        .bind(t, lim);
    }

    const rows = await stmt.all();
    const out = Array.isArray(rows?.results) ? rows.results : [];
    const trail = out
      .map((r) => {
        const base = {
          ts: Number(r.ts),
          price: r.price != null ? Number(r.price) : null,
          htf_score: r.htf_score != null ? Number(r.htf_score) : null,
          ltf_score: r.ltf_score != null ? Number(r.ltf_score) : null,
          completion: r.completion != null ? Number(r.completion) : null,
          phase_pct: r.phase_pct != null ? Number(r.phase_pct) : null,
          state: r.state != null ? String(r.state) : null,
          rank: r.rank != null ? Number(r.rank) : null,
          flags:
            r.flags_json && typeof r.flags_json === "string"
              ? (() => {
                  try {
                    return JSON.parse(r.flags_json);
                  } catch {
                    return {};
                  }
                })()
              : {},
          momentum_elite: false, // derived in UI/logic from flags when needed
          trigger_reason:
            r.trigger_reason != null ? String(r.trigger_reason) : null,
          trigger_dir: r.trigger_dir != null ? String(r.trigger_dir) : null,
          kanban_stage: r.kanban_stage != null ? String(r.kanban_stage) : null,
        };
        
        // Extract extended kanban data from payload_json if requested
        if (includeKanban && r.payload_json) {
          try {
            const payload = JSON.parse(r.payload_json);
            if (!base.kanban_stage && payload.kanban_stage) base.kanban_stage = payload.kanban_stage;
            base.entry_ts = payload.entry_ts || null;
            base.entry_price = payload.entry_price || null;
            base.move_status = payload.move_status || null;
            base.kanban_meta = payload.kanban_meta || null;
          } catch {
            // kanban_stage already populated from direct column
          }
        }
        
        return base;
      })
      .filter((p) => Number.isFinite(p.ts));

    // If we queried DESC (no since), normalize to ASC for consumers
    trail.sort((a, b) => a.ts - b.ts);

    return { ok: true, trail, source: "d1" };
  } catch (err) {
    console.error(`[D1 TRAIL] Query failed for ${ticker}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1GetTrailPayloadRange(
  env,
  ticker,
  sinceTs = null,
  untilTs = null,
  limit = 5000,
) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  const t = String(ticker || "").toUpperCase();
  const lim = Math.max(1, Math.min(20000, Number(limit) || 5000));

  const since =
    sinceTs != null && Number.isFinite(Number(sinceTs))
      ? Number(sinceTs)
      : null;
  const until =
    untilTs != null && Number.isFinite(Number(untilTs))
      ? Number(untilTs)
      : null;

  try {
    let stmt;
    if (since != null && until != null) {
      stmt = db
        .prepare(
          `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3
         ORDER BY ts ASC
         LIMIT ?4`,
        )
        .bind(t, since, until, lim);
    } else if (since != null) {
      stmt = db
        .prepare(
          `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1 AND ts >= ?2
         ORDER BY ts ASC
         LIMIT ?3`,
        )
        .bind(t, since, lim);
    } else {
      stmt = db
        .prepare(
          `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1
         ORDER BY ts DESC
         LIMIT ?2`,
        )
        .bind(t, lim);
    }

    const rows = await stmt.all();
    const results = Array.isArray(rows?.results) ? rows.results : [];
    const payloads = results
      .map((r) => {
        const ts = Number(r.ts);
        const raw = r.payload_json;
        if (!raw || typeof raw !== "string") return null;
        try {
          const p = JSON.parse(raw);
          p.ts = ts; // trust DB ts
          return p;
        } catch {
          return null;
        }
      })
      .filter(Boolean)
      .sort((a, b) => Number(a.ts) - Number(b.ts));

    return { ok: true, payloads, source: "d1" };
  } catch (err) {
    console.error(`[D1 TRAIL] Payload query failed for ${ticker}:`, err);
    return { ok: false, error: String(err) };
  }
}

// ─────────────────────────────────────────────────────────────
// D1 Ledger Storage (alerts + trades + trade_events)
// ─────────────────────────────────────────────────────────────

function isoToMs(v) {
  if (v == null) return null;
  if (typeof v === "number" && Number.isFinite(v)) return v;
  const s = String(v);
  const ms = Date.parse(s);
  return Number.isFinite(ms) ? ms : null;
}

function formatDedupDay(ts) {
  if (!Number.isFinite(ts)) return null;
  return new Date(ts).toISOString().split("T")[0];
}

function buildAlertId(ticker, ts, type) {
  const t = String(ticker || "").toUpperCase();
  const kind = String(type || "ALERT").toUpperCase();
  return `${t}:${ts}:${kind}`;
}

async function d1UpsertAlert(env, alert) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };

  const ticker = String(alert?.ticker || "").toUpperCase();
  const ts = Number(alert?.ts);
  if (!ticker || !Number.isFinite(ts))
    return { ok: false, skipped: true, reason: "bad_key" };

  const alertId = String(alert?.alert_id || `${ticker}:${ts}`);
  const discordSent = alert?.discord_sent ? 1 : 0;

  try {
    await db
      .prepare(
        `INSERT OR REPLACE INTO alerts
          (alert_id, ticker, ts, side, state, rank, rr_at_alert, trigger_reason, dedupe_day,
           discord_sent, discord_status, discord_error, payload_json, meta_json)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14)`,
      )
      .bind(
        alertId,
        ticker,
        ts,
        alert?.side != null ? String(alert.side) : null,
        alert?.state != null ? String(alert.state) : null,
        alert?.rank != null ? Number(alert.rank) : null,
        alert?.rr_at_alert != null ? Number(alert.rr_at_alert) : null,
        alert?.trigger_reason != null ? String(alert.trigger_reason) : null,
        alert?.dedupe_day != null ? String(alert.dedupe_day) : null,
        discordSent,
        alert?.discord_status != null ? Number(alert.discord_status) : null,
        alert?.discord_error != null ? String(alert.discord_error) : null,
        alert?.payload_json != null ? String(alert.payload_json) : null,
        alert?.meta_json != null ? String(alert.meta_json) : null,
      )
      .run();

    return { ok: true, alert_id: alertId };
  } catch (err) {
    console.error(`[D1 LEDGER] Alert upsert failed for ${ticker}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1UpsertTrade(env, trade) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  if (!trade) return { ok: false, skipped: true, reason: "missing_trade" };

  const tradeId = String(trade.id || trade.trade_id || "").trim();
  if (!tradeId) return { ok: false, skipped: true, reason: "missing_trade_id" };

  const ticker = String(trade.ticker || "").toUpperCase();
  const direction = String(trade.direction || "").toUpperCase();
  // Prefer numeric entry_ts (ms); normalize seconds to ms so display is correct
  let entryTs = Number(trade.entry_ts);
  if (!Number.isFinite(entryTs) || entryTs <= 0)
    entryTs = isoToMs(trade.entryTime) || null;
  if (Number.isFinite(entryTs) && entryTs < 1e12) entryTs = entryTs * 1000;
  const createdAt = entryTs || Date.now();
  const updatedAt = Date.now();

  // Best-effort exit ts from trade.exit_ts, then history EXIT event
  let exitTs = Number(trade.exit_ts);
  if (!Number.isFinite(exitTs) || exitTs <= 0) exitTs = null;
  if (exitTs != null && exitTs < 1e12) exitTs = exitTs * 1000;
  let exitEvent = null;
  if (exitTs == null && Array.isArray(trade.history)) {
    for (let i = trade.history.length - 1; i >= 0; i--) {
      const e = trade.history[i];
      if (e && e.type === "EXIT") {
        exitEvent = e;
        exitTs = isoToMs(e.timestamp);
        break;
      }
    }
  }

  // Best-effort exit price/reason from history for legacy trades (so backfill becomes useful)
  const derivedExitPrice =
    trade.exitPrice != null
      ? Number(trade.exitPrice)
      : exitEvent && exitEvent.price != null
        ? Number(exitEvent.price)
        : null;
  const derivedExitReason =
    trade.exitReason != null
      ? String(trade.exitReason)
      : inferExitReasonForLegacyTrade(trade, exitEvent);

  let trimTs = Number(trade.trim_ts);
  if (!Number.isFinite(trimTs) && Array.isArray(trade.history)) {
    for (let i = trade.history.length - 1; i >= 0; i--) {
      const e = trade.history[i];
      if (e && e.type === "TRIM") {
        trimTs = isoToMs(e.timestamp) || Number(e.ts) || 0;
        if (trimTs < 1e12) trimTs = trimTs * 1000;
        break;
      }
    }
  }
  if (Number.isFinite(trimTs) && trimTs < 1e12) trimTs = trimTs * 1000;

  let trimPrice = Number(trade.trim_price ?? trade.trimPrice);
  if (!Number.isFinite(trimPrice) && Array.isArray(trade.history)) {
    for (let i = trade.history.length - 1; i >= 0; i--) {
      const e = trade.history[i];
      if (e && e.type === "TRIM" && e.price != null) {
        trimPrice = Number(e.price);
        break;
      }
    }
  }

  const insertWithTrimPrice = `INSERT OR IGNORE INTO trades
          (trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
           exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct, script_version,
           created_at, updated_at, trim_ts, trim_price)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18, ?19)`;
  const insertWithoutTrimPrice = `INSERT OR IGNORE INTO trades
          (trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
           exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct, script_version,
           created_at, updated_at, trim_ts)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14, ?15, ?16, ?17, ?18)`;

  try {
    // Preserve created_at by inserting once.
    await db
      .prepare(insertWithTrimPrice)
      .bind(
        tradeId,
        ticker || null,
        direction || null,
        entryTs != null ? Number(entryTs) : null,
        trade.entryPrice != null ? Number(trade.entryPrice) : null,
        trade.rank != null ? Number(trade.rank) : null,
        trade.rr != null ? Number(trade.rr) : null,
        trade.status != null ? String(trade.status) : null,
        exitTs != null ? Number(exitTs) : null,
        Number.isFinite(derivedExitPrice) ? derivedExitPrice : null,
        derivedExitReason != null ? String(derivedExitReason) : null,
        trade.trimmedPct != null ? Number(trade.trimmedPct) : null,
        trade.pnl != null ? Number(trade.pnl) : null,
        trade.pnlPct != null ? Number(trade.pnlPct) : null,
        trade.scriptVersion != null
          ? String(trade.scriptVersion)
          : trade.script_version != null
            ? String(trade.script_version)
            : null,
        createdAt,
        updatedAt,
        Number.isFinite(trimTs) ? trimTs : null,
        Number.isFinite(trimPrice) ? trimPrice : null,
      )
      .run();

    await db
      .prepare(
        `UPDATE trades SET
          ticker=?2, direction=?3, entry_ts=?4, entry_price=?5, rank=?6, rr=?7, status=?8,
          exit_ts=?9, exit_price=?10, exit_reason=?11,
          trimmed_pct=?12, pnl=?13, pnl_pct=?14, script_version=?15,
          updated_at=?16, trim_ts=?17, trim_price=?18
         WHERE trade_id=?1`,
      )
      .bind(
        tradeId,
        ticker || null,
        direction || null,
        entryTs != null ? Number(entryTs) : null,
        trade.entryPrice != null ? Number(trade.entryPrice) : null,
        trade.rank != null ? Number(trade.rank) : null,
        trade.rr != null ? Number(trade.rr) : null,
        trade.status != null ? String(trade.status) : null,
        exitTs != null ? Number(exitTs) : null,
        Number.isFinite(derivedExitPrice) ? derivedExitPrice : null,
        derivedExitReason != null ? String(derivedExitReason) : null,
        trade.trimmedPct != null ? Number(trade.trimmedPct) : null,
        trade.pnl != null ? Number(trade.pnl) : null,
        trade.pnlPct != null ? Number(trade.pnlPct) : null,
        trade.scriptVersion != null
          ? String(trade.scriptVersion)
          : trade.script_version != null
            ? String(trade.script_version)
            : null,
        updatedAt,
        Number.isFinite(trimTs) ? trimTs : null,
        Number.isFinite(trimPrice) ? trimPrice : null,
      )
      .run();

    return { ok: true, trade_id: tradeId };
  } catch (err) {
    console.error(`[D1 LEDGER] Trade upsert failed for ${tradeId}:`, err);
    return { ok: false, error: String(err) };
  }
}

async function d1InsertTradeEvent(env, tradeId, event) {
  const db = env?.DB;
  if (!db) return { ok: false, skipped: true, reason: "no_db_binding" };
  if (!tradeId) return { ok: false, skipped: true, reason: "missing_trade_id" };
  if (!event) return { ok: false, skipped: true, reason: "missing_event" };

  const ts = isoToMs(event.timestamp) || Number(event.ts) || null;
  const type = String(event.type || "").toUpperCase();
  if (!Number.isFinite(ts) || !type)
    return { ok: false, skipped: true, reason: "bad_event_key" };

  const eventId = `${tradeId}:${type}:${ts}`;

  // Quantity fields: for TRIM, represent trimmed percentages.
  const qtyPctTotal =
    event.trimPct != null
      ? Number(event.trimPct)
      : event.trimmedPct != null
        ? Number(event.trimmedPct)
        : null;
  const qtyPctDelta =
    event.trimDeltaPct != null ? Number(event.trimDeltaPct) : null;

  const meta = (() => {
    try {
      return JSON.stringify(event);
    } catch {
      return null;
    }
  })();

  try {
    await db
      .prepare(
        `INSERT OR IGNORE INTO trade_events
          (event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json)
         VALUES
          (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)`,
      )
      .bind(
        eventId,
        String(tradeId),
        Number(ts),
        type,
        event.price != null ? Number(event.price) : null,
        qtyPctDelta != null && Number.isFinite(qtyPctDelta)
          ? qtyPctDelta
          : null,
        qtyPctTotal != null && Number.isFinite(qtyPctTotal)
          ? qtyPctTotal
          : null,
        event.pnl_realized != null ? Number(event.pnl_realized) : null,
        event.reason != null ? String(event.reason) : null,
        meta,
      )
      .run();

    return { ok: true, event_id: eventId };
  } catch (err) {
    console.error(`[D1 LEDGER] Trade event insert failed for ${tradeId}:`, err);
    return { ok: false, error: String(err) };
  }
}

// --- Phase 2: positions / lots / execution_actions (lot-based model) ---

async function d1InsertPosition(env, row) {
  const db = env?.DB;
  if (!db || !row) return { ok: false, skipped: true };
  const { position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at, closed_at, script_version, stop_loss, take_profit } = row;
  if (!position_id || !ticker || !direction) return { ok: false, skipped: true, reason: "missing_key" };
  try {
    await db.prepare(
      `INSERT OR IGNORE INTO positions (position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at, closed_at, script_version, stop_loss, take_profit)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12)`
    ).bind(
      position_id,
      String(ticker).toUpperCase(),
      String(direction).toUpperCase(),
      status || "OPEN",
      Number(total_qty) || 0,
      Number(cost_basis) || 0,
      Number(created_at) || Date.now(),
      Number(updated_at) || Date.now(),
      closed_at != null ? Number(closed_at) : null,
      script_version || null,
      Number.isFinite(Number(stop_loss)) ? Number(stop_loss) : null,
      Number.isFinite(Number(take_profit)) ? Number(take_profit) : null,
    ).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true, reason: "schema" };
    console.error("[D1 LEDGER] positions insert failed:", err);
    return { ok: false, error: String(err) };
  }
}

async function d1InsertLot(env, row) {
  const db = env?.DB;
  if (!db || !row) return { ok: false, skipped: true };
  const { lot_id, position_id, ts, qty, price, value, remaining_qty } = row;
  if (!lot_id || !position_id || ts == null) return { ok: false, skipped: true, reason: "missing_key" };
  try {
    await db.prepare(
      `INSERT OR IGNORE INTO lots (lot_id, position_id, ts, qty, price, value, remaining_qty)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7)`
    ).bind(
      lot_id,
      position_id,
      Number(ts),
      Number(qty) || 0,
      Number(price) || 0,
      Number(value) || 0,
      Number(remaining_qty) ?? Number(qty) ?? 0,
    ).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true, reason: "schema" };
    console.error("[D1 LEDGER] lots insert failed:", err);
    return { ok: false, error: String(err) };
  }
}

async function d1InsertExecutionAction(env, row) {
  const db = env?.DB;
  if (!db || !row) return { ok: false, skipped: true };
  const { action_id, position_id, ts, action_type, qty, price, value, pnl_realized, lot_id, reason, meta_json } = row;
  if (!action_id || !position_id || ts == null || !action_type) return { ok: false, skipped: true, reason: "missing_key" };
  try {
    await db.prepare(
      `INSERT OR IGNORE INTO execution_actions (action_id, position_id, ts, action_type, qty, price, value, pnl_realized, lot_id, reason, meta_json)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11)`
    ).bind(
      action_id,
      position_id,
      Number(ts),
      String(action_type).toUpperCase(),
      Number(qty) || 0,
      Number(price) || 0,
      Number(value) || 0,
      pnl_realized != null ? Number(pnl_realized) : null,
      lot_id || null,
      reason || null,
      meta_json || null,
    ).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true, reason: "schema" };
    console.error("[D1 LEDGER] execution_actions insert failed:", err);
    return { ok: false, error: String(err) };
  }
}

// ─────────────────────────────────────────────────────────────────────────────
// Account Ledger: single source of truth for cash balance + realized P&L
// ─────────────────────────────────────────────────────────────────────────────

async function ensureAccountLedgerSchema(db, KV) {
  const throttleKey = "timed:schema:account_ledger:v1";
  try {
    if (KV) {
      const last = Number(await KV.get(throttleKey));
      if (Number.isFinite(last) && Date.now() - last < 24 * 60 * 60 * 1000) return;
    }
    await db.exec(`
      CREATE TABLE IF NOT EXISTS account_ledger (
        ledger_id INTEGER PRIMARY KEY AUTOINCREMENT,
        mode TEXT NOT NULL DEFAULT 'trader',
        ts INTEGER NOT NULL,
        event_type TEXT NOT NULL,
        position_id TEXT,
        ticker TEXT,
        direction TEXT,
        qty REAL,
        price REAL,
        cash_delta REAL NOT NULL,
        realized_pnl REAL DEFAULT 0,
        balance REAL NOT NULL,
        note TEXT
      );
      CREATE INDEX IF NOT EXISTS idx_account_ledger_ts ON account_ledger (ts);
      CREATE INDEX IF NOT EXISTS idx_account_ledger_mode_ts ON account_ledger (mode, ts);
    `);
    if (KV) await KV.put(throttleKey, String(Date.now()));
  } catch (err) {
    console.error("[D1 LEDGER] ensureAccountLedgerSchema failed:", err);
  }
}

/**
 * Insert a row into account_ledger. `balance` is the running cash balance AFTER this event.
 */
async function d1InsertLedgerEntry(env, row) {
  const db = env?.DB;
  if (!db || !row) return { ok: false, skipped: true };
  const { mode, ts, event_type, position_id, ticker, direction, qty, price, cash_delta, realized_pnl, balance, note } = row;
  if (!event_type || ts == null || cash_delta == null || balance == null) return { ok: false, skipped: true, reason: "missing_key" };
  try {
    await ensureAccountLedgerSchema(db, env?.KV_TIMED);
    await db.prepare(
      `INSERT INTO account_ledger (mode, ts, event_type, position_id, ticker, direction, qty, price, cash_delta, realized_pnl, balance, note)
       VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12)`
    ).bind(
      mode || "trader",
      Number(ts),
      String(event_type).toUpperCase(),
      position_id || null,
      ticker || null,
      direction || null,
      qty != null ? Number(qty) : null,
      price != null ? Number(price) : null,
      Number(cash_delta),
      realized_pnl != null ? Number(realized_pnl) : 0,
      Number(balance),
      note || null,
    ).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) {
      try {
        await ensureAccountLedgerSchema(db, null); // force create
        return d1InsertLedgerEntry(env, row); // retry once
      } catch { /* fall through */ }
    }
    console.error("[D1 LEDGER] account_ledger insert failed:", err);
    return { ok: false, error: String(err) };
  }
}

/**
 * Get the latest balance from account_ledger for a mode.
 * Returns the starting capital if no entries exist yet.
 */
async function d1GetLedgerBalance(env, mode = "trader") {
  const db = env?.DB;
  if (!db) return mode === "trader" ? PORTFOLIO_START_CASH : 100000;
  try {
    await ensureAccountLedgerSchema(db, env?.KV_TIMED);
    const row = await db.prepare(
      "SELECT balance FROM account_ledger WHERE mode = ?1 ORDER BY ts DESC, ledger_id DESC LIMIT 1"
    ).bind(mode).first();
    return row ? Number(row.balance) : (mode === "trader" ? PORTFOLIO_START_CASH : 100000);
  } catch {
    return mode === "trader" ? PORTFOLIO_START_CASH : 100000;
  }
}

async function d1GetOpenPosition(env, ticker, direction) {
  const db = env?.DB;
  if (!db || !ticker) return null;
  try {
    const row = await db.prepare(
      `SELECT position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at
       FROM positions WHERE ticker = ?1 AND direction = ?2 AND status = 'OPEN' LIMIT 1`
    ).bind(String(ticker).toUpperCase(), String(direction || "LONG").toUpperCase()).first();
    return row || null;
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    console.error("[D1 LEDGER] get open position failed:", err);
    return null;
  }
}

/** Get any open position for ticker (either direction). Returns null if none. */
async function d1GetAnyOpenPosition(env, ticker) {
  const db = env?.DB;
  if (!db || !ticker) return null;
  try {
    const row = await db.prepare(
      `SELECT position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at
       FROM positions WHERE ticker = ?1 AND status = 'OPEN' LIMIT 1`
    ).bind(String(ticker).toUpperCase()).first();
    return row || null;
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    return null;
  }
}

/**
 * ANTI-CHURNING: Check per-ticker daily trade frequency.
 * 
 * Data shows excessive trading hurts performance:
 * - TLN: 276 trades in 2 days, -$111 total P&L
 * - Top churners all have ~50% win rate (coin flip)
 * 
 * Rule: Max 3 trades per ticker per day, min 30 min cooldown.
 * 
 * @param {object} env - Worker environment with DB binding
 * @param {string} ticker - Ticker symbol
 * @returns {object} - { blocked, reason, todayTrades, lastEntryAge }
 */
async function checkTradeFrequency(env, ticker) {
  const db = env?.DB;
  if (!db || !ticker) {
    return { blocked: false, todayTrades: 0 };
  }
  
  const sym = String(ticker).toUpperCase();
  const now = Date.now();
  const dayStartMs = now - (24 * 60 * 60 * 1000); // 24 hours ago
  const cooldownMs = 30 * 60 * 1000; // 30 minutes
  
  try {
    // Count entries in last 24 hours and get most recent entry time
    const result = await db.prepare(`
      SELECT 
        COUNT(*) as count,
        MAX(ts) as last_entry_ts
      FROM execution_actions 
      WHERE ticker = ?1 AND action_type = 'ENTRY' AND ts > ?2
    `).bind(sym, dayStartMs).first();
    
    const todayTrades = Number(result?.count) || 0;
    const lastEntryTs = Number(result?.last_entry_ts) || 0;
    const lastEntryAge = lastEntryTs > 0 ? now - lastEntryTs : null;
    
    // Rule 1: Max 3 trades per ticker per day
    if (todayTrades >= 3) {
      return {
        blocked: true,
        reason: "max_daily_trades",
        message: `Max 3 trades per ticker per day reached (${todayTrades} trades)`,
        todayTrades,
        lastEntryAge,
      };
    }
    
    // Rule 2: Minimum 30 minute cooldown between entries
    if (lastEntryAge !== null && lastEntryAge < cooldownMs) {
      const minutesRemaining = Math.ceil((cooldownMs - lastEntryAge) / 60000);
      return {
        blocked: true,
        reason: "cooldown_active",
        message: `Cooldown active: ${minutesRemaining} min remaining`,
        todayTrades,
        lastEntryAge,
        cooldownRemaining: cooldownMs - lastEntryAge,
      };
    }
    
    return {
      blocked: false,
      todayTrades,
      lastEntryAge,
    };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) {
      return { blocked: false, todayTrades: 0 };
    }
    console.error("[D1] checkTradeFrequency failed:", err);
    return { blocked: false, todayTrades: 0, error: err.message };
  }
}

/**
 * Get comprehensive position context for a ticker from D1.
 * This is the SINGLE SOURCE OF TRUTH for open position state.
 * 
 * Returns:
 * - position_id, ticker, direction, status
 * - avg_entry_price (calculated from lots)
 * - total_shares (current qty)
 * - entry_ts (first entry timestamp)
 * - realized_pnl (sum of all realized P&L)
 * - last_action (most recent action type)
 * 
 * @param {object} env - Worker environment with DB binding
 * @param {string} ticker - Ticker symbol
 * @returns {object|null} - Position context or null if no open position
 */
async function getPositionContext(env, ticker) {
  const db = env?.DB;
  if (!db || !ticker) return null;
  const sym = String(ticker).toUpperCase();
  
  try {
    // Get position with aggregated data from lots and actions
    const row = await db.prepare(`
      SELECT 
        p.position_id,
        p.ticker,
        p.direction,
        p.status,
        p.total_qty,
        p.cost_basis,
        p.stop_loss,
        p.take_profit,
        p.created_at as entry_ts,
        p.updated_at,
        p.closed_at,
        COALESCE(
          (SELECT SUM(pnl_realized) FROM execution_actions WHERE position_id = p.position_id),
          0
        ) as realized_pnl,
        (SELECT action_type FROM execution_actions WHERE position_id = p.position_id ORDER BY ts DESC LIMIT 1) as last_action,
        CASE 
          WHEN p.total_qty > 0 THEN ROUND(p.cost_basis / p.total_qty, 4)
          ELSE NULL 
        END as avg_entry_price
      FROM positions p
      WHERE p.ticker = ?1 AND p.status = 'OPEN'
      LIMIT 1
    `).bind(sym).first();
    
    if (!row) return null;
    
    return {
      position_id: row.position_id,
      ticker: row.ticker,
      direction: row.direction,
      status: row.status,
      total_shares: row.total_qty || 0,
      avg_entry_price: row.avg_entry_price || 0,
      entryPrice: row.avg_entry_price || 0,  // Alias for compatibility
      avgEntry: row.avg_entry_price || 0,    // Alias for compatibility
      cost_basis: row.cost_basis || 0,
      sl: row.stop_loss || null,              // Trailing stop loss
      tp: row.take_profit || null,            // Take profit target
      entry_ts: row.entry_ts,
      updated_at: row.updated_at,
      realized_pnl: row.realized_pnl || 0,
      last_action: row.last_action,
    };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    console.error("[D1] getPositionContext failed:", err);
    return null;
  }
}

async function d1UpdatePosition(env, position_id, updates) {
  const db = env?.DB;
  if (!db || !position_id) return { ok: false };
  try {
    const updatedAt = Number(updates.updated_at) || Date.now();
    
    // Build dynamic update based on what's provided
    const setClauses = ["updated_at = ?"];
    const params = [position_id, updatedAt];
    let paramIdx = 3;
    
    if (updates.total_qty != null) {
      setClauses.push(`total_qty = ?${paramIdx++}`);
      params.push(Number(updates.total_qty) || 0);
    }
    if (updates.cost_basis != null) {
      setClauses.push(`cost_basis = ?${paramIdx++}`);
      params.push(Number(updates.cost_basis) || 0);
    }
    if (updates.status != null) {
      setClauses.push(`status = ?${paramIdx++}`);
      params.push(String(updates.status));
    }
    if (updates.closed_at !== undefined) {
      setClauses.push(`closed_at = ?${paramIdx++}`);
      params.push(updates.closed_at != null ? Number(updates.closed_at) : null);
    }
    if (updates.stop_loss !== undefined) {
      setClauses.push(`stop_loss = ?${paramIdx++}`);
      params.push(updates.stop_loss != null && Number.isFinite(Number(updates.stop_loss)) ? Number(updates.stop_loss) : null);
    }
    if (updates.take_profit !== undefined) {
      setClauses.push(`take_profit = ?${paramIdx++}`);
      params.push(updates.take_profit != null && Number.isFinite(Number(updates.take_profit)) ? Number(updates.take_profit) : null);
    }
    
    const sql = `UPDATE positions SET ${setClauses.join(", ")} WHERE position_id = ?1`;
    await db.prepare(sql).bind(...params).run();
    
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true };
    console.error("[D1 LEDGER] position update failed:", err);
    return { ok: false, error: String(err) };
  }
}

// Update position's stop-loss in D1
async function d1UpdatePositionSL(env, ticker, newSL) {
  const db = env?.DB;
  if (!db || !ticker) return { ok: false };
  const sym = String(ticker).toUpperCase();
  try {
    await db.prepare(
      `UPDATE positions SET stop_loss = ?2, updated_at = ?3 WHERE ticker = ?1 AND status = 'OPEN'`
    ).bind(sym, Number.isFinite(newSL) ? newSL : null, Date.now()).run();
    return { ok: true };
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return { ok: false, skipped: true };
    console.error("[D1 LEDGER] SL update failed:", err);
    return { ok: false, error: String(err) };
  }
}

/** Phase 3: Load open position from D1 as a trade-like object (for ingest). Returns null if no position or table missing. */
async function getOpenPositionAsTrade(env, ticker, direction) {
  const pos = await d1GetOpenPosition(env, ticker, direction);
  if (!pos || !pos.position_id) return null;
  const db = env?.DB;
  if (!db) return null;
  let history = [];
  try {
    const actionsRes = await db.prepare(
      `SELECT action_id, ts, action_type, qty, price, value, pnl_realized, reason
       FROM execution_actions WHERE position_id = ? ORDER BY ts ASC`
    ).bind(pos.position_id).all();
    const actions = Array.isArray(actionsRes?.results) ? actionsRes.results : [];
    history = actions.map((a) => ({
      type: a.action_type,
      timestamp: Number.isFinite(Number(a.ts)) ? new Date(Number(a.ts)).toISOString() : undefined,
      ts: a.ts,
      price: a.price,
      shares: a.qty,
      value: a.value,
      pnl_realized: a.pnl_realized,
      reason: a.reason,
    }));
  } catch (err) {
    if (err && !(err.message || "").includes("no such table")) console.error("[D1 LEDGER] getOpenPositionAsTrade actions:", err);
  }
  const totalQty = Number(pos.total_qty) || 0;
  const costBasis = Number(pos.cost_basis) || 0;
  const created = Number(pos.created_at) || 0;
  const vwap = totalQty > 0 ? costBasis / totalQty : 0;
  const realizedPnl = history.reduce((sum, ev) => sum + (Number(ev.pnl_realized) || 0), 0);
  let trimmedPct = 0;
  const trimEvents = history.filter((e) => String(e.type || "").toUpperCase() === "TRIM");
  if (trimEvents.length && totalQty > 0) {
    const trimmedQty = trimEvents.reduce((s, e) => s + (Number(e.shares) || 0), 0);
    trimmedPct = Math.min(1, trimmedQty / totalQty);
  }
  return {
    id: pos.position_id,
    trade_id: pos.position_id,
    ticker: String(pos.ticker || "").toUpperCase(),
    direction: String(pos.direction || "LONG").toUpperCase(),
    status: pos.status || "OPEN",
    entryPrice: vwap,
    entry_price: vwap,
    entry_ts: created,
    entryTime: created ? new Date(created).toISOString() : undefined,
    entryTs: created,
    shares: totalQty,
    history,
    realizedPnl,
    trimmedPct,
    pointValue: 1,
  };
}

/** GET /timed/trades?source=positions — Load from positions/lots/execution_actions (Phase 2). Returns same shape as KV. */
async function d1GetAllPositionsAsTrades(env) {
  const db = env?.DB;
  if (!db) return null;
  try {
    const posRes = await db.prepare(
      `SELECT position_id, ticker, direction, status, total_qty, cost_basis, created_at, updated_at, closed_at, script_version, stop_loss, take_profit
       FROM positions ORDER BY created_at DESC`
    ).all();
    const positions = Array.isArray(posRes?.results) ? posRes.results : [];
    if (positions.length === 0) return [];

    const positionIds = positions.map((p) => p.position_id).filter(Boolean);
    const placeholders = positionIds.map(() => "?").join(",");
    const actionsRes = await db.prepare(
      `SELECT action_id, position_id, ts, action_type, qty, price, value, pnl_realized, reason
       FROM execution_actions WHERE position_id IN (${placeholders}) ORDER BY position_id, ts ASC`
    ).bind(...positionIds).all();
    const actionRows = Array.isArray(actionsRes?.results) ? actionsRes.results : [];
    const actionsByPos = {};
    for (const a of actionRows) {
      const id = a.position_id;
      if (!actionsByPos[id]) actionsByPos[id] = [];
      actionsByPos[id].push({
        type: a.action_type,
        ts: a.ts,
        timestamp: Number.isFinite(Number(a.ts)) ? new Date(Number(a.ts)).toISOString() : undefined,
        price: a.price,
        shares: a.qty,
        value: a.value,
        pnl_realized: a.pnl_realized,
        reason: a.reason,
      });
    }

    return positions.map((p) => {
      const history = actionsByPos[p.position_id] || [];
      const created = Number(p.created_at) || 0;
      
      // Calculate entry price: use VWAP if position is open, or ENTRY action price if closed
      let entryPrice = Number(p.total_qty) > 0 ? Number(p.cost_basis) / Number(p.total_qty) : null;
      const entryAction = history.find(h => h.type === "ENTRY");
      if (!entryPrice && entryAction) {
        entryPrice = entryAction.price;
      }
      
      // Calculate P&L from exit action if closed
      let pnlPct = null;
      let exitReason = null;
      let exitPrice = null;
      const exitAction = history.find(h => h.type === "EXIT");
      if (exitAction) {
        exitPrice = exitAction.price;
        exitReason = exitAction.reason;
        if (entryPrice && Number.isFinite(entryPrice) && entryPrice > 0 && Number.isFinite(exitPrice)) {
          pnlPct = p.direction === "LONG"
            ? ((exitPrice - entryPrice) / entryPrice) * 100
            : ((entryPrice - exitPrice) / entryPrice) * 100;
        }
      }
      
      return {
        id: p.position_id,
        trade_id: p.position_id,
        ticker: String(p.ticker || "").toUpperCase(),
        direction: p.direction,
        entryPrice,
        avgEntry: entryPrice,
        entry_ts: created,
        entryTime: created ? new Date(created).toISOString() : undefined,
        status: p.status,
        stop_loss: p.stop_loss,
        take_profit: p.take_profit,
        trimmedPct: null,
        pnl: null,
        pnlPct,
        exitReason,
        scriptVersion: p.script_version,
        script_version: p.script_version,
        shares: Number(p.total_qty) || 0,
        created_at: p.created_at,
        updated_at: p.updated_at,
        history,
      };
    });
  } catch (err) {
    if (err && (err.message || "").includes("no such table")) return null;
    console.error("[D1 LEDGER] d1GetAllPositionsAsTrades failed:", err);
    return null;
  }
}

/** Get price from timed_trail at or closest to the given timestamp (for correct entry price from candle history). */
async function getPriceFromTrailAtTimestamp(db, ticker, tsMs) {
  if (!db || !ticker || !Number.isFinite(tsMs) || tsMs <= 0) return null;
  try {
    const row = await db
      .prepare(
        `SELECT price FROM timed_trail
         WHERE ticker = ?1 AND price IS NOT NULL AND price > 0
         ORDER BY ABS(ts - ?2) ASC
         LIMIT 1`
      )
      .bind(String(ticker).toUpperCase(), tsMs)
      .first();
    const p = Number(row?.price);
    return Number.isFinite(p) && p > 0 ? p : null;
  } catch {
    return null;
  }
}

/** Load all trades from D1 for simulation (same shape as KV). Includes shares from positions. */
async function d1LoadTradesForSimulation(env) {
  const db = env?.DB;
  if (!db) return null;
  try {
    let rows;
    try {
      const tradesRes = await db.prepare(
        `SELECT t.trade_id, t.ticker, t.direction, t.entry_ts, t.entry_price, t.rank, t.rr, t.status,
          t.exit_ts, t.exit_price, t.exit_reason, t.trimmed_pct, t.pnl, t.pnl_pct,
          t.script_version, t.created_at, t.updated_at, t.trim_ts, t.trim_price,
          COALESCE(p.total_qty, 0) AS pos_qty
         FROM trades t
         LEFT JOIN positions p ON p.position_id = t.trade_id
         ORDER BY t.entry_ts DESC`
      ).all();
      rows = Array.isArray(tradesRes?.results) ? tradesRes.results : [];
    } catch (joinErr) {
      if ((joinErr?.message || "").includes("no such table") && (joinErr?.message || "").includes("positions")) {
        const tradesRes = await db.prepare(
          `SELECT trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at, trim_ts, trim_price
           FROM trades ORDER BY entry_ts DESC`
        ).all();
        rows = (Array.isArray(tradesRes?.results) ? tradesRes.results : []).map((r) => ({ ...r, pos_qty: 0 }));
      } else throw joinErr;
    }
    if (rows.length === 0) return [];

    const tradeIds = rows.map((r) => r.trade_id).filter(Boolean);
    const placeholders = tradeIds.map(() => "?").join(",");
    const eventsRes = await db.prepare(
      `SELECT event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
       FROM trade_events WHERE trade_id IN (${placeholders}) ORDER BY trade_id, ts ASC`
    ).bind(...tradeIds).all();
    const eventRows = Array.isArray(eventsRes?.results) ? eventsRes.results : [];
    const eventsByTradeId = {};
    for (const e of eventRows) {
      const id = e.trade_id;
      if (!eventsByTradeId[id]) eventsByTradeId[id] = [];
      eventsByTradeId[id].push({
        type: e.type,
        ts: e.ts,
        timestamp: Number.isFinite(Number(e.ts)) ? new Date(Number(e.ts)).toISOString() : undefined,
        price: e.price != null ? Number(e.price) : undefined,
        trimPct: e.qty_pct_total,
        trimDeltaPct: e.qty_pct_delta,
        pnl_realized: e.pnl_realized != null ? Number(e.pnl_realized) : undefined,
        reason: e.reason || undefined,
        ...(e.meta_json ? (() => { try { return JSON.parse(e.meta_json); } catch { return {}; } })() : {}),
      });
    }

    const out = rows.map((r) => {
      const history = eventsByTradeId[r.trade_id] || [];
      const entryTs = r.entry_ts != null ? Number(r.entry_ts) : null;
      const posQty = Number(r.pos_qty) || 0;
      const trimmedPct = r.trimmed_pct != null ? Number(r.trimmed_pct) : 0;
      const shares = trimmedPct > 0 && trimmedPct < 1 && posQty > 0
        ? posQty / (1 - trimmedPct)
        : posQty;
      return {
        id: r.trade_id,
        trade_id: r.trade_id,
        ticker: String(r.ticker || "").toUpperCase(),
        direction: r.direction,
        entryPrice: r.entry_price != null ? Number(r.entry_price) : undefined,
        entry_price: r.entry_price != null ? Number(r.entry_price) : undefined,
        entry_ts: entryTs,
        entryTime: entryTs != null ? new Date(entryTs).toISOString() : undefined,
        rank: r.rank,
        rr: r.rr,
        status: r.status,
        exit_ts: r.exit_ts != null ? Number(r.exit_ts) : undefined,
        exitPrice: r.exit_price != null ? Number(r.exit_price) : undefined,
        exitReason: r.exit_reason || undefined,
        trimmedPct: r.trimmed_pct != null ? Number(r.trimmed_pct) : undefined,
        trim_ts: r.trim_ts != null ? Number(r.trim_ts) : undefined,
        trim_price: r.trim_price != null ? Number(r.trim_price) : undefined,
        pnl: r.pnl != null ? Number(r.pnl) : undefined,
        pnlPct: r.pnl_pct != null ? Number(r.pnl_pct) : undefined,
        scriptVersion: r.script_version,
        script_version: r.script_version,
        created_at: r.created_at,
        updated_at: r.updated_at,
        shares: Number.isFinite(shares) && shares > 0 ? shares : undefined,
        history,
      };
    });

    // ── Reconcile: close OPEN trades that have no matching OPEN position in D1 ──
    // This prevents phantom trades (e.g. entry failed but trade row persists)
    // from being treated as active positions throughout the system.
    try {
      const posRes = await db.prepare(
        `SELECT DISTINCT ticker FROM positions WHERE status = 'OPEN'`
      ).all();
      const posOpen = new Set((posRes?.results || []).map(r => String(r.ticker).toUpperCase()));
      const seenTicker = new Set();
      for (const t of out) {
        const sym = String(t.ticker || "").toUpperCase();
        const isOpen = t.status === "OPEN" || t.status === "TP_HIT_TRIM";
        if (!isOpen) continue;

        if (!posOpen.has(sym)) {
          const pnlVal = Number(t.pnl || t.realizedPnl || 0);
          t.status = pnlVal > 0 ? "WIN" : pnlVal < 0 ? "LOSS" : "FLAT";
          t.exitReason = t.exitReason || "reconciled_no_position";
          t.exit_ts = t.exit_ts || Date.now();
          db.prepare(
            `UPDATE trades SET status=?, exit_reason=COALESCE(exit_reason,'reconciled_no_position'), exit_ts=COALESCE(exit_ts,?), updated_at=datetime('now') WHERE trade_id=? AND status IN ('OPEN','TP_HIT_TRIM')`
          ).bind(t.status, Date.now(), t.trade_id).run().catch(() => {});
        } else if (seenTicker.has(sym)) {
          const pnlVal = Number(t.pnl || t.realizedPnl || 0);
          t.status = pnlVal > 0 ? "WIN" : pnlVal < 0 ? "LOSS" : "FLAT";
          t.exitReason = "dedup_reconcile";
          t.exit_ts = t.exit_ts || Date.now();
          if (!t.exitPrice && t.trim_price) t.exitPrice = t.trim_price;
          db.prepare(
            `UPDATE trades SET status=?, exit_reason='dedup_reconcile', exit_price=COALESCE(exit_price,?), exit_ts=COALESCE(exit_ts,?), updated_at=datetime('now') WHERE trade_id=? AND status IN ('OPEN','TP_HIT_TRIM','CLOSED')`
          ).bind(t.status, t.exitPrice || null, Date.now(), t.trade_id).run().catch(() => {});
        } else {
          seenTicker.add(sym);
        }
      }
    } catch (reconcileErr) {
      console.warn("[D1 LEDGER] trade reconciliation:", String(reconcileErr).slice(0, 100));
    }

    // Enrich open trades: fill in entry price from candle history at entry_ts
    // ONLY if the trade doesn't already have a valid entry price from the DB.
    const openTrades = out.filter((t) => (t.status === "OPEN" || !t.exit_ts) && t.entry_ts);
    for (const t of openTrades) {
      const existingEp = Number(t.entryPrice ?? t.entry_price);
      if (Number.isFinite(existingEp) && existingEp > 0) continue;
      const fromTrail = await getPriceFromTrailAtTimestamp(db, t.ticker, t.entry_ts);
      if (fromTrail != null) {
        t.entryPrice = fromTrail;
        t.entry_price = fromTrail;
      }
    }
    return out;
  } catch (err) {
    console.error("[D1 LEDGER] d1LoadTradesForSimulation failed:", err);
    return null;
  }
}

/** GET /timed/trades?source=d1 — Alias for backward compatibility. */
async function d1GetAllTradesWithEvents(env) {
  return d1LoadTradesForSimulation(env);
}

function encodeCursor(obj) {
  try {
    const s = JSON.stringify(obj);
    if (typeof btoa === "function") return btoa(s);
    // Node fallback
    return Buffer.from(s, "utf8").toString("base64");
  } catch {
    return null;
  }
}

function decodeCursor(s) {
  if (!s) return null;
  try {
    const raw =
      typeof atob === "function"
        ? atob(String(s))
        : Buffer.from(String(s), "base64").toString("utf8");
    return JSON.parse(raw);
  } catch {
    return null;
  }
}

function parseExitReasonFromText(text) {
  const s = String(text || "").toUpperCase();
  if (!s) return null;
  if (s.includes("TDSEQ") || s.includes("TD9") || s.includes("TD13"))
    return "TDSEQ";
  // Prefer explicit SL phrasing
  if (s.includes("STOP LOSS") || s.includes("STOP-LOSS")) return "SL";
  // Avoid mapping generic "SL" inside words; still helpful for legacy notes
  if (/\bSL\b/.test(s)) return "SL";
  if (s.includes("TP_FULL")) return "TP_FULL";
  if (s.includes("TAKE PROFIT")) return "TP_FULL";
  // Avoid mapping any "TP" occurrence too aggressively
  if (/\bTP\b/.test(s)) return "TP_FULL";
  return null;
}

function parseTrimPctFromText(text) {
  const s = String(text || "");
  const m = s.match(/Trimmed\s+(\d{1,3})%/i);
  if (!m) return null;
  const pct = Number(m[1]);
  if (!Number.isFinite(pct) || pct <= 0) return null;
  return Math.max(0, Math.min(1, pct / 100));
}

function inferExitReasonForLegacyTrade(trade, exitEvent) {
  const explicit =
    (exitEvent && exitEvent.reason) ||
    (trade && trade.exitReason) ||
    (trade && trade.exit_reason);
  if (explicit) return String(explicit);

  const parsed =
    parseExitReasonFromText(exitEvent?.note) ||
    parseExitReasonFromText(exitEvent?.meta_json) ||
    parseExitReasonFromText(exitEvent?.text) ||
    parseExitReasonFromText(exitEvent?.type);
  if (parsed) return parsed;

  // Heuristic fallback for legacy trades with no reason recorded
  const status = String(trade?.status || "").toUpperCase();
  if (status === "LOSS") return "SL";
  if (status === "WIN") return "TP_FULL";
  return "unknown";
}

async function d1GetNearestTrailPayload(
  db,
  ticker,
  targetTs,
  windowMs = 2 * 60 * 60 * 1000,
) {
  if (!db) return null;
  const sym = String(ticker || "").toUpperCase();
  const ts = Number(targetTs);
  if (!sym || !Number.isFinite(ts)) return null;
  const w = Math.max(60 * 1000, Number(windowMs) || 0);
  const lo = ts - w;
  const hi = ts + w;
  try {
    const row = await db
      .prepare(
        `SELECT ts, payload_json
         FROM timed_trail
         WHERE ticker = ?1 AND ts BETWEEN ?2 AND ?3 AND payload_json IS NOT NULL
         ORDER BY ABS(ts - ?4) ASC
         LIMIT 1`,
      )
      .bind(sym, lo, hi, ts)
      .first();
    if (!row || !row.payload_json) return null;
    try {
      return {
        ts: Number(row.ts),
        payload: JSON.parse(String(row.payload_json)),
      };
    } catch {
      return null;
    }
  } catch {
    return null;
  }
}

// Activity feed tracking (1 week history)
async function appendActivity(KV, event) {
  const key = "timed:activity:feed";
  const now = Date.now();
  const oneWeekAgo = now - 7 * 24 * 60 * 60 * 1000;

  const feed = (await kvGetJSON(KV, key)) || [];

  // Add new event with timestamp
  const activityEvent = {
    ...event,
    ts: now,
    id: `${event.ticker}-${now}-${Math.random().toString(36).substr(2, 9)}`,
  };

  feed.unshift(activityEvent); // Add to beginning

  // Remove events older than 1 week
  const filtered = feed.filter((e) => e.ts > oneWeekAgo);

  // Keep max 500 events
  const keep = filtered.slice(0, 500);

  await kvPutJSON(KV, key, keep);
}

// Version management and migration
const CURRENT_DATA_VERSION = "2.5.0"; // Must match SCRIPT_VERSION in Pine Script

async function getStoredVersion(KV) {
  const versionKey = "timed:data_version";
  const stored = await KV.get(versionKey);
  return stored ? stored : null;
}

async function setStoredVersion(KV, version) {
  const versionKey = "timed:data_version";
  await kvPutText(KV, versionKey, version);
}

async function checkAndMigrate(KV, incomingVersion) {
  const storedVersion = await getStoredVersion(KV);
  return checkAndMigrateWithStoredVersion(KV, storedVersion, incomingVersion);
}

async function checkAndMigrateWithStoredVersion(
  KV,
  storedVersion,
  incomingVersion,
) {
  // If no stored version, this is first run - set it and continue
  if (!storedVersion) {
    await setStoredVersion(KV, incomingVersion);
    return { migrated: false, reason: "initial_setup" };
  }

  // If versions match, no migration needed
  if (storedVersion === incomingVersion) {
    return { migrated: false, reason: "version_match" };
  }

  // Version changed - trigger migration
  console.log(
    `Version change detected: ${storedVersion} -> ${incomingVersion}`,
  );

  // Get tickers before purging (for archive)
  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];

  // Archive old data (optional - store timestamp of migration)
  const archiveKey = `timed:archive:${storedVersion}:${Date.now()}`;
  const archiveData = {
    version: storedVersion,
    migratedAt: Date.now(),
    tickerCount: tickers.length,
    tickers: tickers.slice(0, 10), // Store sample of tickers for reference
  };
  await kvPutJSON(KV, archiveKey, archiveData, 30 * 24 * 60 * 60); // Keep archive for 30 days

  // Purge old data
  const purgeResult = await purgeOldData(KV);

  // Update to new version
  await setStoredVersion(KV, incomingVersion);

  return {
    migrated: true,
    reason: "version_changed",
    oldVersion: storedVersion,
    newVersion: incomingVersion,
    archived: true,
    tickerCount: purgeResult.tickerCount,
    purged: purgeResult.purged,
  };
}

async function purgeOldData(KV) {
  // Get tickers BEFORE clearing the index
  const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
  const tickerCount = tickers.length;

  // Build all delete operations in parallel for faster execution
  const deletePromises = [];

  // Clear ticker index first (to prevent race conditions)
  deletePromises.push(KV.delete("timed:tickers"));

  // Create all delete operations for each ticker in parallel
  for (const ticker of tickers) {
    // Latest data
    deletePromises.push(KV.delete(`timed:latest:${ticker}`));
    // Trails
    deletePromises.push(KV.delete(`timed:trail:${ticker}`));
    // Momentum data (all keys)
    deletePromises.push(KV.delete(`timed:momentum:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:marketcap:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:adr:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:volume:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:changes:${ticker}`));
    deletePromises.push(KV.delete(`timed:momentum:history:${ticker}`));
    // State tracking
    deletePromises.push(KV.delete(`timed:prevstate:${ticker}`));
    // Additional state tracking keys
    deletePromises.push(KV.delete(`timed:prevcorridor:${ticker}`));
    deletePromises.push(KV.delete(`timed:prevsqueeze:${ticker}`));
    deletePromises.push(KV.delete(`timed:prevsqueezerel:${ticker}`));
    deletePromises.push(KV.delete(`timed:prevmomentumelite:${ticker}`));
  }

  // Execute all deletes in parallel (much faster than sequential)
  await Promise.all(deletePromises);

  return { purged: tickerCount, tickerCount };
}

async function ensureCaptureIndex(KV, ticker) {
  try {
    const key = "timed:capture:tickers";
    const existing = (await kvGetJSON(KV, key)) || [];
    const upper = String(ticker || "").toUpperCase();
    if (!upper) return;
    if (!existing.includes(upper)) {
      existing.push(upper);
      existing.sort();
      await kvPutJSON(KV, key, existing);
    }
  } catch (err) {
    console.error(`[CAPTURE INDEX] Failed to update index:`, err);
  }
}

// Helper: Generate natural language interpretation for trade actions
function generateTradeActionInterpretation(
  action,
  tickerData,
  trade = null,
  trimPct = null,
) {
  const ticker = tickerData.ticker || "UNKNOWN";
  const direction =
    trade?.direction ||
    (tickerData.state?.includes("BULL")
      ? "LONG"
      : tickerData.state?.includes("BEAR")
        ? "SHORT"
        : null);
  const state = tickerData.state || "";
  const flags = tickerData.flags || {};
  const htfScore = Number(tickerData.htf_score || 0);
  const ltfScore = Number(tickerData.ltf_score || 0);
  const completion = Number(tickerData.completion || 0);
  const phase = Number(tickerData.phase_pct || 0);
  const rr = Number(tickerData.rr || trade?.rr || 0);
  const rank = Number(tickerData.rank || trade?.rank || 0);
  const sqRel = !!flags.sq30_release;
  const sqOn = !!flags.sq30_on;
  const momentumElite = !!flags.momentum_elite;
  const tdSeq = tickerData.td_sequential || {};
  const rsi = tickerData.rsi || {};
  const fourHEMACloud = tickerData.fourh_ema_cloud || {};

  let reasons = [];
  let actionText = "";

  if (action === "ENTRY") {
    actionText = `**Entering a ${direction} position** because:`;

    // State-based reasons
    if (state === "HTF_BULL_LTF_BULL") {
      reasons.push(
        "✅ **HTF and LTF are both bullish** - Strong alignment in favor of upward movement",
      );
    } else if (state === "HTF_BEAR_LTF_BEAR") {
      reasons.push(
        "✅ **HTF and LTF are both bearish** - Strong alignment in favor of downward movement",
      );
    } else if (state === "HTF_BULL_LTF_PULLBACK") {
      reasons.push(
        "✅ **HTF bullish with LTF pullback** - Prime setup for long entry on pullback",
      );
    } else if (state === "HTF_BEAR_LTF_PULLBACK") {
      reasons.push(
        "✅ **HTF bearish with LTF pullback** - Prime setup for short entry on pullback",
      );
    }

    // Score-based reasons
    if (htfScore >= 25) {
      reasons.push(
        `📈 **Strong HTF score (${htfScore.toFixed(
          1,
        )})** - High timeframe momentum is very favorable`,
      );
    } else if (htfScore >= 15) {
      reasons.push(
        `📈 **Good HTF score (${htfScore.toFixed(
          1,
        )})** - High timeframe momentum is favorable`,
      );
    }

    if (ltfScore >= 20) {
      reasons.push(
        `📊 **Strong LTF score (${ltfScore.toFixed(
          1,
        )})** - Low timeframe momentum is very favorable`,
      );
    } else if (ltfScore >= 12) {
      reasons.push(
        `📊 **Good LTF score (${ltfScore.toFixed(
          1,
        )})** - Low timeframe momentum is favorable`,
      );
    }

    // Squeeze reasons
    if (sqRel) {
      reasons.push(
        "🚀 **Squeeze release detected** - Momentum breakout from compression, strong directional move expected",
      );
    } else if (sqOn) {
      reasons.push(
        "💥 **In squeeze** - Building energy for potential explosive move",
      );
    }

    // Completion reasons
    if (completion <= 0.2) {
      reasons.push(
        `🎯 **Early in move (${(completion * 100).toFixed(
          0,
        )}% complete)** - Plenty of room to run`,
      );
    } else if (completion <= 0.4) {
      reasons.push(
        `🎯 **Good entry timing (${(completion * 100).toFixed(
          0,
        )}% complete)** - Still early in the move`,
      );
    }

    // Phase reasons
    if (phase <= 0.3) {
      reasons.push(
        `⚡ **Early phase (${(phase * 100).toFixed(
          0,
        )}%)** - Strong momentum building`,
      );
    }

    // RR reasons
    if (rr >= 2.0) {
      reasons.push(
        `💰 **Excellent Risk/Reward (${rr.toFixed(
          2,
        )}:1)** - High potential reward relative to risk`,
      );
    } else if (rr >= 1.5) {
      reasons.push(
        `💰 **Good Risk/Reward (${rr.toFixed(
          2,
        )}:1)** - Favorable reward relative to risk`,
      );
    }

    // Rank reasons
    if (rank >= 80) {
      reasons.push(
        `⭐ **Top-ranked setup (Rank: ${rank})** - One of the best opportunities in the watchlist`,
      );
    } else if (rank >= 70) {
      reasons.push(
        `⭐ **High-ranked setup (Rank: ${rank})** - Strong opportunity`,
      );
    }

    // Momentum Elite
    if (momentumElite) {
      reasons.push(
        "🚀 **Momentum Elite** - High-quality momentum stock with strong fundamentals",
      );
    }

    // TD Sequential
    if (tdSeq.td9_bullish && direction === "LONG") {
      reasons.push(
        "🔢 **TD9 Bullish signal** - DeMark exhaustion pattern suggests upward reversal",
      );
    } else if (tdSeq.td9_bearish && direction === "SHORT") {
      reasons.push(
        "🔢 **TD9 Bearish signal** - DeMark exhaustion pattern suggests downward reversal",
      );
    }

    // RSI Divergence
    if (rsi.divergence?.type === "bullish" && direction === "LONG") {
      reasons.push(
        "📊 **RSI Bullish Divergence** - Price making lower lows while RSI makes higher lows, suggesting upward reversal",
      );
    } else if (rsi.divergence?.type === "bearish" && direction === "SHORT") {
      reasons.push(
        "📊 **RSI Bearish Divergence** - Price making higher highs while RSI makes lower highs, suggesting downward reversal",
      );
    }

    // EMA Cloud position
    if (fourHEMACloud.position === "above" && direction === "LONG") {
      reasons.push(
        "☁️ **Price above 4H EMA cloud** - Strong trend continuation signal",
      );
    } else if (fourHEMACloud.position === "below" && direction === "SHORT") {
      reasons.push(
        "☁️ **Price below 4H EMA cloud** - Strong trend continuation signal",
      );
    }
  } else if (action === "TRIM") {
    const trimPercent = Math.round((trimPct || 0.5) * 100);
    actionText = `**Trimming ${trimPercent}%** because:`;

    reasons.push(
      `🎯 **Take Profit level hit** - Price reached TP target, locking in ${trimPercent}% of profits`,
    );

    if (trimPct === 0.25) {
      reasons.push(
        "📈 **First trim (25%)** - Securing initial profits while letting the rest run",
      );
    } else if (trimPct === 0.5) {
      reasons.push(
        "📈 **Second trim (50%)** - Locking in half the position, remaining 50% continues to run",
      );
    } else if (trimPct === 0.75) {
      reasons.push(
        "📈 **Third trim (75%)** - Securing most profits, trailing stop on remaining 25%",
      );
    }

    // EMA Cloud position for hold decision
    if (fourHEMACloud.position === "above" && direction === "LONG") {
      reasons.push(
        "☁️ **Price still above 4H EMA cloud** - Trend intact, holding remaining position",
      );
    } else if (fourHEMACloud.position === "below" && direction === "SHORT") {
      reasons.push(
        "☁️ **Price still below 4H EMA cloud** - Trend intact, holding remaining position",
      );
    }
  } else if (action === "CLOSE") {
    // Simplified: the embed now handles exit reason and P&L display directly.
    // This function just provides the "why" context.
    const exitReason = trade?.exitReason || null;
    actionText = `**Closing position**`;

    if (exitReason === "TDSEQ") {
      reasons.push("TD Sequential exhaustion detected");
    } else if (exitReason === "SL" || exitReason === "sl_breached") {
      reasons.push("Stop loss triggered");
    } else if (exitReason === "TP_FULL") {
      reasons.push("All take profit levels achieved");
    } else if (exitReason === "max_loss") {
      reasons.push("Max loss threshold reached");
    }
  }

  // If no reasons found, add generic ones
  if (reasons.length === 0) {
    reasons.push(
      "📊 **System signal detected** - Automated trade management triggered",
    );
  }

  return {
    action: actionText,
    reasons: reasons.join("\n"),
  };
}

// Helper: Create Discord embed for trade entry
function createTradeEntryEmbed(
  ticker,
  direction,
  entryPrice,
  sl,
  tp,
  rr,
  rank,
  state,
  currentPrice = null,
  isBackfill = false,
  tickerData = null,
  execution = null, // { qty, value, pnl } for verifiable history
) {
  const isLong = direction === "LONG";
  const color = isLong ? 0x22c55e : 0xef4444;
  const dirLabel = isLong ? "LONG" : "SHORT";

  // Human-readable description
  const rrLabel = Number.isFinite(rr) && rr > 0 ? ` with a ${rr.toFixed(1)}:1 risk-to-reward ratio` : "";
  const description = `Opened a **${dirLabel.toLowerCase()}** position at **$${entryPrice.toFixed(2)}**${rrLabel}.`;

  const fields = [];

  // 1. Trade Summary — clean key-value layout
  const summaryLines = [
    `Entry:  **$${entryPrice.toFixed(2)}**`,
    `Stop Loss:  **$${sl.toFixed(2)}**`,
    `Take Profit:  **$${tp.toFixed(2)}**`,
  ];
  if (execution && Number.isFinite(execution.qty)) {
    summaryLines.push(`Qty:  **${execution.qty.toFixed(4)}**  |  Value:  **$${Number(execution.value || 0).toFixed(2)}**`);
  }
  fields.push({ name: "Trade Details", value: summaryLines.join("\n"), inline: false });

  // 2. Signal Quality — translated to plain English
  const qualParts = [];
  if (Number.isFinite(rank) && rank > 0) qualParts.push(`Signal Strength: **${rank}**/100`);
  if (Number.isFinite(rr) && rr > 0) qualParts.push(`Risk/Reward: **${rr.toFixed(1)}:1**`);
  // Active signals in plain language
  const sigs = [];
  if (tickerData?.flags?.momentum_elite) sigs.push("Strong Momentum");
  if (tickerData?.flags?.sq30_release) sigs.push("Squeeze Breakout");
  else if (tickerData?.flags?.sq30_on) sigs.push("Compression Building");
  if (tickerData?.td_sequential) {
    if (tickerData.td_sequential.td9_bullish || tickerData.td_sequential.td9_bearish) sigs.push("Exhaustion Signal (TD9)");
    if (tickerData.td_sequential.td13_bullish || tickerData.td_sequential.td13_bearish) sigs.push("Extended Exhaustion (TD13)");
  }
  if (sigs.length > 0) qualParts.push(`Signals: ${sigs.join(", ")}`);
  if (qualParts.length > 0) {
    fields.push({ name: "Signal Quality", value: qualParts.join("\n"), inline: false });
  }

  return {
    title: `${isLong ? "🟢" : "🔴"}  New Trade: ${ticker} ${dirLabel}${isBackfill ? " (backfill)" : ""}`,
    description,
    color,
    fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Timed Trading Simulator" },
  };
}

// Helper: Create Discord embed for trade trimmed
function createTradeTrimmedEmbed(
  ticker,
  direction,
  entryPrice,
  currentPrice,
  tp,
  pnl,
  pnlPct,
  trimmedPct = 0.5,
  tickerData = null,
  trade = null,
  trimDeltaPct = null,
  execution = null, // { qty, value, pnl } for verifiable history
) {
  const trimPercent = Math.round(trimmedPct * 100);
  const remainingPct = Math.round((1 - trimmedPct) * 100);
  const stepPct = Number.isFinite(trimDeltaPct) ? Math.round(trimDeltaPct * 100) : null;
  const isLong = direction === "LONG";

  // Next TP level
  const nextTp = (trade?.tpArray && Array.isArray(trade.tpArray))
    ? [...trade.tpArray]
        .map(x => ({ price: Number(x?.price), trimPct: Number(x?.trimPct), label: x?.label }))
        .filter(x => Number.isFinite(x.price) && Number.isFinite(x.trimPct))
        .sort((a, b) => a.trimPct - b.trimPct)
        .find(x => x.trimPct > trimmedPct + 1e-6) || null
    : null;

  // Human-readable description
  const pnlLabel = pnl >= 0 ? `+$${pnl.toFixed(2)}` : `-$${Math.abs(pnl).toFixed(2)}`;
  const pctLabel = `${pnlPct >= 0 ? "+" : ""}${pnlPct.toFixed(2)}%`;
  const stepLabel = stepPct ? `${stepPct}%` : `${trimPercent}%`;
  const description = pnl >= 0
    ? `Locked in **${pnlLabel}** (${pctLabel}) by trimming **${stepLabel}** of the position. **${remainingPct}%** still running.`
    : `Reduced exposure by trimming **${stepLabel}** of the position at **${pnlLabel}** (${pctLabel}). **${remainingPct}%** still running.`;

  const fields = [];

  // 1. Position & P&L
  const posLines = [
    `Entry:  **$${entryPrice.toFixed(2)}**  |  Current:  **$${currentPrice.toFixed(2)}**`,
    `P&L:  **${pnlLabel}** (${pctLabel})`,
  ];
  if (execution && Number.isFinite(execution.qty)) {
    posLines.push(`Qty trimmed:  **${Number(execution.qty).toFixed(4)}**  |  Value:  **$${Number(execution.value || 0).toFixed(2)}**`);
  }
  fields.push({ name: "Position & P&L", value: posLines.join("\n"), inline: false });

  // 2. Trim Status
  const statusLines = [`Trimmed:  **${trimPercent}%**  |  Remaining:  **${remainingPct}%**`];
  if (nextTp) {
    statusLines.push(`Next target:  **$${nextTp.price.toFixed(2)}** (${nextTp.label || "next tier"})`);
  }
  fields.push({ name: "Trim Status", value: statusLines.join("\n"), inline: false });

  // Use accurate title based on actual P&L (don't say "Taking Profit" when P&L is negative)
  const isProfit = pnl >= 0;
  const titleEmoji = isProfit ? "💰" : "✂️";
  const titleAction = isProfit ? "Taking Profit" : "Trimming Position";

  return {
    title: `${titleEmoji}  ${titleAction}: ${ticker} ${direction} — ${stepLabel}`,
    description,
    color: isProfit ? 0xf59e0b : 0xef4444,
    fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Timed Trading Simulator" },
  };
}

// Helper: Create Discord embed for trade closed
function createTradeClosedEmbed(
  ticker,
  direction,
  status,
  entryPrice,
  exitPrice,
  pnl,
  pnlPct,
  rank,
  rr,
  tickerData = null,
  trade = null,
  execution = null, // { qty, value, pnl } for verifiable history
) {
  const isWin = status === "WIN";
  const isFlat = status === "FLAT";
  const color = isWin ? 0x22c55e : isFlat ? 0x6b7280 : 0xef4444;

  // Always compute P&L% from prices (fixes 0.00% bug when trade.pnlPct not set)
  const computedPnlPct = Number.isFinite(entryPrice) && entryPrice > 0
    ? ((exitPrice - entryPrice) / entryPrice) * 100
    : Number(pnlPct) || 0;
  const finalPnlPct = Math.abs(computedPnlPct) > 0.001 ? computedPnlPct : (Number(pnlPct) || 0);
  const dirMultiplier = direction === "SHORT" ? -1 : 1;
  const adjPnlPct = finalPnlPct * (direction === "SHORT" && finalPnlPct !== 0 && computedPnlPct !== 0 ? 1 : 1);

  // Map exit reason to human-readable text
  const exitReason = trade?.exitReason || null;
  const exitReasonMap = {
    sl_breached: "Hit the stop loss",
    SL: "Hit the stop loss",
    "sl breached": "Hit the stop loss",
    TDSEQ: "Exhaustion signal triggered exit",
    TP_FULL: "All profit targets reached",
    max_loss: "Maximum loss threshold reached",
    critical: "Trade thesis invalidated",
    HARD_FUSE_RSI_EXTREME: "RSI reached extreme levels",
    SOFT_FUSE_RSI_CONFIRMED: "RSI reversal confirmed",
    "tp reached": "Profit target reached",
    below_trigger: "Dropped below entry trigger",
  };
  const rawReason = exitReason || "";
  const humanExitReason = exitReasonMap[rawReason]
    || (rawReason.includes("sl") || rawReason.includes("SL") ? "Hit the stop loss" : null)
    || (rawReason.includes("tp") || rawReason.includes("TP") ? "Profit target reached" : null)
    || (rawReason ? rawReason.replace(/_/g, " ").replace(/,/g, ", ") : null);

  // Build human-readable description
  const pnlLabel = pnl >= 0 ? `+$${pnl.toFixed(2)}` : `-$${Math.abs(pnl).toFixed(2)}`;
  const pctLabel = `${finalPnlPct >= 0 ? "+" : ""}${finalPnlPct.toFixed(2)}%`;
  let description;
  if (isWin) {
    description = `Closed with **${pnlLabel}** profit (${pctLabel}).${humanExitReason ? " " + humanExitReason + "." : ""}`;
  } else if (isFlat) {
    description = `Closed flat at **$${exitPrice.toFixed(2)}**. No meaningful price movement.`;
  } else {
    description = `Closed with **${pnlLabel}** loss (${pctLabel}).${humanExitReason ? " " + humanExitReason + "." : ""}`;
  }

  const fields = [];

  // 1. Trade Summary
  const summaryLines = [
    `Entry:  **$${entryPrice.toFixed(2)}**  |  Exit:  **$${exitPrice.toFixed(2)}**`,
    `P&L:  **${pnlLabel}** (${pctLabel})`,
  ];
  if (execution && Number.isFinite(execution.qty)) {
    summaryLines.push(`Qty:  **${Number(execution.qty).toFixed(4)}**  |  Value:  **$${Number(execution.value || 0).toFixed(2)}**`);
  }
  fields.push({ name: "Trade Summary", value: summaryLines.join("\n"), inline: false });

  // 2. Exit Reason
  if (humanExitReason) {
    fields.push({ name: "Exit Reason", value: humanExitReason, inline: true });
  }

  // 3. Price Movement
  const priceChange = exitPrice - entryPrice;
  fields.push({
    name: "Price Movement",
    value: `**${priceChange >= 0 ? "+" : ""}$${priceChange.toFixed(2)}** (${pctLabel})`,
    inline: true,
  });

  // Choose title based on outcome
  let title;
  if (isWin) {
    title = `🏆  Winner: ${ticker} ${direction}  —  ${pctLabel}`;
  } else if (isFlat) {
    title = `➖  Flat: ${ticker} ${direction}  —  $0.00`;
  } else {
    title = `🛑  Stopped Out: ${ticker} ${direction}  —  ${pctLabel}`;
  }

  return {
    title,
    description,
    color,
    fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Timed Trading Simulator" },
  };
}

// [DEPRECATED] createTD9ExitEmbed — TD exit context now folded into createTradeClosedEmbed
// [DEPRECATED] createTDSeqDefenseEmbed — TD defense context now folded into createKanbanStageEmbed (defend stage)

// Helper: Create Discord embed for Kanban stage transition
function createKanbanStageEmbed(ticker, stage, prevStage, tickerData = null, openTrade = null) {
  const direction =
    tickerData?.state?.includes("BULL") ? "LONG"
    : tickerData?.state?.includes("BEAR") ? "SHORT"
    : openTrade?.direction || null;
  const price = Number(tickerData?.price);
  const rr = Number(tickerData?.rr);
  const rank = Number(tickerData?.rank ?? tickerData?.score);
  const dirLabel = direction || "";

  // Stage config: emoji, label, color, human description
  const stageConfig = {
    enter:     { emoji: "🎯", label: "Entry Signal",      color: 0x22c55e, verb: "is ready for entry" },
    enter_now: { emoji: "🎯", label: "Entry Signal",      color: 0x22c55e, verb: "is ready for entry" },
    hold:      { emoji: "📌", label: "Holding",            color: 0x3b82f6, verb: "is being held" },
    defend:    { emoji: "🛡️", label: "Defending Position", color: 0xf59e0b, verb: "needs attention — tightening stops" },
    trim:      { emoji: "✂️", label: "Taking Profit",      color: 0x8b5cf6, verb: "is approaching profit targets" },
    exit:      { emoji: "🚪", label: "Exiting Position",   color: 0xef4444, verb: "is signaling an exit" },
  };
  const cfg = stageConfig[stage] || { emoji: "📋", label: stage, color: 0x6b7280, verb: "changed stage" };

  // Human-readable description
  const priceStr = Number.isFinite(price) && price > 0 ? ` at **$${price.toFixed(2)}**` : "";
  const dirStr = direction ? ` (${direction})` : "";
  const description = `**${ticker}**${dirStr}${priceStr} — ${cfg.verb}.`;

  const fields = [];

  // ENTER: signal quality in plain language
  if (stage === "enter" || stage === "enter_now") {
    const entryLines = [];
    if (Number.isFinite(rr) && rr > 0) entryLines.push(`Risk/Reward:  **${rr.toFixed(1)}:1**`);
    if (Number.isFinite(rank) && rank > 0) entryLines.push(`Signal Strength:  **${rank}**/100`);
    if (entryLines.length > 0) {
      fields.push({ name: "Entry Signal", value: entryLines.join("\n"), inline: false });
    }
    // Signals in plain language
    const sigs = [];
    if (tickerData?.flags?.momentum_elite) sigs.push("Strong Momentum");
    if (tickerData?.flags?.sq30_release) sigs.push("Squeeze Breakout");
    if (tickerData?.td_sequential) {
      if (tickerData.td_sequential.td9_bullish || tickerData.td_sequential.td9_bearish) sigs.push("Exhaustion Count (TD9)");
    }
    if (sigs.length > 0) {
      fields.push({ name: "Active Signals", value: sigs.join("  |  "), inline: false });
    }
    if (ticker) {
      fields.push({
        name: "Chart",
        value: `[View on TradingView](https://www.tradingview.com/chart/?symbol=${encodeURIComponent(ticker)})`,
        inline: true,
      });
    }
  }

  // DEFEND: position context with clear language
  if (stage === "defend" && openTrade) {
    const entryPx = Number(openTrade.entryPrice);
    const pnlPct = Number.isFinite(entryPx) && entryPx > 0 && Number.isFinite(price)
      ? ((price - entryPx) / entryPx * 100 * (openTrade.direction === "SHORT" ? -1 : 1))
      : null;
    const defendLines = [];
    if (Number.isFinite(pnlPct)) defendLines.push(`Current P&L:  **${pnlPct >= 0 ? "+" : ""}${pnlPct.toFixed(2)}%**`);
    if (Number.isFinite(entryPx)) defendLines.push(`Entry:  **$${entryPx.toFixed(2)}**`);
    const sl = Number(openTrade.sl);
    if (Number.isFinite(sl)) defendLines.push(`Stop Loss:  **$${sl.toFixed(2)}**`);
    if (defendLines.length > 0) {
      fields.push({ name: "Position", value: defendLines.join("\n"), inline: false });
    }
  }

  // TRIM/EXIT: P&L context
  if ((stage === "trim" || stage === "exit") && openTrade) {
    const entryPx = Number(openTrade.entryPrice);
    const pnlPct = Number.isFinite(entryPx) && entryPx > 0 && Number.isFinite(price)
      ? ((price - entryPx) / entryPx * 100 * (openTrade.direction === "SHORT" ? -1 : 1))
      : null;
    const posLines = [];
    if (Number.isFinite(pnlPct)) posLines.push(`Current P&L:  **${pnlPct >= 0 ? "+" : ""}${pnlPct.toFixed(2)}%**`);
    if (Number.isFinite(entryPx)) posLines.push(`Entry:  **$${entryPx.toFixed(2)}**`);
    const trimmedPct = Number(openTrade.trimmedPct);
    if (Number.isFinite(trimmedPct) && trimmedPct > 0) posLines.push(`Already Trimmed:  **${Math.round(trimmedPct * 100)}%**`);
    if (posLines.length > 0) {
      fields.push({ name: "Position", value: posLines.join("\n"), inline: false });
    }
  }

  return {
    title: `${cfg.emoji}  ${cfg.label}: ${ticker}`,
    description,
    color: cfg.color,
    fields,
    timestamp: new Date().toISOString(),
    footer: { text: "Timed Trading Simulator" },
  };
}

// [DEPRECATED] createTD9EntryEmbed — TD entry context now folded into createKanbanStageEmbed (enter stage)
// [DEPRECATED] createFlipWatchEmbed — Flip watch now routes to "setup" kanban stage

// ─────────────────────────────────────────────────────────────
// Sector Mapping & Ratings
// ─────────────────────────────────────────────────────────────

const SECTOR_MAP = {
  // Consumer Discretionary
  AMZN: "Consumer Discretionary",
  TSLA: "Consumer Discretionary",
  NKE: "Consumer Discretionary",
  TJX: "Consumer Discretionary",
  BABA: "Consumer Discretionary",
  EXPE: "Consumer Discretionary",
  RBLX: "Consumer Discretionary",
  ULTA: "Consumer Discretionary",
  APP: "Consumer Discretionary",
  // Industrials
  CAT: "Industrials",
  GE: "Industrials",
  BA: "Industrials",
  EMR: "Industrials",
  ETN: "Industrials",
  DE: "Industrials",
  PH: "Industrials",
  CSX: "Industrials",
  HII: "Industrials",
  GEV: "Industrials",
  TT: "Industrials",
  PWR: "Industrials",
  AWI: "Industrials",
  WTS: "Industrials",
  DY: "Industrials",
  FIX: "Industrials",
  ITT: "Industrials",
  STRL: "Industrials",
  JCI: "Industrials",
  IBP: "Industrials",
  DCI: "Industrials",
  EME: "Industrials",
  IESC: "Industrials",
  BWXT: "Industrials",
  BE: "Industrials",
  JOBY: "Industrials",
  AVAV: "Industrials",
  // Information Technology
  AAPL: "Information Technology",
  MSFT: "Information Technology",
  NVDA: "Information Technology",
  AVGO: "Information Technology",
  AMD: "Information Technology",
  ORCL: "Information Technology",
  CSCO: "Information Technology",
  LRCX: "Information Technology",
  KLAC: "Information Technology",
  ANET: "Information Technology",
  CDNS: "Information Technology",
  CRWD: "Information Technology",
  PANW: "Information Technology",
  PLTR: "Information Technology",
  MDB: "Information Technology",
  PATH: "Information Technology",
  QLYS: "Information Technology",
  PEGA: "Information Technology",
  IOT: "Information Technology",
  PSTG: "Information Technology",
  MU: "Information Technology",
  APLD: "Information Technology",
  CLS: "Information Technology",
  CRS: "Information Technology",
  SANM: "Information Technology",
  IONQ: "Information Technology",
  LITE: "Information Technology",
  ON: "Information Technology",
  KTOS: "Information Technology",
  STX: "Information Technology",
  PI: "Information Technology",
  // Communication Services
  META: "Communication Services",
  GOOGL: "Communication Services",
  NFLX: "Communication Services",
  TWLO: "Communication Services",
  RDDT: "Communication Services",
  // Basic Materials
  ALB: "Basic Materials",
  MP: "Basic Materials",
  NEU: "Basic Materials",
  AU: "Basic Materials",
  CCJ: "Basic Materials",
  RGLD: "Basic Materials",
  SN: "Basic Materials",
  // Energy
  VST: "Energy",
  FSLR: "Energy",
  TLN: "Energy",
  WFRD: "Energy",
  ENS: "Energy",
  // Financials
  JPM: "Financials",
  GS: "Financials",
  AXP: "Financials",
  AXON: "Industrials",
  SPGI: "Financials",
  PNC: "Financials",
  BK: "Financials",
  ALLY: "Financials",
  EWBC: "Financials",
  WAL: "Financials",
  SOFI: "Financials",
  HOOD: "Financials",
  MTB: "Financials",
  // Consumer Staples
  KO: "Consumer Staples",
  WMT: "Consumer Staples",
  COST: "Consumer Staples",
  MNST: "Consumer Staples",
  // Health Care
  AMGN: "Health Care",
  GILD: "Health Care",
  UTHR: "Health Care",
  HIMS: "Health Care",
  NBIS: "Health Care",
  // ETFs & Index Tracking
  QQQ: "ETF",
  SPY: "ETF",
  IWM: "ETF",
  XLB: "ETF",
  XLC: "ETF",
  XLE: "ETF",
  XLF: "ETF",
  XLI: "ETF",
  XLK: "ETF",
  XLP: "ETF",
  XLRE: "ETF",
  XLU: "ETF",
  XLV: "ETF",
  XLY: "ETF",
  AAPU: "ETF",
  // Crypto-Related
  BTCUSD: "Crypto",
  ETHUSD: "Crypto",
  GLXY: "Crypto",
  RIOT: "Crypto",
  ETHA: "Crypto",
  // Precious Metals (GC1!/SI1! are the canonical TV continuous contract symbols)
  // Growth / Momentum
  MSTR: "Information Technology",
  RKLB: "Aerospace & Defense",
  MLI: "Industrials",
  MTZ: "Industrials",
  NXT: "Industrials",
  SGI: "Industrials",
  AYI: "Industrials",
  COIN: "Financials",
  // Futures (TradingView sourced)
  "ES1!": "Futures",
  "NQ1!": "Futures",
  "GC1!": "Futures",
  "SI1!": "Futures",
  "VX1!": "Futures",
  US500: "Futures",
  // Additional tracked tickers
  "BRK-B": "Financials",
  // ── Added tickers (previously watchlist-only, now in SECTOR_MAP for scoring + pricing) ──
  // Health Care
  ABT: "Health Care",
  LLY: "Health Care",
  UNH: "Health Care",
  LMND: "Financials",
  // Information Technology
  ARM: "Information Technology",
  CRM: "Information Technology",
  INTC: "Information Technology",
  INTU: "Information Technology",
  SHOP: "Information Technology",
  SNDK: "Information Technology",
  TSM: "Information Technology",
  WDC: "Information Technology",
  HUBS: "Information Technology",
  IREN: "Information Technology",
  CRWV: "Information Technology",
  U: "Information Technology",
  TEM: "Information Technology",
  // Consumer Discretionary
  CVNA: "Consumer Discretionary",
  DKNG: "Consumer Discretionary",
  JD: "Consumer Discretionary",
  LULU: "Consumer Discretionary",
  MCD: "Consumer Staples",
  CELH: "Consumer Staples",
  SPOT: "Communication Services",
  // Industrials
  FDX: "Industrials",
  RTX: "Industrials",
  UNP: "Industrials",
  UPS: "Industrials",
  WM: "Industrials",
  SWK: "Industrials",
  // Aerospace & Defense
  ASTS: "Aerospace & Defense",
  // Financials
  XYZ: "Financials",
  SBET: "Financials",
  // Energy
  CVX: "Energy",
  XOM: "Energy",
  UUUU: "Energy",
  // Basic Materials / Mining
  B: "Basic Materials",
  HL: "Basic Materials",
  AGYS: "Information Technology",
  AEHR: "Information Technology",
  // Crypto-Related
  BMNR: "Crypto",
  // ETFs
  AGQ: "ETF",
  GDX: "ETF",
  IAU: "ETF",
  SLV: "ETF",
  SOXL: "ETF",
  TNA: "ETF",
  GRNY: "ETF",
  KWEB: "ETF",
  ETHT: "ETF",
  XHB: "ETF",
  DIA: "ETF",
  GOLD: "Basic Materials",
  // Indices
  SPX: "Index",
  // Commodities (Futures)
  "CL1!": "Energy",
};

// Sector Ratings — as of Feb 13, 2026 (S&P Index Weight vs FSI Weight)
const SECTOR_RATINGS = {
  Healthcare:                { rating: "overweight",  boost: 5,  spWeight: 8.2,  fsiWeight: 10.1, delta: 1.9  },
  "Information Technology":  { rating: "overweight",  boost: 3,  spWeight: 26.7, fsiWeight: 27.1, delta: 0.4  },
  Energy:                    { rating: "overweight",  boost: 5,  spWeight: 2.8,  fsiWeight: 5.1,  delta: 2.3  },
  Financials:                { rating: "overweight",  boost: 3,  spWeight: 10.8, fsiWeight: 11.4, delta: 0.6  },
  Industrials:               { rating: "overweight",  boost: 5,  spWeight: 7.5,  fsiWeight: 9.8,  delta: 2.3  },
  Utilities:                 { rating: "neutral",     boost: 0,  spWeight: 1.9,  fsiWeight: 1.9,  delta: 0.0  },
  "Communication Services":  { rating: "neutral",     boost: 0,  spWeight: 8.4,  fsiWeight: 8.4,  delta: 0.0  },
  "Basic Materials":         { rating: "neutral",     boost: 0,  spWeight: 1.7,  fsiWeight: 1.7,  delta: 0.0  },
  "Consumer Discretionary":  { rating: "underweight", boost: -3, spWeight: 9.3,  fsiWeight: 7.3,  delta: -2.0 },
  "Consumer Staples":        { rating: "underweight", boost: -5, spWeight: 5.1,  fsiWeight: 3.0,  delta: -2.1 },
  "Real Estate":             { rating: "underweight", boost: -3, spWeight: 1.6,  fsiWeight: 0.0,  delta: -1.6 },
};

function getSector(ticker) {
  return SECTOR_MAP[ticker?.toUpperCase()] || null;
}

// Load sector mappings from KV (called on startup)
async function loadSectorMappingsFromKV(KV) {
  try {
    if (!KV) {
      console.log(
        `[SECTOR LOAD] KV not available, skipping sector mapping load`,
      );
      return;
    }
    // Get all tickers from watchlist
    const tickersList = await KV.get("timed:tickers", "json");
    if (!tickersList || !Array.isArray(tickersList)) {
      console.log(`[SECTOR LOAD] No tickers list found in KV, skipping`);
      return;
    }

    // Respect the persistent removal blocklist
    const removedList = await KV.get("timed:removed", "json");
    const removedSet = new Set(Array.isArray(removedList) ? removedList : []);

    let loadedCount = 0;
    // Only read KV for tickers NOT already in the hardcoded SECTOR_MAP (much faster)
    const tickersToLoad = tickersList.filter(ticker => {
      const tickerUpper = String(ticker).toUpperCase();
      return !removedSet.has(tickerUpper) && !SECTOR_MAP[tickerUpper];
    });
    // Parallel batch reads (up to 20 at a time) for speed
    const BATCH = 20;
    for (let i = 0; i < tickersToLoad.length; i += BATCH) {
      const batch = tickersToLoad.slice(i, i + BATCH);
      const results = await Promise.all(batch.map(async (ticker) => {
        const tickerUpper = String(ticker).toUpperCase();
        const sector = await KV.get(`timed:sector_map:${tickerUpper}`, "text");
        return { tickerUpper, sector };
      }));
      for (const { tickerUpper, sector } of results) {
        if (sector && sector.trim() !== "") {
          SECTOR_MAP[tickerUpper] = sector.trim();
          loadedCount++;
        } else {
          // Ticker is in watchlist but has no sector mapping — add as Unknown
          SECTOR_MAP[tickerUpper] = "Unknown";
          loadedCount++;
        }
      }
    }

    if (loadedCount > 0) {
      console.log(
        `[SECTOR LOAD] Loaded ${loadedCount} sector mappings from KV (${removedSet.size} blocklisted)`,
      );
    }
  } catch (err) {
    console.error(`[SECTOR LOAD] Error loading sector mappings:`, err);
  }
}

function getSectorRating(sector) {
  return SECTOR_RATINGS[sector] || { rating: "neutral", boost: 0 };
}

function getTickersInSector(sector) {
  return Object.keys(SECTOR_MAP).filter(
    (ticker) => SECTOR_MAP[ticker] === sector,
  );
}

// ═══════════════════════════════════════════════════════════════════════════
// SECTOR ALIGNMENT: Measures HTF consensus across all tickers in a sector.
// When multiple tickers in the same sector are HTF aligned, entries in that
// sector have higher conviction and positions deserve more patience.
//
// REAL WORLD VALIDATION (2/5/26): NVDA, AVGO, TSM all flagged LONG at open.
// They dipped initially but recovered strongly because the ENTIRE semiconductor
// sector was HTF bullish (SOXL +28.77, LRCX +27.35, ON +25.26, TSM +24.46,
// INTC +22.59, KLAC +17.48). Sector alignment predicted the recovery.
// ═══════════════════════════════════════════════════════════════════════════

// In-memory cache: { [sector]: { bullCount, bearCount, totalWithData, avgHTF, ts } }
const _sectorAlignmentCache = {};
const SECTOR_ALIGNMENT_TTL_MS = 5 * 60 * 1000; // 5 minute cache

/**
 * Compute sector alignment from latest KV data for all tickers in the sector.
 * Returns: { aligned: bool, direction: "BULL"|"BEAR"|null, strength: 0-100,
 *            bullCount, bearCount, totalWithData, avgHTF, tickers: [...] }
 */
async function computeSectorAlignment(KV, ticker) {
  const sector = getSector(ticker);
  if (!sector) return null;

  // Check cache
  const cached = _sectorAlignmentCache[sector];
  if (cached && Date.now() - cached.ts < SECTOR_ALIGNMENT_TTL_MS) {
    return cached;
  }

  const sectorTickers = getTickersInSector(sector);
  if (sectorTickers.length < 2) return null;

  let bullCount = 0;
  let bearCount = 0;
  let totalWithData = 0;
  let htfSum = 0;
  const tickerDetails = [];

  // Batch read latest data for all sector tickers
  const promises = sectorTickers.map(async (t) => {
    try {
      const data = await kvGetJSON(KV, `timed:latest:${t}`);
      if (!data || data.htf_score == null) return null;
      return { ticker: t, htf: Number(data.htf_score), state: data.state };
    } catch { return null; }
  });
  const results = await Promise.all(promises);

  for (const r of results) {
    if (!r || !Number.isFinite(r.htf)) continue;
    totalWithData++;
    htfSum += r.htf;
    if (r.htf > 5) {
      bullCount++;
      tickerDetails.push({ ticker: r.ticker, htf: r.htf, side: "BULL" });
    } else if (r.htf < -5) {
      bearCount++;
      tickerDetails.push({ ticker: r.ticker, htf: r.htf, side: "BEAR" });
    } else {
      tickerDetails.push({ ticker: r.ticker, htf: r.htf, side: "NEUTRAL" });
    }
  }

  if (totalWithData < 2) return null;

  const avgHTF = htfSum / totalWithData;
  const bullPct = bullCount / totalWithData;
  const bearPct = bearCount / totalWithData;

  // Aligned if >= 60% of sector tickers agree on direction
  const isBullAligned = bullPct >= 0.6;
  const isBearAligned = bearPct >= 0.6;
  const aligned = isBullAligned || isBearAligned;
  const direction = isBullAligned ? "BULL" : isBearAligned ? "BEAR" : null;

  // Strength: 0-100 based on consensus percentage and average HTF magnitude
  // 60% agreement = 50 strength, 80% = 75, 100% = 100
  // Boosted by average HTF magnitude (stronger convictions = higher strength)
  const consensusPct = Math.max(bullPct, bearPct);
  const htfMagnitude = Math.min(Math.abs(avgHTF) / 30, 1); // Normalize to 0-1 (30 = max HTF)
  const strength = aligned
    ? Math.round(((consensusPct - 0.5) * 2) * 70 + htfMagnitude * 30) // 0-100
    : 0;

  const result = {
    sector,
    aligned,
    direction,
    strength: Math.min(100, Math.max(0, strength)),
    bullCount,
    bearCount,
    totalWithData,
    avgHTF: Math.round(avgHTF * 10) / 10,
    tickers: tickerDetails.sort((a, b) => Math.abs(b.htf) - Math.abs(a.htf)).slice(0, 8),
    ts: Date.now(),
  };

  _sectorAlignmentCache[sector] = result;
  return result;
}

/**
 * Synchronous version for use inside pure functions (qualifiesForEnter, classifyKanbanStage).
 * Uses only the cached data, returns null if no cache exists.
 */
function getSectorAlignmentCached(ticker) {
  const sector = getSector(ticker);
  if (!sector) return null;
  const cached = _sectorAlignmentCache[sector];
  if (!cached || Date.now() - cached.ts > SECTOR_ALIGNMENT_TTL_MS * 2) return null; // 10 min stale tolerance
  return cached;
}

function getAllSectors() {
  return Object.keys(SECTOR_RATINGS);
}

// ─────────────────────────────────────────────────────────────
// Historical P/E Percentile Calculation
// ─────────────────────────────────────────────────────────────

// Calculate percentile from sorted array
function calculatePercentile(sortedArray, percentile) {
  if (!sortedArray || sortedArray.length === 0) return null;
  const index = Math.floor((percentile / 100) * sortedArray.length);
  return sortedArray[Math.min(index, sortedArray.length - 1)];
}

// Calculate all percentiles from P/E history
function calculatePEPercentiles(peHistory) {
  if (!peHistory || peHistory.length < 10) return null; // Need at least 10 data points

  const sorted = [...peHistory].sort((a, b) => a - b);

  return {
    p10: calculatePercentile(sorted, 10),
    p25: calculatePercentile(sorted, 25),
    p50: calculatePercentile(sorted, 50), // Median
    p75: calculatePercentile(sorted, 75),
    p90: calculatePercentile(sorted, 90),
    avg: peHistory.reduce((a, b) => a + b, 0) / peHistory.length,
    count: peHistory.length,
  };
}

// Determine percentile position
function getPercentilePosition(currentPE, percentiles) {
  if (!currentPE || !percentiles) return null;

  if (currentPE < percentiles.p25) return "Bottom 25%";
  if (currentPE < percentiles.p50) return "Below Median";
  if (currentPE < percentiles.p75) return "Above Median";
  return "Top 25%";
}

// ─────────────────────────────────────────────────────────────
// Fair Value Calculation
// ─────────────────────────────────────────────────────────────

// Calculate fair value P/E using multiple methods
function calculateFairValuePE(peHistory, epsGrowthRate, targetPEG = 1.0) {
  const methods = {};

  // Method 1: Historical Average
  if (peHistory && peHistory.length > 0) {
    methods.historical_avg =
      peHistory.reduce((a, b) => a + b, 0) / peHistory.length;
  }

  // Method 2: Historical Median
  if (peHistory && peHistory.length > 0) {
    const sorted = [...peHistory].sort((a, b) => a - b);
    methods.historical_median = sorted[Math.floor(sorted.length / 2)];
  }

  // Method 3: Growth-Adjusted (PEG-based)
  if (epsGrowthRate && epsGrowthRate > 0) {
    const growthBasedPE = epsGrowthRate * targetPEG;
    // Cap at reasonable levels (min: historical avg if available, max: 40x)
    const minPE = methods.historical_avg || 15;
    const maxPE = 40;
    methods.growth_adjusted = Math.max(minPE, Math.min(growthBasedPE, maxPE));
  }

  // Preferred method: Use growth-adjusted if available, otherwise historical median, fallback to avg
  methods.preferred =
    methods.growth_adjusted ||
    methods.historical_median ||
    methods.historical_avg;

  return methods;
}

// Calculate fair value price
function calculateFairValuePrice(eps, fairValuePE) {
  if (!eps || !fairValuePE || eps <= 0) return null;
  return eps * fairValuePE;
}

// Calculate premium/discount percentage
function calculatePremiumDiscount(currentPrice, fairValuePrice) {
  if (!currentPrice || !fairValuePrice || fairValuePrice <= 0) return null;
  return ((currentPrice - fairValuePrice) / fairValuePrice) * 100;
}

// ─────────────────────────────────────────────────────────────
// Valuation Signals
// ─────────────────────────────────────────────────────────────

// Determine valuation signal based on multiple factors
function calculateValuationSignal(
  currentPE,
  fairValuePE,
  pegRatio,
  premiumDiscount,
  percentiles,
) {
  // Default thresholds
  const UNDERVALUED_THRESHOLD = -15; // 15% below fair value
  const OVERVALUED_THRESHOLD = 15; // 15% above fair value
  const PEG_UNDERVALUED = 0.8;
  const PEG_OVERVALUED = 1.5;

  let signals = {
    signal: "fair", // undervalued, fair, overvalued
    is_undervalued: false,
    is_overvalued: false,
    confidence: "medium", // low, medium, high
    reasons: [],
  };

  // Factor 1: Premium/Discount to Fair Value
  if (premiumDiscount !== null) {
    if (premiumDiscount < UNDERVALUED_THRESHOLD) {
      signals.is_undervalued = true;
      signals.reasons.push(
        `Price ${Math.abs(premiumDiscount).toFixed(1)}% below fair value`,
      );
    } else if (premiumDiscount > OVERVALUED_THRESHOLD) {
      signals.is_overvalued = true;
      signals.reasons.push(
        `Price ${premiumDiscount.toFixed(1)}% above fair value`,
      );
    }
  }

  // Factor 2: PEG Ratio
  if (pegRatio !== null) {
    if (pegRatio < PEG_UNDERVALUED) {
      signals.is_undervalued = true;
      signals.reasons.push(
        `PEG ratio ${pegRatio.toFixed(2)} suggests undervalued growth`,
      );
    } else if (pegRatio > PEG_OVERVALUED) {
      signals.is_overvalued = true;
      signals.reasons.push(
        `PEG ratio ${pegRatio.toFixed(2)} suggests overvalued`,
      );
    }
  }

  // Factor 3: Historical P/E Percentile
  if (currentPE && percentiles) {
    if (currentPE < percentiles.p25) {
      signals.is_undervalued = true;
      signals.reasons.push(`P/E in bottom 25% historically`);
    } else if (currentPE > percentiles.p75) {
      signals.is_overvalued = true;
      signals.reasons.push(`P/E in top 25% historically`);
    }
  }

  // Determine final signal
  if (signals.is_undervalued && !signals.is_overvalued) {
    signals.signal = "undervalued";
    signals.confidence = signals.reasons.length >= 2 ? "high" : "medium";
  } else if (signals.is_overvalued && !signals.is_undervalued) {
    signals.signal = "overvalued";
    signals.confidence = signals.reasons.length >= 2 ? "high" : "medium";
  } else {
    signals.signal = "fair";
    signals.confidence = "medium";
  }

  return signals;
}

// ─────────────────────────────────────────────────────────────
// Valuation Boost/Penalty for Ranking
// ─────────────────────────────────────────────────────────────

// Calculate valuation boost/penalty to add to rank
function calculateValuationBoost(fundamentals) {
  if (!fundamentals) return 0;

  let boost = 0;

  // Factor 1: Valuation Signal (primary factor)
  if (fundamentals.is_undervalued) {
    if (fundamentals.valuation_confidence === "high") {
      boost += 5; // Strong undervaluation signal
    } else {
      boost += 3; // Moderate undervaluation signal
    }
  } else if (fundamentals.is_overvalued) {
    if (fundamentals.valuation_confidence === "high") {
      boost -= 5; // Strong overvaluation signal
    } else {
      boost -= 3; // Moderate overvaluation signal
    }
  }

  // Factor 2: PEG Ratio (secondary factor for growth stocks)
  if (fundamentals.peg_ratio !== null && fundamentals.peg_ratio > 0) {
    if (fundamentals.peg_ratio < 0.8) {
      boost += 2; // Excellent PEG (undervalued growth)
    } else if (fundamentals.peg_ratio < 1.0) {
      boost += 1; // Good PEG (fairly valued growth)
    } else if (fundamentals.peg_ratio > 1.5) {
      boost -= 1; // Poor PEG (overvalued)
    } else if (fundamentals.peg_ratio > 2.0) {
      boost -= 3; // Very poor PEG (highly overvalued)
    }
  }

  // Factor 3: Premium/Discount to Fair Value (tertiary factor)
  if (fundamentals.premium_discount_pct !== null) {
    if (fundamentals.premium_discount_pct < -20) {
      boost += 2; // Significantly below fair value
    } else if (fundamentals.premium_discount_pct < -10) {
      boost += 1; // Moderately below fair value
    } else if (fundamentals.premium_discount_pct > 20) {
      boost -= 2; // Significantly above fair value
    } else if (fundamentals.premium_discount_pct > 10) {
      boost -= 1; // Moderately above fair value
    }
  }

  // Cap the boost/penalty to reasonable bounds
  return Math.max(-8, Math.min(8, boost));
}

// Rank tickers within a sector by technical score + sector boost + ETF weight boost
async function rankTickersInSector(KV, sector, limit = 10, etfWeightMap = null) {
  const sectorTickers = getTickersInSector(sector);
  const sectorRating = getSectorRating(sector);

  const tickerData = [];

  // Get data for all tickers in sector
  for (const ticker of sectorTickers) {
    const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
    if (data) {
      const baseRank = Number(data.rank) || 0;
      const sectorBoost = sectorRating.boost;

      // Get valuation boost from fundamentals
      const fundamentals =
        data.fundamentals ||
        (await kvGetJSON(KV, `timed:fundamentals:${ticker}`));
      const valuationBoost = calculateValuationBoost(fundamentals);

      // ETF weight boost (from Granny Shots ETF holdings)
      let etfWeightBoost = 0;
      if (etfWeightMap && etfWeightMap[ticker]) {
        const weights = etfWeightMap[ticker];
        const etfEntries = Object.entries(weights);
        const maxWeight = Math.max(...etfEntries.map(([, w]) => w));
        if (maxWeight >= 3) etfWeightBoost = 3;
        else if (maxWeight >= 2) etfWeightBoost = 2;
        else if (maxWeight > 0) etfWeightBoost = 1;
        // Cross-ETF conviction bonus
        if (etfEntries.length > 1) etfWeightBoost += 1;
      }

      // Calculate total boosted rank: base + sector + valuation + ETF weight
      const boostedRank = baseRank + sectorBoost + valuationBoost + etfWeightBoost;

      tickerData.push({
        ticker,
        rank: baseRank,
        boostedRank,
        sector,
        sectorRating: sectorRating.rating,
        sectorBoost: sectorRating.boost,
        valuationBoost: valuationBoost,
        etfWeightBoost: etfWeightBoost,
        ...data,
      });
    }
  }

  // Sort by boosted rank (descending)
  tickerData.sort((a, b) => b.boostedRank - a.boostedRank);

  return tickerData.slice(0, limit);
}

// Module-level variable for lazy initialization (persists across requests in same isolate)
let sectorMappingsLoaded = false;

export default {
  async fetch(req, env, ctx) {
    // Top-level error handler to prevent 500 errors from crashing the worker
    try {
      const url = new URL(req.url);

      // Serve Trade Tracker dashboard at / and /dashboard (no KV required)
      if (req.method === "GET" && (url.pathname === "/" || url.pathname === "/dashboard")) {
        return new Response(DASHBOARD_HTML, {
          headers: { "Content-Type": "text/html; charset=utf-8" },
        });
      }

      // Always satisfy CORS preflight before touching bindings.
      // This prevents the dashboard from being blocked by CORS when KV/D1 are misconfigured.
      if (req.method === "OPTIONS") {
        return new Response("", {
          status: 204,
          headers: corsHeaders(env, req),
        });
      }

      // ── WebSocket upgrade: /timed/ws → Durable Object PriceHub ──
      if (url.pathname === "/timed/ws" || url.pathname === "/timed/ws/stats") {
        if (!env.PRICE_HUB) {
          return sendJSON({ ok: false, error: "websocket_not_configured" }, 503, corsHeaders(env, req));
        }
        const id = env.PRICE_HUB.idFromName("global");
        const hub = env.PRICE_HUB.get(id);
        // Forward the original request directly to preserve WebSocket upgrade state
        return hub.fetch(req);
      }

      const KV = env.KV_TIMED;

      // Verify KV binding is available
      if (!KV) {
        console.error(`[FETCH ERROR] KV_TIMED binding is not available`, {
          hasEnv: !!env,
          envKeys: env ? Object.keys(env) : [],
          url: req?.url,
        });
        return sendJSON(
          {
            ok: false,
            error: "kv_not_configured",
            message:
              "KV binding is not configured. Please add KV_TIMED binding in Cloudflare Dashboard.",
          },
          500,
          corsHeaders(env, req),
        );
      }

      // Use waitUntil to ensure critical operations complete even after response
      // This helps prevent race conditions with request cancellation

      // Load sector mappings from KV on first request (lazy initialization)
      // Wrap in try-catch to prevent crashes if KV is unavailable
      if (!sectorMappingsLoaded && KV) {
        try {
          // Never let a slow KV read block the entire Worker (can cause all endpoints to hang)
          const withTimeout = (p, ms) =>
            Promise.race([
              p,
              new Promise((_, reject) =>
                setTimeout(
                  () => reject(new Error("sector_mappings_timeout")),
                  ms,
                ),
              ),
            ]);

          await withTimeout(loadSectorMappingsFromKV(KV), 3000);
          sectorMappingsLoaded = true;
        } catch (sectorLoadErr) {
          // Sector mappings are optional — don't spam error logs for a non-critical timeout.
          // Only log once and move on; sectorMappingsLoaded=true prevents retry loops.
          if (sectorLoadErr?.message === "sector_mappings_timeout") {
            console.warn(`[SECTOR LOAD] Timed out (3s) — continuing without KV mappings`);
          } else {
            console.error(`[SECTOR LOAD] Failed:`, String(sectorLoadErr).slice(0, 150));
          }
          sectorMappingsLoaded = true;
        }
      }

      // url already parsed above
      const routeKey = getRouteKey(req.method, url.pathname);
      if (!routeKey) {
        return sendJSON(
          { ok: false, error: "not_found" },
          404,
          corsHeaders(env, req),
        );
      }

      // POST /timed/ingest
      // Accepts ALL tickers — no allowlist/restrictions. Add a ticker in TradingView, update the
      // alert to your watchlist, and the system automatically accepts, scores, and displays it.
      // Purge (cleanup-tickers --strict) is manual/one-off only.
      if (routeKey === "POST /timed/ingest") {
        let body = null; // Declare outside try for catch block access
        try {
          // Early logging to confirm request reception
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          console.log(
            `[INGEST REQUEST RECEIVED] IP: ${ip}, User-Agent: ${
              req.headers.get("User-Agent") || "none"
            }`,
          );

          const authFail = requireKeyOr401(req, env);
          if (authFail) {
            console.log(`[INGEST AUTH FAILED] IP: ${ip}`);
            return authFail;
          }

          console.log(`[INGEST AUTH PASSED] Processing request from IP: ${ip}`);
          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData; // Assign to outer variable
          if (!body) {
            console.log(
              `[INGEST JSON PARSE FAILED] IP: ${ip}, Error: ${String(
                err || "unknown",
              )}, Raw sample: ${String(raw || "").slice(0, 200)}`,
            );
            return ackJSON(
              env,
              {
                ok: false,
                error: "bad_json",
                sample: String(raw || "").slice(0, 200),
                parseError: String(err || ""),
              },
              400,
              req,
            );
          }

          // Log raw payload for debugging (especially for missing tickers)
          const tickerFromBody = normTicker(body?.ticker);
          console.log(`[INGEST RAW] ${tickerFromBody || "UNKNOWN"}:`, {
            hasTicker: !!body?.ticker,
            hasTs: body?.ts !== undefined,
            hasHtf: body?.htf_score !== undefined,
            hasLtf: body?.ltf_score !== undefined,
            ts: body?.ts,
            htf: body?.htf_score,
            ltf: body?.ltf_score,
            tsType: typeof body?.ts,
            htfType: typeof body?.htf_score,
            ltfType: typeof body?.ltf_score,
          });

          const v = validateTimedPayload(body);
          if (!v.ok) {
            console.log(
              `[INGEST VALIDATION FAILED] ${tickerFromBody || "UNKNOWN"}:`,
              {
                error: v.error,
                ticker: body?.ticker,
                ts: body?.ts,
                htf: body?.htf_score,
                ltf: body?.ltf_score,
              },
            );
            return ackJSON(env, v, 400, req);
          }

          const ticker = v.ticker;
          const payload = v.payload;

          const rawPayload =
            typeof raw === "string"
              ? raw
              : (() => {
                  try {
                    return JSON.stringify(body);
                  } catch {
                    return "";
                  }
                })();

          // Store raw webhook receipt (KV + D1) before any filtering or derived logic
          try {
            if (rawPayload) {
              await kvPutText(
                KV,
                `timed:ingest:raw:${ticker}`,
                rawPayload,
                2 * 24 * 60 * 60,
              );
            }
          } catch (rawErr) {
            console.error(
              `[INGEST RAW] KV store failed for ${ticker}:`,
              rawErr,
            );
          }

          d1InsertIngestReceipt(env, ticker, payload, rawPayload).catch(
            (err) => {
              console.error(
                `[D1 INGEST] Receipt insert exception for ${ticker}:`,
                err,
              );
            },
          );

          // ── Replay lock: skip KV latest writes if a replay is in progress ──
          // Candle D1 writes and receipt logging still happen, but we don't
          // overwrite the replay's scored KV state with raw capture data.
          let _replayLockActive = false;
          try {
            const replayLock = await kvGetJSON(KV, "timed:replay:running");
            if (replayLock && typeof replayLock === "object" && replayLock.since) {
              const lockAge = Date.now() - replayLock.since;
              if (lockAge < 15 * 60 * 1000) { // 15 min expiry
                _replayLockActive = true;
                console.log(`[INGEST] ${ticker} — replay in progress, skipping KV latest write`);
              }
            }
          } catch { /* non-critical */ }

          // Migrate BRK.B to BRK-B if needed (TradingView sends BRK.B, but we use BRK-B)
          // Check BEFORE normalization to catch BRK.B from TradingView
          const rawTicker = body?.ticker;
          if (
            rawTicker === "BRK.B" ||
            rawTicker === "BRK-B" ||
            ticker === "BRK-B"
          ) {
            // Check if old BRK.B data exists and migrate it
            const oldData = await kvGetJSON(KV, `timed:latest:BRK.B`);
            const newData = await kvGetJSON(KV, `timed:latest:BRK-B`);

            if (
              oldData &&
              (!newData ||
                (oldData.ts && newData.ts && oldData.ts > newData.ts))
            ) {
              console.log(
                `[MIGRATE BRK] Migrating BRK.B data to BRK-B (old ts: ${
                  oldData.ts
                }, new ts: ${newData?.ts || "none"})`,
              );
              // Copy data to BRK-B (use newer data if both exist)
              const dataToUse =
                newData && newData.ts > oldData.ts ? newData : oldData;
              await kvPutJSON(KV, `timed:latest:BRK-B`, dataToUse);
              // Copy trail if exists
              const oldTrail = await kvGetJSON(KV, `timed:trail:BRK.B`);
              const newTrail = await kvGetJSON(KV, `timed:trail:BRK-B`);
              if (oldTrail) {
                await kvPutJSON(KV, `timed:trail:BRK-B`, oldTrail);
              } else if (newTrail) {
                await kvPutJSON(KV, `timed:trail:BRK-B`, newTrail);
              }
              // Ensure BRK-B is in index (should already be, but double-check)
              await ensureTickerIndex(KV, "BRK-B");
              // Delete old BRK.B data only if we migrated it
              if (dataToUse === oldData) {
                await KV.delete(`timed:latest:BRK.B`);
                await KV.delete(`timed:trail:BRK.B`);
                console.log(
                  `[MIGRATE BRK] Migration complete: BRK.B → BRK-B (deleted old BRK.B)`,
                );
              } else {
                console.log(
                  `[MIGRATE BRK] BRK-B already has newer data, keeping both`,
                );
              }
            }
          }

          // Log ingestion for debugging
          console.log(`[INGEST] ${ticker}:`, {
            ts: payload.ts,
            htf: payload.htf_score,
            ltf: payload.ltf_score,
            state: payload.state,
            price: payload.price,
            script_version: payload.script_version,
          });

          // Check version and migrate if needed (non-blocking for large migrations)
          const incomingVersion = payload.script_version || "unknown";
          const storedVersion = await getStoredVersion(KV);
          let migration = { migrated: false, reason: "version_match" };

          if (!storedVersion) {
            // First run - set version immediately
            await setStoredVersion(KV, incomingVersion);
          } else if (storedVersion !== incomingVersion) {
            // Version changed - run migration in background to avoid timeout
            console.log(
              `Version change detected: ${storedVersion} -> ${incomingVersion}, starting background migration`,
            );

            // Update version immediately to prevent concurrent migrations from multiple requests
            // Migration will still run (it checks storedVersion at start, before we update)
            // But subsequent requests won't trigger migration again
            await setStoredVersion(KV, incomingVersion);

            // Start migration in background (fire and forget) - don't wait for completion
            // This prevents timeout on large data sets (133+ tickers)
            // Use storedVersion from before update to run migration correctly
            const migrationPromise = checkAndMigrateWithStoredVersion(
              KV,
              storedVersion,
              incomingVersion,
            );
            migrationPromise
              .then((result) => {
                if (result.migrated) {
                  console.log(
                    `Background migration completed: ${result.oldVersion} -> ${
                      result.newVersion
                    }, purged ${result.tickerCount || 0} tickers`,
                  );
                  // Optionally notify Discord about migration
                  // Notify Discord about migration with embed card
                  const migrationEmbed = {
                    title: "🔄 Data Model Migration",
                    color: 0x0099ff, // Blue
                    fields: [
                      {
                        name: "Version",
                        value: `${result.oldVersion} → ${result.newVersion}`,
                        inline: true,
                      },
                      {
                        name: "Tickers Purged",
                        value: `${result.tickerCount || 0}`,
                        inline: true,
                      },
                      {
                        name: "Archive Created",
                        value: result.archived ? "Yes" : "No",
                        inline: true,
                      },
                    ],
                    description: "Migration completed in background",
                    timestamp: new Date().toISOString(),
                    footer: {
                      text: "Timed Trading System",
                    },
                  };
                  if (
                    shouldSendDiscordAlert(env, "SYSTEM", { kind: "migration" })
                  ) {
                    notifyDiscord(env, migrationEmbed).catch(() => {}); // Don't let Discord notification errors break anything
                  }
                }
              })
              .catch((err) => {
                console.error(`[MIGRATION ERROR]`, {
                  error: String(err),
                  stack: err.stack,
                  fromVersion: storedVersion,
                  toVersion: incomingVersion,
                });
              });

            migration = {
              migrated: true,
              reason: "version_changed",
              inProgress: true,
            };
          }

          // Dedupe rapid repeats (only if exact same data within 60s)
          // Note: For Force Baseline, TV sends all alerts with same timestamp/data structure
          // We still want to index all tickers, so dedupe only prevents duplicate alert processing
          // but ticker indexing happens regardless
          const basis = JSON.stringify({
            ts: payload.ts,
            htf: payload.htf_score,
            ltf: payload.ltf_score,
            state: payload.state || "",
            completion: payload.completion,
            phase_pct: payload.phase_pct,
            rr: payload.rr,
            trigger_ts: payload.trigger_ts,
            // Note: We don't include ticker in hash because Force Baseline sends same data structure for all
            // Dedupe is per-ticker, so each ticker gets processed even if data is identical
          });

          const hash = stableHash(basis);
          const dedupeKey = `timed:dedupe:${ticker}:${hash}`;
          const alreadyDeduped = await KV.get(dedupeKey);
          const isRapidDeduped = !!alreadyDeduped;
          if (isRapidDeduped) {
            console.log(
              `[INGEST DEDUPED] ${ticker} - same data within 60s (hash: ${hash.substring(
                0,
                8,
              )})`,
            );
          } else {
            await kvPutText(KV, dedupeKey, "1", 60);
            console.log(
              `[INGEST NOT DEDUPED] ${ticker} - new or changed data (hash: ${hash.substring(
                0,
                8,
              )})`,
            );
          }

          // Derived: staleness
          const stale = stalenessBucket(ticker, payload.ts);
          payload.market_type = stale.mt;
          payload.age_min = stale.ageMin;
          payload.staleness = stale.bucket;

          // Derived: rr/rank — always recompute from current price (not stale KV value)
          payload.rr = computeRR(payload);
          // Sanity cap (with price-based RR, extreme values indicate data issues)
          if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
          
          // RR Warning: Data-driven warning based on historical win rates
          payload.rr_warning = computeRRWarning(payload.rr);

          // Calculate Momentum Elite (worker-based with caching)
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] About to compute Momentum Elite`);
          }
          const momentumEliteData = await computeMomentumElite(
            KV,
            ticker,
            payload,
          );
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Momentum Elite computed:`, {
              momentum_elite: momentumEliteData?.momentum_elite,
              hasCriteria: !!momentumEliteData?.criteria,
            });
          }
          if (momentumEliteData && momentumEliteData.momentum_elite) {
            // Update flags with Momentum Elite status
            if (!payload.flags) payload.flags = {};
            payload.flags.momentum_elite = true;
            // Store full criteria for debugging/display
            payload.momentum_elite_criteria = momentumEliteData.criteria;
          } else {
            // Ensure flag is set to false if not elite
            if (!payload.flags) payload.flags = {};
            payload.flags.momentum_elite = false;
          }

          // Data completeness + TF/trigger summaries (used by UI + scoring)
          try {
            payload.data_completeness = computeDataCompleteness(payload);
            const tfSum = tfTechAlignmentSummary(payload);
            if (tfSum) payload.tf_summary = tfSum;
            payload.trigger_summary = triggerSummaryAndScore(payload);
            payload.move_status = computeMoveStatus(payload);
            payload.flags =
              payload.flags && typeof payload.flags === "object"
                ? payload.flags
                : {};
            payload.flags.move_invalidated =
              payload.move_status?.status === "INVALIDATED";
            payload.flags.move_completed =
              payload.move_status?.status === "COMPLETED";
            const trigCorr = triggerReasonCorroboration(payload);
            payload.trigger_reason_corroborated = !!trigCorr.corroborated;
            payload.trigger_reason_note = trigCorr.note || "";
          } catch (e) {
            console.error(
              `[ENRICH] Failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          payload.rank = computeRank(payload);
          payload.score = payload.rank;
          
          // Gold Standard Score: Data-driven scoring based on historical winners
          // Pass existing data for state transition detection
          payload.gold_score = computeGoldScore(payload, existing);

          // Derived: horizon + % metrics (ETA v2 + risk/return)
          try {
            const derived = deriveHorizonAndMetrics(payload);
            Object.assign(payload, derived);
          } catch (e) {
            console.error(`[DERIVED METRICS] Failed for ${ticker}:`, String(e));
          }

          // Trail (light) - store immediately after derived metrics
          try {
            // Load previous state for Flip Watch, Kanban lifecycle, and stage transition detection
            const existing =
              (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
            const trailPoint = {
              ts: payload.ts,
              price: payload.price, // Add price to trail for momentum calculations
              htf_score: payload.htf_score,
              ltf_score: payload.ltf_score,
              completion: payload.completion,
              phase_pct: payload.phase_pct,
              state: payload.state,
              rank: payload.rank,
              flags: payload.flags || {},
              momentum_elite: !!(payload.flags && payload.flags.momentum_elite),
              trigger_reason: payload.trigger_reason,
              trigger_dir: payload.trigger_dir,
            };

            const trail = await appendTrail(KV, ticker, trailPoint, 320); // ~26h at 5m cadence (enables 4h/1d deltas)

            // Compute live thesis features from the updated trail
            try {
              const computed = computeLiveThesisFeaturesFromTrail(
                trail,
                payload,
              );
              if (computed && typeof computed === "object") {
                payload.seq = computed.seq;
                payload.deltas = computed.deltas;
                payload.flags =
                  payload.flags && typeof payload.flags === "object"
                    ? payload.flags
                    : {};
                payload.flags.htf_improving_4h =
                  !!computed.flags?.htf_improving_4h;
                payload.flags.htf_improving_1d =
                  !!computed.flags?.htf_improving_1d;
                payload.flags.htf_move_4h_ge_5 =
                  !!computed.flags?.htf_move_4h_ge_5;
                payload.flags.thesis_match = !!computed.flags?.thesis_match;
              }

              // Flip Watch detection - tickers about to transition from setup to momentum
              try {
                const nowMs = Number(
                  payload?.ts ?? payload?.ingest_ts ?? Date.now(),
                );
                const state = String(payload?.state || "");
                const inPullback =
                  state === "HTF_BULL_LTF_PULLBACK" ||
                  state === "HTF_BEAR_LTF_PULLBACK";
                const isMomentum =
                  state === "HTF_BULL_LTF_BULL" ||
                  state === "HTF_BEAR_LTF_BEAR";

                const flipWatch = detectFlipWatch(payload, trail);
                const prevUntilRaw = Number(existing?.flip_watch_until_ts);
                const prevUntil = Number.isFinite(prevUntilRaw)
                  ? prevUntilRaw
                  : null;
                const prevScore = Number(existing?.flip_watch_score);
                const prevReasons = Array.isArray(existing?.flip_watch_reasons)
                  ? existing.flip_watch_reasons
                  : null;

                // Sticky window: once triggered, keep Flip Watch for 60m *while still in pullback*.
                // If it flips into momentum, release immediately so it can progress (Just Flipped / Enter Now).
                const STICKY_MS = 60 * 60 * 1000;
                const stickyActive =
                  !isMomentum &&
                  inPullback &&
                  prevUntil != null &&
                  Number.isFinite(nowMs) &&
                  nowMs <= prevUntil;

                if (flipWatch) {
                  payload.flags.flip_watch = true;
                  payload.flip_watch_score = flipWatch.score;
                  payload.flip_watch_reasons = flipWatch.reasons;
                  payload.flip_watch_until_ts = nowMs + STICKY_MS;
                } else if (stickyActive) {
                  payload.flags.flip_watch = true;
                  if (Number.isFinite(prevScore))
                    payload.flip_watch_score = prevScore;
                  if (prevReasons) payload.flip_watch_reasons = prevReasons;
                  payload.flip_watch_until_ts = prevUntil;
                } else {
                  payload.flags.flip_watch = false;
                  payload.flip_watch_until_ts = null;
                }
              } catch (e) {
                console.error(
                  `[FLIP WATCH] Detection failed for ${ticker}:`,
                  String(e),
                );
              }
            } catch (e) {
              console.error(
                `[THESIS FEATURES] Compute failed for ${ticker}:`,
                String(e),
              );
            }

            // Kanban Stage classification - ALWAYS run (independent of thesis/flip-watch logic)
            // CRITICAL: Merge entry_ts/entry_price from existing BEFORE classifyKanbanStage.
            // Otherwise computeMoveStatus sees hasEntered=false and tickers that should be HOLD
            // (move passed) end up in Watch. Same for cycle fields (lifecycle gate).
            try {
              if (existing?.entry_ts != null || existing?.entry_price != null) {
                if (payload.entry_ts == null && Number.isFinite(Number(existing?.entry_ts)))
                  payload.entry_ts = Number(existing.entry_ts);
                if (payload.entry_price == null && Number.isFinite(Number(existing?.entry_price)))
                  payload.entry_price = Number(existing.entry_price);
              }
              if (existing?.kanban_cycle_enter_now_ts != null)
                payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
              if (existing?.kanban_cycle_trigger_ts != null)
                payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
              if (existing?.kanban_cycle_side != null)
                payload.kanban_cycle_side = existing.kanban_cycle_side;

              // ═══════════════════════════════════════════════════════════════════
              // D1 SINGLE SOURCE OF TRUTH: Get position context from D1 only
              // KV trade lookup deprecated - D1 positions table is authoritative
              // ═══════════════════════════════════════════════════════════════════
              const openPosition = env?.DB ? await getPositionContext(env, ticker) : null;
              const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
              
              // Inject entry data from D1 position if missing from payload
              if (hasOpenPosition) {
                if (payload.entry_ts == null && openPosition.entry_ts) {
                  payload.entry_ts = openPosition.entry_ts;
                }
                if (payload.entry_price == null && openPosition.avg_entry_price > 0) {
                  payload.entry_price = openPosition.avg_entry_price;
                }
                // Store position context for downstream use
                payload.__position_context = openPosition;
              }
              
              // Recompute move_status so stored payload reflects merged entry_ts
              payload.move_status = computeMoveStatus(payload);
              if (payload.flags) {
                payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
                payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
                payload.flags.has_open_position = hasOpenPosition;
              }

              // ═══════════════════════════════════════════════════════════════════
              // PATTERN LIBRARY ENRICHMENT: Match payload against active patterns
              // Non-blocking: uses in-memory cache, refreshes every 5 minutes
              // Enriches payload with pattern match data for UI + Kanban boost
              // ═══════════════════════════════════════════════════════════════════
              try {
                const cachedPatterns = await getCachedPatterns(env?.DB);
                const patternMatch = matchPatternsForPayload(payload, cachedPatterns);
                if (patternMatch) {
                  payload.pattern_match = patternMatch;
                  // Boost entry confidence when high-confidence bull patterns match
                  if (patternMatch.direction === "BULLISH" && patternMatch.bestBull?.conf > 0.6) {
                    payload.__pattern_boost = "high";
                  } else if (patternMatch.direction === "BULLISH" && patternMatch.bullCount > 0) {
                    payload.__pattern_boost = "medium";
                  } else if (patternMatch.direction === "BEARISH" && patternMatch.bestBear?.conf > 0.6) {
                    payload.__pattern_caution = "high";
                  }
                }
              } catch (e) {
                // Pattern matching is a boost, not a gate — never block on failure
              }

              // Pass open position to classifyKanbanStage for position-aware classification
              const stage = classifyKanbanStage(payload, openPosition);
              const prevStage = existing?.kanban_stage;
              
              // ═══════════════════════════════════════════════════════════════════
              // RECYCLE RULE: Position always wins
              // If there's an open position, NEVER recycle to watch - stay in management mode
              // Only apply recycle rule for non-position tickers
              // ═══════════════════════════════════════════════════════════════════
              let finalStage = stage;
              const prevStageLegacy = prevStage === "archive" || prevStage === "closed";
              const isManagementStage = stage === "active" || stage === "trim" || stage === "exit" ||
                                        stage === "hold" || stage === "just_entered"; // legacy names
              
              if (prevStageLegacy && isManagementStage && !hasOpenPosition) {
                // No open position, was archived - must re-enter via discovery lanes
                finalStage = "watch";
                payload.flags =
                  payload.flags && typeof payload.flags === "object"
                    ? payload.flags
                    : {};
                payload.flags.recycled_from_archive = true;
              }
              // If has open position, position wins - stay in management stage regardless of previous

              // Lifecycle gate: Management stages require open position
              // Exception: first bar of day after AH/PM gap — accept management stages (move in progress)
              try {
                const tsNow = Number(payload?.ts) || Date.now();
                const dayKey = nyTradingDayKey(tsNow);
                const marketOpen = dayKey ? nyWallTimeToUtcMs(dayKey, 9, 30, 0) : null;
                const existingTs = existing?.ts ?? existing?.ingest_ts;
                const firstBarAfterGap = isFirstBarOfDayAfterGap(existingTs, tsNow, marketOpen);

                // Check if stage is a management stage (new or legacy names)
                const mgmt =
                  finalStage === "active" ||
                  finalStage === "trim" ||
                  finalStage === "exit" ||
                  finalStage === "hold" ||        // legacy
                  finalStage === "just_entered";  // legacy
                  
                // Verify open position exists before allowing management lanes
                // If no position exists, clear stale entry data and force to watch
                if (mgmt && !hasOpenPosition) {
                  // Position closed but ticker still shows in management lane
                  // Clear stale entry data and force to discovery lanes
                  payload.entry_ts = null;
                  payload.entry_price = null;
                  payload.kanban_cycle_enter_now_ts = null;
                  payload.kanban_cycle_trigger_ts = null;
                  payload.kanban_cycle_side = null;
                  finalStage = "watch";
                  payload.flags =
                    payload.flags && typeof payload.flags === "object"
                      ? payload.flags
                      : {};
                  payload.flags.position_closed_cleared = true;
                  payload.flags.forced_watch_no_position = true;
                  console.log(
                    `[KANBAN] ${ticker} forced to watch: was in ${prevStage} but no open position in D1`
                  );
                }
                  
                if (mgmt && hasOpenPosition) {
                  const curTriggerTs = Number(payload?.trigger_ts);
                  const curSide = sideFromStateOrScores(payload); // "LONG" | "SHORT" | null
                  const cycleEnterTs = Number(
                    existing?.kanban_cycle_enter_now_ts,
                  );
                  const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
                  const cycleSide =
                    existing?.kanban_cycle_side != null
                      ? String(existing.kanban_cycle_side)
                      : null;
                  const sameTrig =
                    Number.isFinite(curTriggerTs) &&
                    curTriggerTs > 0 &&
                    Number.isFinite(cycleTrig) &&
                    cycleTrig > 0 &&
                    cycleTrig === curTriggerTs;
                  const cycleOk =
                    Number.isFinite(cycleEnterTs) &&
                    cycleEnterTs > 0 &&
                    sameTrig &&
                    !!cycleSide &&
                    !!curSide &&
                    cycleSide === curSide;

                  if (firstBarAfterGap) {
                    if (!payload.flags) payload.flags = {};
                    payload.flags.first_bar_of_day_bridge = true;
                  } else {
                    if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                      finalStage = "watch";
                      payload.flags =
                        payload.flags && typeof payload.flags === "object"
                          ? payload.flags
                          : {};
                      payload.flags.forced_watch_missing_trigger = true;
                    } else if (!cycleOk) {
                      finalStage = "enter_now";
                      payload.flags =
                        payload.flags && typeof payload.flags === "object"
                          ? payload.flags
                          : {};
                      payload.flags.forced_enter_now_gate = true;
                    }
                  }
                }

                if (finalStage === "enter_now") {
                  const curTriggerTs = Number(payload?.trigger_ts);
                  const curSide = sideFromStateOrScores(payload);
                  payload.kanban_cycle_enter_now_ts = tsNow;
                  payload.kanban_cycle_trigger_ts =
                    Number.isFinite(curTriggerTs) && curTriggerTs > 0
                      ? curTriggerTs
                      : null;
                  payload.kanban_cycle_side =
                    curSide != null ? String(curSide) : null;
                } else if (
                  finalStage === "hold" ||
                  finalStage === "just_entered" ||
                  finalStage === "trim" ||
                  finalStage === "exit"
                ) {
                  if (firstBarAfterGap) {
                    payload.kanban_cycle_enter_now_ts = tsNow;
                    payload.kanban_cycle_trigger_ts =
                      Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : tsNow;
                    payload.kanban_cycle_side = sideFromStateOrScores(payload) != null ? String(sideFromStateOrScores(payload)) : null;
                    if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                    if (payload.entry_ts == null && Number.isFinite(tsNow)) payload.entry_ts = tsNow;
                  } else {
                    payload.kanban_cycle_enter_now_ts =
                      existing?.kanban_cycle_enter_now_ts || null;
                    payload.kanban_cycle_trigger_ts =
                      existing?.kanban_cycle_trigger_ts || null;
                    payload.kanban_cycle_side =
                      existing?.kanban_cycle_side || null;
                  }
                } else {
                  // Reset cycle when we're not in ENTER_NOW or management lanes.
                  payload.kanban_cycle_enter_now_ts = null;
                  payload.kanban_cycle_trigger_ts = null;
                  payload.kanban_cycle_side = null;
                }
              } catch (e) {
                console.error(
                  `[KANBAN] lifecycle gate failed for ${ticker}:`,
                  String(e),
                );
              }

              // Stage monotonicity: open positions can only move forward in management lanes
              // Prevents bouncing EXIT→TRIM→ACTIVE due to price fluctuations
              const preMonotonicityStage = finalStage;
              finalStage = enforceStageMonotonicity(finalStage, prevStage, hasOpenPosition);
              if (finalStage !== preMonotonicityStage) {
                if (!payload.flags) payload.flags = {};
                payload.flags.stage_monotonicity_enforced = true;
                payload.flags.stage_before_monotonicity = preMonotonicityStage;
                console.log(
                  `[KANBAN] ${ticker} stage monotonicity: ${preMonotonicityStage} → ${finalStage} (enforced, has open position: ${hasOpenPosition})`
                );
              }

              payload.kanban_stage = finalStage;
              payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
              // Persist last transition source lane so UI can show "from: <lane>".
              // If stage changed: stamp prev_kanban_stage = previous lane (if known).
              // If stage did NOT change: carry forward the last stamped prev_kanban_stage.
              if (
                prevStage != null &&
                finalStage != null &&
                String(prevStage) !== String(finalStage)
              ) {
                payload.prev_kanban_stage = String(prevStage);
                payload.prev_kanban_stage_ts =
                  Number(payload?.ts) || Date.now();
              } else if (existing?.prev_kanban_stage != null) {
                payload.prev_kanban_stage = String(existing.prev_kanban_stage);
                payload.prev_kanban_stage_ts = Number.isFinite(
                  Number(existing?.prev_kanban_stage_ts),
                )
                  ? Number(existing.prev_kanban_stage_ts)
                  : null;
              } else {
                payload.prev_kanban_stage = null;
                payload.prev_kanban_stage_ts = null;
              }

              // Track entry price when entering "enter_now" stage
              if (finalStage === "enter_now" && prevStage !== "enter_now") {
                const price = Number(payload?.price);
                if (Number.isFinite(price) && price > 0) {
                  payload.entry_price = price;
                  payload.entry_ts = payload.ts;
                  console.log(
                    `[KANBAN] ${ticker} entered ENTER_NOW at $${price.toFixed(2)}`,
                  );
                }
              }

              // Discord notification for kanban lane transitions
              const actionableStages = [
                "enter",
                "enter_now",
                "just_entered",
                "hold",
                "defend",
                "trim",
                "exit",
              ];
              if (
                prevStage != null &&
                finalStage != null &&
                String(prevStage) !== String(finalStage) &&
                actionableStages.includes(finalStage)
              ) {
                const alertType = `KANBAN_${finalStage.toUpperCase()}`;
                const tsMs = Number(payload?.ts) || Date.now();
                const dedupeBucket = Math.floor(tsMs / 900000); // 15 min
                const dedupeKey = `timed:discord:kanban:${ticker}:${finalStage}:${dedupeBucket}`;
                ctx.waitUntil(
                  (async () => {
                    try {
                      const already = await KV.get(dedupeKey);
                      if (already) return;
                      await kvPutText(KV, dedupeKey, "1", 60 * 60); // 1h TTL
                      if (!shouldSendDiscordAlert(env, alertType, { ticker }))
                        return;
                      const embed = createKanbanStageEmbed(
                        ticker,
                        finalStage,
                        prevStage,
                        payload,
                      );
                      await notifyDiscord(env, embed).catch((err) => {
                        console.error(
                          `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                          err,
                        );
                      });
                      // In-app notification for kanban stage transition
                      const stageLabels = { enter_now: "Entry Signal", hold: "Holding", defend: "Defending", exit: "Exit Signal", setup: "Setup" };
                      await d1InsertNotification(env, {
                        email: null, type: "kanban",
                        title: `${stageLabels[finalStage] || finalStage.toUpperCase()}: ${ticker}`,
                        body: `${ticker} moved to ${stageLabels[finalStage] || finalStage} (from ${prevStage || "new"})`,
                        link: `/index-react.html?ticker=${ticker}`,
                      }).catch(() => {});
                    } catch (e) {
                      console.error(
                        `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                        e,
                      );
                    }
                  })(),
                );
              }

              // Preserve entry_price if already set and still in the pipeline
              if (finalStage && existing?.entry_price) {
                payload.entry_price = existing.entry_price;
                payload.entry_ts = existing.entry_ts;
              }

              // Calculate % change from entry if we have entry_price
              if (payload.entry_price) {
                const entryPrice = Number(payload.entry_price);
                const currentPrice = Number(payload.price);
                if (
                  Number.isFinite(entryPrice) &&
                  Number.isFinite(currentPrice) &&
                  entryPrice > 0
                ) {
                  payload.entry_change_pct =
                    ((currentPrice - entryPrice) / entryPrice) * 100;
                }
              }

              if (finalStage) console.log(`[KANBAN] ${ticker} → ${finalStage}`);
              
              // Update the last KV trail point with kanban data for Time Travel replay
              try {
                const trailKey = `timed:trail:${ticker}`;
                const currentTrail = await kvGetJSON(KV, trailKey);
                if (Array.isArray(currentTrail) && currentTrail.length > 0) {
                  const lastPoint = currentTrail[currentTrail.length - 1];
                  if (lastPoint && lastPoint.ts === payload.ts) {
                    lastPoint.kanban_stage = finalStage;
                    lastPoint.entry_ts = payload.entry_ts || null;
                    lastPoint.entry_price = payload.entry_price || null;
                    lastPoint.move_status = payload.move_status?.status || null;
                    lastPoint.kanban_meta = payload.kanban_meta || null;
                    await kvPutJSON(KV, trailKey, currentTrail);
                  }
                }
              } catch (trailUpdateErr) {
                // Non-critical - don't fail ingestion
                console.error(`[TRAIL] Failed to update KV trail with kanban for ${ticker}:`, trailUpdateErr);
              }
            } catch (e) {
              console.error(
                `[KANBAN] Stage classification failed for ${ticker}:`,
                String(e),
              );
              payload.kanban_stage = existing?.kanban_stage || null;
              payload.prev_kanban_stage = existing?.prev_kanban_stage || null;
              payload.prev_kanban_stage_ts =
                existing?.prev_kanban_stage_ts || null;
            }

            // Also store into D1 (if configured) for 7-day history.
            // Don't let D1 failures affect ingestion.
            d1InsertTrailPoint(env, ticker, payload).catch((e) => {
              console.error(`[D1 TRAIL] Insert exception for ${ticker}:`, e);
            });

            // Periodic cleanup (throttled) to keep ~35 days retention
            d1CleanupOldTrail(env, 35).catch((e) => {
              console.error(`[D1 TRAIL] Cleanup exception:`, e);
            });
          } catch (trailErr) {
            console.error(
              `[TRAIL ERROR] Failed to append trail for ${ticker}:`,
              {
                error: String(trailErr),
                message: trailErr.message,
                stack: trailErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if trail fails
          }

          // Auto-populate sector: PRIORITIZE SECTOR_MAP over TradingView data
          // TradingView uses industry classifications (e.g., "Electronic Technology", "Retail Trade")
          // but we use GICS sectors (e.g., "Information Technology", "Consumer Discretionary")
          // So we always check SECTOR_MAP first, then fall back to TradingView data for unmapped tickers
          const tickerUpper = String(payload.ticker || ticker).toUpperCase();
          let sectorToUse = null;

          // First, check our SECTOR_MAP (GICS sectors)
          sectorToUse = getSector(tickerUpper);

          // If not in SECTOR_MAP, use TradingView's sector (for new/unmapped tickers)
          if (!sectorToUse) {
            if (
              payload.sector &&
              typeof payload.sector === "string" &&
              payload.sector.trim() !== ""
            ) {
              sectorToUse = payload.sector.trim();
              // Store TradingView sector in KV for reference (but don't override SECTOR_MAP)
              const sectorMapKey = `timed:sector_map:${tickerUpper}`;
              await kvPutText(KV, sectorMapKey, sectorToUse);
              console.log(
                `[SECTOR AUTO-MAP] ${tickerUpper} → ${sectorToUse} (from TradingView, not in SECTOR_MAP)`,
              );
            }
          } else {
            // Ticker is in SECTOR_MAP - use our GICS sector classification
            console.log(
              `[SECTOR] ${tickerUpper} → ${sectorToUse} (from SECTOR_MAP, ignoring TradingView sector: ${
                payload.sector || "none"
              })`,
            );
          }

          // Set sector at top level if we have one
          if (sectorToUse) {
            payload.sector = sectorToUse;
          }

          // Store sector and industry in payload (even if no fundamental data)
          // These are safe fields that work for all asset types
          if (payload.sector && typeof payload.sector === "string") {
            payload.sector = payload.sector.trim();
          }
          if (payload.industry && typeof payload.industry === "string") {
            payload.industry = payload.industry.trim();
          }

          // Store fundamental data if provided
          if (
            payload.pe_ratio !== undefined ||
            payload.eps !== undefined ||
            payload.market_cap !== undefined ||
            payload.eps_growth_rate !== undefined ||
            payload.peg_ratio !== undefined
          ) {
            const currentPE = payload.pe_ratio
              ? Number(payload.pe_ratio)
              : null;
            const eps = payload.eps ? Number(payload.eps) : null;
            const epsGrowthRate = payload.eps_growth_rate
              ? Number(payload.eps_growth_rate)
              : null;
            const pegRatio = payload.peg_ratio
              ? Number(payload.peg_ratio)
              : null;
            const currentPrice = Number(payload.price) || null;

            // ─────────────────────────────────────────────────────────────
            // Historical P/E Percentiles
            // ─────────────────────────────────────────────────────────────
            let peHistory = [];
            let percentiles = null;
            let percentilePosition = null;

            if (currentPE && currentPE > 0 && currentPE < 1000) {
              // Load existing P/E history
              const peHistoryKey = `timed:pe_history:${ticker}`;
              const existingHistory = await kvGetJSON(KV, peHistoryKey);

              if (existingHistory && Array.isArray(existingHistory)) {
                peHistory = existingHistory;
              }

              // Add current P/E to history
              peHistory.push(currentPE);

              // Keep last ~1260 data points (approximately 5 years of daily data)
              const maxHistoryLength = 1260;
              if (peHistory.length > maxHistoryLength) {
                peHistory = peHistory.slice(-maxHistoryLength);
              }

              // Save updated history
              await kvPutJSON(KV, peHistoryKey, peHistory);

              // Calculate percentiles
              percentiles = calculatePEPercentiles(peHistory);
              if (percentiles) {
                percentilePosition = getPercentilePosition(
                  currentPE,
                  percentiles,
                );
              }
            }

            // ─────────────────────────────────────────────────────────────
            // Fair Value Calculation
            // ─────────────────────────────────────────────────────────────
            const fairValuePE = calculateFairValuePE(peHistory, epsGrowthRate);
            const fairValuePrice = calculateFairValuePrice(
              eps,
              fairValuePE?.preferred,
            );
            const premiumDiscount = calculatePremiumDiscount(
              currentPrice,
              fairValuePrice,
            );

            // ─────────────────────────────────────────────────────────────
            // Valuation Signals
            // ─────────────────────────────────────────────────────────────
            const valuationSignals = calculateValuationSignal(
              currentPE,
              fairValuePE?.preferred,
              pegRatio,
              premiumDiscount,
              percentiles,
            );

            // ─────────────────────────────────────────────────────────────
            // Build Fundamentals Object
            // ─────────────────────────────────────────────────────────────
            payload.fundamentals = {
              // Basic metrics
              pe_ratio: currentPE,
              eps: eps,
              eps_growth_rate: epsGrowthRate,
              peg_ratio: pegRatio,
              market_cap: payload.market_cap
                ? Number(payload.market_cap)
                : null,
              industry: payload.industry || null,

              // Historical P/E Percentiles
              pe_percentiles: percentiles
                ? {
                    p10: percentiles.p10,
                    p25: percentiles.p25,
                    p50: percentiles.p50,
                    p75: percentiles.p75,
                    p90: percentiles.p90,
                    avg: percentiles.avg,
                    count: percentiles.count,
                  }
                : null,
              pe_percentile_position: percentilePosition,

              // Fair Value
              fair_value_pe: fairValuePE
                ? {
                    historical_avg: fairValuePE.historical_avg || null,
                    historical_median: fairValuePE.historical_median || null,
                    growth_adjusted: fairValuePE.growth_adjusted || null,
                    preferred: fairValuePE.preferred || null,
                  }
                : null,
              fair_value_price: fairValuePrice,
              premium_discount_pct: premiumDiscount,

              // Valuation Signals
              valuation_signal: valuationSignals.signal,
              is_undervalued: valuationSignals.is_undervalued,
              is_overvalued: valuationSignals.is_overvalued,
              valuation_confidence: valuationSignals.confidence,
              valuation_reasons: valuationSignals.reasons,
            };

            // Store fundamentals in KV for persistence
            const fundamentalsKey = `timed:fundamentals:${ticker}`;
            await kvPutJSON(KV, fundamentalsKey, payload.fundamentals);

            // Apply valuation boost to rank (if fundamentals available)
            if (payload.fundamentals) {
              const valuationBoost = calculateValuationBoost(
                payload.fundamentals,
              );
              if (valuationBoost !== 0) {
                const baseRank = payload.rank || 0;
                payload.rank = Math.max(
                  0,
                  Math.min(100, baseRank + valuationBoost),
                );
                payload.score = payload.rank;

                // Store valuation boost for debugging/display
                if (!payload.rank_components) payload.rank_components = {};
                payload.rank_components.valuation_boost = valuationBoost;
                payload.rank_components.base_rank = baseRank;

                console.log(
                  `[RANK] ${ticker}: Base=${baseRank}, Valuation Boost=${valuationBoost}, Final=${payload.rank}`,
                );
              }
            }
          } else {
            // No fundamental data provided, but still store sector/industry if available
            // Create minimal fundamentals object for UI compatibility
            if (payload.sector || payload.industry) {
              payload.fundamentals = {
                pe_ratio: null,
                eps: null,
                eps_growth_rate: null,
                peg_ratio: null,
                market_cap: null,
                industry: payload.industry
                  ? String(payload.industry).trim()
                  : null,
                sector: payload.sector ? String(payload.sector).trim() : null,
                pe_percentiles: null,
                pe_percentile_position: null,
                fair_value_pe: null,
                fair_value_price: null,
                premium_discount_pct: null,
                valuation_signal: "fair",
                is_undervalued: false,
                is_overvalued: false,
                valuation_confidence: "low",
                valuation_reasons: [],
              };
            }
          }

          // Detect state transition into aligned (enter Q2/Q3)
          const prevKey = `timed:prevstate:${ticker}`;
          const prevState = await KV.get(prevKey);
          await kvPutText(
            KV,
            prevKey,
            String(payload.state || ""),
            7 * 24 * 60 * 60,
          );

          const state = String(payload.state || "");
          const alignedLong = state === "HTF_BULL_LTF_BULL";
          const alignedShort = state === "HTF_BEAR_LTF_BEAR";
          const aligned = alignedLong || alignedShort;
          const enteredAligned = aligned && prevState !== state;

          const trigReason = String(payload.trigger_reason || "");
          const trigOk =
            trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
            trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");

          const flags = payload.flags || {};
          const sqRel = !!flags.sq30_release;

          // Activity feed tracking - detect events (load BEFORE alert logic to check for corridor entry)
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] About to load activity tracking state`);
          }
          const prevCorridorKey = `timed:prevcorridor:${ticker}`;
          const prevInCorridor = await KV.get(prevCorridorKey);

          // Corridor-only logic (must match UI)
          const side = corridorSide(payload); // LONG/SHORT/null
          const inCorridor = !!side;
          const enteredCorridor = inCorridor && prevInCorridor !== "true";

          // corridor must match alignment
          const corridorAlignedOK =
            (side === "LONG" && alignedLong) ||
            (side === "SHORT" && alignedShort);

          // Allow alerts if:
          // 1. ENTERED corridor (just entered) AND aligned AND (entered aligned OR trigger OR squeeze release)
          // 2. OR in corridor AND aligned AND (entered aligned OR trigger OR squeeze release)
          // 3. OR in corridor AND squeeze release (squeeze release is a strong signal even if not fully aligned)
          const shouldConsiderAlert =
            (enteredCorridor &&
              corridorAlignedOK &&
              (enteredAligned || trigOk || sqRel)) ||
            (inCorridor &&
              ((corridorAlignedOK && (enteredAligned || trigOk || sqRel)) ||
                (sqRel && side))); // Squeeze release in corridor is a valid trigger even if not fully aligned
          payload.entry_decision = buildEntryDecision(
            ticker,
            payload,
            prevState,
          );
          const prevSqueezeKey = `timed:prevsqueeze:${ticker}`;
          const prevSqueezeOn = await KV.get(prevSqueezeKey);
          const prevSqueezeRelKey = `timed:prevsqueezerel:${ticker}`;
          const prevSqueezeRel = await KV.get(prevSqueezeRelKey);
          const prevMomentumEliteKey = `timed:prevmomentumelite:${ticker}`;
          const prevMomentumElite = await KV.get(prevMomentumEliteKey);
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Activity tracking state loaded`);
          }

          // Track corridor entry
          // Wrap activity tracking in try-catch to prevent errors from breaking ingestion
          try {
            const actionableOnly = true;
            const enteredCorridor = inCorridor && prevInCorridor !== "true";
            const exitedCorridor = !inCorridor && prevInCorridor === "true";

            if (enteredCorridor) {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "corridor_entry",
                  ticker: ticker,
                  side: side,
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
              await kvPutText(KV, prevCorridorKey, "true", 7 * 24 * 60 * 60);
            } else if (exitedCorridor) {
              await kvPutText(KV, prevCorridorKey, "false", 7 * 24 * 60 * 60);
            }

            // Track squeeze start
            if (flags.sq30_on && prevSqueezeOn !== "true") {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "squeeze_start",
                  ticker: ticker,
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
              await kvPutText(KV, prevSqueezeKey, "true", 7 * 24 * 60 * 60);
            } else if (!flags.sq30_on && prevSqueezeOn === "true") {
              await kvPutText(KV, prevSqueezeKey, "false", 7 * 24 * 60 * 60);
            }

            // Track squeeze release
            if (sqRel && prevSqueezeRel !== "true") {
              await appendActivity(KV, {
                type: "squeeze_release",
                ticker: ticker,
                side:
                  side ||
                  (alignedLong ? "LONG" : alignedShort ? "SHORT" : null),
                price: payload.price,
                state: payload.state,
                rank: payload.rank,
                trigger_dir: payload.trigger_dir,
                sl: payload.sl,
                tp: payload.tp,
                tp_levels: payload.tp_levels,
                rr: payload.rr,
                phase_pct: payload.phase_pct,
                completion: payload.completion,
              });
              await kvPutText(KV, prevSqueezeRelKey, "true", 7 * 24 * 60 * 60);
            } else if (!sqRel && prevSqueezeRel === "true") {
              await kvPutText(KV, prevSqueezeRelKey, "false", 7 * 24 * 60 * 60);
            }

            // Track flip watch (tickers about to flip from PULLBACK to momentum)
            const prevFlipWatchKey = `timed:prev_flip_watch:${ticker}`;
            const prevFlipWatch = await KV.get(prevFlipWatchKey);
            const nowFlipWatch = !!flags.flip_watch;

            if (nowFlipWatch && prevFlipWatch !== "true") {
              // New flip watch - send Discord alert
              const discordEnable = env?.DISCORD_ENABLE || "false";
              const discordWebhook = env?.DISCORD_WEBHOOK_URL;
              const discordConfigured =
                discordEnable === "true" && !!discordWebhook;

              const nowMs = Date.now();
              const hourBucket = new Date(nowMs).toISOString().slice(0, 13);
              const dedupeKey = `timed:dedupe:flip_watch:${ticker}:${hourBucket}`;
              const already = await KV.get(dedupeKey);

              // [DEPRECATED] Flip watch Discord notification removed — routes to "setup" stage now
              // Detection logic preserved for internal tracking, just no separate Discord notification
              if (!already && discordConfigured) {
                await KV.put(dedupeKey, "1", { expirationTtl: 60 * 60 * 4 });
                console.log(
                  `[FLIP WATCH] ${ticker} detected, score=${payload.flip_watch_score} (Discord suppressed — setup stage)`,
                );
              }

              await appendActivity(KV, {
                type: "flip_watch",
                ticker: ticker,
                side: side,
                price: payload.price,
                state: payload.state,
                rank: payload.rank,
                flip_watch_score: payload.flip_watch_score,
                flip_watch_reasons: payload.flip_watch_reasons,
                sl: payload.sl,
                tp: payload.tp,
                tp_levels: payload.tp_levels,
                rr: payload.rr,
                phase_pct: payload.phase_pct,
                completion: payload.completion,
              });

              await kvPutText(KV, prevFlipWatchKey, "true", 7 * 24 * 60 * 60);
            } else if (!nowFlipWatch && prevFlipWatch === "true") {
              await kvPutText(KV, prevFlipWatchKey, "false", 7 * 24 * 60 * 60);
            }

            // Track state change to aligned
            if (enteredAligned) {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "state_aligned",
                  ticker: ticker,
                  side: alignedLong ? "LONG" : "SHORT",
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
            }

            // Track Momentum Elite status change
            const currentMomentumElite = !!(
              payload.flags && payload.flags.momentum_elite
            );
            if (currentMomentumElite && prevMomentumElite !== "true") {
              if (!actionableOnly) {
                await appendActivity(KV, {
                  type: "momentum_elite",
                  ticker: ticker,
                  price: payload.price,
                  state: payload.state,
                  rank: payload.rank,
                  sl: payload.sl,
                  tp: payload.tp,
                  tp_levels: payload.tp_levels,
                  rr: payload.rr,
                  phase_pct: payload.phase_pct,
                  completion: payload.completion,
                });
              }
              await kvPutText(
                KV,
                prevMomentumEliteKey,
                "true",
                7 * 24 * 60 * 60,
              );
            } else if (!currentMomentumElite && prevMomentumElite === "true") {
              await kvPutText(
                KV,
                prevMomentumEliteKey,
                "false",
                7 * 24 * 60 * 60,
              );
            }
          } catch (activityErr) {
            console.error(
              `[ACTIVITY ERROR] Failed to track activity for ${ticker}:`,
              {
                error: String(activityErr),
                message: activityErr.message,
                stack: activityErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if activity tracking fails
          }

          // Add ingestion timestamp to payload for per-ticker tracking
          const now = Date.now();
          payload.ingest_ts = now; // Timestamp when this data was ingested
          payload.ingest_time = new Date(now).toISOString(); // Human-readable format

          // Attach ML v1 score so UI can display model fields immediately.
          try {
            await mlV1AttachToPayload(KV, payload);
          } catch (e) {
            console.warn(
              `[ML V1] attach failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] About to get previous data and store`);
          }

          // Get previous data BEFORE storing new data (for trade simulation comparison)
          const prevLatest = await kvGetJSON(KV, `timed:latest:${ticker}`);

          // ─────────────────────────────────────────────────────────────
          // Daily change support (watchlist-style)
          // We persist a "yesterday close" per ticker in KV and compute day_change/day_change_pct.
          // ─────────────────────────────────────────────────────────────
          try {
            const curTs = Number(payload.ts ?? now);
            const curDay = nyTradingDayKey(curTs);
            const price = Number(payload.price);

            let prevClose = null;
            const prevCloseKey = `timed:prev_close:${ticker}`;
            const storedPrev = await kvGetJSON(KV, prevCloseKey);
            if (
              storedPrev &&
              storedPrev.day &&
              storedPrev.day !== curDay &&
              Number.isFinite(Number(storedPrev.close)) &&
              Number(storedPrev.close) > 0
            ) {
              prevClose = Number(storedPrev.close);
            }

            // If no stored prev close, derive it on day-boundary from the last stored tick
            if (!Number.isFinite(prevClose) && prevLatest) {
              const prevTs = Number(
                prevLatest.ts ?? prevLatest.ingest_ts ?? prevLatest.ingest_time,
              );
              const prevDay = nyTradingDayKey(prevTs);
              const prevPrice = Number(prevLatest.price);
              if (
                curDay &&
                prevDay &&
                prevDay !== curDay &&
                Number.isFinite(prevPrice) &&
                prevPrice > 0
              ) {
                prevClose = prevPrice;
                // Store for up to ~2 weeks
                await kvPutJSON(
                  KV,
                  prevCloseKey,
                  { day: prevDay, close: prevPrice },
                  14 * 24 * 60 * 60,
                );
              }
            }

            if (
              Number.isFinite(price) &&
              price > 0 &&
              Number.isFinite(prevClose) &&
              prevClose > 0
            ) {
              payload.prev_close = prevClose;
              payload.day_change = price - prevClose;
              payload.day_change_pct = ((price - prevClose) / prevClose) * 100;
            }
          } catch (e) {
            console.warn(
              `[DAILY CHANGE] Failed to compute daily change for ${ticker}:`,
              String(e?.message || e),
            );
          }

          if (ticker === "ETHT") {
            console.log(
              `[ETHT DEBUG] Previous data retrieved, about to store latest`,
            );
          }

          // Attach ML score (v1) so UI can display model output immediately.
          // This is lightweight and does not require D1.
          try {
            await mlV1AttachToPayload(KV, payload);
          } catch (e) {
            console.warn(`[ML_V1] attach failed for ${ticker}:`, String(e));
          }

          // Store latest (do this BEFORE alert so UI has it)
          // Delta-based write: skip if no meaningful change to reduce KV write pressure
          // ALSO skip if replay is in progress (replay's scored state takes precedence)
          const _kvWriteNeeded = hasPayloadChangedMeaningfully(existing, payload);
          if (_kvWriteNeeded && !_replayLockActive) {
            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
          }

          // COST OPTIMIZATION: 1m candle D1 writes REMOVED from ingest handler.
          // 1m candles are not used for core scoring (only optional TD Sequential overlay).
          // Saves ~1.8M D1 writes/month from this path alone.

          // Enqueue for ML training (4h and 1d horizons)
          // COST OPTIMIZATION: Throttle to 1 enqueue per ticker per 5 min using INSERT OR IGNORE.
          // The id = ticker:ts:horizon so same-bucket writes are idempotent.
          // Additional guard: only enqueue on scoring-aligned minutes (divisible by 5).
          if (new Date().getUTCMinutes() % 5 === 0) {
            try {
              await d1EnqueueMlV1(env, ticker, payload, [4 * 60 * 60 * 1000, 24 * 60 * 60 * 1000]);
            } catch (e) {
              console.error(`[ML ENQUEUE] Failed for ${ticker}:`, String(e));
            }
          }

          // ═══════════════════════════════════════════════════════════════════
          // MODEL PREDICTION LOGGING (Phase 2 — Self-Learning Model)
          // Check if this scoring update warrants a prediction. Non-blocking.
          // ═══════════════════════════════════════════════════════════════════
          try {
            const DB = env?.DB;
            if (DB) {
              const predCheck = shouldLogPrediction(payload, existing);
              if (predCheck) {
                ctx.waitUntil((async () => {
                  try {
                    // Match against active pattern library
                    const activePatterns = await getActivePatterns(DB);
                    const matched = matchPatterns(payload, activePatterns);
                    const matchedIds = matched.map((m) => m.pattern_id).join(",");

                    // Use highest-confidence pattern's direction if available
                    const bestMatch = matched.sort((a, b) => (b.confidence || 0) - (a.confidence || 0))[0];

                    // Merge structural flags + TD Sequential features for model persistence
                    const flagsWithTD = {
                      ...(payload.flags || {}),
                      ...(extractTDSeqFeatures(payload) || {}),
                    };

                    await logPrediction(DB, {
                      ticker,
                      ts: Number(payload.ts) || Date.now(),
                      price: Number(payload.price) || 0,
                      direction: predCheck.direction,
                      trigger_type: predCheck.trigger_type,
                      confidence: bestMatch?.confidence > 0.7 ? "high" : bestMatch?.confidence > 0.4 ? "medium" : predCheck.confidence || "low",
                      horizon_days: 5,
                      htf_score: payload.htf_score,
                      ltf_score: payload.ltf_score,
                      state: payload.state,
                      completion: payload.completion,
                      phase_pct: payload.phase_pct,
                      rank: payload.rank,
                      kanban_stage: payload.kanban_stage,
                      entry_path: predCheck.entry_path || payload.__entry_path,
                      entry_reason: predCheck.entry_reason || payload.__entry_reason,
                      sector: payload.sector,
                      flags_json: JSON.stringify({
                        ...flagsWithTD,
                        // Phase 1a/2b/3a: entry quality + swing consensus + volatility for model learning
                        entry_quality_score: payload.entry_quality?.score ?? null,
                        entry_quality_structure: payload.entry_quality?.structure ?? null,
                        entry_quality_momentum: payload.entry_quality?.momentum ?? null,
                        swing_consensus_dir: payload.swing_consensus?.direction ?? null,
                        swing_consensus_bullish: payload.swing_consensus?.bullish_count ?? null,
                        regime_daily: payload.regime?.daily ?? null,
                        regime_weekly: payload.regime?.weekly ?? null,
                        regime_combined: payload.regime?.combined ?? null,
                        volatility_tier: payload.volatility_tier ?? null,
                        volatility_atr_pct: payload.volatility_atr_pct ?? null,
                      }),
                      matched_patterns: matchedIds || null,
                    });
                  } catch (e) {
                    console.warn(`[MODEL] Prediction log failed for ${ticker}:`, String(e?.message || e).slice(0, 200));
                  }
                })());
              }
            }
          } catch (e) {
            // Model logging should never break the ingest flow
            console.warn(`[MODEL] Prediction check failed:`, String(e?.message || e).slice(0, 100));
          }

          // Upsert latest snapshot to D1 for fast UI reads (best-effort)
          try {
            ctx.waitUntil(d1UpsertTickerLatest(env, ticker, payload));
            ctx.waitUntil(d1UpsertTickerIndex(env, ticker, payload?.ts));
          } catch {
            // ignore
          }

          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Successfully stored latest data`);
          }

          // Store version-specific snapshot for historical access
          const snapshotVersion = payload.script_version || "unknown";
          if (snapshotVersion !== "unknown") {
            await kvPutJSON(
              KV,
              `timed:snapshot:${ticker}:${snapshotVersion}`,
              payload,
            );
            // Also store timestamp of when this version was last seen
            await kvPutText(
              KV,
              `timed:version:${ticker}:${snapshotVersion}:last_seen`,
              String(payload.ts || Date.now()),
            );
          }

          console.log(
            `[INGEST STORED] ${ticker} - latest data saved at ${new Date(
              now,
            ).toISOString()}`,
          );

          // CRITICAL: Ensure ticker is in index IMMEDIATELY after storage
          // This ensures ticker appears on dashboard even if request is canceled later
          await ensureTickerIndex(KV, ticker);
          if (ticker === "ETHT") {
            console.log(`[ETHT DEBUG] Indexing completed`);
          }

          // CRITICAL: Trade simulation runs BEFORE alert evaluation
          // If a trade is entered, we suppress the alert for this ticker.
          // Wrap in try-catch to prevent trade simulation errors from breaking ingestion
          try {
            // Pre-check: Calculate entry RR first to avoid unnecessary processing
            // Use trigger_price if available, otherwise use current price
            const entryPriceForCheck = payload.trigger_price
              ? Number(payload.trigger_price)
              : payload.price
                ? Number(payload.price)
                : null;

            if (entryPriceForCheck && entryPriceForCheck > 0) {
              const entryRRForCheck = computeRRAtTrigger(payload);
              const payloadWithEntryRR = {
                ...payload,
                rr: entryRRForCheck || payload.rr || 0,
              };

              // Only proceed if initial check passes
              if (
                shouldTriggerTradeSimulation(
                  ticker,
                  payloadWithEntryRR,
                  prevLatest,
                )
              ) {
                await processTradeSimulation(
                  KV,
                  ticker,
                  payload,
                  prevLatest,
                  env,
                );
              } else {
                console.log(
                  `[TRADE SIM] ${ticker}: Pre-check failed - entryRR=${
                    entryRRForCheck?.toFixed(2) || "null"
                  }, rank=${payload.rank || 0}, state=${payload.state || "N/A"}`,
                );
              }
            } else {
              console.log(
                `[TRADE SIM] ${ticker}: Skipping - no valid entry price (trigger_price=${payload.trigger_price}, price=${payload.price})`,
              );
            }
          } catch (tradeSimErr) {
            console.error(
              `[TRADE SIM ERROR] Failed to process trade simulation for ${ticker}:`,
              {
                error: String(tradeSimErr),
                message: tradeSimErr.message,
                stack: tradeSimErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if trade simulation fails
          }

          // CRITICAL: Alert evaluation runs after trade simulation
          // Alert evaluation uses corridor state variables loaded above (prevInCorridor, etc.)
          // Wrap in try-catch to prevent alert errors from breaking ingestion
          try {
            // Threshold gates (with Momentum Elite adjustments)
            const momentumElite = !!flags.momentum_elite;

            // Momentum Elite gets relaxed thresholds (higher quality stocks)
            const baseMinRR = Number(env.ALERT_MIN_RR || "1.5");
            const baseMaxComp = Number(env.ALERT_MAX_COMPLETION || "0.4");
            const baseMaxPhase = Number(env.ALERT_MAX_PHASE || "0.6");
            // Adjust thresholds for Momentum Elite (more lenient for quality stocks)
            const minRR = momentumElite
              ? Math.max(1.2, baseMinRR * 0.9)
              : baseMinRR; // Lower RR requirement
            const maxComp = momentumElite
              ? Math.min(0.5, baseMaxComp * 1.25)
              : baseMaxComp; // Allow higher completion
            const maxPhase = momentumElite
              ? Math.min(0.7, baseMaxPhase * 1.17)
              : baseMaxPhase; // Allow higher phase

            // Use current price for dynamic RR calculation (real-time risk/reward)
            // This shows the current R:R based on where price is now, not where it was at trigger
            // This is more accurate for alerts as it reflects the actual current opportunity
            const currentRR = computeRR(payload);
            const rrToUse =
              currentRR != null
                ? currentRR
                : payload.rr != null
                  ? Number(payload.rr)
                  : 0;
            const rrOk = rrToUse >= minRR;
            const compOk =
              payload.completion == null
                ? true
                : Number(payload.completion) <= maxComp;
            const phaseOk =
              payload.phase_pct == null
                ? true
                : Number(payload.phase_pct) <= maxPhase;

            // Also consider Momentum Elite as a trigger condition (quality signal)
            // Momentum Elite can trigger even if not fully aligned, as long as in corridor
            const momentumEliteTrigger =
              momentumElite && inCorridor && (corridorAlignedOK || sqRel);

            // Enhanced trigger: original conditions OR Momentum Elite in good setup
            const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

            // Debug logging for alert conditions - log all tickers in corridor or entering corridor
            if (inCorridor || enteredCorridor) {
              console.log(`[ALERT DEBUG] ${ticker}:`, {
                inCorridor,
                enteredCorridor,
                prevInCorridor,
                corridorAlignedOK,
                side,
                state: payload.state,
                enteredAligned,
                trigOk,
                trigReason,
                sqRel,
                shouldConsiderAlert,
                momentumEliteTrigger,
                enhancedTrigger,
                rrOk,
                rr: rrToUse,
                rrFromPayload: payload.rr,
                calculatedAtCurrentPrice: currentRR,
                minRR,
                compOk,
                completion: payload.completion,
                maxComp,
                phaseOk,
                phase: payload.phase_pct,
                maxPhase,
                momentumElite,
                flags: payload.flags,
              });
            }

            // Log alert evaluation summary
            console.log(`[ALERT EVAL] ${ticker}:`, {
              enhancedTrigger,
              rrOk,
              rr: rrToUse,
              rrFromPayload: payload.rr,
              calculatedAtCurrentPrice: currentRR,
              compOk,
              completion: payload.completion,
              phaseOk,
              phase: payload.phase_pct,
              allConditionsMet: enhancedTrigger && rrOk && compOk && phaseOk,
            });

            // Enhanced logging for alert conditions - log what's blocking alerts
            if (inCorridor && !(enhancedTrigger && rrOk && compOk && phaseOk)) {
              const blockers = [];
              if (!enhancedTrigger) blockers.push("trigger conditions");
              if (!rrOk)
                blockers.push(
                  `RR (${
                    rrToUse?.toFixed(2) || "null"
                  } < ${minRR}, payload.rr=${
                    payload.rr?.toFixed(2) || "null"
                  }, currentRR=${currentRR?.toFixed(2) || "null"})`,
                );
              if (!compOk)
                blockers.push(
                  `Completion (${
                    payload.completion?.toFixed(2) || "null"
                  } > ${maxComp})`,
                );
              if (!phaseOk)
                blockers.push(
                  `Phase (${
                    payload.phase_pct?.toFixed(2) || "null"
                  } > ${maxPhase})`,
                );

              console.log(
                `[ALERT BLOCKED] ${ticker}: Alert blocked by: ${blockers.join(
                  ", ",
                )}`,
              );
            }

            // Trade simulation already processed above (before alert logic)

            // Check Discord configuration before evaluating conditions
            const discordEnable = env.DISCORD_ENABLE || "false";
            const discordWebhook = env.DISCORD_WEBHOOK_URL;
            const discordConfigured =
              discordEnable === "true" && !!discordWebhook;

            if (!discordConfigured && (inCorridor || enteredCorridor)) {
              console.log(
                `[DISCORD CONFIG] ${ticker}: Discord not configured`,
                {
                  DISCORD_ENABLE: discordEnable,
                  hasWebhook: !!discordWebhook,
                  inCorridor,
                  enteredCorridor,
                },
              );
            }

            const tradeSide = side || getTradeDirection(payload.state);
            
            // D1: Check for open position using D1 as single source of truth
            const d1OpenPosition = env?.DB ? await getPositionContext(env, ticker) : null;
            const hasOpenPosition = !!(d1OpenPosition && d1OpenPosition.status === "OPEN");
            
            // Fallback to KV trade lookup (will be deprecated)
            const openTrade = !hasOpenPosition ? (tradeSide
              ? await findOpenTradeForTicker(KV, ticker, tradeSide)
              : await findOpenTradeForTicker(KV, ticker, null)) : null;
            
            // Anti-churning check: limit trades per ticker per day
            const tradeFrequency = env?.DB ? await checkTradeFrequency(env, ticker) : { blocked: false };
            if (tradeFrequency.blocked) {
              console.log(
                `[ALERT SKIPPED] ${ticker}: Anti-churning block - ${tradeFrequency.reason} (${tradeFrequency.message})`,
              );
            } else if (hasOpenPosition || openTrade) {
              console.log(
                `[ALERT SKIPPED] ${ticker}: Trade already open (${
                  d1OpenPosition?.direction || openTrade?.direction || "UNKNOWN"
                }, source: ${hasOpenPosition ? "D1" : "KV"})`,
              );
            } else if (enhancedTrigger && rrOk && compOk && phaseOk) {
              // Smart dedupe: action + direction + UTC minute bucket (prevents duplicates but allows valid re-alerts)
              const action = "ENTRY";
              const alertEventTs = Number(
                payload.trigger_ts || payload.ts || Date.now(),
              );
              const dedupeInfo = buildAlertDedupeKey({
                ticker,
                action,
                side,
                ts: alertEventTs,
              });
              const akey = dedupeInfo.key;
              const today =
                dedupeInfo.day || new Date().toISOString().split("T")[0];
              const alreadyAlerted = akey ? await KV.get(akey) : null;

              console.log(`[ALERT CHECK] ${ticker}:`, {
                enhancedTrigger,
                rrOk,
                compOk,
                phaseOk,
                allConditionsMet: true,
                today,
                akey,
                dedupe_bucket: dedupeInfo.bucket,
                action,
                alreadyAlerted: !!alreadyAlerted,
                trigger_ts: payload.trigger_ts,
                ts: payload.ts,
              });

              if (!alreadyAlerted) {
                // Store deduplication key for 48 hours (covers edge cases around midnight)
                if (akey) {
                  await kvPutText(KV, akey, "1", 48 * 60 * 60);
                }

                console.log(`[DISCORD ALERT] Sending alert for ${ticker}`, {
                  akey,
                  today,
                  dedupe_bucket: dedupeInfo.bucket,
                  action,
                  side,
                  rank: payload.rank,
                  discordConfigured,
                  DISCORD_ENABLE: discordEnable,
                  hasWebhook: !!discordWebhook,
                });

                const alertTs = alertEventTs;
                const alertPayloadJson = (() => {
                  try {
                    return JSON.stringify(payload);
                  } catch {
                    return null;
                  }
                })();
                const alertMetaJson = (() => {
                  try {
                    return JSON.stringify({
                      akey,
                      today,
                      dedupe_bucket: dedupeInfo.bucket,
                      action,
                      alreadyAlerted: false,
                      side,
                      state: payload.state,
                      rank: payload.rank,
                      rr: rrToUse,
                      rrFromPayload: payload.rr,
                      calculatedAtCurrentPrice: currentRR,
                      thresholds: { minRR, maxComp, maxPhase },
                      checks: {
                        inCorridor,
                        enteredCorridor,
                        prevInCorridor,
                        corridorAlignedOK,
                        enteredAligned,
                        trigOk,
                        trigReason,
                        sqRel,
                        shouldConsiderAlert,
                        momentumEliteTrigger,
                        enhancedTrigger,
                        rrOk,
                        compOk,
                        phaseOk,
                      },
                      discordConfigured,
                    });
                  } catch {
                    return null;
                  }
                })();

                const why =
                  (side === "LONG"
                    ? "Entry corridor Q1→Q2"
                    : "Entry corridor Q4→Q3") +
                  (momentumElite ? " | 🚀 Momentum Elite" : "") +
                  (enteredAligned ? " | Entered aligned" : "") +
                  (trigReason
                    ? ` | ${trigReason}${
                        payload.trigger_dir
                          ? " (" + payload.trigger_dir + ")"
                          : ""
                      }`
                    : "") +
                  (sqRel ? " | ⚡ squeeze release" : "");

                const tv = `https://www.tradingview.com/chart/?symbol=${encodeURIComponent(
                  ticker,
                )}`;

                // Create Discord embed for trading opportunity
                // Calculate current R:R using current price (not trigger price)
                // This gives accurate R:R based on where price is now
                const currentRR = computeRR(payload);
                const rr = currentRR != null ? currentRR : payload.rr || 0;

                // Process TP levels with metadata
                const currentPrice = Number(payload.price) || 0;
                let tpLevels = [];
                let maxTP = Number(payload.tp);
                let minTP = Number(payload.tp);

                if (
                  payload.tp_levels &&
                  Array.isArray(payload.tp_levels) &&
                  payload.tp_levels.length > 0
                ) {
                  tpLevels = payload.tp_levels
                    .map((tpItem) => {
                      if (
                        typeof tpItem === "object" &&
                        tpItem !== null &&
                        tpItem.price != null
                      ) {
                        const price = Number(tpItem.price);
                        if (!Number.isFinite(price) || price <= 0) return null;
                        return {
                          price,
                          source: tpItem.source || "ATR Level",
                          type: tpItem.type || "ATR_FIB",
                          timeframe: tpItem.timeframe || "D",
                          confidence: Number(tpItem.confidence || 0.75),
                          multiplier: tpItem.multiplier
                            ? Number(tpItem.multiplier)
                            : null,
                          label: tpItem.label || "TP",
                        };
                      }
                      const price =
                        typeof tpItem === "number"
                          ? Number(tpItem)
                          : Number(tpItem);
                      if (!Number.isFinite(price) || price <= 0) return null;
                      return {
                        price,
                        source: "ATR Level",
                        type: "ATR_FIB",
                        timeframe: "D",
                        confidence: 0.75,
                        multiplier: null,
                        label: "TP",
                      };
                    })
                    .filter((tp) => tp !== null);

                  if (tpLevels.length > 0) {
                    const tpPrices = tpLevels.map((tp) => tp.price);
                    maxTP = Math.max(...tpPrices);
                    minTP = Math.min(...tpPrices);
                  }
                }

                // Add primary TP if not already in levels
                const primaryTP = Number(payload.tp);
                if (Number.isFinite(primaryTP) && primaryTP > 0) {
                  const exists = tpLevels.some(
                    (tp) => Math.abs(tp.price - primaryTP) < 0.01,
                  );
                  if (!exists) {
                    tpLevels.push({
                      price: primaryTP,
                      source: "Primary TP",
                      type: "ATR_FIB",
                      timeframe: "D",
                      confidence: 0.75,
                      multiplier: null,
                      label: "TP",
                    });
                  }
                }

                // Sort TP levels by price (ascending for LONG, descending for SHORT)
                const state = String(payload.state || "");
                const isLong = state.includes("BULL");
                tpLevels.sort((a, b) =>
                  isLong ? a.price - b.price : b.price - a.price,
                );

                const rrFormatted =
                  rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;

                // Calculate distance to TP and SL from current price
                const distanceToMaxTP =
                  maxTP > 0 ? Math.abs(maxTP - currentPrice) : 0;
                const distanceToSL =
                  Number(payload.sl) > 0
                    ? Math.abs(currentPrice - Number(payload.sl))
                    : 0;
                const maxTPDistancePct =
                  currentPrice > 0
                    ? ((distanceToMaxTP / currentPrice) * 100).toFixed(2)
                    : "0.00";
                const slDistancePct =
                  currentPrice > 0
                    ? ((distanceToSL / currentPrice) * 100).toFixed(2)
                    : "0.00";

                // Generate comprehensive trade opportunity interpretation
                const interpretation = generateTradeActionInterpretation(
                  "ENTRY",
                  payload,
                  {
                    direction: side,
                    rank: payload.rank,
                    rr: rr,
                  },
                );

                // Build comprehensive fields similar to Trade Entered card
                const fields = [];

                // Action & Reasoning (comprehensive explanation)
                if (interpretation) {
                  fields.push({
                    name: "📊 Why This Is A Trade Opportunity",
                    value: `${interpretation.action}\n\n${interpretation.reasons}`,
                    inline: false,
                  });
                } else {
                  // Fallback detailed explanation
                  const reasons = [];
                  if (inCorridor) reasons.push("✅ Price is in entry corridor");
                  if (corridorAlignedOK)
                    reasons.push("✅ Timeframes are aligned");
                  if (enhancedTrigger)
                    reasons.push("✅ Trigger conditions met");
                  if (momentumElite) reasons.push("⭐ Momentum Elite stock");
                  if (rr >= 1.5)
                    reasons.push(`💰 Excellent R:R (${rrFormatted})`);
                  if (payload.rank >= 75)
                    reasons.push(`⭐ High rank (${payload.rank})`);

                  fields.push({
                    name: "📊 Why This Is A Trade Opportunity",
                    value:
                      reasons.length > 0
                        ? reasons.join("\n")
                        : why || "Trade opportunity detected",
                    inline: false,
                  });
                }

                // Entry Details
                fields.push({
                  name: "💰 Entry Details",
                  value: `**Trigger Price:** $${fmt2(
                    payload.trigger_price,
                  )}\n**Current Price:** $${fmt2(
                    payload.price,
                  )}\n**Stop Loss:** $${fmt2(
                    payload.sl,
                  )} (${slDistancePct}% away)`,
                  inline: false,
                });

                // TP Levels with detailed breakdown
                if (tpLevels.length > 0) {
                  const tpLevelText = tpLevels
                    .map((tp) => {
                      const distance = Math.abs(tp.price - currentPrice);
                      const distancePct =
                        currentPrice > 0
                          ? ((distance / currentPrice) * 100).toFixed(2)
                          : "0.00";
                      const isMax = Math.abs(tp.price - maxTP) < 0.01;
                      const prefix = isMax ? "**⭐ MAX TP:**" : `**TP:**`;
                      const typeLabel =
                        tp.type === "STRUCTURE"
                          ? "Structure"
                          : tp.type === "ATR_FIB"
                            ? tp.multiplier
                              ? `ATR×${tp.multiplier}`
                              : "ATR Fib"
                            : tp.type;
                      const tfLabel =
                        tp.timeframe === "W"
                          ? "Weekly"
                          : tp.timeframe === "D"
                            ? "Daily"
                            : tp.timeframe === "240" || tp.timeframe === "4H"
                              ? "4H"
                              : tp.timeframe;
                      return `${prefix} $${tp.price.toFixed(
                        2,
                      )} (${distancePct}% away) - ${typeLabel} @ ${tfLabel} (${(
                        tp.confidence * 100
                      ).toFixed(0)}% conf)`;
                    })
                    .join("\n");

                  fields.push({
                    name: "🎯 Take Profit Levels",
                    value: tpLevelText,
                    inline: false,
                  });
                } else {
                  // Fallback if no TP levels
                  const distanceToTP =
                    primaryTP > 0 ? Math.abs(primaryTP - currentPrice) : 0;
                  const tpDistancePct =
                    currentPrice > 0
                      ? ((distanceToTP / currentPrice) * 100).toFixed(2)
                      : "0.00";
                  const tpVeryClose =
                    currentPrice > 0 && distanceToTP / currentPrice < 0.005;
                  const tpWarning = tpVeryClose ? " ⚠️ Very close!" : "";

                  fields.push({
                    name: "🎯 Take Profit",
                    value: `**Primary TP:** $${fmt2(
                      primaryTP,
                    )} (${tpDistancePct}% away)${tpWarning}`,
                    inline: false,
                  });
                }

                // Scores & Metrics
                const htfScore = Number(payload.htf_score || 0);
                const ltfScore = Number(payload.ltf_score || 0);
                const completion = Number(payload.completion || 0);
                const phase = Number(payload.phase_pct || 0);

                fields.push({
                  name: "📈 Scores & Metrics",
                  value: `**HTF Score:** ${htfScore.toFixed(
                    2,
                  )}\n**LTF Score:** ${ltfScore.toFixed(2)}\n**Completion:** ${(
                    completion * 100
                  ).toFixed(1)}%\n**Phase:** ${(phase * 100).toFixed(1)}%`,
                  inline: true,
                });

                // Quality Metrics
                fields.push({
                  name: "⭐ Quality Metrics",
                  value: `**Rank:** ${
                    payload.rank
                  }\n**Risk/Reward:** ${rrFormatted}${
                    currentRR != null && currentRR !== payload.rr ? " ⚠️" : ""
                  }\n**State:** ${payload.state || "N/A"}\n**ETA:** ${
                    payload.eta_days != null
                      ? `${Number(payload.eta_days).toFixed(1)}d`
                      : "—"
                  }`,
                  inline: true,
                });

                // Active Signals
                if (payload.flags) {
                  const flags = payload.flags;
                  const flagItems = [];
                  if (flags.sq30_release) flagItems.push("🚀 Squeeze Release");
                  if (flags.sq30_on && !flags.sq30_release)
                    flagItems.push("💥 In Squeeze");
                  if (flags.momentum_elite) flagItems.push("⭐ Momentum Elite");
                  if (flags.phase_dot) flagItems.push("⚫ Phase Dot");
                  if (flags.phase_zone_change)
                    flagItems.push("🔄 Phase Zone Change");

                  if (flagItems.length > 0) {
                    fields.push({
                      name: "🚩 Active Signals",
                      value: flagItems.join("\n"),
                      inline: false,
                    });
                  }
                }

                // TD Sequential if available
                if (payload.td_sequential) {
                  const tdSeq = payload.td_sequential;
                  const tdItems = [];
                  if (tdSeq.td9_bullish) tdItems.push("🔢 TD9 Bullish");
                  if (tdSeq.td9_bearish) tdItems.push("🔢 TD9 Bearish");
                  if (tdSeq.td13_bullish) tdItems.push("🔢 TD13 Bullish");
                  if (tdSeq.td13_bearish) tdItems.push("🔢 TD13 Bearish");

                  if (tdItems.length > 0) {
                    fields.push({
                      name: "🔢 TD Sequential",
                      value:
                        tdItems.join("\n") +
                        (tdSeq.boost
                          ? `\n**Boost:** ${Number(tdSeq.boost).toFixed(1)}`
                          : ""),
                      inline: false,
                    });
                  }
                }

                // RSI if available
                if (payload.rsi) {
                  const rsi = payload.rsi;
                  const rsiValue = Number(rsi.value || 0);
                  const rsiLevel = rsi.level || "neutral";
                  const divergence = rsi.divergence || {};

                  let rsiText = `**RSI:** ${rsiValue.toFixed(2)} (${rsiLevel})`;
                  if (divergence.type && divergence.type !== "none") {
                    rsiText += `\n**Divergence:** ${
                      divergence.type === "bullish"
                        ? "🔼 Bullish"
                        : "🔽 Bearish"
                    }`;
                    if (divergence.strength) {
                      rsiText += ` (Strength: ${Number(
                        divergence.strength,
                      ).toFixed(2)})`;
                    }
                  }

                  fields.push({
                    name: "📊 RSI",
                    value: rsiText,
                    inline: false,
                  });
                }

                // EMA Cloud positions if available
                if (
                  payload.daily_ema_cloud ||
                  payload.fourh_ema_cloud ||
                  payload.oneh_ema_cloud
                ) {
                  const cloudItems = [];
                  if (payload.daily_ema_cloud) {
                    const daily = payload.daily_ema_cloud;
                    cloudItems.push(
                      `**Daily (5-8 EMA):** ${daily.position.toUpperCase()}`,
                    );
                  }
                  if (payload.fourh_ema_cloud) {
                    const fourH = payload.fourh_ema_cloud;
                    cloudItems.push(
                      `**4H (8-13 EMA):** ${fourH.position.toUpperCase()}`,
                    );
                  }
                  if (payload.oneh_ema_cloud) {
                    const oneH = payload.oneh_ema_cloud;
                    cloudItems.push(
                      `**1H (13-21 EMA):** ${oneH.position.toUpperCase()}`,
                    );
                  }

                  if (cloudItems.length > 0) {
                    fields.push({
                      name: "☁️ EMA Cloud Positions",
                      value: cloudItems.join("\n"),
                      inline: false,
                    });
                  }
                }

                const allowDiscord = shouldSendDiscordAlert(
                  env,
                  "ALERT_ENTRY",
                  {
                    ticker,
                    side,
                    rank: payload.rank,
                    rr: rrToUse,
                    momentumElite,
                  },
                );

                const opportunityEmbed = {
                  title: `${side === "LONG" ? "🟢" : "🔴"}  Opportunity: ${ticker} ${side}`,
                  color: side === "LONG" ? 0x22c55e : 0xef4444,
                  fields: fields,
                  timestamp: new Date().toISOString(),
                  footer: {
                    text: "Timed Trading Simulator",
                  },
                  url: tv, // Make the title clickable to open TradingView
                };

                const sendRes = allowDiscord
                  ? await notifyDiscord(env, opportunityEmbed)
                  : {
                      ok: false,
                      skipped: true,
                      reason: "suppressed_critical_only",
                    };

                // Persist alert ledger record to D1 (best-effort)
                d1UpsertAlert(env, {
                  ticker,
                  ts: alertTs,
                  side,
                  state: payload.state,
                  rank: payload.rank,
                  rr_at_alert: rrToUse,
                  trigger_reason: trigReason,
                  dedupe_day: today,
                  discord_sent: !!sendRes?.ok,
                  discord_status: sendRes?.status ?? null,
                  discord_error: sendRes?.ok
                    ? null
                    : sendRes?.reason ||
                      sendRes?.statusText ||
                      sendRes?.error ||
                      "discord_send_failed",
                  payload_json: alertPayloadJson,
                  meta_json: alertMetaJson,
                }).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to upsert alert ${ticker}:`,
                    e,
                  );
                });

                // Log Discord alert to activity feed
                if (sendRes?.ok) {
                  await appendActivity(KV, {
                    ticker,
                    type: "discord_alert",
                    direction: side,
                    action: "entry",
                    rank: payload.rank,
                    rr: payload.rr,
                    price: payload.price,
                    trigger_price: payload.trigger_price,
                    sl: payload.sl,
                    tp: payload.tp,
                    state: payload.state,
                    htf_score: payload.htf_score,
                    ltf_score: payload.ltf_score,
                    completion: payload.completion,
                    phase_pct: payload.phase_pct,
                    why: why,
                    momentum_elite: momentumElite,
                  });
                }
              } else {
                console.log(
                  `[DISCORD ALERT] Skipped ${ticker} - already alerted`,
                  {
                    akey,
                    today,
                    dedupe_bucket: dedupeInfo.bucket,
                    action,
                  },
                );

                // Persist deduped alert decision to D1 (best-effort)
                const alertTs = alertEventTs;
                const alertPayloadJson = (() => {
                  try {
                    return JSON.stringify(payload);
                  } catch {
                    return null;
                  }
                })();
                const alertMetaJson = (() => {
                  try {
                    return JSON.stringify({
                      akey,
                      today,
                      dedupe_bucket: dedupeInfo.bucket,
                      action,
                      alreadyAlerted: true,
                      side,
                      state: payload.state,
                      rank: payload.rank,
                      rr: rrToUse,
                      rrFromPayload: payload.rr,
                      calculatedAtCurrentPrice: currentRR,
                      thresholds: { minRR, maxComp, maxPhase },
                      checks: {
                        inCorridor,
                        enteredCorridor,
                        prevInCorridor,
                        corridorAlignedOK,
                        enteredAligned,
                        trigOk,
                        trigReason,
                        sqRel,
                        shouldConsiderAlert,
                        momentumEliteTrigger,
                        enhancedTrigger,
                        rrOk,
                        compOk,
                        phaseOk,
                      },
                      discordConfigured,
                    });
                  } catch {
                    return null;
                  }
                })();
                d1UpsertAlert(env, {
                  ticker,
                  ts: alertTs,
                  side,
                  state: payload.state,
                  rank: payload.rank,
                  rr_at_alert: rrToUse,
                  trigger_reason: trigReason,
                  dedupe_day: today,
                  discord_sent: false,
                  discord_status: null,
                  discord_error: "deduped_already_alerted",
                  payload_json: alertPayloadJson,
                  meta_json: alertMetaJson,
                }).catch((e) => {
                  console.error(
                    `[D1 LEDGER] Failed to upsert deduped alert ${ticker}:`,
                    e,
                  );
                });
              }
            } else if (inCorridor && corridorAlignedOK) {
              // Log why alert didn't fire
              const reasons = [];
              if (!enhancedTrigger) reasons.push("no trigger condition");
              if (!rrOk)
                reasons.push(
                  `RR ${rrToUse?.toFixed(2) || "null"} < ${minRR} (payload.rr=${
                    payload.rr?.toFixed(2) || "null"
                  })`,
                );
              if (!compOk)
                reasons.push(`Completion ${payload.completion} > ${maxComp}`);
              if (!phaseOk)
                reasons.push(`Phase ${payload.phase_pct} > ${maxPhase}`);
              console.log(`[ALERT SKIPPED] ${ticker}: ${reasons.join(", ")}`);
            }

            // Check for TD9 entry signals (potential reversal setups)
            // NOTE: td_sequential now preferably computed server-side from D/W/M candles
            // (via computeTDSequentialMultiTF in indicators.js). Webhook data serves as fallback.
            const tdSeq = payload.td_sequential || {};
            const td9Bullish =
              tdSeq.td9_bullish === true || tdSeq.td9_bullish === "true";
            const td9Bearish =
              tdSeq.td9_bearish === true || tdSeq.td9_bearish === "true";
            const td13Bullish =
              tdSeq.td13_bullish === true || tdSeq.td13_bullish === "true";
            const td13Bearish =
              tdSeq.td13_bearish === true || tdSeq.td13_bearish === "true";

            // TD9 entry signal: TD9/TD13 bullish suggests LONG, TD9/TD13 bearish suggests SHORT
            const hasTD9Signal =
              td9Bullish || td9Bearish || td13Bullish || td13Bearish;
            if (hasTD9Signal) {
              const suggestedDirection =
                td9Bullish || td13Bullish ? "LONG" : "SHORT";
              const signalType = td13Bullish || td13Bearish ? "TD13" : "TD9";

              // Check if TD9 signal aligns with corridor direction (potential entry)
              const td9AlignsWithCorridor =
                (suggestedDirection === "LONG" && side === "LONG") ||
                (suggestedDirection === "SHORT" && side === "SHORT");

              // Only alert if TD9 signal aligns with corridor and has reasonable RR
              if (td9AlignsWithCorridor && payload.rr >= 1.2) {
                const td9AlertKey = `timed:td9_alerted:${ticker}:${signalType}:${suggestedDirection}`;
                const alreadyTD9Alerted = await KV.get(td9AlertKey);

                if (!alreadyTD9Alerted) {
                  await kvPutText(KV, td9AlertKey, "1", 24 * 60 * 60); // 24h dedup

                  // Add activity feed event
                  await appendActivity(KV, {
                    ticker,
                    type: "td9_entry",
                    direction: suggestedDirection,
                    signalType,
                    price: payload.price,
                    sl: payload.sl,
                    tp: payload.tp,
                    rr: payload.rr,
                    rank: payload.rank,
                    td9_bullish: td9Bullish,
                    td9_bearish: td9Bearish,
                    td13_bullish: td13Bullish,
                    td13_bearish: td13Bearish,
                  });

                  // Send Discord alert (suppressed in critical-only mode)
                  // [DEPRECATED] TD9 entry notification removed — TD context now folded into KANBAN_ENTER embed
                  // The TD signal still contributes to entry qualification; if it triggers KANBAN_ENTER, that embed includes TD context

                  console.log(
                    `[TD9 ENTRY ALERT] ${ticker} ${suggestedDirection} - ${signalType} signal`,
                  );
                }
              }
            }
          } catch (alertErr) {
            console.error(
              `[ALERT ERROR] Failed to process alert evaluation for ${ticker}:`,
              {
                error: String(alertErr),
                message: alertErr.message,
                stack: alertErr.stack,
              },
            );
            // Don't throw - continue with ingestion even if alert evaluation fails
          }

          // Store version-specific snapshot for historical access
          const version = payload.script_version || "unknown";
          if (version !== "unknown") {
            await kvPutJSON(KV, `timed:snapshot:${ticker}:${version}`, payload);
            // Also store timestamp of when this version was last seen
            await kvPutText(
              KV,
              `timed:version:${ticker}:${version}:last_seen`,
              String(payload.ts || Date.now()),
            );
          }

          await ensureTickerIndex(KV, ticker);
          await kvPutText(KV, "timed:last_ingest_ms", String(Date.now()));

          // Get current ticker count for logging
          const currentTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const wasNewTicker = !currentTickers.includes(ticker);
          console.log(
            `[INGEST COMPLETE] ${ticker} - ${
              wasNewTicker ? "NEW TICKER ADDED" : "updated existing"
            } - Total tickers in index: ${currentTickers.length} - Version: ${
              payload.script_version || "unknown"
            }`,
          );

          // Log all tickers in index if count is low (to debug missing tickers)
          if (currentTickers.length < 130) {
            console.log(
              `[INGEST INDEX DEBUG] Current tickers (${currentTickers.length}):`,
              currentTickers.slice(0, 30).join(", "),
              currentTickers.length > 30
                ? `... (showing first 30 of ${currentTickers.length})`
                : "",
            );
          }

          // Get final ticker count
          const finalTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          console.log(
            `[INGEST SUCCESS] ${ticker} - completed successfully. Total tickers: ${finalTickers.length}`,
          );
          return ackJSON(
            env,
            { ok: true, ticker, totalTickers: finalTickers.length },
            200,
            req,
          );
        } catch (error) {
          // Catch any unexpected errors during ingestion
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          const ticker = normTicker(body?.ticker) || "UNKNOWN";
          console.error(`[INGEST ERROR] ${ticker} - IP: ${ip}`, {
            error: String(error),
            stack: error.stack,
            message: error.message,
            body: body ? { ticker: body.ticker, ts: body.ts } : null,
          });
          // Return 500 instead of 429 to avoid confusion
          return ackJSON(
            env,
            {
              ok: false,
              error: "internal_error",
              message: "An error occurred during ingestion",
              ticker: ticker !== "UNKNOWN" ? ticker : null,
            },
            500,
            req,
          );
        }
      }

      // POST /timed/heartbeat (minimal KV + D1 fallback for new tickers)
      // Accepts ALL tickers. If ticker not in D1, creates minimal entry so it appears in UI.
      if (routeKey === "POST /timed/heartbeat") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const hbRate = await checkRateLimit(KV, ip, "/timed/heartbeat", 15000, 3600);
        if (!hbRate.allowed) {
          return sendJSON({ ok: false, error: "rate_limit_exceeded", retryAfter: 3600 }, 429, corsHeaders(env, req));
        }
        let body = null;
        try {
          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData;
          if (!body) {
            return ackJSON(env, { ok: false, error: "bad_json" }, 400, req);
          }
          const ticker = normTicker(body?.ticker);
          if (!ticker) {
            return ackJSON(env, { ok: false, error: "missing_ticker" }, 400, req);
          }
          const HEARTBEAT_TTL = 2 * 24 * 60 * 60; // 2 days
          const payload = {
            ticker,
            ts: body.ts ?? body.time_close ?? Date.now(),
            price: body.price,
            prev_close: body.prev_close ?? body.previous_close,
            day_change: body.day_change ?? body.change,
            day_change_pct: body.day_change_pct ?? body.change_pct,
            session: body.session,
            is_rth: body.is_rth,
            ingest_ts: Date.now(),
            ingest_kind: "heartbeat_minimal",
          };
          await kvPutJSON(KV, `timed:heartbeat:${ticker}`, payload, HEARTBEAT_TTL);
          // For new tickers: create minimal D1 entry so they appear in UI (accept all, no restrictions)
          try {
            if (env?.DB) {
              await d1EnsureLatestSchema(env);
              const existing = await env.DB.prepare(`SELECT 1 FROM ticker_latest WHERE ticker = ?1`).bind(ticker).first();
              if (!existing) {
                await d1UpsertTickerLatest(env, ticker, payload);
                await ensureTickerIndex(KV, ticker);
                await d1UpsertTickerIndex(env, ticker, payload.ts);
              }
            }
          } catch (e) {
            console.warn(`[HEARTBEAT] D1/index fallback failed for ${ticker}:`, String(e?.message || e));
          }
          return ackJSON(env, { ok: true, ticker }, 200, req);
        } catch (e) {
          console.error("[HEARTBEAT] Error:", e);
          return ackJSON(env, { ok: false, error: "internal_error" }, 500, req);
        }
      }

      // POST /timed/ingest-capture (capture-only heartbeat)
      if (routeKey === "POST /timed/ingest-capture") {
        let body = null;
        try {
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          console.log(
            `[CAPTURE INGEST RECEIVED] IP: ${ip}, User-Agent: ${
              req.headers.get("User-Agent") || "none"
            }`,
          );

          const authFail = requireKeyOr401(req, env);
          if (authFail) return authFail;

          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData;
          if (!body) {
            return ackJSON(
              env,
              {
                ok: false,
                error: "bad_json",
                sample: String(raw || "").slice(0, 200),
                parseError: String(err || ""),
              },
              400,
              req,
            );
          }

          const v = validateCapturePayload(body);
          if (!v.ok) return ackJSON(env, v, 400, req);

          const ticker = v.ticker;
          const payload = v.payload;
          const rawPayload =
            typeof raw === "string"
              ? raw
              : (() => {
                  try {
                    return JSON.stringify(body);
                  } catch {
                    return "";
                  }
                })();

          // Store raw capture payload separately for audit
          try {
            if (rawPayload) {
              await kvPutText(
                KV,
                `timed:capture:raw:${ticker}`,
                rawPayload,
                2 * 24 * 60 * 60,
              );
            }
          } catch (rawErr) {
            console.error(
              `[CAPTURE RAW] KV store failed for ${ticker}:`,
              rawErr,
            );
          }

          d1InsertIngestReceipt(env, ticker, payload, rawPayload).catch(
            (err) => {
              console.error(
                `[D1 CAPTURE] Receipt insert exception for ${ticker}:`,
                err,
              );
            },
          );

          const now = Date.now();
          payload.ingest_ts = now;
          payload.ingest_time = new Date(now).toISOString();

          // Compute Momentum Elite for capture payload too (display-only enrichment).
          // This lets the UI show 🚀 + criteria even if the ticker's scoring feed is separate.
          try {
            payload.flags =
              payload.flags && typeof payload.flags === "object"
                ? payload.flags
                : {};
            const m = await computeMomentumElite(KV, ticker, payload);
            if (m) {
              payload.flags.momentum_elite = !!m.momentum_elite;
              payload.momentum_elite_criteria = m.criteria;
            }
          } catch (e) {
            console.error(
              `[CAPTURE MOMENTUM] Failed for ${ticker}:`,
              String(e),
            );
          }

          // Persist context separately so it survives bars where context is omitted.
          // The capture heartbeat throttles context and otherwise sends a minimal payload;
          // without this, `timed:capture:latest:*` gets overwritten and context disappears.
          try {
            if (payload.context && typeof payload.context === "object") {
              // Avoid downgrading richer context (e.g. keep name/description if a later payload omits them).
              const incoming = sanitizeTickerContext(payload.context, payload);
              const saved = await kvGetJSON(KV, `timed:context:${ticker}`);
              const merged = mergeTickerContext(saved, incoming);
              await kvPutJSON(
                KV,
                `timed:context:${ticker}`,
                merged || incoming || payload.context,
                30 * 24 * 60 * 60,
              );
            }
          } catch (e) {
            console.error(
              `[CAPTURE CONTEXT] KV store failed for ${ticker}:`,
              String(e),
            );
          }

          await kvPutJSON(KV, `timed:capture:latest:${ticker}`, payload);
          // Best-effort: persist the heartbeat daily-change fields into D1 ticker_latest so /timed/all stays KV-free.
          try {
            ctx.waitUntil(
              d1PatchTickerLatestFields(env, ticker, {
                prev_close: payload.prev_close,
                day_change: payload.day_change,
                day_change_pct: payload.day_change_pct,
                change: payload.change,
                change_pct: payload.change_pct,
                session: payload.session,
                is_rth: payload.is_rth,
              }),
            );
          } catch {
            // ignore
          }
          await appendCaptureTrail(KV, ticker, {
            ts: payload.ts,
            price: payload.price,
            bar_index: payload.bar_index,
            time_close: payload.time_close,
          });
          await ensureCaptureIndex(KV, ticker);

          await kvPutText(KV, "timed:capture:last_ingest_ms", String(now));

          // COST OPTIMIZATION: 1m candle D1 writes REMOVED from capture handler.
          // 1m candles are not used for core scoring.

          // If payload includes tf_candles, upsert them to D1 (heartbeat can now send both capture + candles).
          if (payload.tf_candles && typeof payload.tf_candles === "object") {
            try {
              await d1EnsureCandleSchema(env);
              for (const [tf, candle] of Object.entries(payload.tf_candles)) {
                if (candle && typeof candle === "object") {
                  ctx.waitUntil(d1UpsertCandle(env, ticker, tf, candle));
                }
              }
            } catch (candleErr) {
              console.error(
                `[CAPTURE CANDLES] Upsert failed for ${ticker}:`,
                String(candleErr),
              );
            }
          }

          // ── Replay lock: skip KV latest writes if a replay is in progress ──
          let _replayLockActive = false;
          try {
            const replayLock = await kvGetJSON(KV, "timed:replay:running");
            if (replayLock && typeof replayLock === "object" && replayLock.since) {
              const lockAge = Date.now() - replayLock.since;
              if (lockAge < 15 * 60 * 1000) {
                _replayLockActive = true;
                console.log(`[CAPTURE] ${ticker} — replay in progress, skipping KV latest write`);
              }
            }
          } catch { /* non-critical */ }

          // --- Server-side re-score when capture has candles but no scores ---
          // The Capture Heartbeat sends OHLCV but not scores. After upserting candles
          // to D1, re-compute scores from the full candle history so timed:latest stays fresh.
          let captureServerScored = false;
          try {
            const hasScoresAlready =
              isNum(payload?.htf_score) &&
              isNum(payload?.ltf_score);
            if (!hasScoresAlready && payload.tf_candles && isNum(payload?.price)) {
              const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);
              const scored = await computeServerSideScores(ticker, d1GetCandles, env, existing);
              if (scored) {
                scored.rank = computeRank(scored);
                scored.score = scored.rank;
                // Merge capture-specific fields into the scored result
                scored.script_version = payload.script_version || scored.script_version;
                scored.session = payload.session ?? scored.session;
                scored.is_rth = payload.is_rth ?? scored.is_rth;
                scored.prev_close = payload.prev_close ?? scored.prev_close;
                scored.day_change = payload.day_change ?? scored.day_change;
                scored.day_change_pct = payload.day_change_pct ?? scored.day_change_pct;
                scored.change = payload.change ?? scored.change;
                scored.change_pct = payload.change_pct ?? scored.change_pct;
                scored.ingest_ts = payload.ingest_ts;
                scored.ingest_time = payload.ingest_time;
                scored.ingest_kind = "capture+server_score";
                // Save to KV + D1 (skip KV if replay in progress)
                if (!_replayLockActive) {
                  await kvPutJSON(KV, `timed:latest:${ticker}`, scored);
                }
                ctx.waitUntil(d1UpsertTickerLatest(env, ticker, scored));
                captureServerScored = true;
                console.log(`[CAPTURE SCORE] ${ticker}: server-side re-scored, price=${scored.price}, htf=${scored.htf_score}, ltf=${scored.ltf_score}`);
              }
            }
          } catch (scoreErr) {
            console.error(`[CAPTURE SCORE] Server-side scoring failed for ${ticker}:`, String(scoreErr));
          }

// Promote capture payload into main latest/trail when it contains full score fields.
          // This fixes the “stale latest despite fresh receipts” issue when some alerts are wired to /ingest-capture.
          try {
            const hasScores =
              isNum(payload?.htf_score) &&
              isNum(payload?.ltf_score) &&
              isNum(payload?.ts);
            if (hasScores && !captureServerScored) {
              // Ensure RR is present (used widely by UI/alerts)
              if (!isNum(payload?.rr)) {
                try {
                  payload.rr = computeRR(payload);
                } catch {
                  // ignore
                }
              }

              // Store latest and trail (KV) and write to D1 trail, but do NOT run alert/discord logic here.
              // Ensure kanban_stage is always computed even on capture-promote path
              try {
                const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);
                // CRITICAL: Merge entry_ts/entry_price from existing so ACTIVE (not Watch) when move passed
                if (existing?.entry_ts != null || existing?.entry_price != null) {
                  if (payload.entry_ts == null && Number.isFinite(Number(existing?.entry_ts)))
                    payload.entry_ts = Number(existing.entry_ts);
                  if (payload.entry_price == null && Number.isFinite(Number(existing?.entry_price)))
                    payload.entry_price = Number(existing.entry_price);
                }
                if (existing?.kanban_cycle_enter_now_ts != null)
                  payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
                if (existing?.kanban_cycle_trigger_ts != null)
                  payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
                if (existing?.kanban_cycle_side != null)
                  payload.kanban_cycle_side = existing.kanban_cycle_side;
                  
                // D1 SINGLE SOURCE OF TRUTH: Get position context from D1 only
                const openPosition = env?.DB ? await getPositionContext(env, ticker) : null;
                const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
                if (hasOpenPosition) {
                  if (payload.entry_ts == null && openPosition.entry_ts) {
                    payload.entry_ts = openPosition.entry_ts;
                  }
                  if (payload.entry_price == null && openPosition.avg_entry_price > 0) {
                    payload.entry_price = openPosition.avg_entry_price;
                  }
                }
                payload.move_status = computeMoveStatus(payload);
                if (payload.flags) {
                  payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
                  payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
                  payload.flags.has_open_position = hasOpenPosition;
                }
                const stage = classifyKanbanStage(payload, openPosition);
                const prevStage = existing?.kanban_stage;
                let finalStage = stage;

                const tsNowCap = Number(payload?.ts) || Date.now();
                const dayKeyCap = nyTradingDayKey(tsNowCap);
                const marketOpenCap = dayKeyCap ? nyWallTimeToUtcMs(dayKeyCap, 9, 30, 0) : null;
                const existingTsCap = existing?.ts ?? existing?.ingest_ts;
                const firstBarAfterGapCap = isFirstBarOfDayAfterGap(existingTsCap, tsNowCap, marketOpenCap);

                // Lifecycle gate: Management stages require open position. Exception: first bar of day after AH/PM gap.
                try {
                  const mgmt =
                    finalStage === "active" ||
                    finalStage === "trim" ||
                    finalStage === "exit" ||
                    finalStage === "hold" ||        // legacy
                    finalStage === "just_entered";  // legacy
                    
                  // If management stage but no open position, force to watch
                  if (mgmt && !hasOpenPosition) {
                    finalStage = "watch";
                    if (!payload.flags) payload.flags = {};
                    payload.flags.forced_watch_no_position = true;
                  }
                  
                  if (mgmt && hasOpenPosition) {
                    const curTriggerTs = Number(payload?.trigger_ts);
                    const curSide = sideFromStateOrScores(payload);
                    const cycleEnterTs = Number(
                      existing?.kanban_cycle_enter_now_ts,
                    );
                    const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
                    const cycleSide =
                      existing?.kanban_cycle_side != null
                        ? String(existing.kanban_cycle_side)
                        : null;
                    const sameTrig =
                      Number.isFinite(curTriggerTs) &&
                      curTriggerTs > 0 &&
                      Number.isFinite(cycleTrig) &&
                      cycleTrig > 0 &&
                      cycleTrig === curTriggerTs;
                    const cycleOk =
                      Number.isFinite(cycleEnterTs) &&
                      cycleEnterTs > 0 &&
                      sameTrig &&
                      !!cycleSide &&
                      !!curSide &&
                      cycleSide === curSide;

                    if (firstBarAfterGapCap) {
                      if (!payload.flags) payload.flags = {};
                      payload.flags.first_bar_of_day_bridge = true;
                    } else {
                      if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                        finalStage = "watch";
                        payload.flags =
                          payload.flags && typeof payload.flags === "object"
                            ? payload.flags
                            : {};
                        payload.flags.forced_watch_missing_trigger = true;
                      } else if (!cycleOk) {
                        finalStage = "enter_now";
                        payload.flags =
                          payload.flags && typeof payload.flags === "object"
                            ? payload.flags
                            : {};
                        payload.flags.forced_enter_now_gate = true;
                      }
                    }
                  }

                  const tsNow = tsNowCap;
                  if (finalStage === "enter_now") {
                    const curTriggerTs = Number(payload?.trigger_ts);
                    const curSide = sideFromStateOrScores(payload);
                    payload.kanban_cycle_enter_now_ts = tsNow;
                    payload.kanban_cycle_trigger_ts =
                      Number.isFinite(curTriggerTs) && curTriggerTs > 0
                        ? curTriggerTs
                        : null;
                    payload.kanban_cycle_side =
                      curSide != null ? String(curSide) : null;
                  } else if (
                    finalStage === "hold" ||
                    finalStage === "just_entered" ||
                    finalStage === "trim" ||
                    finalStage === "exit"
                  ) {
                    if (firstBarAfterGapCap) {
                      payload.kanban_cycle_enter_now_ts = tsNow;
                      payload.kanban_cycle_trigger_ts =
                        Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : tsNow;
                      payload.kanban_cycle_side = sideFromStateOrScores(payload) != null ? String(sideFromStateOrScores(payload)) : null;
                      if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                      if (payload.entry_ts == null && Number.isFinite(tsNow)) payload.entry_ts = tsNow;
                    } else {
                      payload.kanban_cycle_enter_now_ts =
                        existing?.kanban_cycle_enter_now_ts || null;
                      payload.kanban_cycle_trigger_ts =
                        existing?.kanban_cycle_trigger_ts || null;
                      payload.kanban_cycle_side =
                        existing?.kanban_cycle_side || null;
                    }
                  } else {
                    payload.kanban_cycle_enter_now_ts = null;
                    payload.kanban_cycle_trigger_ts = null;
                    payload.kanban_cycle_side = null;
                  }
                } catch (e) {
                  console.error(
                    `[KANBAN] capture-promote lifecycle gate failed for ${ticker}:`,
                    String(e),
                  );
                }

                payload.kanban_stage = finalStage;
                if (
                  prevStage != null &&
                  stage != null &&
                  String(prevStage) !== String(stage)
                ) {
                  payload.prev_kanban_stage = String(prevStage);
                  payload.prev_kanban_stage_ts =
                    Number(payload?.ts) || Date.now();
                } else if (existing?.prev_kanban_stage != null) {
                  payload.prev_kanban_stage = String(
                    existing.prev_kanban_stage,
                  );
                  payload.prev_kanban_stage_ts = Number.isFinite(
                    Number(existing?.prev_kanban_stage_ts),
                  )
                    ? Number(existing.prev_kanban_stage_ts)
                    : null;
                } else {
                  payload.prev_kanban_stage = null;
                  payload.prev_kanban_stage_ts = null;
                }

                // Discord notification for kanban lane transitions (capture-promote path)
                const actionableStages = [
                  "enter",
                  "enter_now",
                  "just_entered",
                  "hold",
                  "defend",
                  "trim",
                  "exit",
                ];
                if (
                  prevStage != null &&
                  finalStage != null &&
                  String(prevStage) !== String(finalStage) &&
                  actionableStages.includes(finalStage)
                ) {
                  const alertType = `KANBAN_${finalStage.toUpperCase()}`;
                  const tsMs = Number(payload?.ts) || Date.now();
                  const dedupeBucket = Math.floor(tsMs / 900000);
                  const dedupeKey = `timed:discord:kanban:${ticker}:${finalStage}:${dedupeBucket}`;
                  ctx.waitUntil(
                    (async () => {
                      try {
                        const already = await KV.get(dedupeKey);
                        if (already) return;
                        await kvPutText(KV, dedupeKey, "1", 60 * 60);
                        if (!shouldSendDiscordAlert(env, alertType, { ticker }))
                          return;
                        const embed = createKanbanStageEmbed(
                          ticker,
                          finalStage,
                          prevStage,
                          payload,
                        );
                        await notifyDiscord(env, embed).catch((err) => {
                          console.error(
                            `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                            err,
                          );
                        });
                        // In-app notification for kanban stage transition
                        const stageLabels2 = { enter_now: "Entry Signal", hold: "Holding", defend: "Defending", exit: "Exit Signal", setup: "Setup" };
                        await d1InsertNotification(env, {
                          email: null, type: "kanban",
                          title: `${stageLabels2[finalStage] || finalStage.toUpperCase()}: ${ticker}`,
                          body: `${ticker} moved to ${stageLabels2[finalStage] || finalStage} (from ${prevStage || "new"})`,
                          link: `/index-react.html?ticker=${ticker}`,
                        }).catch(() => {});
                      } catch (e) {
                        console.error(
                          `[KANBAN DISCORD] ${ticker} ${finalStage}:`,
                          e,
                        );
                      }
                    })(),
                  );
                }

                if (stage === "enter_now" && prevStage !== "enter_now") {
                  const price = Number(payload?.price);
                  if (Number.isFinite(price) && price > 0) {
                    payload.entry_price = price;
                    payload.entry_ts = payload.ts;
                  }
                }
                if (stage && existing?.entry_price) {
                  payload.entry_price = existing.entry_price;
                  payload.entry_ts = existing.entry_ts;
                }
                if (payload.entry_price) {
                  const entryPrice = Number(payload.entry_price);
                  const currentPrice = Number(payload.price);
                  if (
                    Number.isFinite(entryPrice) &&
                    Number.isFinite(currentPrice) &&
                    entryPrice > 0
                  ) {
                    payload.entry_change_pct =
                      ((currentPrice - entryPrice) / entryPrice) * 100;
                  }
                }
              } catch (e) {
                console.error(
                  `[KANBAN] capture-promote stage compute failed for ${ticker}:`,
                  String(e),
                );
              }

              // Attach ML score (v1) so UI can display model output immediately.
              try {
                await mlV1AttachToPayload(KV, payload);
              } catch (e) {
                console.warn(
                  `[ML_V1] attach failed (capture-promote) for ${ticker}:`,
                  String(e),
                );
              }

              if (!_replayLockActive) {
                await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
              }

              // Upsert latest snapshot to D1 for fast UI reads (best-effort)
              try {
                ctx.waitUntil(d1UpsertTickerLatest(env, ticker, payload));
                ctx.waitUntil(d1UpsertTickerIndex(env, ticker, payload?.ts));
              } catch {
                // ignore
              }
              await appendTrail(
                KV,
                ticker,
                {
                  ts: payload.ts,
                  price: payload.price,
                  htf_score: payload.htf_score,
                  ltf_score: payload.ltf_score,
                  completion: payload.completion,
                  phase_pct: payload.phase_pct,
                  state: payload.state,
                  rank: payload.rank,
                  flags: payload.flags,
                  trigger_reason: payload.trigger_reason,
                  trigger_dir: payload.trigger_dir,
                },
                20,
              );
              d1InsertTrailPoint(env, ticker, payload).catch((e) => {
                console.error(
                  `[D1 CAPTURE→TRAIL] Insert failed for ${ticker}:`,
                  String(e),
                );
              });
              await ensureTickerIndex(KV, ticker);
              await kvPutText(KV, "timed:last_ingest_ms", String(now));
            }
          } catch (promoteErr) {
            console.error(
              `[CAPTURE PROMOTE] Failed for ${ticker}:`,
              String(promoteErr),
            );
          }

          return ackJSON(env, { ok: true, ticker, capture: true }, 200, req);
        } catch (err) {
          console.error(`[CAPTURE INGEST ERROR]`, err);
          return ackJSON(
            env,
            { ok: false, error: String(err?.message || err) },
            500,
            req,
          );
        }
      }

      // POST /timed/ingest-candles (multi-timeframe OHLCV)
      if (routeKey === "POST /timed/ingest-candles") {
        let body = null;
        try {
          const authFail = requireKeyOr401(req, env);
          if (authFail) return authFail;

          const { obj: bodyData, raw, err } = await readBodyAsJSON(req);
          body = bodyData;
          if (!body) {
            return ackJSON(
              env,
              {
                ok: false,
                error: "bad_json",
                sample: String(raw || "").slice(0, 200),
                parseError: String(err || ""),
              },
              400,
              req,
            );
          }

          const v = validateCandlesPayload(body);
          if (!v.ok) return ackJSON(env, v, 400, req);

          const ticker = v.ticker;
          const payload = v.payload;
          const tfCandles = payload?.tf_candles || {};

          // Check if bulk mode (tf_candles values are arrays of candles instead of single candles)
          const isBulk = Object.values(tfCandles).some((val) => Array.isArray(val));

          let okCount = 0;
          let errCount = 0;
          try {
            await d1EnsureCandleSchema(env);
          } catch {
            // ignore
          }

          const db = env?.DB;
          if (!db) {
            return ackJSON(env, { ok: false, error: "no_db_binding" }, 500, req);
          }

          // Collect all valid candle statements for batch execution.
          // This avoids the "Too many API requests" error that occurs with
          // individual d1UpsertCandle calls when TradingView sends bulk data.
          const stmts = [];
          const updatedAt = Date.now();
          const tfKeyNorm = (tf) => normalizeTfKey(tf);

          for (const [tf, candleOrArray] of Object.entries(tfCandles)) {
            const tfKey = tfKeyNorm(tf);
            if (!tfKey) continue;
            const candles = (isBulk && Array.isArray(candleOrArray))
              ? candleOrArray
              : [candleOrArray];
            for (const candle of candles) {
              if (!candle || typeof candle !== "object") continue;
              const ts = Number(candle.ts);
              const o = Number(candle.o);
              const h = Number(candle.h);
              const l = Number(candle.l);
              const c = Number(candle.c);
              const v = candle.v != null ? Number(candle.v) : null;
              if (!Number.isFinite(ts) || ![o, h, l, c].every(x => Number.isFinite(x))) {
                errCount++;
                continue;
              }
              stmts.push(
                db.prepare(
                  `INSERT INTO ticker_candles (ticker, tf, ts, o, h, l, c, v, updated_at)
                   VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9)
                   ON CONFLICT(ticker, tf, ts) DO UPDATE SET
                     o=excluded.o, h=excluded.h, l=excluded.l, c=excluded.c, v=excluded.v,
                     updated_at=excluded.updated_at`
                ).bind(ticker, tfKey, ts, o, h, l, c, v, updatedAt)
              );
            }
          }

          // D1 safe batch limit
          const BATCH_SIZE = 100;
          for (let i = 0; i < stmts.length; i += BATCH_SIZE) {
            const chunk = stmts.slice(i, i + BATCH_SIZE);
            try {
              await db.batch(chunk);
              okCount += chunk.length;
            } catch (batchErr) {
              console.error(`[CANDLES INGEST] Batch ${i / BATCH_SIZE} failed for ${ticker}:`, String(batchErr).slice(0, 200));
              errCount += chunk.length;
            }
          }

          return ackJSON(
            env,
            {
              ok: true,
              ticker,
              ingested: okCount,
              rejected: errCount,
              tfs: Object.keys(tfCandles),
              bulk: isBulk,
            },
            200,
            req,
          );
        } catch (err) {
          console.error(`[CANDLES INGEST ERROR]`, err);
          return ackJSON(
            env,
            { ok: false, error: String(err?.message || err) },
            500,
            req,
          );
        }
      }

      // GET /timed/latest?ticker=
      if (routeKey === "GET /timed/latest") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/latest",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker)
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        // Prefer D1 for reads (single-row query)
        let data = null;
        let d1Stage = null;
        let d1PrevStage = null;
        let d1UpdatedAt = null;
        try {
          if (env?.DB) {
            await d1EnsureLatestSchema(env);
            const row = await env.DB.prepare(
              `SELECT payload_json, kanban_stage, prev_kanban_stage, updated_at
                 FROM ticker_latest
                 WHERE ticker = ?1`,
            )
              .bind(String(ticker || "").toUpperCase())
              .first();
            if (row) {
              d1Stage =
                row.kanban_stage != null ? String(row.kanban_stage) : null;
              d1PrevStage =
                row.prev_kanban_stage != null
                  ? String(row.prev_kanban_stage)
                  : null;
              d1UpdatedAt = Number(row.updated_at);
              if (!Number.isFinite(d1UpdatedAt)) d1UpdatedAt = null;
            }
            if (row && row.payload_json) {
              try {
                data = JSON.parse(String(row.payload_json));
              } catch {
                data = null;
              }
            }
          }
        } catch (e) {
          console.error(`[D1 LATEST] Read failed for ${ticker}:`, String(e));
        }

        // Fallback to KV if D1 misses (and best-effort backfill D1)
        if (!data) {
          data = await kvGetJSON(KV, `timed:latest:${ticker}`);
          if (data) {
            try {
              ctx.waitUntil(d1UpsertTickerLatest(env, ticker, data));
              ctx.waitUntil(d1UpsertTickerIndex(env, ticker, data?.ts));
            } catch {
              // ignore
            }
          }
        }
        const capture = await kvGetJSON(KV, `timed:capture:latest:${ticker}`);
        const heartbeat = await kvGetJSON(KV, `timed:heartbeat:${ticker}`);
        if (data) {
          // Overlay lightweight heartbeat (KV, 2d TTL) for fresh price/daily change
          if (heartbeat && typeof heartbeat === "object") {
            if (Number.isFinite(Number(heartbeat.price))) data.price = heartbeat.price;
            if (heartbeat.prev_close != null) data.prev_close = heartbeat.prev_close;
            if (heartbeat.day_change != null) {
              data.day_change = heartbeat.day_change;
              data.change = heartbeat.day_change;
            }
            if (heartbeat.day_change_pct != null) {
              data.day_change_pct = heartbeat.day_change_pct;
              data.change_pct = heartbeat.day_change_pct;
            }
            if (heartbeat.ingest_ts != null) data.ingest_ts = heartbeat.ingest_ts;
            if (heartbeat.session != null) data.session = heartbeat.session;
            if (heartbeat.is_rth != null) data.is_rth = heartbeat.is_rth;
          }
          // Ensure prev/current lane fields are present even if payload_json is older.
          if (data.kanban_stage == null && d1Stage != null)
            data.kanban_stage = d1Stage;
          if (data.prev_kanban_stage == null && d1PrevStage != null)
            data.prev_kanban_stage = d1PrevStage;
          if (
            data.prev_kanban_stage != null &&
            data.prev_kanban_stage_ts == null &&
            d1UpdatedAt != null
          ) {
            // Best-effort: when we only know "prev stage" from columns, approximate timestamp from row update.
            data.prev_kanban_stage_ts = d1UpdatedAt;
          }
          // Merge capture-only enrichment fields when present (non-destructive).
          // This helps after-hours analytics + Momentum Elite metadata even if heartbeat is wired to /ingest-capture.
          if (capture && typeof capture === "object") {
            // Prefer capture for daily-change fields (more reliable for UI/analysis).
            for (const k of ["prev_close", "day_change", "day_change_pct"]) {
              if (capture[k] != null) data[k] = capture[k];
            }
            for (const k of [
              "session",
              "is_rth",
              "avg_vol_30",
              "avg_vol_50",
              "adr_14",
              "momentum_pct",
              "momentum_elite_criteria",
            ]) {
              if (data[k] == null && capture[k] != null) data[k] = capture[k];
            }
            if (capture.flags && typeof capture.flags === "object") {
              data.flags =
                data.flags && typeof data.flags === "object" ? data.flags : {};
              // Override from capture: score payloads don't compute Momentum Elite reliably.
              if (capture.flags.momentum_elite != null)
                data.flags.momentum_elite = !!capture.flags.momentum_elite;
            }
          }

          // Context enrichment is now delivered via /timed/ingest-capture (throttled in Pine).
          // Merge it opportunistically when present (non-blocking).
          try {
            if (capture && typeof capture === "object") {
              const ctx =
                capture.context && typeof capture.context === "object"
                  ? capture.context
                  : null;
              if (ctx) {
                const cleaned = sanitizeTickerContext(ctx, data);
                data.context = mergeTickerContext(data.context, cleaned || ctx);
              }
            }
          } catch (e) {
            console.error(
              `[CONTEXT] /timed/latest capture merge failed for ${ticker}:`,
              String(e),
            );
          }

          // If capture doesn't include context on this bar, fall back to the persisted context blob.
          try {
            if (!data.context) {
              const saved = await kvGetJSON(KV, `timed:context:${ticker}`);
              if (saved && typeof saved === "object") {
                const cleaned = sanitizeTickerContext(saved, data);
                data.context = cleaned || saved;
              }
            }
          } catch (e) {
            console.error(
              `[CONTEXT] /timed/latest persisted context read failed for ${ticker}:`,
              String(e),
            );
          }

          // Final fallback: derive minimal context from fundamentals/profile fields.
          try {
            if (!data.context) {
              const derived = deriveTickerContext(data);
              if (derived) {
                const cleaned = sanitizeTickerContext(derived, data);
                data.context = cleaned || derived;
              }
            }
          } catch {
            // ignore
          }

          // Ensure Momentum Elite reflects the most recent computed status.
          // Score payloads often default flags.momentum_elite=false; use cached momentum computation when available.
          try {
            const m = await kvGetJSON(KV, `timed:momentum:${ticker}`);
            if (m && typeof m === "object" && m.momentum_elite != null) {
              data.flags =
                data.flags && typeof data.flags === "object" ? data.flags : {};
              data.flags.momentum_elite = !!m.momentum_elite;
              if (data.momentum_elite_criteria == null && m.criteria) {
                data.momentum_elite_criteria = m.criteria;
              }
            }
          } catch {
            // ignore
          }
          // Always recompute RR to ensure it uses the latest max TP from tp_levels
          data.rr = computeRR(data);

          // Ensure watchlist-style daily change is correct (prev trading day 4pm ET close).
          // This is used by the UI header/kanban and should not depend on ingest quirks.
          try {
            if (env?.DB) {
              const asOfTs = Number(data.ts ?? data.ingest_ts ?? Date.now());
              const rec = await computePrevCloseFromTrail(
                env.DB,
                ticker,
                asOfTs,
              );
              const price = Number(data.price);
              // Only backfill if daily-change fields are missing. Heartbeat capture is preferred when present.
              if (
                rec &&
                Number.isFinite(price) &&
                price > 0 &&
                !(
                  Number.isFinite(Number(data.day_change_pct)) &&
                  Number.isFinite(Number(data.day_change))
                )
              ) {
                data.prev_close = rec.close;
                data.day_change = price - rec.close;
                data.day_change_pct = ((price - rec.close) / rec.close) * 100;
              }
            }
          } catch (e) {
            console.warn(
              `[DAILY CHANGE] /timed/latest backfill failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          // Canonicalize daily change: if day_* disagrees with change_* (heartbeat), prefer change_*.
          try {
            const dayPct = Number(data.day_change_pct);
            const altPct = Number(data.change_pct);
            const dayChg = Number(data.day_change);
            const altChg = Number(data.change);
            const price = Number(data.price);
            const hasHeartbeatSession =
              data.session != null || data.is_rth != null;
            // If heartbeat fields are present, treat change/change_pct as authoritative watchlist daily change.
            if (hasHeartbeatSession && Number.isFinite(altPct)) {
              data.day_change_pct = altPct;
              if (Number.isFinite(altChg)) data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            }
            const disagree =
              Number.isFinite(dayPct) &&
              Number.isFinite(altPct) &&
              (dayPct >= 0 !== altPct >= 0 || Math.abs(dayPct - altPct) >= 1.5);
            const absurd = Number.isFinite(dayPct) && Math.abs(dayPct) > 5;
            const saneAlt = Number.isFinite(altPct) && Math.abs(altPct) <= 5;
            if ((disagree || (absurd && saneAlt)) && Number.isFinite(altPct)) {
              data.day_change_pct = altPct;
              if (Number.isFinite(altChg)) data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            } else if (!Number.isFinite(dayPct) && Number.isFinite(altPct)) {
              data.day_change_pct = altPct;
              if (Number.isFinite(altChg)) data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            } else if (!Number.isFinite(dayChg) && Number.isFinite(altChg)) {
              data.day_change = altChg;
              if (Number.isFinite(price) && Number.isFinite(altChg))
                data.prev_close = price - altChg;
            }
          } catch {
            // ignore
          }

          // Back-compat: older KV entries may not have derived horizon/ETA v2 fields yet,
          // or may be missing the newer target TP fields. Compute on-the-fly.
          try {
            if (
              !data.horizon_bucket ||
              data.eta_days_v2 == null ||
              data.tp_target_price == null ||
              data.tp_target_pct == null
            ) {
              const derived = deriveHorizonAndMetrics(data);
              Object.assign(data, derived);
            }
          } catch (e) {
            console.error(
              `[DERIVED METRICS] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }
          // Back-compat: compute entry decision if missing
          try {
            if (!data.entry_decision) {
              data.entry_decision = buildEntryDecision(ticker, data, null);
            }
          } catch (e) {
            console.error(
              `[ENTRY DECISION] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }

          // Back-compat: attach ML v1 fields if missing (for older payloads).
          try {
            if (!data.ml_v1) {
              await mlV1AttachToPayload(KV, data);
            } else if (data.ml == null) {
              data.ml = data.ml_v1;
            }
          } catch (e) {
            console.error(
              `[ML V1] /timed/latest failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          // Back-compat: compute thesis features if missing (older KV entries)
          try {
            const hasThesisMatch =
              data?.flags &&
              typeof data.flags === "object" &&
              data.flags.thesis_match != null;
            const hasSeq = data?.seq && typeof data.seq === "object";
            const hasDeltas = data?.deltas && typeof data.deltas === "object";
            if (!hasThesisMatch || !hasSeq || !hasDeltas) {
              const trail =
                (await kvGetJSON(KV, `timed:trail:${ticker}`)) || null;
              if (trail && Array.isArray(trail) && trail.length >= 2) {
                const computed = computeLiveThesisFeaturesFromTrail(
                  trail,
                  data,
                );
                if (computed && typeof computed === "object") {
                  data.seq = computed.seq;
                  data.deltas = computed.deltas;
                  data.flags =
                    data.flags && typeof data.flags === "object"
                      ? data.flags
                      : {};
                  data.flags.htf_improving_4h =
                    !!computed.flags?.htf_improving_4h;
                  data.flags.htf_improving_1d =
                    !!computed.flags?.htf_improving_1d;
                  data.flags.htf_move_4h_ge_5 =
                    !!computed.flags?.htf_move_4h_ge_5;
                  data.flags.thesis_match = !!computed.flags?.thesis_match;

                  // Persist backfill so future reads don’t need to recompute.
                  try { await kvPutJSON(KV, `timed:latest:${ticker}`, data); } catch { /* non-critical */ }
                }
              }
            }
          } catch (e) {
            console.error(
              `[THESIS FEATURES] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }

          // Back-compat: compute completeness + summaries if missing (older KV entries)
          try {
            if (!data.data_completeness) {
              data.data_completeness = computeDataCompleteness(data);
            }
            if (!data.tf_summary) {
              const tfSum = tfTechAlignmentSummary(data);
              if (tfSum) data.tf_summary = tfSum;
            }
            if (!data.trigger_summary) {
              data.trigger_summary = triggerSummaryAndScore(data);
            }
            if (!data.move_status) {
              data.move_status = computeMoveStatus(data);
            }
            data.flags =
              data.flags && typeof data.flags === "object" ? data.flags : {};
            data.flags.move_invalidated =
              data.move_status?.status === "INVALIDATED";
            data.flags.move_completed =
              data.move_status?.status === "COMPLETED";
          } catch (e) {
            console.error(
              `[ENRICH] /timed/latest failed for ${ticker}:`,
              String(e?.message || e),
            );
          }

          try {
            const corrData = await computeOpenTradesCorrelation(env, KV);
            const corr =
              corrData && corrData.avgCorrByTicker
                ? corrData.avgCorrByTicker[String(ticker).toUpperCase()]
                : null;
            if (corr) {
              data.avg_corr = corr.avg_corr;
              data.diversity_score = corr.diversity_score;
              data.corr_count = corr.corr_count;
            }
          } catch (e) {
            console.error(
              `[CORR] /timed/latest failed for ${ticker}:`,
              String(e),
            );
          }

          // Ensure kanban_stage reflects current logic for Action Center flow
          try {
            const cMax = computeCompletionToTpMax(data);
            if (Number.isFinite(cMax)) data.completion = cMax;
            const rr = computeRR(data);
            if (Number.isFinite(rr)) data.rr = rr;
            const rrTargets = computeRRTargets(data);
            if (rrTargets) Object.assign(data, rrTargets);
            data.move_status = computeMoveStatus(data);
          } catch {
            // ignore
          }
          try {
            data.flags =
              data.flags && typeof data.flags === "object" ? data.flags : {};
            data.flags.move_invalidated =
              data.move_status?.status === "INVALIDATED";
            data.flags.move_completed =
              data.move_status?.status === "COMPLETED";
          } catch {
            // ignore
          }
          try {
            const prevStage =
              data?.kanban_stage != null ? String(data.kanban_stage) : null;
            // CRITICAL: Fetch open position so classifyKanbanStage produces
            // a management-mode stage when there IS an active trade.
            // Without this, read-time recompute can revert "hold" → "setup".
            let readTimePosition = null;
            try {
              if (env?.DB) readTimePosition = await getPositionContext(env, ticker);
            } catch { /* non-critical */ }
            // ── Execution readiness pre-check (smart gates) ──
            // If there's no open position, check concentration + RTH gates
            // so classifyKanbanStage can distinguish "setup" (blocked) from "enter" (ready).
            if (!readTimePosition && env?.DB) {
              try {
                const blockReasons = [];
                // Check RTH
                const nyNowReadTime = new Date(new Date().toLocaleString("en-US", { timeZone: "America/New_York" }));
                const hh = nyNowReadTime.getHours();
                const mm = nyNowReadTime.getMinutes();
                const dayOfWeek = nyNowReadTime.getDay();
                if (dayOfWeek === 0 || dayOfWeek === 6) blockReasons.push("weekend");
                else if (hh < 9 || (hh === 9 && mm < 30) || hh >= 16) blockReasons.push("outside_RTH");
                // Smart concentration gates
                if (!blockReasons.length) {
                  const openPosResult = await env.DB.prepare(
                    `SELECT ticker, direction FROM positions WHERE status = 'OPEN'`
                  ).all();
                  const openPositions = openPosResult?.results || [];
                  const tkSym = String(ticker).toUpperCase();
                  const tkSector = getSector(tkSym) || "UNKNOWN";
                  const entryPathCheck = String(data?.__entry_path || data?.entry_path || data?.state || "").toUpperCase();
                  const tkDir = (entryPathCheck.includes("SHORT") || entryPathCheck.startsWith("HTF_BEAR")) ? "SHORT" : "LONG";
                  // Sector concentration
                  let sectorCnt = 0;
                  for (const p of openPositions) {
                    const pSector = getSector(String(p.ticker).toUpperCase()) || "UNKNOWN";
                    if (pSector === tkSector && tkSector !== "UNKNOWN") sectorCnt++;
                  }
                  if (sectorCnt >= 5) blockReasons.push(`sector_full:${sectorCnt}/5 ${tkSector}`);
                  // Directional concentration
                  let dirCnt = 0;
                  for (const p of openPositions) {
                    if (String(p.direction).toUpperCase() === tkDir) dirCnt++;
                  }
                  if (dirCnt >= 12) blockReasons.push(`direction_full:${dirCnt}/12 ${tkDir}`);
                  // Correlation guard
                  if (sectorCnt >= 3 && !blockReasons.some(r => r.startsWith("sector_full"))) {
                    const eq = Number(data?.entry_quality?.score || data?.__entry_quality) || 0;
                    if (eq > 0 && eq < 75) blockReasons.push(`correlated:${sectorCnt} in ${tkSector}`);
                  }
                }
                // ALWAYS clear stale cron-stored block reasons
                delete data.__entry_block_reason;
                if (blockReasons.length > 0) {
                  data.__execution_ready = false;
                  data.__execution_block_reason = blockReasons.join("+");
                } else {
                  data.__execution_ready = true;
                  delete data.__execution_block_reason;
                }
              } catch { /* non-critical */ }
            }
            const stage = classifyKanbanStage(data, readTimePosition);
            data.kanban_stage = stage;
            data.kanban_meta = deriveKanbanMeta(data, stage);
            // Track lane transitions even on read-time recompute (so UI can show prev lane + highlight).
            if (
              prevStage != null &&
              stage != null &&
              String(prevStage) !== String(stage)
            ) {
              data.prev_kanban_stage = String(prevStage);
              data.prev_kanban_stage_ts = Date.now();
              try {
                ctx.waitUntil(d1UpsertTickerLatest(env, ticker, data));
                ctx.waitUntil(d1UpsertTickerIndex(env, ticker, data?.ts));
              } catch {
                // ignore
              }
            }
          } catch {
            // ignore
          }

          return sendJSON(
            { ok: true, ticker, latestData: data, data },
            200,
            corsHeaders(env, req),
          );
        }
        return sendJSON(
          { ok: false, error: "ticker_not_found", ticker },
          404,
          corsHeaders(env, req),
        );
      }

      // GET /timed/tickers
      if (routeKey === "GET /timed/tickers") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/tickers",
          20000, // Increased: UI polling + multiple tabs
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        // Prefer D1 for reads (fast index table). Merge with KV watchlist so tickers
        // in timed:tickers (and not in timed:removed) always appear even if D1 is out of sync.
        let tickers = [];
        try {
          if (env?.DB) {
            await d1EnsureLatestSchema(env);
            const rows = await env.DB.prepare(
              `SELECT ticker FROM ticker_index ORDER BY ticker ASC`,
            ).all();
            const list = rows?.results || [];
            tickers = list
              .map((r) => String(r.ticker || "").toUpperCase())
              .filter(Boolean);
          }
        } catch (e) {
          console.error(`[D1 LATEST] /timed/tickers read failed:`, String(e));
        }
        const kvTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const removedSet = new Set((await kvGetJSON(KV, "timed:removed")) || []);
        _removedTickersCache = removedSet;
        tickers = tickers.filter((t) => !removedSet.has(t));
        const kvActive = Array.isArray(kvTickers)
          ? kvTickers.map((t) => String(t).toUpperCase()).filter((t) => t && !removedSet.has(t))
          : [];
        const merged = [...new Set([...tickers, ...kvActive])].sort();
        if (merged.length > (tickers.length || 0)) {
          tickers = merged;
          try {
            ctx.waitUntil(d1SyncLatestBatchFromKV(env, ctx, 50));
          } catch {
            // ignore
          }
        } else if (
          !Array.isArray(tickers) ||
          tickers.length === 0
        ) {
          tickers = kvActive.length > 0 ? kvActive : (Array.isArray(kvTickers) ? kvTickers : []);
          try {
            ctx.waitUntil(d1SyncLatestBatchFromKV(env, ctx, 50));
          } catch {
            // ignore
          }
        }
        return sendJSON(
          { ok: true, tickers, count: tickers.length },
          200,
          { ...corsHeaders(env, req), "Cache-Control": "public, max-age=300" },
        );
      }

      // GET /timed/all?version=2.5.0 (optional version parameter)
      if (routeKey === "GET /timed/all") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/all",
          20000,
          3600,
        ); // Increased for single-user

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }
        // KV snapshot fast-path: serve pre-assembled snapshot if fresh (<300s old)
        // Scoring cron rebuilds the snapshot every 5 min, so 300s TTL matches the cycle.
        // Falls through to D1 if snapshot is missing or stale
        try {
          const snapshot = await kvGetJSON(KV, "timed:all:snapshot");
          const SNAPSHOT_MAX_AGE = isWithinOperatingHours() ? 300000 : 86400000;
          if (snapshot?.data && snapshot?.built_at && (Date.now() - snapshot.built_at) < SNAPSHOT_MAX_AGE) {
            const _rawRemoved = (await kvGetJSON(KV, "timed:removed")) || [];
            const removedSet = new Set(Array.isArray(_rawRemoved) ? _rawRemoved : []);
            const userAdded = await d1GetActiveUserTickersCached(env);
            const activeSet = new Set([...Object.keys(SECTOR_MAP), ...userAdded, ...MARKET_PULSE_SYMS]);
            const data = {};
            for (const [sym, payload] of Object.entries(snapshot.data)) {
              if (activeSet.has(sym)) data[sym] = payload;
            }

            // ── Fill gaps: tickers in SECTOR_MAP but missing from snapshot ──
            // Catches tickers like SPX that have D1 data but may lack a
            // timed:latest entry due to KV eventual consistency.
            if (env?.DB) {
              const missingSyms = [...activeSet].filter(s => !data[s]);
              for (const sym of missingSyms) {
                try {
                  const kvPayload = await kvGetJSON(KV, `timed:latest:${sym}`);
                  if (kvPayload && typeof kvPayload === "object" && Number(kvPayload.price) > 0) {
                    data[sym] = kvPayload;
                    continue;
                  }
                  const todayNY = currentTradingDayKey();
                  const cutoffMs = todayNY
                    ? (nyWallTimeToUtcMs(todayNY, 0, 0, 0) || new Date(todayNY + "T00:00:00Z").getTime())
                    : 0;
                  const latestRow = await env.DB.prepare(
                    `SELECT ts, o, h, l, c FROM ticker_candles WHERE ticker = ?1 AND tf = 'D' ORDER BY ts DESC LIMIT 1`
                  ).bind(sym).all();
                  let prevClose = 0;
                  if (cutoffMs > 0) {
                    const prevRow = await env.DB.prepare(
                      `SELECT c FROM ticker_candles WHERE ticker = ?1 AND tf = 'D' AND ts < ?2 ORDER BY ts DESC LIMIT 1`
                    ).bind(sym, cutoffMs).all();
                    if (prevRow?.results?.[0]) prevClose = Number(prevRow.results[0].c) || 0;
                  }
                  if (latestRow?.results?.length >= 1) {
                    const latest = latestRow.results[0];
                    const price = Number(latest.c);
                    if (price > 0) {
                      data[sym] = {
                        ticker: sym, ts: Number(latest.ts), price, close: price,
                        open: Number(latest.o) || price, high: Number(latest.h) || price,
                        low: Number(latest.l) || price,
                        prev_close: prevClose > 0 ? prevClose : undefined,
                        day_change: prevClose > 0 ? price - prevClose : undefined,
                        day_change_pct: prevClose > 0 ? ((price - prevClose) / prevClose) * 100 : undefined,
                        ingest_kind: "d1_gap_fill",
                      };
                    }
                  }
                } catch (_) { /* skip */ }
              }
            }

            // ── Market Pulse placeholders: ensure futures/indices/crypto exist in data ──
            for (const sym of MARKET_PULSE_SYMS) {
              if (!data[sym]) data[sym] = { ticker: sym };
            }

            // ── Overlay live prices + daily change from timed:prices ──
            // The scoring cron builds the snapshot every 5 min, but timed:prices is updated
            // every minute by the price feed. This overlay ensures the frontend always sees
            // the freshest prices and daily-change values even between scoring runs.
            try {
              const livePrices = await kvGetJSON(KV, "timed:prices");
              if (livePrices?.prices) {
                const pricesUpdatedAt = livePrices.updated_at || Date.now();
                // Load daily prev_close for accurate bestPc.
                // Try KV cache first; if stale/empty, fall back to D1 daily candle query.
                let pcCache = {};
                try {
                  const cached = await kvGetJSON(KV, "timed:cache:daily_prev_close");
                  if (cached?.dailyCandle && Object.keys(cached.dailyCandle).length >= 50) {
                    pcCache = cached.dailyCandle;
                  }
                } catch (_) {}
                // If KV cache is empty/stale, query D1 directly (one lightweight GROUP BY query)
                if (Object.keys(pcCache).length < 50 && env?.DB) {
                  try {
                    const todayNY = currentTradingDayKey();
                    const cutoffMs = todayNY
                      ? (nyWallTimeToUtcMs(todayNY, 0, 0, 0) || new Date(todayNY + "T00:00:00Z").getTime())
                      : Date.now();
                    const dcRows = await env.DB.prepare(
                      `WITH ranked AS (
                        SELECT ticker, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                        FROM ticker_candles WHERE tf = 'D' AND ts < ?1
                      ) SELECT ticker, c FROM ranked WHERE rn = 1`
                    ).bind(cutoffMs).all();
                    for (const r of (dcRows?.results || [])) {
                      const sym = String(r.ticker).toUpperCase();
                      const close = Number(r.c);
                      if (Number.isFinite(close) && close > 0) pcCache[sym] = close;
                    }
                  } catch (_) { /* D1 unavailable — proceed with what we have */ }
                }

                for (const sym of Object.keys(data)) {
                  const pf = livePrices.prices[sym];
                  if (!pf || !(Number(pf.p) > 0)) continue;
                  const obj = data[sym];

                  // Update live price
                  obj.price = pf.p;
                  obj._live_price = pf.p;
                  obj._price_updated_at = pricesUpdatedAt;
                  obj._live_daily_high = pf.dh;
                  obj._live_daily_low = pf.dl;
                  obj._live_daily_volume = pf.dv;
                  // Extended hours (AH/pre-market) change from price feed
                  const pfAhDp2 = Number(pf.ahdp);
                  const pfAhDc2 = Number(pf.ahdc);
                  const pfAhP2 = Number(pf.ahp);
                  if (Number.isFinite(pfAhDp2) && pfAhDp2 !== 0) {
                    obj._ah_change_pct = pfAhDp2;
                    obj._ah_change = Number.isFinite(pfAhDc2) ? pfAhDc2 : 0;
                    if (Number.isFinite(pfAhP2) && pfAhP2 > 0) obj._ah_price = pfAhP2;
                  }

                  // Pick best prev_close: daily candle > pf.pc (if divergent) > stored
                  const dailyCandlePc = pcCache[sym] || 0;
                  const pfPc = Number(pf.pc);
                  const pfP = Number(pf.p);
                  const pfPcUsable = Number.isFinite(pfPc) && pfPc > 0 && pfP > 0
                    && (Math.abs(pfPc - pfP) / pfP * 100) > 0.05;
                  let bestPc = dailyCandlePc > 0
                    ? dailyCandlePc
                    : pfPcUsable
                      ? pfPc
                      : (obj.prev_close || obj._live_prev_close || 0);
                  // Sanity: skip extreme daily change (>25%)
                  if (bestPc > 0 && pfP > 0 && Math.abs((pfP - bestPc) / bestPc * 100) > 25) {
                    bestPc = obj.prev_close || obj._live_prev_close || 0;
                  }
                  if (bestPc > 0) obj._live_prev_close = bestPc;

                  // Apply daily change from price feed if non-zero
                  const pfDc = Number(pf.dc);
                  const pfDp = Number(pf.dp);
                  if (Number.isFinite(pfDp) && pfDp !== 0) {
                    obj.day_change_pct = pfDp;
                    obj.change_pct = pfDp;
                    if (Number.isFinite(pfDc) && pfDc !== 0) {
                      obj.day_change = pfDc;
                      obj.change = pfDc;
                    }
                    if (bestPc > 0) obj.prev_close = bestPc;
                  } else if (!Number.isFinite(Number(obj.day_change_pct)) || Number(obj.day_change_pct) === 0) {
                    // Price feed has no daily change AND snapshot has none — compute from bestPc
                    if (bestPc > 0 && pfP > 0) {
                      const computedDc = Math.round((pfP - bestPc) * 100) / 100;
                      const computedDp = Math.round(((pfP - bestPc) / bestPc) * 10000) / 100;
                      if (computedDp !== 0) {
                        obj.day_change = computedDc;
                        obj.day_change_pct = computedDp;
                        obj.change = computedDc;
                        obj.change_pct = computedDp;
                        obj.prev_close = bestPc;
                      }
                    }
                  }
                }
              }
            } catch (_) { /* price overlay failed — serve snapshot as-is */ }

            // ── Heartbeat fallback: catch futures/crypto still missing from data ──
            try {
              const stillMissing = [...activeSet].filter(s => !data[s]);
              if (stillMissing.length > 0) {
                const hbResults = await Promise.all(
                  stillMissing.map(s => kvGetJSON(KV, `timed:heartbeat:${s}`))
                );
                for (let i = 0; i < stillMissing.length; i++) {
                  const hb = hbResults[i];
                  if (hb && typeof hb === "object" && Number(hb.price) > 0) {
                    data[stillMissing[i]] = {
                      ticker: stillMissing[i],
                      price: Number(hb.price),
                      close: Number(hb.price),
                      prev_close: Number(hb.prev_close || 0) || undefined,
                      day_change: hb.day_change ?? undefined,
                      day_change_pct: hb.day_change_pct ?? undefined,
                      ingest_ts: hb.ingest_ts || Date.now(),
                      ingest_kind: "heartbeat_fallback",
                    };
                  }
                }
              }
            } catch (_) {}

            // ── Read-time execution readiness (RTH + concentration gates) ──
            // The snapshot carries block reasons from the scoring cron, which may
            // be stale (e.g. "outside_RTH" written pre-market, still present after
            // market opens). Re-evaluate at read time using current clock.
            try {
              let snapRthBlock = null;
              if (!isNyRegularMarketOpen()) {
                const nowDow = new Date().toLocaleString("en-US", { timeZone: "America/New_York", weekday: "short" });
                snapRthBlock = (nowDow === "Sat" || nowDow === "Sun") ? "weekend" : "outside_RTH";
              }
              // Load open positions for concentration checks (lightweight D1 query)
              let snapOpenPositions = [];
              if (env?.DB && !snapRthBlock) {
                try {
                  const posResult = await env.DB.prepare(
                    `SELECT ticker, direction FROM positions WHERE status = 'OPEN'`
                  ).all();
                  snapOpenPositions = posResult?.results || [];
                } catch { /* non-critical */ }
              }
              for (const sym of Object.keys(data)) {
                const obj = data[sym];
                if (!obj) continue;
                // Skip position tickers — their block reasons are managed differently
                const isPositionTicker = snapOpenPositions.some(p => String(p.ticker).toUpperCase() === sym);
                if (isPositionTicker) continue;
                const tickerBlockReasons = [];
                if (snapRthBlock) tickerBlockReasons.push(snapRthBlock);
                // Per-ticker concentration checks (only during RTH)
                if (!snapRthBlock && snapOpenPositions.length > 0) {
                  const tkSector = getSector(sym) || "UNKNOWN";
                  const entryPathCheck = String(obj?.__entry_path || obj?.entry_path || obj?.state || "").toUpperCase();
                  const tkDir = (entryPathCheck.includes("SHORT") || entryPathCheck.startsWith("HTF_BEAR")) ? "SHORT" : "LONG";
                  let sectorCnt = 0;
                  for (const p of snapOpenPositions) {
                    const pSector = getSector(String(p.ticker).toUpperCase()) || "UNKNOWN";
                    if (pSector === tkSector && tkSector !== "UNKNOWN") sectorCnt++;
                  }
                  if (sectorCnt >= 5) tickerBlockReasons.push(`sector_full:${sectorCnt}/5 ${tkSector}`);
                  let dirCnt = 0;
                  for (const p of snapOpenPositions) {
                    if (String(p.direction).toUpperCase() === tkDir) dirCnt++;
                  }
                  if (dirCnt >= 12) tickerBlockReasons.push(`direction_full:${dirCnt}/12 ${tkDir}`);
                  if (sectorCnt >= 3 && !tickerBlockReasons.some(r => r.startsWith("sector_full"))) {
                    const eq = Number(obj?.entry_quality?.score || obj?.__entry_quality) || 0;
                    if (eq > 0 && eq < 75) tickerBlockReasons.push(`correlated:${sectorCnt} in ${tkSector}`);
                  }
                }
                delete obj.__entry_block_reason;
                if (tickerBlockReasons.length > 0) {
                  obj.__execution_ready = false;
                  obj.__execution_block_reason = tickerBlockReasons.join("+");
                } else {
                  obj.__execution_ready = true;
                  delete obj.__execution_block_reason;
                }
              }
            } catch (_) { /* non-critical — serve snapshot with original block reasons */ }

            // ── Daily-candle close overlay ──
            // prev_close = previous *trading day* close. Use ts < today-midnight-ET so we get the
            // last closed day's candle (fixes AEHR and others when "second row" was wrong).
            // Use row-with-max-ts per ticker so c is the close from that candle, not arbitrary.
            try {
              if (env?.DB) {
                const rthOpen = isNyRegularMarketOpen();
                const todayNY = currentTradingDayKey();
                const cutoffMs = todayNY
                  ? (nyWallTimeToUtcMs(todayNY, 0, 0, 0) || new Date(todayNY + "T00:00:00Z").getTime())
                  : 0;
                const prevCloseByTicker = {};
                if (cutoffMs > 0) {
                  const prevRows = await env.DB.prepare(
                    `WITH ranked AS (
                      SELECT ticker, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                      FROM ticker_candles WHERE tf = 'D' AND ts < ?1
                    ) SELECT ticker, c FROM ranked WHERE rn = 1`
                  ).bind(cutoffMs).all();
                  for (const r of (prevRows?.results || [])) {
                    const sym = String(r.ticker).toUpperCase();
                    const c = Number(r.c);
                    if (Number.isFinite(c) && c > 0) prevCloseByTicker[sym] = c;
                  }
                }
                // Latest candle per ticker (for "today" close when market closed)
                const latestRows = await env.DB.prepare(
                  `WITH ranked AS (
                    SELECT ticker, c, ts, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                    FROM ticker_candles WHERE tf = 'D'
                  ) SELECT ticker, c FROM ranked WHERE rn = 1`
                ).all();
                const latestByTicker = {};
                for (const r of (latestRows?.results || [])) {
                  const sym = String(r.ticker).toUpperCase();
                  const c = Number(r.c);
                  if (Number.isFinite(c) && c > 0) latestByTicker[sym] = c;
                }
                for (const sym of Object.keys(data)) {
                  const obj = data[sym];
                  const todayClose = latestByTicker[sym];
                  const pc = prevCloseByTicker[sym];
                  if (todayClose > 0) {
                    const liveFreshMs = obj._price_updated_at ? Date.now() - obj._price_updated_at : Infinity;
                    const liveFresh = liveFreshMs < 30 * 60 * 1000;
                    if (!rthOpen && !liveFresh) {
                      obj.price = todayClose;
                      obj.close = todayClose;
                    }
                  }
                  if (pc > 0) {
                    const effectivePrice = Number(obj.price) || obj.close || 0;
                    if (effectivePrice > 0 && Math.abs((effectivePrice - pc) / pc * 100) < 30) {
                      obj.prev_close = pc;
                      obj._live_prev_close = pc;
                      obj.day_change = Math.round((effectivePrice - pc) * 100) / 100;
                      obj.day_change_pct = Math.round(((effectivePrice - pc) / pc) * 10000) / 100;
                      obj.change = obj.day_change;
                      obj.change_pct = obj.day_change_pct;
                    }
                  }
                }
              }
            } catch (_) { /* daily candle overlay non-critical */ }

            // ── Weekly change enrichment: compare current price to ~5 trading days ago ──
            try {
              if (env?.DB) {
                const weeklyRows = await env.DB.prepare(
                  `WITH deduped AS (
                    SELECT ticker, ts, c,
                      ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                    FROM ticker_candles WHERE tf = 'D'
                  )
                  SELECT ticker, ts, c FROM (
                    SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                    FROM deduped WHERE day_rn = 1
                  ) WHERE rn <= 7
                  ORDER BY ticker, ts DESC`
                ).all();
                const weekMap = {};
                for (const r of (weeklyRows?.results || [])) {
                  const sym = String(r.ticker).toUpperCase();
                  if (!weekMap[sym]) weekMap[sym] = [];
                  weekMap[sym].push({ ts: Number(r.ts), c: Number(r.c) });
                }
                for (const [sym, candles] of Object.entries(weekMap)) {
                  if (!data[sym] || candles.length < 5) continue;
                  const currentPx = Number(data[sym].price) || candles[0]?.c || 0;
                  const weekAgoClose = candles[4]?.c || candles[candles.length - 1]?.c || 0;
                  if (currentPx > 0 && weekAgoClose > 0) {
                    data[sym].weekly_change_pct = Math.round(((currentPx - weekAgoClose) / weekAgoClose) * 10000) / 100;
                    data[sym].weekly_change = Math.round((currentPx - weekAgoClose) * 100) / 100;
                  }
                }
              }
            } catch (_) { /* weekly change enrichment non-critical */ }

            // ── Sparkline enrichment at serve time ──
            // If the snapshot was built before sparklines were added, or if the
            // scoring cron hasn't run since deploy, enrich inline from D1 daily candles.
            try {
              const totalTickers = Object.keys(data).length;
              const withSparkline = Object.values(data).filter(d => Array.isArray(d?._sparkline) && d._sparkline.length >= 30).length;
              if (totalTickers > 0 && withSparkline < totalTickers * 0.5 && env?.DB) {
                const sparkRows = await env.DB.prepare(
                  `WITH deduped AS (
                    SELECT ticker, ts, c,
                      ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                    FROM ticker_candles WHERE tf = 'D'
                  )
                  SELECT ticker, ts, c FROM (
                    SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                    FROM deduped WHERE day_rn = 1
                  ) WHERE rn <= 60
                  ORDER BY ticker, ts ASC`
                ).all();
                const sparkMap = {};
                for (const r of (sparkRows?.results || [])) {
                  const sym = String(r.ticker).toUpperCase();
                  if (!sparkMap[sym]) sparkMap[sym] = [];
                  sparkMap[sym].push(Number(r.c));
                }
                for (const [sym, closes] of Object.entries(sparkMap)) {
                  if (data[sym]) data[sym]._sparkline = closes;
                }
                // Async-update KV snapshot so subsequent requests skip the D1 query
                ctx.waitUntil((async () => {
                  try {
                    const enrichedSnapshot = {};
                    for (const [sym, payload] of Object.entries(snapshot.data)) {
                      enrichedSnapshot[sym] = { ...payload };
                      if (sparkMap[sym]) enrichedSnapshot[sym]._sparkline = sparkMap[sym];
                    }
                    await kvPutJSON(KV, "timed:all:snapshot", {
                      data: enrichedSnapshot,
                      count: Object.keys(enrichedSnapshot).length,
                      built_at: snapshot.built_at,
                    });
                  } catch (_) {}
                })());
              }
            } catch (_) { /* sparkline enrichment non-critical */ }

            return sendJSON(
              { ok: true, data, count: Object.keys(data).length, source: "kv_snapshot", built_at: snapshot.built_at },
              200,
              { ...corsHeaders(env, req), "Cache-Control": "public, max-age=15" },
            );
          }
        } catch (_) { /* fall through to D1 */ }

        // Read from D1 (single query) — fallback when KV snapshot is stale or missing
        try {
          if (!env?.DB) {
            return sendJSON(
              { ok: false, error: "no_db_binding" },
              500,
              corsHeaders(env, req),
            );
          }

          await d1EnsureLatestSchema(env);
          const rows = await env.DB.prepare(
            `SELECT ticker, payload_json, updated_at, kanban_stage, prev_kanban_stage FROM ticker_latest`,
          ).all();

          // Filter: must be in SECTOR_MAP
          const activeSet = new Set(Object.keys(SECTOR_MAP));
          const results = (rows?.results || []).filter(r => {
            const sym = String(r?.ticker || "").toUpperCase();
            return sym && activeSet.has(sym);
          });
          const data = {};
          let maxUpdatedAt = 0;

          // POSITION-AWARE CLASSIFICATION: Load all open positions from D1
          // This ensures kanban lanes reflect management mode for open positions
          // Query includes fallback to lots table for entry price if cost_basis is missing
          const openPositionsMap = new Map();
          try {
            const positionsResult = await env.DB.prepare(
              `SELECT p.ticker, p.position_id, p.direction, p.status, p.stop_loss, p.take_profit,
                      p.cost_basis, p.total_qty, p.created_at,
                      CASE WHEN p.total_qty > 0 AND p.cost_basis > 0 
                           THEN p.cost_basis / p.total_qty 
                           ELSE (SELECT l.price FROM lots l WHERE l.position_id = p.position_id ORDER BY l.ts ASC LIMIT 1) 
                      END as avgEntry
               FROM positions p WHERE p.status = 'OPEN'`
            ).all();
            const openPositions = positionsResult?.results || [];
            for (const pos of openPositions) {
              const sym = String(pos.ticker).toUpperCase();
              if (sym) {
                // Dedupe: Keep only one position per ticker (most recent by created_at)
                const existing = openPositionsMap.get(sym);
                if (!existing || (pos.created_at > existing.created_at)) {
                  openPositionsMap.set(sym, {
                    ...pos,
                    entryPrice: pos.avgEntry,
                    entry_ts: pos.created_at,
                    sl: pos.stop_loss,
                    tp: pos.take_profit
                  });
                }
              }
            }
            if (openPositionsMap.size > 0) {
              console.log(`[/timed/all] Loaded ${openPositionsMap.size} open positions for position-aware classification`);
            }
          } catch (posErr) {
            console.warn("[/timed/all] Failed to load open positions:", String(posErr?.message || posErr));
          }

          // Pre-compute sector alignment for all sectors with data
          // This populates the cache so getSectorAlignmentCached() works in the loop below
          try {
            const sectorsToCompute = new Set();
            for (const r of results) {
              const sym = String(r?.ticker || "").toUpperCase();
              const sector = getSector(sym);
              if (sector) sectorsToCompute.add(sym);
            }
            // Compute for up to 10 unique sectors (dedupes via cache)
            const sectorTickers = [...sectorsToCompute].slice(0, 10);
            await Promise.all(sectorTickers.map(t => computeSectorAlignment(KV, t).catch(() => null)));
          } catch {
            // Sector alignment is a boost, never a gate
          }

          // ── Execution readiness pre-check (shared across all tickers) ──
          // Compute once: RTH + load open positions for per-ticker concentration checks.
          let execRthBlock = null; // shared RTH/weekend block (applies to all)
          // OPTIMIZATION: Reuse openPositionsMap (loaded above at line ~19278) instead of
          // querying D1 again. This eliminates a duplicate SELECT on every /timed/all request.
          let execOpenPositions = [];
          try {
            if (!isNyRegularMarketOpen()) {
              const nowDow = new Date().toLocaleString("en-US", { timeZone: "America/New_York", weekday: "short" });
              execRthBlock = (nowDow === "Sat" || nowDow === "Sun") ? "weekend" : "outside_RTH";
            }
            // Derive from openPositionsMap — already has ticker + direction for all OPEN positions
            for (const [sym, pos] of openPositionsMap) {
              execOpenPositions.push({ ticker: sym, direction: pos.direction });
            }
          } catch { /* non-critical */ }
          // Daily entry count (shared across all tickers)
          let execDailyLimitBlock = null;
          try {
            const today = new Date().toISOString().slice(0, 10);
            const dailyResult = await env.DB.prepare(
              `SELECT COUNT(*) as cnt FROM execution_actions WHERE type = 'ENTRY' AND day = ?`
            ).bind(today).first();
            const dailyCount = Number(dailyResult?.cnt) || 0;
            if (dailyCount >= 10) execDailyLimitBlock = `daily_limit:${dailyCount}/10`;
          } catch { /* non-critical */ }

          for (const r of results) {
            const sym = String(r?.ticker || "").toUpperCase();
            if (!sym) continue;
            if (Number(r?.updated_at) > maxUpdatedAt)
              maxUpdatedAt = Number(r.updated_at);
            const raw = r?.payload_json;
            if (!raw) continue;
            try {
              const obj = JSON.parse(String(raw));
              // Ensure price is available for UI (some sources use "close")
              if ((obj.price == null || !Number.isFinite(Number(obj.price))) && obj.close != null && Number.isFinite(Number(obj.close)))
                obj.price = obj.close;
              // Ensure lane fields are present even if payload_json is older than the D1 columns.
              if (obj.kanban_stage == null && r?.kanban_stage != null)
                obj.kanban_stage = String(r.kanban_stage);
              if (obj.prev_kanban_stage == null && r?.prev_kanban_stage != null)
                obj.prev_kanban_stage = String(r.prev_kanban_stage);
              if (
                obj.prev_kanban_stage != null &&
                obj.prev_kanban_stage_ts == null &&
                Number.isFinite(Number(r?.updated_at))
              ) {
                obj.prev_kanban_stage_ts = Number(r.updated_at);
              }
              // Canonicalize daily change fields: prefer heartbeat capture semantics (change/change_pct)
              // when stored day_change_pct is poisoned by a bad prev_close anchor.
              try {
                const dayPct = Number(obj.day_change_pct);
                const altPct = Number(obj.change_pct);
                const altChg = Number(obj.change);
                const price = Number(obj.price);
                const hasHeartbeatSession =
                  obj.session != null || obj.is_rth != null;
                if (hasHeartbeatSession && Number.isFinite(altPct)) {
                  obj.day_change_pct = altPct;
                  if (Number.isFinite(altChg)) obj.day_change = altChg;
                  if (Number.isFinite(price) && Number.isFinite(altChg))
                    obj.prev_close = price - altChg;
                }
                const disagree =
                  Number.isFinite(dayPct) &&
                  Number.isFinite(altPct) &&
                  (dayPct >= 0 !== altPct >= 0 ||
                    Math.abs(dayPct - altPct) >= 1.5);
                const absurd = Number.isFinite(dayPct) && Math.abs(dayPct) > 5;
                const saneAlt =
                  Number.isFinite(altPct) && Math.abs(altPct) <= 5;
                if (
                  (disagree || (absurd && saneAlt)) &&
                  Number.isFinite(altPct)
                ) {
                  obj.day_change_pct = altPct;
                  if (Number.isFinite(altChg)) obj.day_change = altChg;
                  if (Number.isFinite(price) && Number.isFinite(altChg))
                    obj.prev_close = price - altChg;
                } else if (
                  !Number.isFinite(dayPct) &&
                  Number.isFinite(altPct)
                ) {
                  obj.day_change_pct = altPct;
                  if (Number.isFinite(altChg)) obj.day_change = altChg;
                  if (Number.isFinite(price) && Number.isFinite(altChg))
                    obj.prev_close = price - altChg;
                }
              } catch {
                // ignore
              }
              // Ensure stage/status reflect current logic even if no new ingests
              try {
                const cMax = computeCompletionToTpMax(obj);
                if (Number.isFinite(cMax)) obj.completion = cMax;
                const rr = computeRR(obj);
                if (Number.isFinite(rr)) obj.rr = rr;
                const rrTargets = computeRRTargets(obj);
                if (rrTargets) Object.assign(obj, rrTargets);
                obj.move_status = computeMoveStatus(obj);
              } catch {
                // ignore
              }
              try {
                obj.flags =
                  obj.flags && typeof obj.flags === "object" ? obj.flags : {};
                obj.flags.move_invalidated =
                  obj.move_status?.status === "INVALIDATED";
                obj.flags.move_completed =
                  obj.move_status?.status === "COMPLETED";
              } catch {
                // ignore
              }
              try {
                const prevStage =
                  obj?.kanban_stage != null ? String(obj.kanban_stage) : null;
                // POSITION-AWARE: Only re-classify when there's an open position
                // (needs real-time SL/phase checks). Otherwise trust the stored stage
                // from the last process cycle — avoids lane flipping on read.
                // LIFECYCLE GATE: Management stages require an open position.
                // If no position exists, reclassify to prevent stale replay stages
                // from showing tickers in hold/defend/trim/exit without a real trade.
                const openPosition = openPositionsMap.get(sym) || null;
                const mgmtStages = new Set(["active", "hold", "just_entered", "defend", "trim", "exit"]);
                // Inject execution readiness for discovery tickers (per-ticker smart gates)
                if (!openPosition) {
                  const tickerBlockReasons = [];
                  if (execRthBlock) tickerBlockReasons.push(execRthBlock);
                  if (execDailyLimitBlock) tickerBlockReasons.push(execDailyLimitBlock);
                  // Per-ticker concentration checks
                  if (!execRthBlock && execOpenPositions.length > 0) {
                    const tkSector = getSector(sym) || "UNKNOWN";
                    const entryPathCheck = String(obj?.__entry_path || obj?.entry_path || obj?.state || "").toUpperCase();
                    const tkDir = (entryPathCheck.includes("SHORT") || entryPathCheck.startsWith("HTF_BEAR")) ? "SHORT" : "LONG";
                    // Sector concentration
                    let sectorCnt = 0;
                    for (const p of execOpenPositions) {
                      const pSector = getSector(String(p.ticker).toUpperCase()) || "UNKNOWN";
                      if (pSector === tkSector && tkSector !== "UNKNOWN") sectorCnt++;
                    }
                    if (sectorCnt >= 5) tickerBlockReasons.push(`sector_full:${sectorCnt}/5 ${tkSector}`);
                    // Directional concentration
                    let dirCnt = 0;
                    for (const p of execOpenPositions) {
                      if (String(p.direction).toUpperCase() === tkDir) dirCnt++;
                    }
                    if (dirCnt >= 12) tickerBlockReasons.push(`direction_full:${dirCnt}/12 ${tkDir}`);
                    // Correlation guard: 3+ in same sector → need higher quality
                    if (sectorCnt >= 3 && !tickerBlockReasons.some(r => r.startsWith("sector_full"))) {
                      const eq = Number(obj?.entry_quality?.score || obj?.__entry_quality) || 0;
                      if (eq > 0 && eq < 75) tickerBlockReasons.push(`correlated:${sectorCnt} in ${tkSector}`);
                    }
                  }
                  // ALWAYS clear stale cron-stored block reasons — the read-time
                  // check supersedes whatever the cron wrote. Without this, stale
                  // __entry_block_reason="outside_RTH" persists even during market hours.
                  delete obj.__entry_block_reason;
                  if (tickerBlockReasons.length > 0) {
                    obj.__execution_ready = false;
                    obj.__execution_block_reason = tickerBlockReasons.join("+");
                  } else {
                    obj.__execution_ready = true;
                    delete obj.__execution_block_reason;
                  }
                }
                // Re-classify all tickers through classifyKanbanStage for fresh
                // lane assignment. During market hours, ALWAYS re-classify (the stored
                // stage may be stale from a previous scoring cycle). During market close,
                // pin non-management stages to prevent flicker from stale data.
                const marketClosed = !!execRthBlock; // "outside_RTH" or "weekend"
                let stage;
                if (openPosition) {
                  // Position tickers: always re-classify (need real-time SL/phase)
                  stage = classifyKanbanStage(obj, openPosition);
                } else if (marketClosed && prevStage && !mgmtStages.has(prevStage)) {
                  // Market closed + valid discovery stage → pin to prevent flicker.
                  stage = prevStage;
                } else {
                  // Market open → always re-classify. This ensures tickers that
                  // qualify for "enter" are promoted from "setup"/"watch" immediately,
                  // without waiting for the next scoring cron cycle.
                  stage = classifyKanbanStage(obj);
                }
                obj.kanban_stage = stage;
                // Attach sector alignment data for UI display
                const sectorInfo = getSectorAlignmentCached(sym);
                if (sectorInfo) {
                  obj.sector_alignment = {
                    sector: sectorInfo.sector,
                    aligned: sectorInfo.aligned,
                    direction: sectorInfo.direction,
                    strength: sectorInfo.strength,
                    consensus: `${sectorInfo.bullCount}B/${sectorInfo.bearCount}S of ${sectorInfo.totalWithData}`,
                  };
                }
                // Track if this ticker has an open position for UI display
                if (openPosition) {
                  obj.has_open_position = true;
                  obj.position_direction = openPosition.direction;
                  obj.position_entry = openPosition.entryPrice;
                  obj.position_sl = openPosition.sl;
                  obj.position_sl_original = openPosition.sl_original;
                  obj.position_tp = openPosition.tp;
                }
                obj.kanban_meta = deriveKanbanMeta(obj, stage);
                // Track lane transitions even if no new ingests (persist back into D1 so UI can highlight).
                if (
                  prevStage != null &&
                  stage != null &&
                  String(prevStage) !== String(stage)
                ) {
                  obj.prev_kanban_stage = String(prevStage);
                  obj.prev_kanban_stage_ts = Date.now();
                  try {
                    ctx.waitUntil(d1UpsertTickerLatest(env, sym, obj));
                    ctx.waitUntil(d1UpsertTickerIndex(env, sym, obj?.ts));
                  } catch {
                    // ignore
                  }
                }
              } catch {
                // ignore
              }

              // Context inline derivation (fast, no KV reads).
              // KV fallback is done in a batch AFTER the loop for much better performance.
              try {
                if (obj.context && typeof obj.context === "object") {
                  const cleaned = sanitizeTickerContext(obj.context, obj);
                  if (cleaned) obj.context = cleaned;
                } else if (!obj.context) {
                  const derived = deriveTickerContext(obj);
                  if (derived) {
                    const cleaned = sanitizeTickerContext(derived, obj);
                    obj.context = cleaned || derived;
                  }
                }
              } catch {
                // ignore
              }

              data[sym] = obj;
            } catch {
              // skip bad rows
            }
          }

          // ── BATCH context enrichment from KV ──
          // Instead of doing 200+ sequential KV reads inside the loop, we collect
          // all tickers still missing context.name and fetch them in parallel.
          try {
            const needCtx = Object.entries(data)
              .filter(([, v]) => !v?.context?.name)
              .map(([sym]) => sym);
            if (needCtx.length > 0) {
              // Parallel KV reads in batches of 50 for safety
              for (let b = 0; b < needCtx.length; b += 50) {
                const batch = needCtx.slice(b, b + 50);
                const kvResults = await Promise.all(
                  batch.map(sym => kvGetJSON(KV, `timed:context:${sym}`))
                );
                for (let i = 0; i < batch.length; i++) {
                  const kvCtx = kvResults[i];
                  if (kvCtx && typeof kvCtx === "object" && kvCtx.name) {
                    const sym = batch[i];
                    data[sym].context = { ...(data[sym].context || {}), ...kvCtx };
                  }
                }
              }
            }
          } catch (ctxBatchErr) {
            console.warn("[/timed/all] Batch context enrichment failed:", String(ctxBatchErr?.message || ctxBatchErr));
          }

          // POSITION RECONCILIATION: Ensure active tickers with open positions appear in data
          // Even if they're missing from ticker_latest, we need them visible in kanban
          // But skip tickers on the removal blocklist
          try {
            for (const [sym, pos] of openPositionsMap.entries()) {
              if (!data[sym] && !removedSet.has(sym)) {
                // Try to get latest data from KV
                let latestData = await kvGetJSON(KV, `timed:latest:${sym}`);
                
                if (latestData && typeof latestData === "object") {
                  // Apply position-aware classification
                  const stage = classifyKanbanStage(latestData, pos);
                  latestData.kanban_stage = stage;
                  latestData.kanban_meta = deriveKanbanMeta(latestData, stage);
                  latestData.has_open_position = true;
                  latestData.position_direction = pos.direction;
                  latestData.position_entry = pos.entryPrice;
                  latestData.position_sl = pos.sl;
                  latestData.position_sl_original = pos.sl_original;
                  latestData.position_tp = pos.tp;
                  data[sym] = latestData;
                  console.log(`[/timed/all] Injected missing position ticker ${sym} from KV (stage: ${stage})`);
                } else {
                  // Minimal placeholder for UI visibility
                  data[sym] = {
                    ticker: sym,
                    kanban_stage: "just_entered",
                    has_open_position: true,
                    position_direction: pos.direction,
                    position_entry: pos.entryPrice,
                    position_sl: pos.sl,
                    position_sl_original: pos.sl_original,
                    position_tp: pos.tp,
                    _synthetic: true,
                    _reason: "open_position_missing_data"
                  };
                  console.warn(`[/timed/all] Created synthetic entry for position ticker ${sym} (no data in KV or D1)`);
                }
              }
            }
          } catch (reconcileErr) {
            console.warn("[/timed/all] Position reconciliation failed:", String(reconcileErr?.message || reconcileErr));
          }

          // ── Market Pulse placeholders (D1 fallback path) ──
          for (const sym of MARKET_PULSE_SYMS) {
            if (!data[sym]) data[sym] = { ticker: sym };
          }

          // Overlay lightweight heartbeat (KV, 2d TTL) for fresh price/daily change
          try {
            const syms = Object.keys(data);
            const heartbeats = await Promise.all(
              syms.map((s) => kvGetJSON(KV, `timed:heartbeat:${s}`)),
            );
            const tickersWithPriceUpdate = new Set();
            for (let i = 0; i < syms.length; i++) {
              const hb = heartbeats[i];
              if (hb && typeof hb === "object") {
                const obj = data[syms[i]];
                if (!obj) continue;
                if (Number.isFinite(Number(hb.price))) {
                  obj.price = hb.price;
                  tickersWithPriceUpdate.add(syms[i]);
                }
                if (hb.prev_close != null) obj.prev_close = hb.prev_close;
                if (hb.day_change != null) {
                  obj.day_change = hb.day_change;
                  obj.change = hb.day_change;
                }
                if (hb.day_change_pct != null) {
                  obj.day_change_pct = hb.day_change_pct;
                  obj.change_pct = hb.day_change_pct;
                }
                // Only overlay ingest_ts if heartbeat is NEWER — never overwrite fresh scoring with stale TradingView data
                if (hb.ingest_ts != null) {
                  const hbMs = typeof hb.ingest_ts === "number" ? hb.ingest_ts : (hb.ingest_ts < 1e12 ? hb.ingest_ts * 1000 : new Date(String(hb.ingest_ts)).getTime());
                  const objMs = Number(obj.ingest_ts) || Number(obj.ts) || 0;
                  const objMsNorm = objMs > 0 && objMs < 1e12 ? objMs * 1000 : objMs;
                  if (Number.isFinite(hbMs) && hbMs > 0 && (objMsNorm <= 0 || hbMs > objMsNorm)) {
                    obj.ingest_ts = hb.ingest_ts;
                    if (hb.ingest_time != null) obj.ingest_time = hb.ingest_time;
                  }
                }
                if (hb.session != null) obj.session = hb.session;
                if (hb.is_rth != null) obj.is_rth = hb.is_rth;
              }
            }
            
            // RE-CLASSIFY KANBAN STAGE with updated prices — ONLY for tickers
            // with open positions (need real-time SL breach detection).
            // Discovery-mode tickers keep their stored stage to prevent lane
            // flipping on every UI refresh when market is closed.
            if (tickersWithPriceUpdate.size > 0) {
              for (const sym of tickersWithPriceUpdate) {
                const obj = data[sym];
                if (!obj) continue;
                const openPosition = openPositionsMap.get(sym) || null;
                if (!openPosition) continue; // trust stored stage for discovery tickers
                try {
                  const prevStage = obj.kanban_stage;
                  const newStage = classifyKanbanStage(obj, openPosition);
                  if (newStage !== prevStage) {
                    obj.kanban_stage = newStage;
                    obj.kanban_meta = deriveKanbanMeta(obj, newStage);
                  }
                } catch (reClassifyErr) {
                  console.warn(`[HEARTBEAT] Re-classification failed for ${sym}:`, String(reClassifyErr?.message || reClassifyErr));
                }
              }
            }
          } catch (e) {
            console.warn("[HEARTBEAT] Merge failed:", String(e?.message || e));
          }

          // ── Load daily candle prev_close for all tickers (yesterday's actual close) ──
          // BUG FIX: The old code used midnight UTC which, after 7 PM ET (midnight UTC
          // rollover), would include today's daily candle as "yesterday's close", giving
          // 0% change after hours. Fix: compute NY midnight today in UTC and use that
          // as the cutoff. Alpaca daily bars use ts = midnight ET, so ts < NY-midnight
          // always excludes today's candle regardless of UTC clock position.
          let allDailyPcMap = {};
          try {
            if (env?.DB) {
              // Use current trading day (roll back on weekends so we get correct prev_close).
              const todayNY = currentTradingDayKey();
              if (todayNY) {
                // Parse as midnight in ET. We detect EST vs EDT by comparing
                // a known date's NY representation against UTC.
                // Simple: Jan = EST (UTC-5), Jul = EDT (UTC-4). Check current month.
                const etNow = new Date().toLocaleString("en-US", { timeZone: "America/New_York" });
                const etMonth = new Date(etNow).getMonth(); // 0-indexed
                // DST in US: Mar second Sun - Nov first Sun. Approximate: months 2-10 inclusive.
                const isDST = etMonth >= 2 && etMonth <= 10;
                const etOffsetHours = isDST ? 4 : 5;
                // todayNY midnight ET = todayNY + etOffsetHours in UTC
                const cutoffMs = new Date(`${todayNY}T00:00:00Z`).getTime() + etOffsetHours * 3600000;

                // Use MAX(ts) + GROUP BY to get one row per ticker instead of scanning
                // the entire candles table (SQLite bare-column guarantee on MAX).
                const dcRows = await env.DB.prepare(
                  `SELECT ticker, c, MAX(ts) as latest_ts FROM ticker_candles WHERE tf = 'D' AND ts < ?1 GROUP BY ticker`
                ).bind(cutoffMs).all();
                for (const r of (dcRows?.results || [])) {
                  const sym = String(r.ticker).toUpperCase();
                  const close = Number(r.c);
                  if (Number.isFinite(close) && close > 0) allDailyPcMap[sym] = close;
                }
              }
            }
          } catch (_) { /* non-critical */ }

          // ── Overlay canonical timed:prices (Alpaca + TradingView merged by price feed cron) ──
          // This is the SAME data the frontend polls via /timed/prices, applied here so the
          // very first page load matches what usePriceFeed would deliver 30s later.
          // Applied AFTER the heartbeat overlay: for stocks, timed:prices has Alpaca data with
          // the sanity check (more trustworthy); for futures, it contains the same TV heartbeat
          // data merged by the cron. The heartbeat overlay above remains as a first-pass fallback
          // when timed:prices is unavailable (e.g. cron hasn't run yet).
          try {
            const livePrices = await kvGetJSON(KV, "timed:prices");
            if (livePrices && livePrices.prices && typeof livePrices.prices === "object") {
              const pricesUpdatedAt = livePrices.updated_at || 0;
              for (const sym of Object.keys(data)) {
                const pf = livePrices.prices[sym];
                if (!pf || !(Number(pf.p) > 0)) continue;
                const obj = data[sym];
                if (!obj) continue;
                // ONLY update live price from timed:prices.
                obj.price = pf.p;
                obj._live_price = pf.p;
                // Pick best prev_close: daily candle > price feed pc > D1 stored > fallback
                // Daily candle is the authoritative source (yesterday's actual 4pm ET close).
                const dailyCandlePc = allDailyPcMap[sym] || 0;
                const pfPc = Number(pf.pc);
                const pfP = Number(pf.p);
                const pfPcUsable = Number.isFinite(pfPc) && pfPc > 0 && pfP > 0
                  && (Math.abs(pfPc - pfP) / pfP * 100) > 0.05;
                let bestPc = dailyCandlePc > 0
                  ? dailyCandlePc
                  : pfPcUsable
                    ? pfPc
                    : (obj.prev_close || obj._live_prev_close || undefined);
                // Sanity check: if bestPc gives extreme daily change (>25%), skip it
                if (bestPc > 0 && pf.p > 0 && Math.abs((pf.p - bestPc) / bestPc * 100) > 25) {
                  bestPc = obj.prev_close || obj._live_prev_close || undefined;
                }
                if (bestPc > 0) obj._live_prev_close = bestPc;
                // Apply daily change from price feed if it has meaningful non-zero values.
                // This ensures daily change survives page refresh even when D1/KV stored values are stale.
                const pfDc = Number(pf.dc);
                const pfDp = Number(pf.dp);
                if (Number.isFinite(pfDp) && pfDp !== 0) {
                  obj.day_change_pct = pfDp;
                  obj.change_pct = pfDp;
                  if (Number.isFinite(pfDc) && pfDc !== 0) {
                    obj.day_change = pfDc;
                    obj.change = pfDc;
                  }
                  if (bestPc > 0) obj.prev_close = bestPc;
                } else if (!Number.isFinite(Number(obj.day_change_pct)) || Number(obj.day_change_pct) === 0) {
                  // No price feed daily change AND no stored daily change — compute from bestPc
                  if (bestPc > 0 && pf.p > 0) {
                    const computedDc = Math.round((pf.p - bestPc) * 100) / 100;
                    const computedDp = Math.round(((pf.p - bestPc) / bestPc) * 10000) / 100;
                    if (computedDp !== 0) {
                      obj.day_change = computedDc;
                      obj.day_change_pct = computedDp;
                      obj.change = computedDc;
                      obj.change_pct = computedDp;
                      obj.prev_close = bestPc;
                    }
                  }
                }
                obj._live_daily_high = pf.dh;
                obj._live_daily_low = pf.dl;
                obj._live_daily_volume = pf.dv;
                obj._price_updated_at = pricesUpdatedAt;
                // Extended hours (AH/pre-market) change from price feed
                const pfAhDp = Number(pf.ahdp);
                const pfAhDc = Number(pf.ahdc);
                const pfAhP = Number(pf.ahp);
                if (Number.isFinite(pfAhDp) && pfAhDp !== 0) {
                  obj._ah_change_pct = pfAhDp;
                  obj._ah_change = Number.isFinite(pfAhDc) ? pfAhDc : 0;
                  if (Number.isFinite(pfAhP) && pfAhP > 0) obj._ah_price = pfAhP;
                }
                if (Number.isFinite(pricesUpdatedAt) && pricesUpdatedAt > 0) {
                  const existingTs = Number(obj.ingest_ts) || Number(obj.ts) || 0;
                  const existingNorm = existingTs > 0 && existingTs < 1e12 ? existingTs * 1000 : existingTs;
                  if (pricesUpdatedAt > existingNorm) {
                    obj.ingest_ts = pricesUpdatedAt;
                    obj.ingest_time = new Date(pricesUpdatedAt).toISOString();
                  }
                }
              }
            }
          } catch (e) {
            console.warn("[PRICE ENRICH] timed:prices merge failed:", String(e?.message || e));
          }

          // If D1 is warming up, report total index from KV for transparency
          let totalIndex = Object.keys(data).length;
          try {
            const kvTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
            if (Array.isArray(kvTickers) && kvTickers.length > totalIndex) {
              totalIndex = kvTickers.length;
              // Background sync to accelerate warm-up
              try {
                ctx.waitUntil(d1SyncLatestBatchFromKV(env, ctx, 75));
              } catch {
                // ignore
              }
            }
          } catch {
            // ignore
          }

          // Compute rank positions and add score/position (canonical) alongside rank/rank_position
          const ranked = Object.entries(data)
            .map(([ticker, value]) => {
              const sc = Number(value?.dynamicScore ?? value?.rank);
              const safeScore = Number.isFinite(sc)
                ? sc
                : (value && computeDynamicScore(value)) || Number(value?.rank) || 0;
              return { ticker, score: safeScore };
            })
            .sort((a, b) => b.score - a.score);
          const rankTotal = ranked.length;
          ranked.forEach((item, idx) => {
            const entry = data[item.ticker];
            if (!entry) return;
            const pos = idx + 1;
            entry.rank_position = pos;
            entry.position = pos;
            entry.rank_total = rankTotal;
            entry.rank_score = item.score;
            entry.score = Number(entry?.rank ?? item.score);
          });

          const socialAdditions = (await kvGetJSON(KV, "timed:social:additions")) || [];

          // ── Background auto-enrich: fill missing context from Alpaca asset API ──
          // On each /timed/all request, enrich up to 10 tickers that have no context.name.
          // This progressively fills the context cache without blocking the response.
          try {
            const missingCtx = Object.entries(data)
              .filter(([, v]) => !v?.context?.name)
              .map(([sym]) => sym)
              .slice(0, 10);
            if (missingCtx.length > 0 && env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY) {
              ctx.waitUntil(alpacaEnrichMissingContext(env, KV, missingCtx));
            }
          } catch { /* non-critical */ }

          // ── Daily-candle close overlay (D1 fallback path) ──
          try {
            if (env?.DB) {
              const rthOpen = isNyRegularMarketOpen();
              const candleRows = await env.DB.prepare(
                `WITH deduped AS (
                  SELECT ticker, ts, c,
                    ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                  FROM ticker_candles WHERE tf = 'D'
                )
                SELECT ticker, ts, c FROM (
                  SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                  FROM deduped WHERE day_rn = 1
                ) WHERE rn <= 2
                ORDER BY ticker, ts DESC`
              ).all();
              const candleMap = {};
              for (const r of (candleRows?.results || [])) {
                const sym = String(r.ticker).toUpperCase();
                if (!candleMap[sym]) candleMap[sym] = [];
                candleMap[sym].push({ ts: Number(r.ts), c: Number(r.c) });
              }
              for (const [sym, candles] of Object.entries(candleMap)) {
                if (!data[sym]) continue;
                const obj = data[sym];
                const todayCandle = candles[0];
                const prevCandle = candles[1];
                if (!todayCandle || !Number.isFinite(todayCandle.c) || todayCandle.c <= 0) continue;
                const liveFreshMs = obj._price_updated_at ? Date.now() - obj._price_updated_at : Infinity;
                const liveFresh = liveFreshMs < 30 * 60 * 1000;
                if (!rthOpen && !liveFresh) {
                  obj.price = todayCandle.c;
                  obj.close = todayCandle.c;
                }
                if (prevCandle && Number.isFinite(prevCandle.c) && prevCandle.c > 0) {
                  const effectivePrice = Number(obj.price) || todayCandle.c;
                  const pc = prevCandle.c;
                  if (effectivePrice > 0 && Math.abs((effectivePrice - pc) / pc * 100) < 30) {
                    obj.prev_close = pc;
                    obj._live_prev_close = pc;
                    obj.day_change = Math.round((effectivePrice - pc) * 100) / 100;
                    obj.day_change_pct = Math.round(((effectivePrice - pc) / pc) * 10000) / 100;
                    obj.change = obj.day_change;
                    obj.change_pct = obj.day_change_pct;
                  }
                }
              }
            }
          } catch (_) { /* daily candle overlay non-critical */ }

          // ── Weekly change enrichment (D1 fallback path) ──
          try {
            if (env?.DB) {
              const weeklyRows = await env.DB.prepare(
                `WITH deduped AS (
                  SELECT ticker, ts, c,
                    ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                  FROM ticker_candles WHERE tf = 'D'
                )
                SELECT ticker, ts, c FROM (
                  SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                  FROM deduped WHERE day_rn = 1
                ) WHERE rn <= 7
                ORDER BY ticker, ts DESC`
              ).all();
              const weekMap = {};
              for (const r of (weeklyRows?.results || [])) {
                const sym = String(r.ticker).toUpperCase();
                if (!weekMap[sym]) weekMap[sym] = [];
                weekMap[sym].push({ ts: Number(r.ts), c: Number(r.c) });
              }
              for (const [sym, candles] of Object.entries(weekMap)) {
                if (!data[sym] || candles.length < 5) continue;
                const currentPx = Number(data[sym].price) || candles[0]?.c || 0;
                const weekAgoClose = candles[4]?.c || candles[candles.length - 1]?.c || 0;
                if (currentPx > 0 && weekAgoClose > 0) {
                  data[sym].weekly_change_pct = Math.round(((currentPx - weekAgoClose) / weekAgoClose) * 10000) / 100;
                  data[sym].weekly_change = Math.round((currentPx - weekAgoClose) * 100) / 100;
                }
              }
            }
          } catch (_) { /* weekly change enrichment non-critical */ }

          // ── Sparkline enrichment (D1 fallback path) ──
          try {
            const withSpark = Object.values(data).filter(d => Array.isArray(d?._sparkline) && d._sparkline.length >= 30).length;
            if (Object.keys(data).length > 0 && withSpark < Object.keys(data).length * 0.5 && env?.DB) {
              const sparkRows = await env.DB.prepare(
                `WITH deduped AS (
                  SELECT ticker, ts, c,
                    ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                  FROM ticker_candles WHERE tf = 'D'
                )
                SELECT ticker, ts, c FROM (
                  SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                  FROM deduped WHERE day_rn = 1
                ) WHERE rn <= 60
                ORDER BY ticker, ts ASC`
              ).all();
              const sparkMap = {};
              for (const r of (sparkRows?.results || [])) {
                const sym = String(r.ticker).toUpperCase();
                if (!sparkMap[sym]) sparkMap[sym] = [];
                sparkMap[sym].push(Number(r.c));
              }
              for (const [sym, closes] of Object.entries(sparkMap)) {
                if (data[sym]) data[sym]._sparkline = closes;
              }
            }
          } catch (_) { /* sparkline enrichment non-critical */ }

          return sendJSON(
            {
              ok: true,
              count: Object.keys(data).length,
              totalIndex,
              data,
              socialAdditions: Array.isArray(socialAdditions) ? socialAdditions : [],
              d1_max_updated_at: maxUpdatedAt || null,
            },
            200,
            { ...corsHeaders(env, req), "Cache-Control": "public, max-age=15" },
          );
        } catch (e) {
          console.error(`[D1 LATEST] /timed/all failed:`, String(e));
          return sendJSON(
            {
              ok: false,
              error: "d1_all_failed",
              message: String(e?.message || e),
            },
            500,
            corsHeaders(env, req),
          );
        }

        /* REMOVED: On-demand computation (KV-based) - replaced by D1 reads
        const useLightweightMode = true;
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const storedVersion =
          (await getStoredVersion(KV)) || CURRENT_DATA_VERSION;

        // Debug: Check if BMNR is in the ticker index
        if (tickers.includes("BMNR") || tickers.includes("BABA")) {
          console.log(`[ALL ENDPOINT] BMNR/BABA in index:`, {
            BMNR: tickers.includes("BMNR"),
            BABA: tickers.includes("BABA"),
            totalTickers: tickers.length,
            indexSample: tickers.slice(0, 10),
          });
        } else {
          console.log(
            `[ALL ENDPOINT] BMNR/BABA NOT in index. Total tickers: ${tickers.length}`
          );
        }

        // Check if version parameter is provided
        const requestedVersion = url.searchParams.get("version");
        const useVersionSnapshots =
          requestedVersion && requestedVersion !== "latest";

        // Use Promise.all for parallel KV reads instead of sequential
        const dataPromises = tickers.map(async (t) => {
          let value;
          if (useVersionSnapshots) {
            // Try to get version-specific snapshot first
            value = await kvGetJSON(
              KV,
              `timed:snapshot:${t}:${requestedVersion}`
            );
            // If no snapshot found, fall back to latest
            if (!value) {
              value = await kvGetJSON(KV, `timed:latest:${t}`);
              // Only include if version matches
              if (value && value.script_version !== requestedVersion) {
                value = null; // Don't include mismatched versions
              }
            }
          } else if (useLightweightMode) {
            // LIGHTWEIGHT MODE: Only get latest data, skip capture/context/momentum merges
            value = await kvGetJSON(KV, `timed:latest:${t}`);
          } else {
            // Default: get latest data
            value = await kvGetJSON(KV, `timed:latest:${t}`);

            // Merge capture-only enrichment fields when present (non-destructive).
            // This helps after-hours analytics + Momentum Elite metadata even if heartbeat is wired to /ingest-capture.
            if (!useLightweightMode) {
              try {
                const capture = await kvGetJSON(KV, `timed:capture:latest:${t}`);
                if (value && capture && typeof capture === "object") {
                // Prefer capture for daily-change fields (more reliable for UI/analysis).
                for (const k of ["prev_close", "day_change", "day_change_pct"]) {
                  if (capture[k] != null) value[k] = capture[k];
                }
                for (const k of [
                  "session",
                  "is_rth",
                  "avg_vol_30",
                  "avg_vol_50",
                  "adr_14",
                  "momentum_pct",
                  "momentum_elite_criteria",
                ]) {
                  if (value[k] == null && capture[k] != null) value[k] = capture[k];
                }
                if (capture.flags && typeof capture.flags === "object") {
                  value.flags = value.flags && typeof value.flags === "object" ? value.flags : {};
                  // Override from capture: score payloads don't compute Momentum Elite reliably.
                  if (capture.flags.momentum_elite != null) value.flags.momentum_elite = !!capture.flags.momentum_elite;
                }

                // Context enrichment rides along on capture payload (throttled in Pine).
                if (capture.context && typeof capture.context === "object") {
                  value.context = capture.context;
                }
              }
            } catch (e) {
              // ignore merge failures
            }

            // If capture doesn't include context on this bar, fall back to persisted context.
            try {
              if (value && !value.context) {
                const saved = await kvGetJSON(KV, `timed:context:${t}`);
                if (saved && typeof saved === "object") value.context = saved;
              }
            } catch {
              // ignore
            }

            // Ensure Momentum Elite reflects the most recent computed status.
            try {
              if (value) {
                const m = await kvGetJSON(KV, `timed:momentum:${t}`);
                if (m && typeof m === "object" && m.momentum_elite != null) {
                  value.flags = value.flags && typeof value.flags === "object" ? value.flags : {};
                  value.flags.momentum_elite = !!m.momentum_elite;
                  if (value.momentum_elite_criteria == null && m.criteria) {
                    value.momentum_elite_criteria = m.criteria;
                  }
                }
              }
              } catch {
                // ignore
              }
            } // End lightweight mode skip

            // Debug: Check if BMNR data exists in KV
            if (t === "BMNR" || t === "BABA") {
              console.log(`[ALL ENDPOINT] Fetched ${t} from KV:`, {
                hasValue: !!value,
                valueKeys: value ? Object.keys(value) : [],
                htf_score: value?.htf_score,
                ltf_score: value?.ltf_score,
                script_version: value?.script_version,
              });
            }
          }
          return { ticker: t, value };
        });
        const results = await Promise.all(dataPromises);

        // Find all versions in the data
        const versionsSeen = new Set();
        for (const { value } of results) {
          if (value && value.script_version) {
            versionsSeen.add(value.script_version);
          }
        }

        // Accept ANY version that exists in the data, plus "unknown" for legacy data
        // This prevents filtering out data during version transitions
        const acceptedVersions = new Set([
          storedVersion,
          CURRENT_DATA_VERSION,
          "unknown", // Legacy data without script_version
          ...Array.from(versionsSeen), // All versions seen in current data
        ]);

        const data = {};
        let corrData = null;
        if (!useLightweightMode) {
          try {
            corrData = await computeOpenTradesCorrelation(env, KV);
          } catch (e) {
            console.error(`[CORR] /timed/all compute failed:`, String(e));
          }
        }
        let versionFilteredCount = 0;
        const versionBreakdown = {}; // Track which versions are being filtered

        for (const { ticker, value } of results) {
          // Debug specific tickers that aren't showing
          if (ticker === "BMNR" || ticker === "BABA") {
            console.log(`[ALL ENDPOINT DEBUG] ${ticker}:`, {
              inIndex: tickers.includes(ticker),
              hasValue: !!value,
              valueKeys: value ? Object.keys(value) : [],
              htf_score: value?.htf_score,
              ltf_score: value?.ltf_score,
              script_version: value?.script_version,
              price: value?.price,
              state: value?.state,
            });
          }

          if (value) {
            // Accept ALL data - don't filter by version unless explicitly requested
            // This ensures all historical data is accessible
            const tickerVersion = value.script_version || "unknown";

            // Only filter if a specific version was requested AND it doesn't match
            if (useVersionSnapshots && tickerVersion !== requestedVersion) {
              versionFilteredCount++;
              // Track which versions are being filtered
              if (!versionBreakdown[tickerVersion]) {
                versionBreakdown[tickerVersion] = 0;
              }
              versionBreakdown[tickerVersion]++;
              console.log(
                `[FILTER] Ticker ${ticker} filtered: version=${tickerVersion}, requested=${requestedVersion}`
              );
            } else {
              // LIGHTWEIGHT MODE: Skip heavy enrichment, just return raw data
              if (!useLightweightMode) {
                // Always recompute RR to ensure it uses the latest max TP from tp_levels
                value.rr = computeRR(value);
              }

              // Back-compat: compute completeness + summaries if missing (older KV entries)
              if (!useLightweightMode) {
                try {
                if (!value.data_completeness) {
                  value.data_completeness = computeDataCompleteness(value);
                }
                if (!value.tf_summary) {
                  const tfSum = tfTechAlignmentSummary(value);
                  if (tfSum) value.tf_summary = tfSum;
                }
                if (!value.trigger_summary) {
                  value.trigger_summary = triggerSummaryAndScore(value);
                }
                if (!value.move_status) {
                  value.move_status = computeMoveStatus(value);
                }
                value.flags = value.flags && typeof value.flags === "object" ? value.flags : {};
                value.flags.move_invalidated = value.move_status?.status === "INVALIDATED";
                value.flags.move_completed = value.move_status?.status === "COMPLETED";
              } catch (e) {
                console.error(
                  `[ENRICH] /timed/all failed for ${ticker}:`,
                  String(e?.message || e)
                );
                }
              } // End lightweight mode skip

              // Calculate dynamicScore (for ranking) - backend calculation
              if (!useLightweightMode) {
                value.dynamicScore = computeDynamicScore(value);
              }

              // Back-compat: compute derived horizon/ETA v2 + target TP fields if missing
              if (!useLightweightMode) {
              try {
                if (
                  !value.horizon_bucket ||
                  value.eta_days_v2 == null ||
                  value.tp_target_price == null ||
                  value.tp_target_pct == null
                ) {
                  const derived = deriveHorizonAndMetrics(value);
                  Object.assign(value, derived);
                }
              } catch (e) {
                console.error(
                  `[DERIVED METRICS] /timed/all failed for ${ticker}:`,
                  String(e)
                );
              }
              // Back-compat: compute entry decision if missing
              try {
                if (!value.entry_decision) {
                  value.entry_decision = buildEntryDecision(
                    ticker,
                    value,
                    null
                  );
                }
              } catch (e) {
                console.error(
                  `[ENTRY DECISION] /timed/all failed for ${ticker}:`,
                  String(e)
                );
                }
              } // End lightweight mode skip

              if (!useLightweightMode) {
                if (corrData && corrData.avgCorrByTicker) {
                  const corr =
                    corrData.avgCorrByTicker[String(ticker).toUpperCase()];
                  if (corr) {
                    value.avg_corr = corr.avg_corr;
                    value.diversity_score = corr.diversity_score;
                    value.corr_count = corr.corr_count;
                  }
                }
              }

              // Enrich with sector from SECTOR_MAP if not present in data
              if (!value.sector && !value.fundamentals?.sector) {
                const sectorFromMap = getSector(ticker);
                if (sectorFromMap) {
                  // Add sector to both top-level and fundamentals for consistency
                  value.sector = sectorFromMap;
                  if (!value.fundamentals) {
                    value.fundamentals = {};
                  }
                  value.fundamentals.sector = sectorFromMap;
                }
              }

              data[ticker] = value;
            }
          } else {
            // Log tickers in index but without data
            if (ticker === "BMNR" || ticker === "BABA") {
              console.log(
                `[ALL ENDPOINT DEBUG] ${ticker}: In index but no data found in KV`
              );
            }
          }
        }

        // Backfill daily change fields (watchlist-style) if missing.
        // Many tickers do not include prev close / session change from TradingView,
        // so we derive prev_close from D1 timed_trail and cache it in KV.
        //
        // IMPORTANT: We anchor "current day" to each ticker's own last timestamp.
        // This makes weekends behave like a trading platform watchlist:
        // - Sat/Sun: compare Friday close vs Thursday close (since ticker ts is Friday)
        // - Mon: compare current vs Friday close
        // - Tue: compare current vs Monday close, etc.
        try {
          const db = env?.DB;
          if (db) {
            const needs = [];
            const byDay = new Map(); // dayKey -> Set(ticker)

            for (const [sym, v] of Object.entries(data)) {
              if (!v || typeof v !== "object") continue;
              const price = Number(v.price);
              if (!Number.isFinite(price) || price <= 0) continue;
              if (
                v.prev_close != null ||
                v.day_change != null ||
                v.day_change_pct != null
              ) {
                continue;
              }
              const ts = Number(v.ts ?? v.ingest_ts);
              const dayKey = nyTradingDayKey(ts);
              if (!dayKey) continue;
              needs.push(sym);
              if (!byDay.has(dayKey)) byDay.set(dayKey, new Set());
              byDay.get(dayKey).add(String(sym).toUpperCase());
            }

            if (needs.length > 0 && byDay.size > 0) {
              const cachePromises = [];

              for (const [dayKey, tickSet] of byDay.entries()) {
                const prevKey = prevTradingDayKey(dayKey);
                if (!prevKey) continue;
                const closeCutoff = nyWallTimeToUtcMs(prevKey, 16, 0, 0);
                if (!Number.isFinite(closeCutoff)) continue;
                const lookbackStart = closeCutoff - 14 * 24 * 60 * 60 * 1000;

                // Watchlist semantics: prev_close = prior trading day regular close (4pm ET).
                const rows = await db
                  .prepare(
                    `SELECT t1.ticker AS ticker, t1.price AS price, t1.ts AS ts
                     FROM timed_trail t1
                     JOIN (
                       SELECT ticker, MAX(ts) AS tsMax
                       FROM timed_trail
                       WHERE ts >= ?1 AND ts <= ?2 AND price IS NOT NULL
                       GROUP BY ticker
                     ) t2
                     ON t1.ticker = t2.ticker AND t1.ts = t2.tsMax`
                  )
                  .bind(lookbackStart, closeCutoff + 1000)
                  .all();

                const closeMap = new Map();
                for (const r of rows?.results || []) {
                  const sym = String(r.ticker || "").toUpperCase();
                  const p = Number(r.price);
                  if (sym && Number.isFinite(p) && p > 0 && !closeMap.has(sym)) {
                    closeMap.set(sym, { close: p, ts: Number(r.ts) });
                  }
                }

                for (const sym of tickSet.values()) {
                  const v = data[sym];
                  if (!v) continue;
                  const price = Number(v.price);
                  const rec = closeMap.get(sym);
                  const prevClose = Number(rec?.close);
                  if (!Number.isFinite(price) || price <= 0) continue;
                  if (!Number.isFinite(prevClose) || prevClose <= 0) continue;

                  v.prev_close = prevClose;
                  v.day_change = price - prevClose;
                  v.day_change_pct = ((price - prevClose) / prevClose) * 100;

                  const prevDayKey = prevKey;
                  if (prevDayKey) {
                    cachePromises.push(
                      kvPutJSON(
                        KV,
                        `timed:prev_close:${sym}`,
                        { day: prevDayKey, close: prevClose },
                        14 * 24 * 60 * 60
                      )
                    );
                  }
                }
              }

              if (cachePromises.length > 0) {
                await Promise.allSettled(cachePromises);
              }
            }
          }
        } catch (e) {
          console.warn(`[DAILY CHANGE] /timed/all backfill failed:`, String(e?.message || e));
        }

        // Log summary if any data was filtered
        if (versionFilteredCount > 0) {
          console.log(
            `[FILTER] Filtered ${versionFilteredCount} tickers by version. Breakdown:`,
            versionBreakdown
          );
        }

        // Compute rank positions once (server-authoritative)
        const ranked = Object.entries(data)
          .map(([ticker, value]) => {
            const score = Number(value?.dynamicScore);
            const safeScore = Number.isFinite(score)
              ? score
              : computeDynamicScore(value || {});
            return { ticker, score: safeScore };
          })
          .sort((a, b) => b.score - a.score);
        const rankTotal = ranked.length;
        ranked.forEach((item, idx) => {
          const entry = data[item.ticker];
          if (!entry) return;
          entry.rank_position = idx + 1;
          entry.rank_total = rankTotal;
          entry.rank_score = item.score;
        });

        const responseData = {
          ok: true,
          count: Object.keys(data).length,
          totalIndex: tickers.length,
          versionFiltered: versionFilteredCount,
          versionBreakdown: versionBreakdown,
          dataVersion: storedVersion,
          requestedVersion: requestedVersion || "latest",
          versionsSeen: Array.from(versionsSeen),
          acceptedVersions: Array.from(acceptedVersions),
          currentDataVersion: CURRENT_DATA_VERSION,
          data,
          cached_at: Date.now(),
        };
        
        // Cache the response for future requests (background write, don't await)
        ctx.waitUntil(kvPutJSON(KV, "timed:all:cache", responseData));
        
        return sendJSON(responseData, 200, corsHeaders(env, req));
        */
        // END OF REMOVED ON-DEMAND COMPUTATION CODE
      }

      // GET /timed/prices — lightweight real-time price feed
      // Returns current price + daily change for all tickers from KV cache
      // Updated every 1 minute by the price feed cron
      if (routeKey === "GET /timed/prices") {
        try {
          const cached = await kvGetJSON(KV, "timed:prices");
          if (cached) {
            return sendJSON(
              { ok: true, prices: cached.prices || {}, updated_at: cached.updated_at || 0 },
              200,
              { ...corsHeaders(env, req), "Cache-Control": "public, max-age=15" },
            );
          }
          // Fallback: no cached prices yet
          return sendJSON(
            { ok: true, prices: {}, updated_at: 0, note: "price_feed_not_initialized" },
            200,
            corsHeaders(env, req),
          );
        } catch (e) {
          console.error("[PRICES] /timed/prices error:", e);
          return sendJSON({ ok: false, error: "internal_error" }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/market-calendar — Returns the current market calendar for frontend use.
      // Includes equity holidays, early closes, futures closes, session constants, and current status.
      if (routeKey === "GET /timed/market-calendar") {
        try {
          const cal = _cronCalendar || await loadCalendar(env);
          const now = new Date();
          const etDateStr = new Date().toLocaleDateString("en-CA", { timeZone: "America/New_York" });
          return sendJSON({
            ok: true,
            source: cal.source || "unknown",
            fetched_at: cal.fetchedAt,
            equity: {
              holidays: [...(cal.equityHolidays || [])],
              early_closes: [...(cal.equityEarlyClose || [])],
              is_holiday_today: cal.equityHolidays?.has?.(etDateStr) || false,
              is_early_close_today: cal.equityEarlyClose?.has?.(etDateStr) || false,
            },
            futures: {
              full_closes: [...(cal.futuresFullClose || [])],
              early_closes: [...(cal.futuresEarlyClose || [])],
            },
            session: {
              pm_start: _RTH_OPEN - 330,
              rth_open: _RTH_OPEN,
              rth_close: _RTH_CLOSE,
              ah_end: 1200,
              is_within_operating_hours: _calIsWithinOH(cal, now),
              is_rth: _calIsNyRegularMarketOpen(cal, now),
              session_type: _calGetSessionType(_calGetETMinutes(now)),
            },
            updated_at: Date.now(),
          }, 200, corsHeaders(env, req));
        } catch (e) {
          console.error("[MARKET-CAL] GET failed:", String(e));
          return sendJSON({ ok: false, error: "internal_error" }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/earnings/upcoming — cached upcoming earnings for universe tickers
      if (routeKey === "GET /timed/earnings/upcoming") {
        try {
          let cached = await kvGetJSON(KV, "timed:earnings:upcoming");
          const staleMs = 6 * 3600 * 1000;
          const isEmpty = !cached?.events || cached.events.length === 0;
          const isStale = cached?.updated_at && (Date.now() - cached.updated_at) > staleMs;
          if (isEmpty || isStale) {
            try {
              const today = new Date().toLocaleDateString("en-CA", { timeZone: "America/New_York" });
              const future = new Date(Date.now() + 5 * 86400000).toLocaleDateString("en-CA", { timeZone: "America/New_York" });
              const raw = await fetchFinnhubEarnings(env, today, future);
              const universeSet = new Set(Object.keys(SECTOR_MAP));
              const filtered = raw
                .filter(e => e.symbol && universeSet.has(e.symbol.toUpperCase()))
                .map(e => ({ ...e, symbol: e.symbol.toUpperCase() }));
              cached = { events: filtered, updated_at: Date.now() };
              ctx.waitUntil(kvPutJSON(KV, "timed:earnings:upcoming", cached, 86400).catch(() => {}));
            } catch (fetchErr) {
              console.warn("[EARNINGS] On-demand fetch failed:", String(fetchErr?.message || fetchErr).slice(0, 150));
            }
          }
          return sendJSON(
            { ok: true, events: cached?.events || [], updated_at: cached?.updated_at || 0 },
            200,
            { ...corsHeaders(env, req), "Cache-Control": "public, max-age=300" },
          );
        } catch (e) {
          console.error("[EARNINGS] GET error:", String(e));
          return sendJSON({ ok: false, error: "internal_error" }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/candles?ticker=&tf=&limit=
      if (routeKey === "GET /timed/candles") {
        try {
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          const rateLimit = await checkRateLimitFixedWindow(
            KV,
            ip,
            "/timed/candles",
            20000,
            3600,
          );
          if (!rateLimit.allowed) {
            const retryAfter = Math.max(
              1,
              Math.ceil((rateLimit.resetAt - Date.now()) / 1000),
            );
            return sendJSON(
              { ok: false, error: "rate_limit_exceeded", retryAfter },
              429,
              {
                ...corsHeaders(env, req),
                "Retry-After": String(retryAfter),
                "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
                "X-RateLimit-Remaining": "0",
                "X-RateLimit-Reset": String(rateLimit.resetAt),
              },
            );
          }

          const ticker = normTicker(url.searchParams.get("ticker"));
          const tf = url.searchParams.get("tf");
          const limitRaw = url.searchParams.get("limit");
          const limit =
            limitRaw != null && limitRaw !== "" ? Number(limitRaw) : 200;
          if (!ticker || !tf) {
            return sendJSON(
              { ok: false, error: "missing ticker/tf" },
              400,
              corsHeaders(env, req),
            );
          }

          const res = await d1GetCandles(env, ticker, tf, limit);
          if (!res?.ok) {
            return sendJSON(
              { ok: false, error: res?.error || "candles_read_failed" },
              500,
              corsHeaders(env, req),
            );
          }
          return sendJSON(res, 200, corsHeaders(env, req));
        } catch (e) {
          console.error(`[CANDLES] /timed/candles failed:`, String(e));
          return sendJSON(
            { ok: false, error: "internal_error" },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/trail/performance?ticker=XYZ
      // Lightweight endpoint: returns daily close prices at key lookback dates
      // for 5D/15D/30D/90D performance calculations using actual daily candles.
      if (routeKey === "GET /timed/trail/performance") {
        try {
          const ticker = normTicker(url.searchParams.get("ticker"));
          if (!ticker) {
            return sendJSON({ ok: false, error: "missing ticker" }, 400, corsHeaders(env, req));
          }

          const db = env?.DB;
          if (!db) {
            return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          }

          const t = String(ticker).toUpperCase();

          // Fetch daily candles for the past ~400 trading days (covers 90D+ easily)
          // Sorted descending so most recent is first
          const rows = await db
            .prepare(
              `SELECT ts, c AS close FROM ticker_candles
               WHERE ticker = ?1 AND tf = 'D' AND c IS NOT NULL
               ORDER BY ts DESC
               LIMIT 400`,
            )
            .bind(t)
            .all();

          const candles = Array.isArray(rows?.results) ? rows.results : [];

          if (candles.length === 0) {
            return sendJSON(
              { ok: true, ticker, performance: {}, latestClose: null },
              200,
              corsHeaders(env, req),
            );
          }

          // Most recent candle close = reference price
          const latestClose = Number(candles[0].close);
          const latestTs = Number(candles[0].ts);

          // Build performance for each period
          const periods = [
            { key: "1D", days: 1 },
            { key: "5D", days: 5 },
            { key: "15D", days: 15 },
            { key: "30D", days: 30 },
            { key: "90D", days: 90 },
          ];

          const now = Date.now();
          const performance = {};

          for (const { key, days } of periods) {
            const cutoff = now - days * 24 * 60 * 60 * 1000;
            // Find the closest candle at or before the cutoff
            let closest = null;
            for (const c of candles) {
              if (Number(c.ts) <= cutoff) {
                closest = c;
                break; // candles are DESC sorted, first match is closest
              }
            }
            if (closest) {
              const oldPrice = Number(closest.close);
              const changePct = ((latestClose - oldPrice) / oldPrice) * 100;
              const changePoints = latestClose - oldPrice;
              const actualDays = Math.round((latestTs - Number(closest.ts)) / (24 * 60 * 60 * 1000));
              performance[key] = {
                oldPrice,
                oldTs: Number(closest.ts),
                changePct: Math.round(changePct * 100) / 100,
                changePoints: Math.round(changePoints * 100) / 100,
                actualDays,
                isUp: changePct >= 0,
              };
            }
          }

          return sendJSON(
            { ok: true, ticker, latestClose, latestTs, performance },
            200,
            corsHeaders(env, req),
          );
        } catch (e) {
          return sendJSON(
            { ok: false, error: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/trail?ticker=
      if (routeKey === "GET /timed/trail") {
        try {
          // Rate limiting
          const ip = req.headers.get("CF-Connecting-IP") || "unknown";
          const rateLimit = await checkRateLimitFixedWindow(
            KV,
            ip,
            "/timed/trail",
            20000, // Higher limit: UI may fetch many tickers' trails
            3600,
          );

          if (!rateLimit.allowed) {
            const retryAfter = Math.max(
              1,
              Math.ceil((rateLimit.resetAt - Date.now()) / 1000),
            );
            return sendJSON(
              { ok: false, error: "rate_limit_exceeded", retryAfter },
              429,
              {
                ...corsHeaders(env, req),
                "Retry-After": String(retryAfter),
                "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
                "X-RateLimit-Remaining": "0",
                "X-RateLimit-Reset": String(rateLimit.resetAt),
              },
            );
          }

          const ticker = normTicker(url.searchParams.get("ticker"));
          if (!ticker) {
            return sendJSON(
              { ok: false, error: "missing ticker" },
              400,
              corsHeaders(env, req),
            );
          }

          const sinceRaw = url.searchParams.get("since");
          const cursorRaw = url.searchParams.get("cursor");
          const limitRaw = url.searchParams.get("limit");
          const includeKanbanRaw = url.searchParams.get("include_kanban");
          // cursor takes precedence over since (both represent a timestamp lower bound)
          const since =
            cursorRaw != null && cursorRaw !== "" ? Number(cursorRaw) :
            sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
          const limit = Math.min(
            limitRaw != null && limitRaw !== "" ? Number(limitRaw) : 1000,
            5000,
          );
          // include_kanban=1 or include_kanban=true to get kanban_stage, entry_ts, move_status in trail points
          // Useful for Time Travel replay feature
          const includeKanban = includeKanbanRaw === "1" || includeKanbanRaw === "true";

          // Prefer D1 for longer history, but fall back to KV if D1 is empty/sparse.
          const d1Result = await d1GetTrailRange(env, ticker, since, limit, includeKanban);
          const d1Trail =
            d1Result && Array.isArray(d1Result.trail) ? d1Result.trail : [];

          // KV (rolling window) — also used as fallback when D1 is sparse.
          let kvTrail = [];
          try {
            kvTrail = (await kvGetJSON(KV, `timed:trail:${ticker}`)) || [];
            if (!Array.isArray(kvTrail)) kvTrail = [];
          } catch (kvError) {
            console.error(`[TRAIL] KV read error for ${ticker}:`, kvError);
            kvTrail = [];
          }

          if (since != null && Number.isFinite(since)) {
            kvTrail = kvTrail.filter((p) => Number(p?.ts) >= since);
          }

          // IMPORTANT:
          // D1 can be "ok" but still return very few rows (e.g. not backfilled / intermittent writes),
          // while KV may still have a healthy recent window. If D1 is sparse and KV is richer,
          // return KV so the UI can render a usable trail.
          if (d1Result.ok && d1Trail.length > 0) {
            const d1IsSparse = d1Trail.length < 2;
            const kvIsRicher = kvTrail.length > d1Trail.length;
            if (!d1IsSparse || !kvIsRicher) {
              // Compute next_cursor for pagination: if we hit the limit, the last trail point's ts is the cursor
              const nextCursor = d1Trail.length >= limit && d1Trail.length > 0
                ? Number(d1Trail[d1Trail.length - 1]?.ts) || null
                : null;
              return sendJSON(
                {
                  ok: true,
                  ticker,
                  trail: d1Trail,
                  count: d1Trail.length,
                  source: d1Result.source,
                  next_cursor: nextCursor,
                },
                200,
                {
                  ...corsHeaders(env, req),
                  "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
                  "X-RateLimit-Remaining": String(rateLimit.remaining ?? 0),
                  "X-RateLimit-Reset": String(rateLimit.resetAt ?? Date.now()),
                },
              );
            }
          }

          // KV response (either fallback, or D1 is sparse/unavailable)
          const trail = kvTrail.slice(0, limit);
          const nextCursor = kvTrail.length > limit && trail.length > 0
            ? Number(trail[trail.length - 1]?.ts) || null
            : null;

          return sendJSON(
            {
              ok: true,
              ticker,
              trail,
              count: trail.length,
              source: "kv",
              next_cursor: nextCursor,
              note: d1Result.ok
                ? d1Trail.length > 0
                  ? `D1 returned sparse rows (${d1Trail.length}) — using KV recent window`
                  : "D1 returned 0 rows (falling back to KV)"
                : d1Result.skipped
                  ? `D1 unavailable (${d1Result.reason || "unknown"})`
                  : d1Result.error
                    ? `D1 error (${d1Result.error})`
                    : "D1 unavailable",
            },
            200,
            {
              ...corsHeaders(env, req),
              "X-RateLimit-Limit": String(rateLimit.limit ?? 20000),
              "X-RateLimit-Remaining": String(rateLimit.remaining ?? 0),
              "X-RateLimit-Reset": String(rateLimit.resetAt ?? Date.now()),
            },
          );
        } catch (error) {
          console.error(`[TRAIL] Unexpected error:`, error);
          // Return empty trail instead of 500 error
          const ticker =
            normTicker(url.searchParams.get("ticker")) || "UNKNOWN";
          return sendJSON(
            { ok: true, ticker, trail: [], count: 0, source: "error" },
            200,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/top?bucket=long|short|setup&n=10
      if (routeKey === "GET /timed/top") {
        const n = Math.max(
          1,
          Math.min(50, Number(url.searchParams.get("n") || "10")),
        );
        const bucket = String(
          url.searchParams.get("bucket") || "long",
        ).toLowerCase();
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];

        const items = [];
        for (const t of tickers) {
          const d = await kvGetJSON(KV, `timed:latest:${t}`);
          if (d) items.push(d);
        }

        // IMPORTANT: Top lists should favor corridor relevance for "long/short" tabs.
        // long bucket shows Q2 (bull aligned), short shows Q3 (bear aligned), setup shows Q1/Q4.
        const isLongAligned = (d) => d.state === "HTF_BULL_LTF_BULL";
        const isShortAligned = (d) => d.state === "HTF_BEAR_LTF_BEAR";
        const isSetup = (d) =>
          d.state === "HTF_BULL_LTF_PULLBACK" ||
          d.state === "HTF_BEAR_LTF_PULLBACK";

        let filtered =
          bucket === "long"
            ? items.filter(isLongAligned)
            : bucket === "short"
              ? items.filter(isShortAligned)
              : items.filter(isSetup);

        filtered.sort((a, b) => Number(b.rank || 0) - Number(a.rank || 0));
        filtered = filtered.slice(0, n);

        return sendJSON(
          { ok: true, bucket, n: filtered.length, data: filtered },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/momentum?ticker=XYZ
      if (routeKey === "GET /timed/momentum") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/momentum",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker)
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        let data = await kvGetJSON(KV, `timed:momentum:${ticker}`);
        if (!data) {
          // On-demand compute using latest + capture enrichment (avoids waiting for next cache fill).
          try {
            const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
            const capture = await kvGetJSON(
              KV,
              `timed:capture:latest:${ticker}`,
            );
            const base =
              latest && typeof latest === "object" ? { ...latest } : {};
            if (capture && typeof capture === "object") {
              for (const k of [
                "avg_vol_30",
                "avg_vol_50",
                "adr_14",
                "momentum_pct",
                "price",
              ]) {
                if (base[k] == null && capture[k] != null) base[k] = capture[k];
              }
            }
            if (base && Object.keys(base).length > 0) {
              data = await computeMomentumElite(KV, ticker, base);
            }
          } catch {
            // ignore
          }
        }
        return sendJSON({ ok: true, ticker, data }, 200, corsHeaders(env, req));
      }

      // GET /timed/momentum/history?ticker=XYZ
      if (routeKey === "GET /timed/momentum/history") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/momentum/history",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker)
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        const history =
          (await kvGetJSON(KV, `timed:momentum:history:${ticker}`)) || [];
        return sendJSON(
          { ok: true, ticker, history },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/momentum/all
      if (routeKey === "GET /timed/momentum/all") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/momentum/all",
          1000, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const eliteTickers = [];
        for (const t of tickers) {
          const momentumData = await kvGetJSON(KV, `timed:momentum:${t}`);
          if (momentumData && momentumData.momentum_elite) {
            eliteTickers.push({ ticker: t, ...momentumData });
          }
        }
        return sendJSON(
          { ok: true, count: eliteTickers.length, tickers: eliteTickers },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/sectors - Get all sectors and their ratings
      if (routeKey === "GET /timed/sectors") {
        const sectors = getAllSectors().map((sector) => ({
          sector,
          ...getSectorRating(sector),
          tickerCount: getTickersInSector(sector).length,
        }));

        return sendJSON({ ok: true, sectors }, 200, corsHeaders(env, req));
      }

      // GET /timed/sectors/:sector/tickers?limit=10 - Get top tickers in a sector
      if (routeKey === "GET /timed/sectors/:sector/tickers") {
        const sectorPath = url.pathname
          .replace("/timed/sectors/", "")
          .replace("/tickers", "");
        const sector = decodeURIComponent(sectorPath);
        const limit = Math.max(
          1,
          Math.min(50, Number(url.searchParams.get("limit") || "10")),
        );

        if (!getAllSectors().includes(sector)) {
          return sendJSON(
            { ok: false, error: `Invalid sector: ${sector}` },
            400,
            corsHeaders(env, req),
          );
        }

        const etfWMap = await loadETFWeightMap(env);
        const topTickers = await rankTickersInSector(KV, sector, limit, etfWMap);

        return sendJSON(
          {
            ok: true,
            sector,
            rating: getSectorRating(sector),
            limit: topTickers.length,
            tickers: topTickers,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/sectors/recommendations?limit=10 - Get top tickers across all overweight sectors
      if (routeKey === "GET /timed/sectors/recommendations") {
        const limitPerSector = Math.max(
          1,
          Math.min(20, Number(url.searchParams.get("limit") || "10")),
        );
        const totalLimit = Math.max(
          1,
          Math.min(100, Number(url.searchParams.get("totalLimit") || "50")),
        );

        const overweightSectors = getAllSectors().filter(
          (sector) => getSectorRating(sector).rating === "overweight",
        );

        const allRecommendations = [];
        const etfWMapReco = await loadETFWeightMap(env);

        for (const sector of overweightSectors) {
          const topTickers = await rankTickersInSector(
            KV,
            sector,
            limitPerSector,
            etfWMapReco,
          );
          allRecommendations.push(
            ...topTickers.map((t) => ({
              ...t,
              sector,
            })),
          );
        }

        // Sort by boosted rank and take top N
        allRecommendations.sort((a, b) => b.boostedRank - a.boostedRank);
        const topRecommendations = allRecommendations.slice(0, totalLimit);

        return sendJSON(
          {
            ok: true,
            sectors: overweightSectors,
            limitPerSector,
            totalLimit: topRecommendations.length,
            recommendations: topRecommendations,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/debug/migrate-brk?key=... - Migrate BRK.B to BRK-B
      if (routeKey === "POST /timed/debug/migrate-brk") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const oldData = await kvGetJSON(KV, `timed:latest:BRK.B`);
          const newData = await kvGetJSON(KV, `timed:latest:BRK-B`);

          if (!oldData && !newData) {
            return sendJSON(
              { ok: false, error: "No BRK data found" },
              404,
              corsHeaders(env, req),
            );
          }

          // Use newer data if both exist
          const dataToUse =
            oldData && newData && newData.ts > oldData.ts
              ? newData
              : oldData || newData;
          const migrated = !!oldData && oldData !== dataToUse;

          await kvPutJSON(KV, `timed:latest:BRK-B`, dataToUse);

          // Migrate trail data
          const oldTrail = await kvGetJSON(KV, `timed:trail:BRK.B`);
          const newTrail = await kvGetJSON(KV, `timed:trail:BRK-B`);
          if (oldTrail || newTrail) {
            await kvPutJSON(KV, `timed:trail:BRK-B`, oldTrail || newTrail);
          }

          // Ensure BRK-B is in index
          await ensureTickerIndex(KV, "BRK-B");

          // Remove BRK.B from index if it exists
          let tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          if (tickers.includes("BRK.B")) {
            tickers = tickers.filter((t) => t !== "BRK.B");
            await kvPutJSON(KV, "timed:tickers", tickers);
          }

          // Delete old BRK.B data if we migrated
          if (migrated) {
            await KV.delete(`timed:latest:BRK.B`);
            await KV.delete(`timed:trail:BRK.B`);
          }

          return sendJSON(
            {
              ok: true,
              message: "BRK migration completed",
              hadOldData: !!oldData,
              hadNewData: !!newData,
              migrated,
              finalTicker: "BRK-B",
              ts: dataToUse?.ts,
              htf_score: dataToUse?.htf_score,
              ltf_score: dataToUse?.ltf_score,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          console.error(`[MIGRATE BRK ERROR]`, {
            error: String(err),
            message: err.message,
            stack: err.stack,
          });
          return sendJSON(
            { ok: false, error: "internal_error", message: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/cleanup-duplicates?key=... - Remove duplicate/empty tickers from index
      if (routeKey === "POST /timed/debug/cleanup-duplicates") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const duplicatesToRemove = [
            "BTC", // Duplicate of BTCUSD (BTCUSD has data)
            "ES", // Duplicate of ES1! (ES1! has data)
            "ETH", // Duplicate of ETHUSD (ETHUSD has data)
            "NQ", // Duplicate of NQ1! (NQ1! has data)
            "MES1!", // Not sending data
            "MNQ1!", // Not sending data
          ];

          const removed = [];
          const notFound = [];
          const hasData = [];

          for (const ticker of duplicatesToRemove) {
            if (!tickers.includes(ticker)) {
              notFound.push(ticker);
              continue;
            }

            // Check if ticker has data
            const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
            if (
              data &&
              (data.htf_score !== undefined || data.ltf_score !== undefined)
            ) {
              hasData.push(ticker);
              continue; // Don't remove if it has data
            }

            // Remove from index
            removed.push(ticker);

            // Also delete the data if it exists (even without scores)
            await KV.delete(`timed:latest:${ticker}`);
            await KV.delete(`timed:trail:${ticker}`);
          }

          // Update index once after processing all removals
          if (removed.length > 0) {
            const updatedTickers = tickers.filter((t) => !removed.includes(t));
            updatedTickers.sort();
            await kvPutJSON(KV, "timed:tickers", updatedTickers);
          }

          const finalTickers = (await kvGetJSON(KV, "timed:tickers")) || [];

          return sendJSON(
            {
              ok: true,
              message: "Cleanup completed",
              removed,
              notFound,
              hasData,
              beforeCount: tickers.length,
              afterCount: finalTickers.length,
              removedCount: removed.length,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/fix-index?key=...&ticker=BMNR - Manually add ticker to index if data exists
      if (routeKey === "POST /timed/debug/fix-index") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        // Allow requests without origin for debug endpoints (curl, direct API calls)
        const cors = corsHeaders(env, req, true);

        try {
          const ticker = normTicker(url.searchParams.get("ticker"));
          if (!ticker) {
            return sendJSON(
              { ok: false, error: "ticker parameter required" },
              400,
              cors,
            );
          }

          // Check if data exists in KV
          const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
          const inIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const alreadyInIndex = inIndex.includes(ticker);

          if (!data) {
            return sendJSON(
              {
                ok: false,
                error: "ticker data not found in KV",
                ticker,
                inIndex: alreadyInIndex,
              },
              404,
              cors,
            );
          }

          // Add to index if not already there
          if (!alreadyInIndex) {
            await ensureTickerIndex(KV, ticker);
            const updatedIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
            const nowInIndex = updatedIndex.includes(ticker);

            return sendJSON(
              {
                ok: true,
                message: `Ticker ${ticker} ${
                  nowInIndex ? "added to" : "failed to add to"
                } index`,
                ticker,
                hadData: true,
                wasInIndex: false,
                nowInIndex,
                indexSize: updatedIndex.length,
              },
              200,
              cors,
            );
          } else {
            return sendJSON(
              {
                ok: true,
                message: `Ticker ${ticker} already in index`,
                ticker,
                hadData: true,
                inIndex: true,
                indexSize: inIndex.length,
              },
              200,
              cors,
            );
          }
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, cors);
        }
      }

      // Check which symbols exist and are tradable in Alpaca's US equity universe.
      // Returns { valid: string[], invalid: string[] }. If Alpaca not configured, returns all as valid.
      async function alpacaValidateSymbols(env, symbols) {
        const apiKeyId = env?.ALPACA_API_KEY_ID;
        const apiSecret = env?.ALPACA_API_SECRET_KEY;
        if (!apiKeyId || !apiSecret || !symbols.length) {
          return { valid: [...symbols], invalid: [] };
        }
        const base = env.ALPACA_API_BASE || "https://paper-api.alpaca.markets";
        const valid = [];
        const invalid = [];
        for (const sym of symbols) {
          try {
            const url = `${base}/v2/assets/${encodeURIComponent(sym)}`;
            const resp = await fetch(url, {
              headers: {
                "APCA-API-KEY-ID": apiKeyId,
                "APCA-API-SECRET-KEY": apiSecret,
                "Accept": "application/json",
              },
            });
            if (!resp.ok) {
              invalid.push(sym);
              continue;
            }
            const asset = await resp.json();
            if (asset && asset.tradable === true) {
              valid.push(sym);
            } else {
              invalid.push(sym);
            }
          } catch (_) {
            invalid.push(sym);
          }
        }
        return { valid, invalid };
      }

      // ── Alpaca Auto-Enrichment: fetch company name from /v2/assets/{sym} ──
      // Used by /timed/all background enrichment and POST /timed/enrich-alpaca bulk endpoint.
      async function alpacaEnrichMissingContext(env, KV, symbols) {
        const apiKeyId = env?.ALPACA_API_KEY_ID;
        const apiSecret = env?.ALPACA_API_SECRET_KEY;
        if (!apiKeyId || !apiSecret || !symbols.length) return { enriched: 0, skipped: 0 };
        const base = env.ALPACA_API_BASE || "https://paper-api.alpaca.markets";
        let enriched = 0, skipped = 0;
        for (const sym of symbols) {
          try {
            // Check if already enriched in KV (avoid redundant Alpaca calls)
            const existing = await kvGetJSON(KV, `timed:context:${sym}`);
            if (existing && existing.name) { skipped++; continue; }

            const url = `${base}/v2/assets/${encodeURIComponent(sym)}`;
            const resp = await fetch(url, {
              headers: {
                "APCA-API-KEY-ID": apiKeyId,
                "APCA-API-SECRET-KEY": apiSecret,
                "Accept": "application/json",
              },
            });
            if (!resp.ok) { skipped++; continue; }
            const asset = await resp.json();
            if (!asset?.name) { skipped++; continue; }

            const enrichment = {
              name: asset.name,
              _enriched_at: Date.now(),
              _source: "alpaca_asset",
            };
            if (asset.exchange) enrichment.exchange = asset.exchange;
            // Merge with any existing partial context
            const merged = { ...(existing || {}), ...enrichment };
            await kvPutJSON(KV, `timed:context:${sym}`, merged, 90 * 24 * 60 * 60);

            // Also patch D1 ticker_latest so /timed/all includes context on next load
            try {
              if (env?.DB) {
                const row = await env.DB.prepare(`SELECT payload_json FROM ticker_latest WHERE ticker = ?`).bind(sym).first();
                if (row?.payload_json) {
                  const payload = JSON.parse(row.payload_json);
                  payload.context = { ...(payload.context || {}), ...enrichment };
                  await env.DB.prepare(`UPDATE ticker_latest SET payload_json = ? WHERE ticker = ?`).bind(JSON.stringify(payload), sym).run();
                }
              }
            } catch { /* D1 patch non-critical */ }

            enriched++;
          } catch (e) {
            console.warn(`[ALPACA ENRICH] Failed for ${sym}:`, String(e));
            skipped++;
          }
        }
        if (enriched > 0) {
          console.log(`[ALPACA ENRICH] Enriched ${enriched} tickers, skipped ${skipped}`);
        }
        return { enriched, skipped };
      }

      // POST /timed/watchlist/add?key=... - Add tickers to watchlist
      // Validates equity symbols against Alpaca universe before adding. Then triggers backfill (prev 30 days).
      // Supports both API key and CF Access JWT (admin) authentication.
      if (routeKey === "POST /timed/watchlist/add") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;

        try {
          const { obj: body } = await readBodyAsJSON(req);
          const tickersToAdd = body.tickers || [];

          if (!Array.isArray(tickersToAdd) || tickersToAdd.length === 0) {
            return sendJSON(
              { ok: false, error: "tickers array required" },
              400,
              corsHeaders(env, req),
            );
          }

          // Normalize and dedupe
          const normalized = [...new Set(tickersToAdd.map(t => String(t).toUpperCase().trim()).filter(Boolean))];
          if (normalized.length === 0) {
            return sendJSON(
              { ok: false, error: "no valid ticker symbols" },
              400,
              corsHeaders(env, req),
            );
          }

          // Validate equity symbols against Alpaca (skip futures 1!, crypto, etc.)
          const toValidate = normalized.filter(t => !t.endsWith("1!"));
          if (toValidate.length > 0 && env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY) {
            const { valid: alpacaValid, invalid: alpacaInvalid } = await alpacaValidateSymbols(env, toValidate);
            if (alpacaInvalid.length > 0) {
              return sendJSON(
                {
                  ok: false,
                  error: "alpaca_symbol_not_found",
                  invalid: alpacaInvalid,
                  message: `These symbols are not in the Alpaca US equity universe or are not tradable: ${alpacaInvalid.join(", ")}. Try another symbol.`,
                },
                400,
                corsHeaders(env, req),
              );
            }
          }

          const currentTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const blocklist = new Set((await kvGetJSON(KV, "timed:removed")) || []);
          const added = [];
          const reactivated = [];

          for (const ticker of normalized) {
            const tickerUpper = String(ticker).toUpperCase().trim();
            if (!tickerUpper) continue;

            const wasRemoved = blocklist.has(tickerUpper);
            const inIndex = currentTickers.includes(tickerUpper);

            if (wasRemoved) {
              // Ticker was removed — un-remove it and ensure it's in the index
              blocklist.delete(tickerUpper);
              if (!inIndex) {
                currentTickers.push(tickerUpper);
                await ensureTickerIndex(KV, tickerUpper);
              }
              reactivated.push(tickerUpper);
              added.push(tickerUpper);
            } else if (!inIndex) {
              // Brand new ticker
              currentTickers.push(tickerUpper);
              added.push(tickerUpper);
              await ensureTickerIndex(KV, tickerUpper);
            } else {
              // Already in index and not removed — still treat as "added" for backfill
              reactivated.push(tickerUpper);
              added.push(tickerUpper);
            }
          }

          // Sort and save
          currentTickers.sort();
          await kvPutJSON(KV, "timed:tickers", currentTickers);
          await kvPutJSON(KV, "timed:removed", [...blocklist]);

          // Ensure new tickers have a sector_map entry so ingestion-status and SECTOR_MAP show them
          for (const tickerUpper of added) {
            try {
              const existing = await KV.get(`timed:sector_map:${tickerUpper}`, "text");
              if (!existing || existing.trim() === "") {
                await KV.put(`timed:sector_map:${tickerUpper}`, "Unknown");
                SECTOR_MAP[tickerUpper] = "Unknown";
              }
            } catch (_) { /* best-effort */ }
          }

          // Add to D1 ticker_index and a minimal ticker_latest row so /timed/tickers and
          // /timed/all include the new ticker immediately (dashboard and Tickers Page show it).
          const db = env?.DB;
          if (db && added.length > 0) {
            const now = Date.now();
            for (const tickerUpper of added) {
              try {
                await d1UpsertTickerIndex(env, tickerUpper, now);
              } catch (e) {
                console.warn("[WATCHLIST ADD] D1 ticker_index failed for", tickerUpper, String(e?.message || e).slice(0, 150));
              }
              try {
                const placeholder = { ticker: tickerUpper, ts: now, price: null };
                const latestResult = await d1UpsertTickerLatest(env, tickerUpper, placeholder);
                if (!latestResult?.ok) {
                  console.warn("[WATCHLIST ADD] D1 ticker_latest failed for", tickerUpper, latestResult?.reason || latestResult?.error || "unknown");
                }
              } catch (e) {
                console.warn("[WATCHLIST ADD] D1 ticker_latest exception for", tickerUpper, String(e?.message || e).slice(0, 150));
              }
            }
          }

          // Trigger Alpaca candle backfill for added tickers (background via ctx.waitUntil)
          // After backfill completes, auto-score each ticker so CP + dashboard data appear immediately
          const backfillTriggered = [];
          if (added.length > 0 && env.ALPACA_ENABLED === "true" && env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY) {
            const tickersToBackfill = added.filter((t) => !t.endsWith("1!")).slice(0, 10);
            if (tickersToBackfill.length > 0) {
              ctx.waitUntil(
                alpacaBackfill(env, tickersToBackfill, d1UpsertCandle, "all", 30)
                  .then(async (res) => {
                    console.log(`[WATCHLIST ADD] Backfill done:`, JSON.stringify(res));
                    // Auto-score each backfilled ticker so price/scores appear immediately
                    for (const tk of tickersToBackfill) {
                      try {
                        const existing = await kvGetJSON(KV, `timed:latest:${tk}`);
                        const scored = await computeServerSideScores(tk, d1GetCandles, env, existing);
                        if (scored) {
                          scored.rank = computeRank(scored);
                          scored.score = scored.rank;
                          scored.data_source = "alpaca";
                          scored.trigger_ts = Date.now();
                          await kvPutJSON(KV, `timed:latest:${tk}`, scored);
                          await d1UpsertTickerLatest(env, tk, scored);
                          console.log(`[WATCHLIST ADD] Auto-scored ${tk}: price=${scored.price}, state=${scored.state}`);
                        } else {
                          console.warn(`[WATCHLIST ADD] Auto-score ${tk}: insufficient candle data`);
                        }
                      } catch (scoreErr) {
                        console.error(`[WATCHLIST ADD] Auto-score ${tk} error:`, String(scoreErr));
                      }
                    }
                  })
                  .catch((err) => console.error(`[WATCHLIST ADD] Backfill error:`, err))
              );
              backfillTriggered.push(...tickersToBackfill);
            }
          }

          return sendJSON(
            {
              ok: true,
              added: added.length,
              reactivated: reactivated.length,
              addedTickers: added,
              reactivatedTickers: reactivated,
              totalTickers: currentTickers.length,
              backfillTriggered: backfillTriggered,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/watchlist/remove?key=... - Remove tickers from watchlist
      if (routeKey === "POST /timed/watchlist/remove") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;

        try {
          const { obj: body } = await readBodyAsJSON(req);
          const tickersToRemove = body.tickers || [];

          if (!Array.isArray(tickersToRemove) || tickersToRemove.length === 0) {
            return sendJSON(
              { ok: false, error: "tickers array required" },
              400,
              corsHeaders(env, req),
            );
          }

          const removeSet = new Set(tickersToRemove.map(t => String(t).toUpperCase().trim()).filter(Boolean));
          const removed = [...removeSet];

          // 1) Remove from KV ticker index (if present)
          const currentTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const updatedTickers = currentTickers.filter(t => !removeSet.has(t));
          updatedTickers.sort();
          await kvPutJSON(KV, "timed:tickers", updatedTickers);

          // 2) Add to persistent blocklist in KV so ingestion-status filters them out
          //    across all worker isolates (SECTOR_MAP is per-isolate and resets on cold start)
          const blocklist = new Set((await kvGetJSON(KV, "timed:removed")) || []);
          for (const t of removed) blocklist.add(t);
          await kvPutJSON(KV, "timed:removed", [...blocklist]);

          // 3) Remove from in-memory SECTOR_MAP (helps this isolate immediately)
          for (const ticker of removed) {
            delete SECTOR_MAP[ticker];
          }

          // 4) Clean up ALL per-ticker KV data for removed tickers
          const cleanKV = body.cleanKV !== false; // default true
          if (cleanKV) {
            for (const ticker of removed) {
              for (const prefix of TICKER_KV_PREFIXES) {
                try { await KV.delete(`${prefix}${ticker}`); } catch (_) {}
              }
            }
          }

          // 5) Remove from D1 ticker_index + ticker_latest (so /timed/tickers reflects removal)
          const db = env?.DB;
          if (db && removed.length > 0) {
            try {
              const placeholders = removed.map((_, i) => `?${i + 1}`).join(",");
              await db.batch([
                db.prepare(`DELETE FROM ticker_index WHERE ticker IN (${placeholders})`).bind(...removed),
                db.prepare(`DELETE FROM ticker_latest WHERE ticker IN (${placeholders})`).bind(...removed),
              ]);
            } catch (e) {
              console.warn("[WATCHLIST REMOVE] D1 cleanup failed:", String(e?.message || e).slice(0, 200));
            }
          }

          return sendJSON(
            {
              ok: true,
              removed: removed.length,
              removedTickers: removed,
              totalTickers: updatedTickers.length,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/queued-actions
      if (routeKey === "GET /timed/queued-actions") {
        try {
          await d1EnsureQueueSchema(env);
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const cutoff = Date.now() - 24 * 60 * 60 * 1000;
          const [rows, countRow] = await Promise.all([
            db.prepare(
              `SELECT id, ticker, action, direction, session, reason, status, resolution, queued_at, resolved_at
               FROM queued_actions WHERE status = 'PENDING' OR resolved_at > ?1
               ORDER BY queued_at DESC LIMIT 200`
            ).bind(cutoff).all(),
            db.prepare(`SELECT COUNT(*) as cnt FROM queued_actions WHERE status = 'PENDING'`).first(),
          ]);
          return sendJSON({
            ok: true,
            actions: (rows?.results || []).map(r => ({ ...r, snapshot: undefined })),
            pendingCount: Number(countRow?.cnt) || 0,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/activity
      if (routeKey === "GET /timed/activity") {
        const feed = (await kvGetJSON(KV, "timed:activity:feed")) || [];

        const now = Date.now();
        const oneWeekAgo = now - 7 * 24 * 60 * 60 * 1000;
        const currentEvents = [];

        // Merge feed events with current events, deduplicate by ticker+type
        const allEvents = [...feed, ...currentEvents];
        const seen = new Set();
        const uniqueEvents = allEvents.filter((e) => {
          const key = `${e.ticker}-${e.type}-${Math.floor(
            e.ts / (60 * 60 * 1000),
          )}`; // Group by hour
          if (seen.has(key)) return false;
          seen.add(key);
          return e.ts > oneWeekAgo; // Only keep events from last week
        });

        // Sort by timestamp descending
        uniqueEvents.sort((a, b) => b.ts - a.ts);

        const limit = Math.min(
          100,
          Number(url.searchParams.get("limit") || "100"),
        );
        const filtered = uniqueEvents.slice(0, limit);

        return sendJSON(
          {
            ok: true,
            count: filtered.length,
            events: filtered,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/check-ticker?ticker=AAPL
      if (routeKey === "GET /timed/check-ticker") {
        const ticker = url.searchParams.get("ticker");
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "ticker parameter required" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickerUpper = ticker.toUpperCase();
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const inIndex = tickers.includes(tickerUpper);
        const latest = await kvGetJSON(KV, `timed:latest:${tickerUpper}`);
        const trail = await kvGetJSON(KV, `timed:trail:${tickerUpper}`);

        // Capture-only channel (some TV alerts may be wired to /timed/ingest-capture)
        const captureTickers =
          (await kvGetJSON(KV, "timed:capture:tickers")) || [];
        const inCaptureIndex = Array.isArray(captureTickers)
          ? captureTickers.includes(tickerUpper)
          : false;
        const captureLatest = await kvGetJSON(
          KV,
          `timed:capture:latest:${tickerUpper}`,
        );
        const captureTrail = await kvGetJSON(
          KV,
          `timed:capture:trail:${tickerUpper}`,
        );

        // Raw payload breadcrumbs (last seen) to identify which endpoint is receiving data.
        // NOTE: truncated for safety/size.
        const ingestRawKey = `timed:ingest:raw:${tickerUpper}`;
        const captureRawKey = `timed:capture:raw:${tickerUpper}`;
        const ingestRaw = await KV.get(ingestRawKey);
        const captureRaw = await KV.get(captureRawKey);
        const ingestRawSample = ingestRaw
          ? String(ingestRaw).slice(0, 500)
          : null;
        const captureRawSample = captureRaw
          ? String(captureRaw).slice(0, 500)
          : null;

        const latestTs =
          latest?.ingest_ts ?? latest?.ingest_time ?? latest?.ts ?? null;
        const captureTs =
          captureLatest?.ingest_ts ??
          captureLatest?.ingest_time ??
          captureLatest?.ts ??
          null;
        const likelyCaptureOnly = !!captureLatest && !latest && inCaptureIndex;

        return sendJSON(
          {
            ok: true,
            ticker: tickerUpper,
            inIndex,
            hasLatest: !!latest,
            hasTrail: !!trail,
            latestData: latest || null,
            trailLength: trail ? trail.length : 0,
            inCaptureIndex,
            hasCaptureLatest: !!captureLatest,
            hasCaptureTrail: !!captureTrail,
            captureLatestData: captureLatest || null,
            captureTrailLength: captureTrail ? captureTrail.length : 0,
            debug: {
              latestTs,
              captureTs,
              likelyCaptureOnly,
              raw: {
                ingestRawPresent: !!ingestRaw,
                captureRawPresent: !!captureRaw,
                ingestRawSample,
                captureRawSample,
              },
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ingest-status
      if (routeKey === "GET /timed/ingest-status") {
        try {
          const now = new Date();
          const result = await checkIngestCoverage(KV, now);
          return sendJSON(
            {
              ok: true,
              marketHoursET: isMarketHoursET(now),
              checked: result.checked || 0,
              missing: result.missing || [],
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: String(err?.message || err) },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/ingestion/stats?since&until&bucketMin
      // Coverage = distinct(ticker,bucket) / (watchlist_count * bucket_count)
      if (routeKey === "GET /timed/ingestion/stats") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const now = Date.now();
        const since = numParam(url, "since", now - 6 * 60 * 60 * 1000);
        const until = numParam(url, "until", now);
        const bucketMin = Math.max(
          1,
          Math.floor(numParam(url, "bucketMin", 5)),
        );
        const bucketMs = bucketMin * 60 * 1000;
        const threshold = Math.max(
          0,
          Math.min(1, numParam(url, "threshold", 0.9)),
        );
        const basis = String(url.searchParams.get("basis") || "payload")
          .trim()
          .toLowerCase(); // payload|received

        if (
          !Number.isFinite(since) ||
          !Number.isFinite(until) ||
          until <= since
        ) {
          return sendJSON(
            { ok: false, error: "invalid_since_until" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const watchlistCount = Array.isArray(tickers) ? tickers.length : 0;

        const bucketStart = Math.floor(since / bucketMs) * bucketMs;
        const bucketEnd = Math.floor(until / bucketMs) * bucketMs;
        const bucketCount =
          bucketEnd >= bucketStart
            ? Math.floor((bucketEnd - bucketStart) / bucketMs) + 1
            : 0;
        const expectedPairs = watchlistCount * bucketCount;

        const receiptsTotalRow = await db
          .prepare(
            `SELECT COUNT(*) AS n
             FROM ingest_receipts
             WHERE received_ts >= ?1 AND received_ts <= ?2`,
          )
          .bind(since, until)
          .first();

        const distinctPairsRow = await db
          .prepare(
            basis === "received"
              ? `SELECT COUNT(DISTINCT ticker || ':' || (CAST(received_ts / ?1 AS INTEGER) * ?1)) AS n
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3`
              : `SELECT COUNT(DISTINCT ticker || ':' || (CAST(ts / ?1 AS INTEGER) * ?1)) AS n
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3`,
          )
          .bind(bucketMs, since, until)
          .first();

        const receiptsTotal = Number(receiptsTotalRow?.n) || 0;
        const distinctPairs = Number(distinctPairsRow?.n) || 0;
        const coverage =
          expectedPairs > 0 ? distinctPairs / expectedPairs : null;

        return sendJSON(
          {
            ok: true,
            window: {
              since,
              until,
              bucketMin,
              bucketMs,
              bucketStart,
              bucketEnd,
              bucketCount,
            },
            basis,
            watchlistCount,
            expectedPairs,
            receiptsTotal,
            distinctPairs,
            coveragePct:
              coverage == null ? null : Math.round(coverage * 10000) / 100,
            meetsThreshold: coverage == null ? null : coverage >= threshold,
            thresholdPct: Math.round(threshold * 10000) / 100,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/watchlist/coverage?since&until&bucketMin&threshold
      // Per-ticker coverage across expected buckets (uses ingest_receipts)
      if (routeKey === "GET /timed/watchlist/coverage") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const now = Date.now();
        const since = numParam(url, "since", now - 6 * 60 * 60 * 1000);
        const until = numParam(url, "until", now);
        const bucketMin = Math.max(
          1,
          Math.floor(numParam(url, "bucketMin", 5)),
        );
        const bucketMs = bucketMin * 60 * 1000;
        const threshold = Math.max(
          0,
          Math.min(1, numParam(url, "threshold", 0.9)),
        );
        const basis = String(url.searchParams.get("basis") || "payload")
          .trim()
          .toLowerCase(); // payload|received

        if (
          !Number.isFinite(since) ||
          !Number.isFinite(until) ||
          until <= since
        ) {
          return sendJSON(
            { ok: false, error: "invalid_since_until" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const list = Array.isArray(tickers)
          ? tickers
              .map((t) =>
                String(t || "")
                  .trim()
                  .toUpperCase(),
              )
              .filter(Boolean)
          : [];

        const bucketStart = Math.floor(since / bucketMs) * bucketMs;
        const bucketEnd = Math.floor(until / bucketMs) * bucketMs;
        const bucketCount =
          bucketEnd >= bucketStart
            ? Math.floor((bucketEnd - bucketStart) / bucketMs) + 1
            : 0;

        const rows = await db
          .prepare(
            basis === "received"
              ? `SELECT
                  ticker,
                  COUNT(DISTINCT (CAST(received_ts / ?1 AS INTEGER) * ?1)) AS seen_buckets
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3
                 GROUP BY ticker`
              : `SELECT
                  ticker,
                  COUNT(DISTINCT (CAST(ts / ?1 AS INTEGER) * ?1)) AS seen_buckets
                 FROM ingest_receipts
                 WHERE received_ts >= ?2 AND received_ts <= ?3
                 GROUP BY ticker`,
          )
          .bind(bucketMs, since, until)
          .all();

        const seenByTicker = new Map();
        for (const r of rows?.results || []) {
          const t = String(r.ticker || "").toUpperCase();
          const n = Number(r.seen_buckets) || 0;
          if (t) seenByTicker.set(t, n);
        }

        const perTicker = list.map((t) => {
          const seen = seenByTicker.get(t) || 0;
          const pct = bucketCount > 0 ? seen / bucketCount : 0;
          return {
            ticker: t,
            seenBuckets: seen,
            expectedBuckets: bucketCount,
            coveragePct: bucketCount > 0 ? Math.round(pct * 10000) / 100 : null,
            meetsThreshold: bucketCount > 0 ? pct >= threshold : null,
          };
        });

        const tickersTotal = perTicker.length;
        const tickersAny = perTicker.filter(
          (t) => (t.seenBuckets || 0) > 0,
        ).length;
        const tickersMeet = perTicker.filter(
          (t) => t.meetsThreshold === true,
        ).length;

        // Sort “worst first” to make it easy to spot dropouts
        perTicker.sort((a, b) => (a.coveragePct ?? 0) - (b.coveragePct ?? 0));

        return sendJSON(
          {
            ok: true,
            window: {
              since,
              until,
              bucketMin,
              bucketMs,
              bucketStart,
              bucketEnd,
              bucketCount,
            },
            basis,
            thresholdPct: Math.round(threshold * 10000) / 100,
            summary: {
              tickersTotal,
              tickersAny,
              pctTickersAny:
                tickersTotal > 0
                  ? Math.round((tickersAny / tickersTotal) * 10000) / 100
                  : null,
              tickersMeet,
              pctTickersMeet:
                tickersTotal > 0
                  ? Math.round((tickersMeet / tickersTotal) * 10000) / 100
                  : null,
            },
            worst: perTicker.slice(0, 25),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ingest-audit?since&until&bucket&ticker&includeKv&scriptVersion
      if (routeKey === "GET /timed/ingest-audit") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const bucketRaw = url.searchParams.get("bucket");
        const tickerParam = normTicker(url.searchParams.get("ticker"));
        const includeKv = url.searchParams.get("includeKv") === "1";
        const scriptVersion = url.searchParams.get("scriptVersion");

        const now = Date.now();
        const since =
          sinceRaw != null && sinceRaw !== ""
            ? Number(sinceRaw)
            : now - 6 * 60 * 60 * 1000;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : now;
        const bucketMin = Math.max(1, Number(bucketRaw) || 5);
        const bucketMs = bucketMin * 60 * 1000;

        if (
          !Number.isFinite(since) ||
          !Number.isFinite(until) ||
          until <= since
        ) {
          return sendJSON(
            { ok: false, error: "invalid_since_until" },
            400,
            corsHeaders(env, req),
          );
        }

        const tickers = tickerParam
          ? [tickerParam]
          : (await kvGetJSON(KV, "timed:tickers")) || [];

        const expectedBuckets = [];
        for (let t = since; t <= until; t += bucketMs) {
          expectedBuckets.push(Math.floor(t / bucketMs) * bucketMs);
        }

        const receiptRows = await db
          .prepare(
            `SELECT
              ticker,
              (ts / ?1) * ?1 AS bucket,
              COUNT(*) AS cnt
             FROM ingest_receipts
             WHERE ts >= ?2 AND ts <= ?3
             ${scriptVersion ? "AND script_version = ?4" : ""}
             ${tickerParam ? `AND ticker = ?${scriptVersion ? 5 : 4}` : ""}
             GROUP BY ticker, bucket`,
          )
          .bind(
            bucketMs,
            since,
            until,
            ...(scriptVersion ? [scriptVersion] : []),
            ...(tickerParam ? [tickerParam] : []),
          )
          .all();

        const trailRows = await db
          .prepare(
            `SELECT
              ticker,
              (ts / ?1) * ?1 AS bucket,
              COUNT(*) AS cnt
             FROM timed_trail
             WHERE ts >= ?2 AND ts <= ?3
             ${tickerParam ? "AND ticker = ?4" : ""}
             GROUP BY ticker, bucket`,
          )
          .bind(bucketMs, since, until, ...(tickerParam ? [tickerParam] : []))
          .all();

        const receiptMap = new Map();
        for (const row of receiptRows?.results || []) {
          const t = String(row.ticker || "").toUpperCase();
          if (!receiptMap.has(t)) receiptMap.set(t, new Set());
          receiptMap.get(t).add(Number(row.bucket));
        }

        const trailMap = new Map();
        for (const row of trailRows?.results || []) {
          const t = String(row.ticker || "").toUpperCase();
          if (!trailMap.has(t)) trailMap.set(t, new Set());
          trailMap.get(t).add(Number(row.bucket));
        }

        const kvMap = new Map();
        if (includeKv && tickerParam) {
          try {
            let kvTrail =
              (await kvGetJSON(KV, `timed:trail:${tickerParam}`)) || [];
            if (!Array.isArray(kvTrail)) kvTrail = [];
            const buckets = new Set();
            for (const point of kvTrail) {
              const ts = Number(point?.ts);
              if (!Number.isFinite(ts)) continue;
              if (ts < since || ts > until) continue;
              buckets.add(Math.floor(ts / bucketMs) * bucketMs);
            }
            kvMap.set(tickerParam, buckets);
          } catch (err) {
            console.error(`[INGEST AUDIT] KV trail read failed:`, err);
          }
        }

        const perTicker = tickers.map((t) => {
          const ticker = String(t || "").toUpperCase();
          const receiptBuckets = receiptMap.get(ticker) || new Set();
          const trailBuckets = trailMap.get(ticker) || new Set();
          const kvBuckets = kvMap.get(ticker) || null;

          const missingReceipts = expectedBuckets.filter(
            (b) => !receiptBuckets.has(b),
          );
          const missingTrail = expectedBuckets.filter(
            (b) => !trailBuckets.has(b),
          );
          const missingKv = kvBuckets
            ? expectedBuckets.filter((b) => !kvBuckets.has(b))
            : null;

          return {
            ticker,
            expectedBuckets: expectedBuckets.length,
            receiptBuckets: receiptBuckets.size,
            trailBucketsD1: trailBuckets.size,
            trailBucketsKV: kvBuckets ? kvBuckets.size : null,
            missingReceipts: missingReceipts.length,
            missingTrailD1: missingTrail.length,
            missingTrailKV: missingKv ? missingKv.length : null,
            missingReceiptSamples: missingReceipts.slice(0, 20),
            missingTrailSamples: missingTrail.slice(0, 20),
            missingTrailKvSamples: missingKv ? missingKv.slice(0, 20) : null,
          };
        });

        return sendJSON(
          {
            ok: true,
            since,
            until,
            bucketMinutes: bucketMin,
            tickers: tickers.length,
            includeKv: includeKv && !!tickerParam,
            scriptVersion: scriptVersion || null,
            perTicker,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/auth — Auth trigger: this Worker route is behind CF Access.
      // Navigating here forces CF Access to authenticate the user, then redirects
      // to the dashboard. Used by the LoginScreen when the user clicks "Sign In".
      if (routeKey === "GET /timed/auth") {
        const redirectTo = url.searchParams.get("redirect") || "/index-react.html";
        // Sanitize: only allow same-origin paths
        const safePath = redirectTo.startsWith("/") ? redirectTo : "/index-react.html";
        return new Response(null, {
          status: 302,
          headers: { ...corsHeaders(env, req), Location: safePath },
        });
      }

      // ── AlpacaStream management endpoints (admin only) ──
      if (routeKey === "GET /timed/alpaca-stream/status") {
        const status = await alpacaStreamStatus(env);
        return sendJSON(status, 200, corsHeaders(env, req));
      }
      if (routeKey === "POST /timed/alpaca-stream/start") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        const alpacaBlocklist = new Set(["ES1!","NQ1!","YM1!","RTY1!","CL1!","GC1!","SI1!","HG1!","NG1!","BTCUSD","ETHUSD","US500","VX1!","SPX"]);
        const symbols = Object.keys(SECTOR_MAP).filter(t => !alpacaBlocklist.has(t) && /^[A-Z]{1,5}(-[A-Z]{1,2})?$/.test(t));
        const result = await alpacaStreamStart(env, symbols);
        return sendJSON({ ok: true, result, symbols: symbols.length }, 200, corsHeaders(env, req));
      }
      if (routeKey === "POST /timed/alpaca-stream/stop") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        const result = await alpacaStreamStop(env);
        return sendJSON({ ok: true, result }, 200, corsHeaders(env, req));
      }

      // GET /timed/health
      if (routeKey === "GET /timed/health") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/health",
          500,
          3600,
        ); // Increased for single-user

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const last = Number(await KV.get("timed:last_ingest_ms")) || 0;
        const captureLast =
          Number(await KV.get("timed:capture:last_ingest_ms")) || 0;
        const scoringLast = await kvGetJSON(KV, "timed:scoring:last_run");
        const scoringTs = scoringLast && typeof scoringLast === "object" ? Number(scoringLast.ts) : 0;
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const captureTickers =
          (await kvGetJSON(KV, "timed:capture:tickers")) || [];
        const storedVersion = await getStoredVersion(KV);
        return sendJSON(
          {
            ok: true,
            now: Date.now(),
            lastIngestMs: last,
            minutesSinceLast: last ? (Date.now() - last) / 60000 : null,
            captureLastIngestMs: captureLast,
            captureMinutesSinceLast: captureLast
              ? (Date.now() - captureLast) / 60000
              : null,
            scoringLastRunMs: scoringTs || null,
            minutesSinceScoring: scoringTs ? (Date.now() - scoringTs) / 60000 : null,
            scoringElapsedMs: scoringLast?.elapsedMs || null,
            scoringCore: scoringLast?.core || null,
            scoringUserAdded: scoringLast?.userAdded || null,
            tickers: tickers.length,
            captureTickers: Array.isArray(captureTickers)
              ? captureTickers.length
              : 0,
            dataVersion: storedVersion || "none",
            expectedVersion: CURRENT_DATA_VERSION,
          },
          200,
          { ...corsHeaders(env, req), "Cache-Control": "public, max-age=60" },
        );
      }

      // POST /timed/purge?key=... (Manual purge endpoint)
      if (routeKey === "POST /timed/purge") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const result = await purgeOldData(KV);
        await setStoredVersion(KV, CURRENT_DATA_VERSION);

        return sendJSON(
          {
            ok: true,
            message: "Data purged successfully",
            purged: result.purged,
            tickerCount: result.tickerCount,
            version: CURRENT_DATA_VERSION,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/cleanup-no-scores?key=... (Remove tickers without score data from index)
      if (routeKey === "POST /timed/cleanup-no-scores") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const tickersToKeep = [];
        const tickersRemoved = [];

        for (const ticker of tickers) {
          const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
          const hasScores =
            data &&
            (data.htf_score !== undefined || data.ltf_score !== undefined);

          if (hasScores) {
            tickersToKeep.push(ticker);
          } else {
            tickersRemoved.push(ticker);
            // Also clean up the latest data entry if it exists but has no scores
            await KV.delete(`timed:latest:${ticker}`);
          }
        }

        await kvPutJSON(KV, "timed:tickers", tickersToKeep);

        return sendJSON(
          {
            ok: true,
            message: `Cleaned up ${tickersRemoved.length} tickers without scores`,
            removed: tickersRemoved,
            kept: tickersToKeep.length,
            totalBefore: tickers.length,
            totalAfter: tickersToKeep.length,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/rebuild-index?key=... (Rebuild ticker index from watchlist)
      if (routeKey === "POST /timed/rebuild-index") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;

        // Known ticker list from watchlists (Q1 2026 + Sectors)
        // This should match your TradingView watchlists
        const knownTickers = [
          "TSLA",
          "STX",
          "AU",
          "CCJ",
          "CLS",
          "CRS",
          "VST",
          "FSLR",
          "JCI",
          "ORCL",
          "AMZN",
          "BRK-B",
          "BABA",
          "WMT",
          "PH",
          "GEV",
          "HII",
          "ULTA",
          "SHOP",
          "CSX",
          "PWR",
          "HOOD",
          "SPGI",
          "APP",
          "PANW",
          "RDDT",
          "TT",
          "GLXY",
          "ETHA",
          "META",
          "NVDA",
          "AMD",
          "ANET",
          "GS",
          "TJX",
          "SOFI",
          "PNC",
          "PLTR",
          "NFLX",
          "MSTR",
          "MSFT",
          "MNST",
          "LRCX",
          "KLAC",
          "JPM",
          "GOOGL",
          "GE",
          "EXPE",
          "ETN",
          "EMR",
          "DE",
          "CRWD",
          "COST",
          "CDNS",
          "CAT",
          "BK",
          "AXP",
          "AXON",
          "AVGO",
          "AAPL",
          "RKLB",
          "LITE",
          "SN",
          "ALB",
          "RGLD",
          "MTZ",
          "ON",
          "ALLY",
          "DY",
          "EWBC",
          "PATH",
          "WFRD",
          "WAL",
          "IESC",
          "ENS",
          "TWLO",
          "MLI",
          "KTOS",
          "MDB",
          "TLN",
          "EME",
          "AWI",
          "IBP",
          "DCI",
          "WTS",
          "FIX",
          "UTHR",
          "NBIS",
          "SGI",
          "AYI",
          "RIOT",
          "NXT",
          "SANM",
          "BWXT",
          "PEGA",
          "JOBY",
          "IONQ",
          "ITT",
          "STRL",
          "QLYS",
          "MP",
          "HIMS",
          "IOT",
          "BE",
          "NEU",
          "AVAV",
          "PSTG",
          "RBLX",
          "CSCO",
          "BA",
          "NKE",
          "PI",
          "APLD",
          "MU",
          // ETFs
          "XLK",
          "XLF",
          "XLY",
          "XLP",
          "XLC",
          "XLB",
          "XLE",
          "XLU",
          "XLV",
          // Futures & Crypto
          "ES",
          "NQ",
          "BTC",
          "ETH",
          "BTCUSD",
          "ETHUSD",
          // Futures contracts
          "ES1!",
          "NQ1!",
          "MES1!",
          "MNQ1!",
          "YM1!",
          "RTY1!",
          "CL1!",
          // Indices
          "SPX",
        ]
          .map((t) => t.toUpperCase())
          .filter((v, i, a) => a.indexOf(v) === i); // Deduplicate

        const currentIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
        const addedTickers = [];
        const existingTickers = new Set(currentIndex);

        for (const ticker of knownTickers) {
          if (!existingTickers.has(ticker)) {
            currentIndex.push(ticker);
            addedTickers.push(ticker);
          }
        }

        // Sort and save
        currentIndex.sort();
        await kvPutJSON(KV, "timed:tickers", currentIndex);

        // Seed timed:latest:<ticker> from D1 candle data for tickers without live data.
        // This ensures index-only tickers (like SPX) that depend on TradingView
        // webhooks still appear in the UI with their last known price.
        // We also collect freshPayloads to inject directly into the snapshot below
        // (avoids KV eventual-consistency issues where a just-written key isn't readable yet).
        const seededTickers = [];
        const freshPayloads = {}; // sym -> payload, for D1-seeded tickers
        if (env?.DB) {
          for (const ticker of knownTickers) {
            try {
              const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);
              if (existing && existing.price > 0) {
                // If it's a d1_seed that already exists, keep it in freshPayloads for snapshot
                if (existing.ingest_kind === "d1_seed") freshPayloads[ticker] = existing;
                continue;
              }

              // Query D1 for the latest daily candle (ticker_candles uses o/h/l/c columns)
              const row = await env.DB.prepare(
                `SELECT ts, o, h, l, c FROM ticker_candles
                 WHERE ticker = ?1 AND tf = 'D'
                 ORDER BY ts DESC LIMIT 2`
              ).bind(ticker).all();

              if (row?.results?.length >= 1) {
                const latest = row.results[0];
                const prev = row.results.length >= 2 ? row.results[1] : null;
                const price = Number(latest.c);
                if (price > 0) {
                  const prevClose = prev ? Number(prev.c) : 0;
                  const dayChange = prevClose > 0 ? price - prevClose : 0;
                  const dayChangePct = prevClose > 0 ? ((price - prevClose) / prevClose) * 100 : 0;
                  const payload = {
                    ticker,
                    ts: Number(latest.ts),
                    price,
                    close: price,
                    open: Number(latest.o) || price,
                    high: Number(latest.h) || price,
                    low: Number(latest.l) || price,
                    prev_close: prevClose || undefined,
                    day_change: dayChange || undefined,
                    day_change_pct: dayChangePct || undefined,
                    ingest_ts: Date.now(),
                    ingest_kind: "d1_seed",
                  };
                  await kvPutJSON(KV, `timed:latest:${ticker}`, payload, 7 * 86400);
                  seededTickers.push(ticker);
                  freshPayloads[ticker] = payload;
                }
              }
            } catch (e) {
              console.warn(`[ENSURE-TICKERS] D1 seed failed for ${ticker}:`, String(e?.message || e));
            }
          }
        }

        // ── Rebuild timed:all:snapshot so newly seeded tickers appear immediately ──
        // First read current snapshot, then merge in fresh payloads to avoid KV consistency gaps
        let snapshotCount = 0;
        try {
          const removedSet = new Set((await kvGetJSON(KV, "timed:removed")) || []);
          _removedTickersCache = removedSet;
          const _userAddedRebuild = await d1GetActiveUserTickersCached(env);
          const activeSyms = [...new Set([...Object.keys(SECTOR_MAP), ..._userAddedRebuild])].filter(t => !removedSet.has(t));

          // Start from current snapshot (if exists) to preserve existing data
          const currentSnapshot = await kvGetJSON(KV, "timed:all:snapshot");
          const snapshot = (currentSnapshot?.data && typeof currentSnapshot.data === "object")
            ? { ...currentSnapshot.data }
            : {};

          // Overlay fresh KV reads for all active tickers
          for (const sym of activeSyms) {
            if (!snapshot[sym]) {
              const payload = await kvGetJSON(KV, `timed:latest:${sym}`);
              if (payload && typeof payload === "object") {
                snapshot[sym] = payload;
              }
            }
          }

          // Inject D1-seeded payloads directly (bypasses KV eventual consistency)
          for (const [sym, payload] of Object.entries(freshPayloads)) {
            if (activeSyms.includes(sym)) {
              snapshot[sym] = payload;
            }
          }

          // Remove tickers not in activeSyms
          for (const sym of Object.keys(snapshot)) {
            if (!activeSyms.includes(sym)) delete snapshot[sym];
          }

          // Enrich with sparkline data (last 60 daily closes per ticker)
          try {
            const sparkRows = await env.DB.prepare(
              `WITH deduped AS (
                SELECT ticker, ts, c,
                  ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                FROM ticker_candles WHERE tf = 'D'
              )
              SELECT ticker, ts, c FROM (
                SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                FROM deduped WHERE day_rn = 1
              ) WHERE rn <= 60
              ORDER BY ticker, ts ASC`
            ).all();
            const sparkMap = {};
            for (const r of (sparkRows?.results || [])) {
              const sym = String(r.ticker).toUpperCase();
              if (!sparkMap[sym]) sparkMap[sym] = [];
              sparkMap[sym].push(Number(r.c));
            }
            for (const [sym, closes] of Object.entries(sparkMap)) {
              if (snapshot[sym]) snapshot[sym]._sparkline = closes;
            }
          } catch (sparkErr) {
            console.warn("[REBUILD-INDEX] Sparkline enrichment failed:", String(sparkErr?.message || sparkErr).slice(0, 150));
          }

          await kvPutJSON(KV, "timed:all:snapshot", {
            data: snapshot,
            count: Object.keys(snapshot).length,
            built_at: Date.now(),
          });
          snapshotCount = Object.keys(snapshot).length;
        } catch (e) {
          console.warn("[REBUILD-INDEX] Snapshot rebuild failed:", String(e?.message || e));
        }

        return sendJSON(
          {
            ok: true,
            message: `Index rebuilt. Added ${addedTickers.length} tickers. Seeded ${seededTickers.length} from D1. Snapshot: ${snapshotCount} tickers.`,
            beforeCount: currentIndex.length - addedTickers.length,
            afterCount: currentIndex.length,
            addedTickers: addedTickers.slice(0, 20),
            totalAdded: addedTickers.length,
            seededFromD1: seededTickers,
            snapshotRebuilt: snapshotCount,
            note: "Index will continue to grow as TradingView sends alerts for these tickers.",
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/purge-trades-by-version?key=...&version=2.6.0 (Purge trades by version)
      if (routeKey === "POST /timed/purge-trades-by-version") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const targetVersion = url.searchParams.get("version");
        if (!targetVersion) {
          return sendJSON(
            { ok: false, error: "version parameter required" },
            400,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

        const beforeCount = allTrades.length;
        const filteredTrades = allTrades.filter((trade) => {
          const tradeVersion =
            trade.scriptVersion || trade.script_version || "unknown";
          return tradeVersion !== targetVersion;
        });
        const purgedCount = beforeCount - filteredTrades.length;

        await kvPutJSON(KV, tradesKey, filteredTrades);

        return sendJSON(
          {
            ok: true,
            message: `Purged ${purgedCount} trades with version ${targetVersion}`,
            beforeCount,
            afterCount: filteredTrades.length,
            purgedCount,
            targetVersion,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/cleanup-tickers?key=... (Remove unapproved tickers, keep only approved list, normalize Gold/Silver)
      // POST /timed/clear-rate-limit?key=...&all=true (Reset all) or &ip=...&endpoint=... (Clear specific)
      if (routeKey === "POST /timed/clear-rate-limit") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const ip = url.searchParams.get("ip") || null;
        const endpoint = url.searchParams.get("endpoint") || null;
        const clearAll = url.searchParams.get("all") === "true";

        // List of all known endpoints that use rate limiting
        const allEndpoints = [
          "/timed/all",
          "/timed/latest",
          "/timed/activity",
          "/timed/trail",
          "/timed/top",
          "/timed/momentum",
          "/timed/momentum/history",
          "/timed/momentum/all",
          "/timed/trades",
          "/timed/health",
          "/timed/version",
          "/timed/alert-debug",
          "/timed/check-ticker",
        ];

        let cleared = 0;
        const clearedKeys = [];

        if (clearAll) {
          // Clear ALL rate limits - note: KV doesn't support listing all keys
          // So we return a message that rate limits will expire naturally
          // For immediate clearing, users should specify IP
          return sendJSON(
            {
              ok: true,
              message:
                "Rate limit reset acknowledged. Note: Cloudflare KV doesn't support listing all keys, so active rate limits will expire naturally after 1 hour. For immediate clearing, use ?ip=IP_ADDRESS to clear all endpoints for a specific IP.",
              note: "To clear all rate limits for your IP immediately, use: ?ip=YOUR_IP",
              endpoints: allEndpoints,
            },
            200,
            corsHeaders(env, req),
          );
        } else if (ip && endpoint) {
          // Clear specific IP + endpoint combination
          const legacyKey = `ratelimit:${ip}:${endpoint}`;
          await KV.delete(legacyKey);
          clearedKeys.push(legacyKey);
          cleared++;

          // Also clear fixed-window buckets (current + previous bucket)
          const window = 3600;
          const bucket = Math.floor(Date.now() / (window * 1000));
          const fixedKeyNow = `ratelimit:${ip}:${endpoint}:${bucket}`;
          const fixedKeyPrev = `ratelimit:${ip}:${endpoint}:${bucket - 1}`;
          await KV.delete(fixedKeyNow);
          await KV.delete(fixedKeyPrev);
          clearedKeys.push(fixedKeyNow, fixedKeyPrev);
          cleared++;
        } else if (ip) {
          // Clear all rate limits for a specific IP (all endpoints)
          for (const ep of allEndpoints) {
            const legacyKey = `ratelimit:${ip}:${ep}`;
            await KV.delete(legacyKey);
            cleared++;
            clearedKeys.push(legacyKey);

            // Also clear fixed-window buckets (current + previous bucket)
            const window = 3600;
            const bucket = Math.floor(Date.now() / (window * 1000));
            const fixedKeyNow = `ratelimit:${ip}:${ep}:${bucket}`;
            const fixedKeyPrev = `ratelimit:${ip}:${ep}:${bucket - 1}`;
            await KV.delete(fixedKeyNow);
            await KV.delete(fixedKeyPrev);
            cleared += 2;
            clearedKeys.push(fixedKeyNow, fixedKeyPrev);
          }
        } else if (endpoint) {
          // Clear all rate limits for a specific endpoint (all IPs)
          // Note: This is not directly possible without listing all IPs
          // For now, return an error suggesting to specify IP
          return sendJSON(
            {
              ok: false,
              error:
                "Cannot clear endpoint without IP. Please specify both 'ip' and 'endpoint', or just 'ip' to clear all endpoints for that IP.",
            },
            400,
            corsHeaders(env, req),
          );
        } else {
          // No parameters - return usage info
          return sendJSON(
            {
              ok: false,
              error: "Missing parameters",
              usage: {
                clearAll: "POST /timed/clear-rate-limit?key=YOUR_KEY&all=true",
                clearSpecific:
                  "POST /timed/clear-rate-limit?key=YOUR_KEY&ip=IP_ADDRESS&endpoint=/timed/activity",
                clearAllForIP:
                  "POST /timed/clear-rate-limit?key=YOUR_KEY&ip=IP_ADDRESS",
              },
            },
            400,
            corsHeaders(env, req),
          );
        }

        return sendJSON(
          {
            ok: true,
            message: `Cleared ${cleared} rate limit(s)`,
            cleared,
            keys: clearedKeys,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/cleanup-tickers?key=...&strict=1 (strict=1: purge-only, no social-additions)
      if (routeKey === "POST /timed/cleanup-tickers") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const url = new URL(req.url || `https://x/${req.url}`);
        const strictPurge = url.searchParams.get("strict") === "1";

        // Approved ticker list — WATCHLIST_Q1_2026
        const approvedTickers = new Set([
          "AAPL", "AEHR", "AGQ", "ALB", "ALLY", "AMD", "AMGN", "AMZN", "ANET", "APLD", "APP", "ASTS",
          "AU", "AVAV", "AVGO", "AWI", "AXON", "AXP", "AYI", "B", "BA", "BABA", "BE", "BK", "BMNR",
          "BRK-B", "BRK.B", "BTCUSD", "BWXT", "CAT", "CCJ", "CDNS", "CLS", "COIN", "COST", "CRS",
          "CRWD", "CRWV", "CSCO", "CSX", "CVNA", "CVX", "DCI", "DE", "DY", "EME", "EMR", "ENS", "ES1!", "ETHA",
          "ETHT", "ETHUSD", "ETN", "EWBC", "EXPE", "FIX", "FSLR", "GE", "GEV", "GILD",
          "GLXY", "GOLD", "GOOGL", "GS", "HII", "HIMS", "HL", "HOOD", "IAU", "IBP", "IESC",
          "INTC", "INTU", "IONQ", "IOT", "IREN", "ITT", "IWM", "JCI", "JOBY", "JPM", "KLAC", "KO",
          "KTOS", "LLY", "LITE", "LRCX", "LULU", "MCD", "MDB", "META", "MLI", "MNST", "MP", "MSFT", "MSTR", "MTB", "MTZ",
          "MU", "NBIS", "NEU", "NFLX", "NKE", "NQ1!", "NVDA", "NXT", "ON", "ORCL", "PANW",
          "PATH", "PEGA", "PH", "PI", "PLTR", "PNC", "PSTG", "PWR", "QLYS", "QQQ", "RBLX", "RDDT",
          "RGLD", "RIOT", "RKLB", "SANM", "SGI", "SHOP", "SILVER", "SLV", "SN", "SNDK", "SOFI",
          "SOXL", "SPGI", "SPY", "STRL", "STX", "SWK", "TJX", "TLN", "TSM", "TSLA", "TT", "TWLO", "ULTA",
          "UTHR", "UUUU", "US500", "VST", "VX1!", "WAL", "WDC", "WFRD", "WM", "WMT", "WTS",
          "XLB", "XLC", "XLE", "XLF", "XLI", "XLK", "XLP", "XLRE", "XLU", "XLV", "XLY", "XOM",
          "NQ", "RTY", "YM", "DIA", "BTC", "SPX", "CL", "CL1!",
        ]);

        const tickerMap = {
          "BRK.B": "BRK-B",
          NQ: "NQ1!",
          RTY: "RTY1!",
          YM: "YM1!",
          CL: "CL1!",
          BTC: "BTCUSD",
        };

        let approvedSet = new Set(approvedTickers);
        if (!strictPurge) {
          const socialAdditions = (await kvGetJSON(KV, "timed:social:additions")) || [];
          for (const t of socialAdditions) {
            if (t && typeof t === "string") approvedSet.add(String(t).toUpperCase());
          }
        }

        const currentTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const toRemove = [];
        const toKeep = [];
        const renamed = [];
        const addedToSocial = [];

        for (const ticker of currentTickers) {
          const upperTicker = ticker.toUpperCase();
          const normalized = tickerMap[upperTicker] || upperTicker;

          if (approvedSet.has(upperTicker) || approvedSet.has(normalized)) {
            if (normalized !== upperTicker && tickerMap[upperTicker]) {
              renamed.push({ from: ticker, to: normalized });
              toKeep.push(normalized);
            } else {
              toKeep.push(ticker);
            }
          } else {
            if (!strictPurge) {
              // Accept new ticker: add to Social and keep
              const additions = (await kvGetJSON(KV, "timed:social:additions")) || [];
              const upper = upperTicker;
              if (!additions.includes(upper)) {
                additions.push(upper);
                additions.sort();
                await kvPutJSON(KV, "timed:social:additions", additions);
                addedToSocial.push(upper);
              }
              approvedSet.add(upper);
              toKeep.push(ticker);
            } else {
              toRemove.push(ticker);
            }
          }
        }

        let removedCount = 0;
        for (const ticker of toRemove) {
          await KV.delete(`timed:latest:${ticker}`);
          await KV.delete(`timed:trail:${ticker}`);
          await KV.delete(`timed:heartbeat:${ticker}`);
          if (env?.DB) {
            try {
              await env.DB.prepare(`DELETE FROM ticker_latest WHERE ticker = ?1`).bind(ticker).run();
            } catch (_) {}
          }
          removedCount++;
        }

        // Purge trades/positions for tickers not in watchlist (strict mode only)
        let tradesPurged = 0;
        if (strictPurge && env?.DB && toRemove.length > 0) {
          try {
            for (const ticker of toRemove) {
              const posRows = await env.DB.prepare(`SELECT position_id FROM positions WHERE ticker = ?1`).bind(ticker).all();
              const posIds = (posRows?.results || []).map((r) => r.position_id);
              for (const pid of posIds) {
                await env.DB.prepare(`DELETE FROM execution_actions WHERE position_id = ?1`).bind(pid).run();
                await env.DB.prepare(`DELETE FROM lots WHERE position_id = ?1`).bind(pid).run();
              }
              const posDel = await env.DB.prepare(`DELETE FROM positions WHERE ticker = ?1`).bind(ticker).run();
              const tradeIds = (await env.DB.prepare(`SELECT trade_id FROM trades WHERE ticker = ?1`).bind(ticker).all())?.results || [];
              for (const row of tradeIds) {
                await env.DB.prepare(`DELETE FROM trade_events WHERE trade_id = ?1`).bind(row.trade_id).run();
              }
              const tradeDel = await env.DB.prepare(`DELETE FROM trades WHERE ticker = ?1`).bind(ticker).run();
              tradesPurged += (tradeDel?.meta?.changes || 0) + (posDel?.meta?.changes || 0);
            }
          } catch (e) {
            console.warn("[cleanup-tickers] D1 trade purge error:", String(e?.message || e));
          }
        }

        // Also purge trades for tickers in D1 that aren't in approvedSet (covers already-removed tickers like BTBT)
        if (strictPurge && env?.DB) {
          try {
            const allTradeTickers = (await env.DB.prepare(`SELECT DISTINCT ticker FROM trades`).all())?.results || [];
            const allPosTickers = (await env.DB.prepare(`SELECT DISTINCT ticker FROM positions`).all())?.results || [];
            const tickersToPurge = new Set();
            for (const r of allTradeTickers) {
              const t = String(r?.ticker || "").toUpperCase();
              const norm = tickerMap[t] || t;
              if (!approvedSet.has(t) && !approvedSet.has(norm)) tickersToPurge.add(r.ticker);
            }
            for (const r of allPosTickers) {
              const t = String(r?.ticker || "").toUpperCase();
              const norm = tickerMap[t] || t;
              if (!approvedSet.has(t) && !approvedSet.has(norm)) tickersToPurge.add(r.ticker);
            }
            for (const ticker of tickersToPurge) {
              if (toRemove.includes(ticker)) continue;
              const posRows = await env.DB.prepare(`SELECT position_id FROM positions WHERE ticker = ?1`).bind(ticker).all();
              const posIds = (posRows?.results || []).map((r) => r.position_id);
              for (const pid of posIds) {
                await env.DB.prepare(`DELETE FROM execution_actions WHERE position_id = ?1`).bind(pid).run();
                await env.DB.prepare(`DELETE FROM lots WHERE position_id = ?1`).bind(pid).run();
              }
              await env.DB.prepare(`DELETE FROM positions WHERE ticker = ?1`).bind(ticker).run();
              const tradeIds = (await env.DB.prepare(`SELECT trade_id FROM trades WHERE ticker = ?1`).bind(ticker).all())?.results || [];
              for (const row of tradeIds) {
                await env.DB.prepare(`DELETE FROM trade_events WHERE trade_id = ?1`).bind(row.trade_id).run();
              }
              await env.DB.prepare(`DELETE FROM trades WHERE ticker = ?1`).bind(ticker).run();
              tradesPurged++;
            }
          } catch (e) {
            console.warn("[cleanup-tickers] D1 orphan trade purge error:", String(e?.message || e));
          }
        }

        let renamedCount = 0;
        for (const { from, to } of renamed) {
          const latestData = await kvGetJSON(KV, `timed:latest:${from}`);
          const trailData = await kvGetJSON(KV, `timed:trail:${from}`);
          if (latestData) {
            await kvPutJSON(KV, `timed:latest:${to}`, latestData);
            await KV.delete(`timed:latest:${from}`);
          }
          if (trailData) {
            await kvPutJSON(KV, `timed:trail:${to}`, trailData);
            await KV.delete(`timed:trail:${from}`);
          }
          if (env?.DB) {
            try {
              await env.DB.prepare(`UPDATE ticker_latest SET ticker = ?1 WHERE ticker = ?2`).bind(to, from).run();
            } catch (_) {}
          }
          renamedCount++;
        }

        await kvPutJSON(KV, "timed:tickers", toKeep.sort());

        return sendJSON(
          {
            ok: true,
            message: strictPurge ? "One-time purge completed (strict mode)" : "Cleanup completed (new tickers added to Social)",
            removed: removedCount,
            renamed: renamedCount,
            addedToSocial: addedToSocial.length,
            kept: toKeep.length,
            tradesPurged: tradesPurged,
            removedTickers: toRemove.sort(),
            addedToSocialTickers: addedToSocial,
            renamedTickers: renamed,
            finalTickers: toKeep.sort(),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/social-additions — tickers accepted into Social group (not in watchlist)
      if (routeKey === "GET /timed/social-additions") {
        const additions = (await kvGetJSON(KV, "timed:social:additions")) || [];
        return sendJSON(
          { ok: true, additions: Array.isArray(additions) ? additions : [] },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/cors-debug (Debug CORS configuration)
      if (routeKey === "GET /timed/cors-debug") {
        const corsConfig = env.CORS_ALLOW_ORIGIN || "";
        const allowedOrigins = corsConfig
          .split(",")
          .map((o) => o.trim())
          .filter(Boolean);
        const origin = req?.headers?.get("Origin") || "";

        return sendJSON(
          {
            ok: true,
            cors: {
              config: corsConfig,
              allowedOrigins: allowedOrigins,
              requestedOrigin: origin,
              isAllowed: allowedOrigins.includes(origin),
              willReturn:
                allowedOrigins.length === 0
                  ? "*"
                  : allowedOrigins.includes(origin)
                    ? origin
                    : "null",
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/version (Check current version)
      if (routeKey === "GET /timed/version") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/version",
          500, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const storedVersion = await getStoredVersion(KV);
        return sendJSON(
          {
            ok: true,
            storedVersion: storedVersion || "none",
            expectedVersion: CURRENT_DATA_VERSION,
            match: storedVersion === CURRENT_DATA_VERSION,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/alert-debug?ticker=XYZ (Debug why alerts aren't firing)
      if (routeKey === "GET /timed/alert-debug") {
        // Rate limiting
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/alert-debug",
          500, // Increased for single-user
          3600,
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        }

        const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
        if (!data) {
          return sendJSON(
            { ok: false, error: "no data for ticker", ticker },
            404,
            corsHeaders(env, req),
          );
        }

        // Replicate alert logic
        const state = String(data.state || "");
        const alignedLong = state === "HTF_BULL_LTF_BULL";
        const alignedShort = state === "HTF_BEAR_LTF_BEAR";
        const aligned = alignedLong || alignedShort;

        const prevKey = `timed:prevstate:${ticker}`;
        const prevState = await KV.get(prevKey);
        const enteredAligned = aligned && prevState !== state;

        const trigReason = String(data.trigger_reason || "");
        const trigOk =
          trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
          trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");

        const flags = data.flags || {};
        const sqRel = !!flags.sq30_release;

        const side = corridorSide(data);
        const inCorridor = !!side;
        const corridorAlignedOK =
          (side === "LONG" && alignedLong) ||
          (side === "SHORT" && alignedShort);

        const shouldConsiderAlert =
          inCorridor &&
          corridorAlignedOK &&
          (enteredAligned || trigOk || sqRel);

        // Threshold gates (with Momentum Elite adjustments)
        const momentumElite = !!flags.momentum_elite;

        // Momentum Elite gets relaxed thresholds (higher quality stocks)
        const baseMinRR = Number(env.ALERT_MIN_RR || "1.5");
        const baseMaxComp = Number(env.ALERT_MAX_COMPLETION || "0.4");
        const baseMaxPhase = Number(env.ALERT_MAX_PHASE || "0.6");
        // Adjust thresholds for Momentum Elite (more lenient for quality stocks)
        const minRR = momentumElite
          ? Math.max(1.2, baseMinRR * 0.9)
          : baseMinRR; // Lower RR requirement
        const maxComp = momentumElite
          ? Math.min(0.5, baseMaxComp * 1.25)
          : baseMaxComp; // Allow higher completion
        const maxPhase = momentumElite
          ? Math.min(0.7, baseMaxPhase * 1.17)
          : baseMaxPhase; // Allow higher phase

        // Use current price for dynamic RR calculation (matches actual alert logic)
        const currentRR = computeRR(data);
        const rrToUse =
          currentRR != null ? currentRR : data.rr != null ? Number(data.rr) : 0;
        const rrOk = rrToUse >= minRR;
        const compToMax = computeCompletionToTpMax(data);
        const compRaw = data.completion == null ? null : Number(data.completion);
        const compVal = Number.isFinite(compToMax) ? compToMax : compRaw;
        const compOk = compVal == null ? true : compVal <= maxComp;
        const phaseOk =
          data.phase_pct == null ? true : Number(data.phase_pct) <= maxPhase;

        // Also consider Momentum Elite as a trigger condition (quality signal)
        const momentumEliteTrigger =
          momentumElite && inCorridor && corridorAlignedOK;

        // Enhanced trigger: original conditions OR Momentum Elite in good setup
        const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

        const discordEnabled = (env.DISCORD_ENABLE || "false") === "true";
        const discordUrlSet = !!env.DISCORD_WEBHOOK_URL;

        const wouldAlert =
          enhancedTrigger &&
          rrOk &&
          compOk &&
          phaseOk &&
          discordEnabled &&
          discordUrlSet;

        return sendJSON(
          {
            ok: true,
            ticker,
            wouldAlert,
            discord: {
              enabled: discordEnabled,
              urlSet: discordUrlSet,
              configured: discordEnabled && discordUrlSet,
            },
            conditions: {
              inCorridor,
              side: side || "none",
              corridorAlignedOK,
              enteredAligned,
              trigOk,
              sqRel,
              momentumElite,
              shouldConsiderAlert,
              momentumEliteTrigger,
              enhancedTrigger,
              rrOk: {
                value: rrToUse,
                valueFromPayload: data.rr,
                calculatedAtCurrentPrice: currentRR,
                baseRequired: baseMinRR,
                adjustedRequired: minRR,
                ok: rrOk,
              },
              compOk: {
                value: data.completion,
                baseRequired: baseMaxComp,
                adjustedRequired: maxComp,
                ok: compOk,
              },
              phaseOk: {
                value: data.phase_pct,
                baseRequired: baseMaxPhase,
                adjustedRequired: maxPhase,
                ok: phaseOk,
              },
            },
            thresholds: {
              base: {
                minRR: baseMinRR,
                maxComp: baseMaxComp,
                maxPhase: baseMaxPhase,
              },
              adjusted: { minRR, maxComp, maxPhase },
              momentumEliteAdjustments: momentumElite,
            },
            data: {
              state,
              htf_score: data.htf_score,
              ltf_score: data.ltf_score,
              rr: data.rr,
              completion: data.completion,
              phase_pct: data.phase_pct,
              trigger_reason: data.trigger_reason,
              flags: data.flags,
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/alert-replay?ticker=XYZ&since=<ms>&until=<ms>&limit=<n>
      // Replays alert eligibility across historical ingest payloads (D1-backed).
      if (routeKey === "GET /timed/alert-replay") {
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/alert-replay",
          200, // conservative; this endpoint can be heavy
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        }

        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const limitRaw = url.searchParams.get("limit");

        const now = Date.now();
        const since =
          sinceRaw != null && sinceRaw !== ""
            ? Number(sinceRaw)
            : now - 8 * 24 * 60 * 60 * 1000; // default: last ~week
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;
        const limit =
          limitRaw != null && limitRaw !== "" ? Number(limitRaw) : 5000;

        const history = await d1GetTrailPayloadRange(
          env,
          ticker,
          since,
          until,
          limit,
        );
        if (!history.ok) {
          return sendJSON(
            {
              ok: false,
              error: history.skipped
                ? `d1_unavailable:${history.reason || "unknown"}`
                : "d1_query_failed",
              details: history.error || null,
              ticker,
            },
            503,
            corsHeaders(env, req),
          );
        }

        const payloads = Array.isArray(history.payloads)
          ? history.payloads
          : [];
        if (payloads.length === 0) {
          return sendJSON(
            {
              ok: true,
              ticker,
              source: history.source,
              since,
              until,
              count: 0,
              results: [],
              note: "No historical payloads found in D1 for requested range.",
            },
            200,
            corsHeaders(env, req),
          );
        }

        const discordEnabled = (env.DISCORD_ENABLE || "false") === "true";
        const discordUrlSet = !!env.DISCORD_WEBHOOK_URL;

        const baseMinRR = Number(env.ALERT_MIN_RR || "1.5");
        const baseMaxComp = Number(env.ALERT_MAX_COMPLETION || "0.4");
        const baseMaxPhase = Number(env.ALERT_MAX_PHASE || "0.6");

        let prevState = null;
        const results = [];
        const wouldDays = new Set();

        for (const data of payloads) {
          const state = String(data.state || "");
          const alignedLong = state === "HTF_BULL_LTF_BULL";
          const alignedShort = state === "HTF_BEAR_LTF_BEAR";
          const aligned = alignedLong || alignedShort;

          const enteredAligned =
            aligned && prevState != null && prevState !== state;

          const trigReason = String(data.trigger_reason || "");
          const trigOk =
            trigReason === "EMA_CROSS" || trigReason === "SQUEEZE_RELEASE" ||
            trigReason.includes("EMA_CROSS") || trigReason.includes("SQUEEZE_RELEASE");

          const flags = data.flags || {};
          const sqRel = !!flags.sq30_release;

          const side = corridorSide(data);
          const inCorridor = !!side;
          const corridorAlignedOK =
            (side === "LONG" && alignedLong) ||
            (side === "SHORT" && alignedShort);

          const shouldConsiderAlert =
            inCorridor &&
            corridorAlignedOK &&
            (enteredAligned || trigOk || sqRel);

          const momentumElite = !!flags.momentum_elite;

          const minRR = momentumElite
            ? Math.max(1.2, baseMinRR * 0.9)
            : baseMinRR;
          const maxComp = momentumElite
            ? Math.min(0.5, baseMaxComp * 1.25)
            : baseMaxComp;
          const maxPhase = momentumElite
            ? Math.min(0.7, baseMaxPhase * 1.17)
            : baseMaxPhase;

          const currentRR = computeRR(data);
          const rrToUse =
            currentRR != null
              ? currentRR
              : data.rr != null
                ? Number(data.rr)
                : 0;
          const rrOk = rrToUse >= minRR;
          const compOk =
            data.completion == null ? true : Number(data.completion) <= maxComp;
          const phaseOk =
            data.phase_pct == null ? true : Number(data.phase_pct) <= maxPhase;

          const momentumEliteTrigger =
            momentumElite && inCorridor && corridorAlignedOK;
          const enhancedTrigger = shouldConsiderAlert || momentumEliteTrigger;

          const wouldAlertLogic = enhancedTrigger && rrOk && compOk && phaseOk;
          const wouldAlert = wouldAlertLogic && discordEnabled && discordUrlSet;

          const action = "ENTRY";
          const ts = Number(data.trigger_ts || data.ts);
          const dedupeInfo = buildAlertDedupeKey({
            ticker,
            action,
            side,
            ts,
          });
          if (wouldAlert && dedupeInfo.key) wouldDays.add(dedupeInfo.key);

          if (wouldAlertLogic) {
            results.push({
              ts,
              day: dedupeInfo.day,
              dedupe_key: dedupeInfo.key,
              dedupe_bucket: dedupeInfo.bucket,
              action,
              state,
              side: side || "none",
              inCorridor,
              corridorAlignedOK,
              enteredAligned,
              trigOk,
              trigger_reason: trigReason || null,
              sqRel,
              momentumElite,
              rr: rrToUse,
              rrOk,
              completion: data.completion,
              compOk,
              phase_pct: data.phase_pct,
              phaseOk,
              rank: data.rank,
              enhancedTrigger,
              wouldAlertLogic,
              wouldAlert, // includes discord configured
            });
          }

          prevState = state;
        }

        // Check KV dedupe keys for alert buckets (so replay can explain "blocked by dedupe")
        const dedupe = {};
        const days = Array.from(wouldDays);
        await Promise.all(
          days.map(async (day) => {
            const v = await KV.get(day);
            dedupe[day] = { key: day, alreadyAlerted: !!v };
          }),
        );

        // Compute "wouldSendIfFirstBucket" as a deterministic simulation of dedupe behavior
        const firstOfDaySeen = new Set();
        const enriched = results.map((r) => {
          if (!r.wouldAlert)
            return {
              ...r,
              dedupe: dedupe[r.dedupe_key] || null,
              wouldSend: false,
            };
          const already =
            (dedupe[r.dedupe_key] && dedupe[r.dedupe_key].alreadyAlerted) ||
            false;
          const first = r.dedupe_key && !firstOfDaySeen.has(r.dedupe_key);
          if (r.dedupe_key && first) firstOfDaySeen.add(r.dedupe_key);
          return {
            ...r,
            dedupe: dedupe[r.dedupe_key] || null,
            wouldSend: !already && first,
          };
        });

        return sendJSON(
          {
            ok: true,
            ticker,
            source: history.source,
            since,
            until,
            pointsFetched: payloads.length,
            eligiblePoints: enriched.length, // only those passing logic
            wouldSendCount: enriched.filter((x) => x.wouldSend).length,
            discord: { enabled: discordEnabled, urlSet: discordUrlSet },
            thresholds: {
              base: {
                minRR: baseMinRR,
                maxComp: baseMaxComp,
                maxPhase: baseMaxPhase,
              },
            },
            results: enriched,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/trades?since&until&ticker&status&limit&cursor&mode=trader|investor
      if (routeKey === "GET /timed/ledger/trades") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/ledger/trades",
          600,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        // ── INVESTOR MODE: query investor_lots + investor_positions ──
        const mode = (url.searchParams.get("mode") || "trader").toLowerCase();
        if (mode === "investor") {
          try {
            const ticker = normTicker(url.searchParams.get("ticker")) || null;
            const sinceRaw = url.searchParams.get("since");
            const untilRaw = url.searchParams.get("until");
            const limitVal = Math.max(1, Math.min(1000, Number(url.searchParams.get("limit")) || 200));
            let where = "WHERE 1=1";
            const binds = [];
            if (ticker) { where += " AND l.ticker = ?"; binds.push(ticker.toUpperCase()); }
            if (sinceRaw) { where += " AND l.ts >= ?"; binds.push(Number(sinceRaw)); }
            if (untilRaw) { where += " AND l.ts <= ?"; binds.push(Number(untilRaw)); }
            const sql = `SELECT l.id as lot_id, l.position_id, l.ticker, l.action, l.shares, l.price, l.value, l.ts, l.reason,
                           p.status, p.total_shares, p.cost_basis, p.avg_entry, p.investor_stage
                         FROM investor_lots l
                         LEFT JOIN investor_positions p ON l.position_id = p.id
                         ${where}
                         ORDER BY l.ts DESC
                         LIMIT ?`;
            const rows = await db.prepare(sql).bind(...binds, limitVal + 1).all();
            const results = rows?.results || [];
            const page = results.slice(0, limitVal);
            const hasMore = results.length > limitVal;
            // Normalize to trade-like shape for frontend consistency
            const trades = page.map(r => ({
              trade_id: r.lot_id,
              position_id: r.position_id,
              ticker: r.ticker,
              direction: "LONG",
              action: r.action,
              entry_ts: r.ts,
              entry_price: r.price,
              shares: r.shares,
              value: r.value || (r.shares * r.price),
              reason: r.reason,
              status: r.status,
              investor_stage: r.investor_stage,
              total_shares: r.total_shares,
              cost_basis: r.cost_basis,
              avg_entry: r.avg_entry,
              pnl: r.action === "SELL" ? ((r.price - (r.avg_entry || 0)) * r.shares) : null,
              pnl_pct: r.action === "SELL" && r.avg_entry > 0 ? (((r.price - r.avg_entry) / r.avg_entry) * 100) : null,
            }));
            return sendJSON({ ok: true, mode: "investor", count: trades.length, hasMore, trades }, 200, corsHeaders(env, req));
          } catch (e) {
            const msg = (e?.message || String(e));
            if (msg.includes("no such table")) {
              return sendJSON({ ok: true, mode: "investor", count: 0, hasMore: false, trades: [] }, 200, corsHeaders(env, req));
            }
            return sendJSON({ ok: false, error: msg }, 500, corsHeaders(env, req));
          }
        }

        const ticker = normTicker(url.searchParams.get("ticker")) || null;
        const statusRaw = url.searchParams.get("status");
        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const limitRaw = url.searchParams.get("limit");
        const cursorRaw = url.searchParams.get("cursor");

        const since =
          sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;
        const limit = Math.max(1, Math.min(1000, Number(limitRaw) || 200));
        const cursor = decodeCursor(cursorRaw);

        let where = "WHERE 1=1";
        const binds = [];
        if (ticker) {
          where += " AND ticker = ?";
          binds.push(String(ticker).toUpperCase());
        }
        const statusNorm =
          statusRaw != null ? String(statusRaw).trim().toLowerCase() : "";
        if (statusNorm && statusNorm !== "all") {
          // UX-friendly filters used by the ledger UI
          if (statusNorm === "closed") {
            where += " AND status IN ('WIN','LOSS','FLAT')";
          } else if (statusNorm === "open") {
            // Includes OPEN + TRIMMED-style intermediate statuses + nulls
            where += " AND (status IS NULL OR status NOT IN ('WIN','LOSS','FLAT'))";
          } else {
            // Exact match fallback (stored statuses are uppercase)
            where += " AND status = ?";
            binds.push(String(statusRaw).toUpperCase());
          }
        }
        if (since != null && Number.isFinite(since)) {
          where += " AND entry_ts >= ?";
          binds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          where += " AND entry_ts <= ?";
          binds.push(Number(until));
        }
        if (
          cursor &&
          Number.isFinite(Number(cursor.entry_ts)) &&
          cursor.trade_id
        ) {
          where += " AND (entry_ts < ? OR (entry_ts = ? AND trade_id < ?))";
          binds.push(
            Number(cursor.entry_ts),
            Number(cursor.entry_ts),
            String(cursor.trade_id),
          );
        }

        const sqlFull = `SELECT
            trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at, trim_ts, trim_price
          FROM trades
          ${where}
          ORDER BY entry_ts DESC, trade_id DESC
          LIMIT ?`;
        const sqlWithoutTrimPrice = `SELECT
            trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at, trim_ts
          FROM trades
          ${where}
          ORDER BY entry_ts DESC, trade_id DESC
          LIMIT ?`;
        const sqlWithoutTrimTs = `SELECT
            trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
            exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
            script_version, created_at, updated_at
          FROM trades
          ${where}
          ORDER BY entry_ts DESC, trade_id DESC
          LIMIT ?`;

        let rows;
        try {
          rows = await db
            .prepare(sqlFull)
            .bind(...binds, limit + 1)
            .all();
        } catch (e) {
          const msg = (e && (e.message || String(e))) || "";
          if (msg.includes("trim_price") || msg.includes("no such column")) {
            try {
              rows = await db
                .prepare(sqlWithoutTrimPrice)
                .bind(...binds, limit + 1)
                .all();
              if (Array.isArray(rows?.results)) {
                rows.results = rows.results.map((r) => ({ ...r, trim_price: null }));
              }
            } catch (e2) {
              const msg2 = (e2 && (e2.message || String(e2))) || "";
              if (msg2.includes("trim_ts") || msg2.includes("no such column")) {
                rows = await db
                  .prepare(sqlWithoutTrimTs)
                  .bind(...binds, limit + 1)
                  .all();
                if (Array.isArray(rows?.results)) {
                  rows.results = rows.results.map((r) => ({ ...r, trim_ts: null, trim_price: null }));
                }
              } else {
                throw e2;
              }
            }
          } else if (msg.includes("trim_ts") || msg.includes("no such column")) {
            rows = await db
              .prepare(sqlWithoutTrimTs)
              .bind(...binds, limit + 1)
              .all();
            if (Array.isArray(rows?.results)) {
              rows.results = rows.results.map((r) => ({ ...r, trim_ts: null, trim_price: null }));
            }
          } else {
            throw e;
          }
        }
        const results = Array.isArray(rows?.results) ? rows.results : [];
        const page = results.slice(0, limit);
        const hasMore = results.length > limit;
        const last = page.length > 0 ? page[page.length - 1] : null;
        const nextCursor =
          hasMore && last
            ? encodeCursor({ entry_ts: last.entry_ts, trade_id: last.trade_id })
            : null;

        // Enrich with quantity from positions (remaining qty) for Holdings display
        try {
          const ids = page.map((r) => r.trade_id).filter(Boolean);
          if (ids.length > 0) {
            const placeholders = ids.map(() => "?").join(",");
            const posRows = await db
              .prepare(
                `SELECT position_id, total_qty FROM positions WHERE position_id IN (${placeholders})`,
              )
              .bind(...ids)
              .all();
            const qtyByTrade = new Map();
            for (const r of posRows?.results || []) {
              qtyByTrade.set(String(r.position_id), Number(r.total_qty) || 0);
            }
            for (const t of page) {
              const qty = qtyByTrade.get(String(t.trade_id));
              if (qty != null) {
                t.quantity = qty;
                t.shares = qty;
              } else if (Number(t.trimmed_pct ?? 0) >= 0.9999) {
                t.quantity = 0;
                t.shares = 0;
              }
            }
          }
        } catch {
          for (const t of page) {
            t.quantity = null;
            t.shares = null;
          }
        }

        return sendJSON(
          { ok: true, count: page.length, hasMore, nextCursor, trades: page },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/trades/:tradeId
      // GET /timed/ledger/trades/:tradeId/decision-card?type=ENTRY|TRIM|EXIT&ts=...
      // Returns a Discord-style "Action & Reasoning" card using the nearest trail snapshot.
      if (routeKey === "GET /timed/ledger/trades/:id/decision-card") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const raw = url.pathname.split("/timed/ledger/trades/")[1] || "";
        const tradeId = decodeURIComponent(
          raw.replace(/\/decision-card$/, ""),
        ).trim();
        if (!tradeId) {
          return sendJSON(
            { ok: false, error: "missing trade_id" },
            400,
            corsHeaders(env, req),
          );
        }

        const typeRaw = String(
          url.searchParams.get("type") || url.searchParams.get("event") || "",
        )
          .trim()
          .toUpperCase();
        const type =
          typeRaw === "CLOSE"
            ? "EXIT"
            : typeRaw === "ENTRY" || typeRaw === "TRIM" || typeRaw === "EXIT"
              ? typeRaw
              : null;
        if (!type) {
          return sendJSON(
            {
              ok: false,
              error: "missing_or_invalid_type",
              allowed: ["ENTRY", "TRIM", "EXIT"],
            },
            400,
            corsHeaders(env, req),
          );
        }

        const tsParam = url.searchParams.get("ts");
        const ts = tsParam != null && tsParam !== "" ? Number(tsParam) : null;

        const tradeRow = await db
          .prepare(
            `SELECT
              trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
              exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
              script_version, created_at, updated_at
             FROM trades WHERE trade_id = ?1 LIMIT 1`,
          )
          .bind(tradeId)
          .first();

        if (!tradeRow) {
          return sendJSON(
            { ok: false, error: "not_found", trade_id: tradeId },
            404,
            corsHeaders(env, req),
          );
        }

        const ticker = String(tradeRow.ticker || "").toUpperCase();
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing_ticker", trade_id: tradeId },
            400,
            corsHeaders(env, req),
          );
        }

        const evRowFromDb = await (async () => {
          if (Number.isFinite(ts)) {
            // Find closest event in time (best for "By Day Activity" clicks)
            const r = await db
              .prepare(
                `SELECT
                  event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
                 FROM trade_events
                 WHERE trade_id = ?1 AND type = ?2
                 ORDER BY ABS(ts - ?3) ASC
                 LIMIT 1`,
              )
              .bind(tradeId, type, Number(ts))
              .first();
            return r || null;
          }
          // Default: entry -> earliest; others -> latest
          const order = type === "ENTRY" ? "ASC" : "DESC";
          const r = await db
            .prepare(
              `SELECT
                event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
               FROM trade_events
               WHERE trade_id = ?1 AND type = ?2
               ORDER BY ts ${order}
               LIMIT 1`,
            )
            .bind(tradeId, type)
            .first();
          return r || null;
        })();

        // Resilience: some environments may not have trade_events populated.
        // In that case, fall back to the timestamp passed by the client (preferred),
        // or use the trade's own lifecycle timestamps.
        const fallbackTs = (() => {
          if (Number.isFinite(ts)) return Number(ts);
          if (type === "ENTRY") return Number(tradeRow.entry_ts);
          if (type === "EXIT") return Number(tradeRow.exit_ts);
          // TRIM: best available fallback is updated_at when trim status is present
          const trimmed = Number(tradeRow.trimmed_pct || 0);
          if (type === "TRIM" && trimmed > 0)
            return Number(tradeRow.updated_at);
          return null;
        })();

        const evRow = evRowFromDb
          ? evRowFromDb
          : Number.isFinite(Number(fallbackTs))
            ? {
                event_id: null,
                trade_id: String(tradeId),
                ts: Number(fallbackTs),
                type,
                price: null,
                qty_pct_delta: null,
                qty_pct_total:
                  type === "TRIM"
                    ? Number(tradeRow.trimmed_pct || 0) || null
                    : null,
                pnl_realized: null,
                reason: null,
                meta_json: null,
              }
            : null;

        if (!evRow || !Number.isFinite(Number(evRow.ts))) {
          return sendJSON(
            { ok: false, error: "event_not_found", trade_id: tradeId, type },
            404,
            corsHeaders(env, req),
          );
        }

        const evTs = Number(evRow.ts);
        const snapWindowMs =
          type === "ENTRY" ? 3 * 60 * 60 * 1000 : 2 * 60 * 60 * 1000;
        const snap = await d1GetNearestTrailPayload(
          db,
          ticker,
          evTs,
          snapWindowMs,
        );

        const tickerData = snap && snap.payload ? snap.payload : null;
        if (!tickerData) {
          return sendJSON(
            {
              ok: false,
              error: "missing_snapshot",
              trade_id: tradeId,
              type,
              ts: evTs,
            },
            404,
            corsHeaders(env, req),
          );
        }

        const tradeLite = {
          direction: tradeRow.direction,
          rank: Number(tradeRow.rank) || 0,
          rr: Number(tradeRow.rr) || 0,
          status: tradeRow.status,
          exitReason: tradeRow.exit_reason || null,
          pnl: Number(tradeRow.pnl) || 0,
          pnlPct: Number(tradeRow.pnl_pct) || 0,
        };

        const trimPct = (() => {
          const v =
            evRow.qty_pct_total != null ? Number(evRow.qty_pct_total) : null;
          if (Number.isFinite(v)) return v;
          const fromMeta = parseTrimPctFromText(evRow.meta_json);
          return Number.isFinite(fromMeta) ? fromMeta : null;
        })();

        const actionKey = type === "EXIT" ? "CLOSE" : type;
        const interpretation = generateTradeActionInterpretation(
          actionKey,
          tickerData,
          tradeLite,
          trimPct,
        );

        return sendJSON(
          {
            ok: true,
            trade: tradeRow,
            event: evRow,
            snapshot: { ts: Number(snap.ts), payload: tickerData },
            card: {
              title:
                `${ticker} ${String(tradeLite.direction || "").toUpperCase()}`.trim(),
              action: interpretation?.action || null,
              reasons: interpretation?.reasons || null,
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      if (routeKey === "GET /timed/ledger/trades/:id") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const tradeId = decodeURIComponent(
          url.pathname.split("/timed/ledger/trades/")[1] || "",
        ).trim();
        if (!tradeId) {
          return sendJSON(
            { ok: false, error: "missing trade_id" },
            400,
            corsHeaders(env, req),
          );
        }

        const includeEvidence =
          (url.searchParams.get("includeEvidence") || "") === "1";

        const tradeRow = await db
          .prepare(
            `SELECT
              trade_id, ticker, direction, entry_ts, entry_price, rank, rr, status,
              exit_ts, exit_price, exit_reason, trimmed_pct, pnl, pnl_pct,
              script_version, created_at, updated_at
             FROM trades WHERE trade_id = ?1 LIMIT 1`,
          )
          .bind(tradeId)
          .first();

        if (!tradeRow) {
          return sendJSON(
            { ok: false, error: "not_found", trade_id: tradeId },
            404,
            corsHeaders(env, req),
          );
        }

        const eventsRows = await db
          .prepare(
            `SELECT
              event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
             FROM trade_events
             WHERE trade_id = ?1
             ORDER BY ts ASC`,
          )
          .bind(tradeId)
          .all();

        const events = Array.isArray(eventsRows?.results)
          ? eventsRows.results
          : [];

        let evidence = null;
        let entry_evidence = null;
        if (includeEvidence) {
          const ticker = String(tradeRow.ticker || "").toUpperCase();
          // Always try to attach a "best" entry snapshot (bubble-style detail)
          entry_evidence = await d1GetNearestTrailPayload(
            db,
            ticker,
            tradeRow.entry_ts,
            3 * 60 * 60 * 1000,
          );

          evidence = [];
          for (const ev of events) {
            const ts = Number(ev.ts);
            if (!ticker || !Number.isFinite(ts)) continue;
            const snap = await d1GetNearestTrailPayload(
              db,
              ticker,
              ts,
              2 * 60 * 60 * 1000,
            );
            if (snap && snap.payload) {
              evidence.push({
                event_id: ev.event_id,
                ts: ts,
                snapshot_ts: Number(snap.ts),
                payload: snap.payload,
              });
            }
          }
        }

        return sendJSON(
          { ok: true, trade: tradeRow, events, evidence, entry_evidence },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/alerts?since&until&ticker&dedupe_day&limit&cursor
      if (routeKey === "GET /timed/ledger/alerts") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/ledger/alerts",
          600,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const ticker = normTicker(url.searchParams.get("ticker")) || null;
        const dedupeDay = url.searchParams.get("dedupe_day");
        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const limitRaw = url.searchParams.get("limit");
        const cursorRaw = url.searchParams.get("cursor");

        const since =
          sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;
        const limit = Math.max(1, Math.min(1000, Number(limitRaw) || 200));
        const cursor = decodeCursor(cursorRaw);

        let where = "WHERE 1=1";
        const binds = [];
        if (ticker) {
          where += " AND ticker = ?";
          binds.push(String(ticker).toUpperCase());
        }
        if (dedupeDay && dedupeDay !== "all") {
          where += " AND dedupe_day = ?";
          binds.push(String(dedupeDay));
        }
        if (since != null && Number.isFinite(since)) {
          where += " AND ts >= ?";
          binds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          where += " AND ts <= ?";
          binds.push(Number(until));
        }
        if (cursor && Number.isFinite(Number(cursor.ts)) && cursor.alert_id) {
          where += " AND (ts < ? OR (ts = ? AND alert_id < ?))";
          binds.push(
            Number(cursor.ts),
            Number(cursor.ts),
            String(cursor.alert_id),
          );
        }

        const sql = `SELECT
            alert_id, ticker, ts, side, state, rank, rr_at_alert, trigger_reason, dedupe_day,
            discord_sent, discord_status, discord_error
          FROM alerts
          ${where}
          ORDER BY ts DESC, alert_id DESC
          LIMIT ?`;

        const rows = await db
          .prepare(sql)
          .bind(...binds, limit + 1)
          .all();
        const results = Array.isArray(rows?.results) ? rows.results : [];
        const page = results.slice(0, limit);
        const hasMore = results.length > limit;
        const last = page.length > 0 ? page[page.length - 1] : null;
        const nextCursor =
          hasMore && last
            ? encodeCursor({ ts: last.ts, alert_id: last.alert_id })
            : null;

        return sendJSON(
          { ok: true, count: page.length, hasMore, nextCursor, alerts: page },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/ledger/summary?since&until
      if (routeKey === "GET /timed/ledger/summary") {
        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/ledger/summary",
          300,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        const sinceRaw = url.searchParams.get("since");
        const untilRaw = url.searchParams.get("until");
        const since =
          sinceRaw != null && sinceRaw !== "" ? Number(sinceRaw) : null;
        const until =
          untilRaw != null && untilRaw !== "" ? Number(untilRaw) : null;

        let where = "WHERE 1=1";
        const binds = [];
        if (since != null && Number.isFinite(since)) {
          where += " AND entry_ts >= ?";
          binds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          where += " AND entry_ts <= ?";
          binds.push(Number(until));
        }

        const overall = await db
          .prepare(
            `SELECT
              COUNT(*) AS total,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN 1 ELSE 0 END) AS closed,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS closed_pnl,
              SUM(CASE WHEN status = 'WIN' THEN pnl ELSE 0 END) AS gross_win,
              SUM(CASE WHEN status = 'LOSS' THEN -pnl ELSE 0 END) AS gross_loss,
              AVG(CASE WHEN status = 'WIN' THEN pnl ELSE NULL END) AS avg_win,
              AVG(CASE WHEN status = 'LOSS' THEN -pnl ELSE NULL END) AS avg_loss_abs
            FROM trades
            ${where}`,
          )
          .bind(...binds)
          .first();

        const closed = Number(overall?.closed || 0);
        const openTrades = Math.max(0, Number(overall?.total || 0) - closed);
        const wins = Number(overall?.wins || 0);
        const losses = Number(overall?.losses || 0);
        const winRate = closed > 0 ? (wins / closed) * 100 : 0;
        const grossWin = Number(overall?.gross_win || 0);
        const grossLoss = Number(overall?.gross_loss || 0);
        const profitFactor =
          grossLoss > 0 ? grossWin / grossLoss : grossWin > 0 ? Infinity : 0;
        const avgWin = Number(overall?.avg_win || 0);
        const avgLossAbs = Number(overall?.avg_loss_abs || 0);
        const expectancy =
          closed > 0 ? Number(overall?.closed_pnl || 0) / closed : 0;

        const rankBuckets = await db
          .prepare(
            `SELECT
              CASE
                WHEN rank >= 80 THEN '80+'
                WHEN rank >= 70 THEN '70-79'
                WHEN rank >= 60 THEN '60-69'
                WHEN rank IS NULL THEN 'unknown'
                ELSE '<60'
              END AS bucket,
              COUNT(*) AS n,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS pnl
            FROM trades
            ${where}
            GROUP BY bucket
            ORDER BY bucket`,
          )
          .bind(...binds)
          .all();

        const rrBuckets = await db
          .prepare(
            `SELECT
              CASE
                WHEN rr >= 2.0 THEN '2.0+'
                WHEN rr >= 1.5 THEN '1.5-1.99'
                WHEN rr >= 1.0 THEN '1.0-1.49'
                WHEN rr IS NULL THEN 'unknown'
                ELSE '<1.0'
              END AS bucket,
              COUNT(*) AS n,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS pnl
            FROM trades
            ${where}
            GROUP BY bucket
            ORDER BY bucket`,
          )
          .bind(...binds)
          .all();

        const exitReasons = await db
          .prepare(
            `SELECT
              COALESCE(exit_reason, 'unknown') AS reason,
              COUNT(*) AS n,
              SUM(CASE WHEN status = 'WIN' THEN 1 ELSE 0 END) AS wins,
              SUM(CASE WHEN status = 'LOSS' THEN 1 ELSE 0 END) AS losses,
              SUM(CASE WHEN status IN ('WIN','LOSS') THEN pnl ELSE 0 END) AS pnl
            FROM trades
            ${where}
            GROUP BY reason
            ORDER BY n DESC`,
          )
          .bind(...binds)
          .all();

        // Trigger reasons from alerts (sent + skipped) in same time window (best-effort)
        let alertWhere = "WHERE 1=1";
        const alertBinds = [];
        if (since != null && Number.isFinite(since)) {
          alertWhere += " AND ts >= ?";
          alertBinds.push(Number(since));
        }
        if (until != null && Number.isFinite(until)) {
          alertWhere += " AND ts <= ?";
          alertBinds.push(Number(until));
        }

        const triggerReasons = await db
          .prepare(
            `SELECT
              COALESCE(trigger_reason, 'unknown') AS reason,
              COUNT(*) AS n,
              SUM(CASE WHEN discord_sent = 1 THEN 1 ELSE 0 END) AS sent,
              SUM(CASE WHEN discord_sent = 0 THEN 1 ELSE 0 END) AS not_sent
            FROM alerts
            ${alertWhere}
            GROUP BY reason
            ORDER BY n DESC`,
          )
          .bind(...alertBinds)
          .all();

        return sendJSON(
          {
            ok: true,
            since,
            until,
            totals: {
              totalTrades: Number(overall?.total || 0),
              openTrades,
              closedTrades: closed,
              wins,
              losses,
              winRate,
              closedPnl: Number(overall?.closed_pnl || 0),
              profitFactor,
              avgWin,
              avgLoss: avgLossAbs,
              expectancy,
              grossWin,
              grossLoss,
            },
            breakdown: {
              byRank: rankBuckets?.results || [],
              byRR: rrBuckets?.results || [],
              byExitReason: exitReasons?.results || [],
              byTriggerReason: triggerReasons?.results || [],
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-trades?key=...&limit=...&offset=...&ticker=...
      // Backfill KV trades/history into D1 ledger tables (idempotent via upserts + INSERT OR IGNORE).
      if (routeKey === "POST /timed/admin/backfill-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
        const filtered = Array.isArray(allTrades)
          ? allTrades.filter((t) => {
              if (!t || !t.id) return false;
              if (tickerFilter)
                return String(t.ticker || "").toUpperCase() === tickerFilter;
              return true;
            })
          : [];

        const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
        const limit =
          qLimit > 0 ? Math.max(1, Math.min(5000, qLimit)) : filtered.length;
        const slice = filtered.slice(offset, offset + limit);

        let tradesUpserted = 0;
        let eventsInserted = 0;
        const errors = [];

        const batchSize = 50;
        for (let i = 0; i < slice.length; i += batchSize) {
          const batch = slice.slice(i, i + batchSize);
          await Promise.all(
            batch.map(async (t) => {
              try {
                // Enrich legacy history (trim percentages + inferred exit reason/price)
                const tradeCopy = { ...t };
                if (Array.isArray(tradeCopy.history)) {
                  let prevTrimTotal = 0;
                  for (let idx = 0; idx < tradeCopy.history.length; idx++) {
                    const ev = tradeCopy.history[idx];
                    if (!ev || !ev.type) continue;
                    if (String(ev.type).toUpperCase() === "TRIM") {
                      const inferredTotal =
                        ev.trimPct != null
                          ? Number(ev.trimPct)
                          : (parseTrimPctFromText(ev.note) ??
                            parseTrimPctFromText(ev.meta_json));
                      if (
                        inferredTotal != null &&
                        Number.isFinite(inferredTotal)
                      ) {
                        ev.trimPct = inferredTotal;
                        if (ev.trimDeltaPct == null && prevTrimTotal != null) {
                          ev.trimDeltaPct = Math.max(
                            0,
                            inferredTotal - prevTrimTotal,
                          );
                        }
                        prevTrimTotal = inferredTotal;
                      }
                    }
                    if (String(ev.type).toUpperCase() === "EXIT") {
                      // Add explicit reason for better bucketing
                      ev.reason =
                        ev.reason ||
                        inferExitReasonForLegacyTrade(tradeCopy, ev);
                      // Ensure price is a number if present
                      if (ev.price != null) ev.price = Number(ev.price);
                    }
                  }
                }

                // Ensure trade-level exit fields exist for legacy trades
                if (
                  (String(tradeCopy.status || "").toUpperCase() === "WIN" ||
                    String(tradeCopy.status || "").toUpperCase() === "LOSS") &&
                  Array.isArray(tradeCopy.history)
                ) {
                  const exitEv =
                    [...tradeCopy.history]
                      .reverse()
                      .find((e) => e && e.type === "EXIT") || null;
                  if (exitEv) {
                    if (tradeCopy.exitPrice == null && exitEv.price != null)
                      tradeCopy.exitPrice = Number(exitEv.price);
                    if (!tradeCopy.exitReason)
                      tradeCopy.exitReason = inferExitReasonForLegacyTrade(
                        tradeCopy,
                        exitEv,
                      );
                  }
                }

                const r = await d1UpsertTrade(env, tradeCopy);
                if (r.ok) tradesUpserted += 1;

                if (Array.isArray(tradeCopy.history)) {
                  for (const ev of tradeCopy.history) {
                    const er = await d1InsertTradeEvent(
                      env,
                      String(tradeCopy.id),
                      ev,
                    );
                    if (er.ok) eventsInserted += 1;
                  }
                }
              } catch (e) {
                errors.push({ trade_id: t?.id || null, error: String(e) });
              }
            }),
          );
        }

        return sendJSON(
          {
            ok: true,
            ticker: tickerFilter || null,
            totalInKV: Array.isArray(allTrades) ? allTrades.length : 0,
            filtered: filtered.length,
            offset,
            limit: slice.length,
            tradesUpserted,
            eventsInserted,
            errorsCount: errors.length,
            errors: errors.slice(0, 25),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-positions?key=...&limit=...&offset=...
      // Backfill positions/lots/execution_actions from existing D1 trades + trade_events (idempotent).
      if (routeKey === "POST /timed/admin/backfill-positions") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));

        let tradeRows = [];
        try {
          let sql = `SELECT trade_id, ticker, direction, entry_ts, entry_price, status, trimmed_pct, pnl, script_version, created_at, updated_at, exit_ts
            FROM trades WHERE 1=1`;
          const binds = [];
          if (tickerFilter) {
            sql += " AND ticker = ?";
            binds.push(tickerFilter);
          }
          sql += " ORDER BY entry_ts ASC";
          if (qLimit > 0) {
            sql += " LIMIT ? OFFSET ?";
            binds.push(qLimit, qOffset);
          }
          const res = await db.prepare(sql).bind(...binds).all();
          tradeRows = Array.isArray(res?.results) ? res.results : [];
        } catch (e) {
          return sendJSON(
            { ok: false, error: "trades_query_failed", message: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }

        let positionsInserted = 0;
        let lotsInserted = 0;
        let actionsInserted = 0;
        const errors = [];

        for (const row of tradeRows) {
          try {
            const tradeId = row.trade_id;
            const ticker = String(row.ticker || "").toUpperCase();
            const direction = String(row.direction || "LONG").toUpperCase();
            let entryTs = Number(row.entry_ts) || Number(row.created_at) || 0;
            if (entryTs < 1e12) entryTs *= 1000;
            const status = row.status && (row.status === "WIN" || row.status === "LOSS") ? "CLOSED" : "OPEN";
            const closedAt = status === "CLOSED" ? (Number(row.exit_ts) || Number(row.updated_at) || null) : null; // trades has exit_ts, not closed_at

            const eventsRes = await db.prepare(
              `SELECT event_id, trade_id, ts, type, price, qty_pct_delta, qty_pct_total, pnl_realized, reason, meta_json
               FROM trade_events WHERE trade_id = ? ORDER BY ts ASC`
            ).bind(tradeId).all();
            const events = Array.isArray(eventsRes?.results) ? eventsRes.results : [];

            const entryPrice = Number(row.entry_price) || 0;
            let totalQty = 0;
            let costBasis = 0;
            const parseShares = (ev) => {
              if (ev.meta_json) {
                try {
                  const m = JSON.parse(ev.meta_json);
                  if (Number.isFinite(m.shares)) return m.shares;
                } catch {}
              }
              if (ev.price != null && ev.price > 0 && Number.isFinite(ev.value)) return ev.value / ev.price;
              return null;
            };

            const r1 = await d1InsertPosition(env, {
              position_id: tradeId,
              ticker,
              direction,
              status,
              total_qty: 0,
              cost_basis: 0,
              created_at: entryTs,
              updated_at: Number(row.updated_at) || Date.now(),
              closed_at: closedAt,
              script_version: row.script_version || null,
            });
            if (r1.ok) positionsInserted++;

            for (const ev of events) {
              const ts = Number(ev.ts) || 0;
              const tsMs = ts < 1e12 ? ts * 1000 : ts;
              const type = String(ev.type || "").toUpperCase();
              const price = ev.price != null ? Number(ev.price) : 0;
              let qty = parseShares(ev);
              if (qty == null && type === "ENTRY" && entryPrice > 0) {
                qty = 1000 / entryPrice;
              }
              if (qty == null || qty <= 0) continue;
              const value = price * qty;

              if (type === "ENTRY" || type === "SCALE_IN") {
                const lotId = `${tradeId}-lot-${tsMs}`;
                const actionType = type === "SCALE_IN" ? "ADD_ENTRY" : "ENTRY";
                const actionId = `${tradeId}-${actionType}-${tsMs}`;
                const r2 = await d1InsertLot(env, {
                  lot_id: lotId,
                  position_id: tradeId,
                  ts: tsMs,
                  qty,
                  price,
                  value,
                  remaining_qty: type === "ENTRY" ? qty : qty,
                });
                if (r2.ok) lotsInserted++;
                totalQty += qty;
                costBasis += value;
                const r3 = await d1InsertExecutionAction(env, {
                  action_id: actionId,
                  position_id: tradeId,
                  ts: tsMs,
                  action_type: actionType,
                  qty,
                  price,
                  value,
                  pnl_realized: null,
                  reason: ev.reason || actionType,
                });
                if (r3.ok) actionsInserted++;
              } else if (type === "TRIM" || type === "EXIT") {
                const actionId = `${tradeId}-${type}-${tsMs}`;
                const pnl = ev.pnl_realized != null ? Number(ev.pnl_realized) : null;
                const r3 = await d1InsertExecutionAction(env, {
                  action_id: actionId,
                  position_id: tradeId,
                  ts: tsMs,
                  action_type: type,
                  qty,
                  price,
                  value: price * qty,
                  pnl_realized: pnl,
                  reason: ev.reason || type,
                });
                if (r3.ok) actionsInserted++;
                if (type === "EXIT") {
                  totalQty = 0;
                  costBasis = 0;
                }
              }
            }

            if (totalQty > 0 || costBasis > 0) {
              await d1UpdatePosition(env, tradeId, {
                total_qty: totalQty,
                cost_basis: costBasis,
                updated_at: Number(row.updated_at) || Date.now(),
                ...(status === "CLOSED" ? { status: "CLOSED", closed_at: closedAt } : {}),
              });
            }
          } catch (e) {
            errors.push({ trade_id: row?.trade_id, error: String(e?.message || e) });
          }
        }

        return sendJSON(
          {
            ok: true,
            tradesProcessed: tradeRows.length,
            positionsInserted,
            lotsInserted,
            actionsInserted,
            errorsCount: errors.length,
            errors: errors.slice(0, 20),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-alerts?key=...&limit=...&offset=...&ticker=...&source=trades|activity|all
      // Backfill KV activity + trades into D1 alerts ledger (idempotent via upserts).
      if (routeKey === "POST /timed/admin/backfill-alerts") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "d1_not_configured" },
            503,
            corsHeaders(env, req),
          );
        }

        const source = String(
          url.searchParams.get("source") || "all",
        ).toLowerCase();
        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));

        let alertsUpserted = 0;
        const errors = [];

        const upsertAlertSafe = async (payload) => {
          try {
            const r = await d1UpsertAlert(env, payload);
            if (r.ok) alertsUpserted += 1;
          } catch (err) {
            errors.push(String(err));
          }
        };

        if (source === "activity" || source === "all") {
          try {
            const feed = (await kvGetJSON(KV, "timed:activity:feed")) || [];
            const activityAlerts = feed.filter((e) => {
              if (!e || !e.ticker) return false;
              if (
                tickerFilter &&
                String(e.ticker).toUpperCase() !== tickerFilter
              )
                return false;
              return (
                e.type === "discord_alert" ||
                e.type === "trade_entry" ||
                e.type === "td9_exit"
              );
            });
            for (const ev of activityAlerts) {
              const ts = Number(ev.ts) || Date.now();
              const side =
                ev.direction || ev.side || ev.trigger_dir || ev.action || null;
              const alertType =
                ev.type === "discord_alert"
                  ? "ALERT_ENTRY"
                  : ev.type === "trade_entry"
                    ? "TRADE_ENTRY"
                    : "TD9_EXIT";
              const payloadJson = (() => {
                try {
                  return JSON.stringify(ev);
                } catch {
                  return null;
                }
              })();
              const metaJson = (() => {
                try {
                  return JSON.stringify({ source: "activity", type: ev.type });
                } catch {
                  return null;
                }
              })();
              await upsertAlertSafe({
                alert_id: buildAlertId(ev.ticker, ts, alertType),
                ticker: ev.ticker,
                ts,
                side,
                state: ev.state,
                rank: ev.rank,
                rr_at_alert: ev.rr,
                trigger_reason: ev.trigger_reason || ev.action || alertType,
                dedupe_day: formatDedupDay(ts),
                discord_sent: true,
                discord_status: 200,
                discord_error: null,
                payload_json: payloadJson,
                meta_json: metaJson,
              });
            }
          } catch (err) {
            errors.push(String(err));
          }
        }

        if (source === "trades" || source === "all") {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const filtered = Array.isArray(allTrades)
            ? allTrades.filter((t) => {
                if (!t || !t.id) return false;
                if (tickerFilter)
                  return String(t.ticker || "").toUpperCase() === tickerFilter;
                return true;
              })
            : [];

          const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
          const limit =
            qLimit > 0 ? Math.max(1, Math.min(5000, qLimit)) : filtered.length;
          const slice = filtered.slice(offset, offset + limit);

          for (const trade of slice) {
            if (!Array.isArray(trade.history)) continue;
            for (const ev of trade.history) {
              if (!ev || !ev.type) continue;
              const ts = isoToMs(ev.timestamp) || Number(ev.ts) || Date.now();
              const type = String(ev.type).toUpperCase();
              const reason =
                ev.reason ||
                (type === "EXIT"
                  ? trade.exitReason || trade.exit_reason
                  : type);
              const payloadJson = (() => {
                try {
                  return JSON.stringify({
                    trade_id: trade.id,
                    trade,
                    event: ev,
                  });
                } catch {
                  return null;
                }
              })();
              const metaJson = (() => {
                try {
                  return JSON.stringify({ source: "trade_history", type });
                } catch {
                  return null;
                }
              })();
              await upsertAlertSafe({
                alert_id: buildAlertId(trade.ticker, ts, type),
                ticker: trade.ticker,
                ts,
                side: trade.direction,
                state: trade.state,
                rank: trade.rank,
                rr_at_alert: trade.rr,
                trigger_reason: reason,
                dedupe_day: formatDedupDay(ts),
                discord_sent: false,
                discord_status: null,
                discord_error: null,
                payload_json: payloadJson,
                meta_json: metaJson,
              });
            }
          }
        }

        return sendJSON(
          { ok: true, alertsUpserted, errors },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/backfill-derived?key=...&limit=...&offset=...&ticker=...&includeTrades=1
      // Recompute derived horizon/ETA/TP fields for latest tickers (and optionally trades) and persist to KV.
      if (routeKey === "POST /timed/admin/backfill-derived") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const qLimit = Number(url.searchParams.get("limit") || "0");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));
        const includeTrades =
          String(url.searchParams.get("includeTrades") || "") === "1";

        const tickersList = (await kvGetJSON(KV, "timed:tickers")) || [];
        const filteredTickers = Array.isArray(tickersList)
          ? tickersList.filter((t) => {
              if (!t) return false;
              if (tickerFilter)
                return String(t).toUpperCase() === String(tickerFilter);
              return true;
            })
          : [];

        const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
        const limit =
          qLimit > 0
            ? Math.max(1, Math.min(2000, qLimit))
            : filteredTickers.length;
        const slice = filteredTickers.slice(offset, offset + limit);

        let tickersUpdated = 0;
        let tradesUpdated = 0;
        const errors = [];

        for (const t of slice) {
          try {
            const ticker = String(t || "").toUpperCase();
            if (!ticker) continue;
            const latestKey = `timed:latest:${ticker}`;
            const latest = await kvGetJSON(KV, latestKey);
            if (!latest || typeof latest !== "object") continue;
            const derived = deriveHorizonAndMetrics(latest);
            Object.assign(latest, derived);
            await kvPutJSON(KV, latestKey, latest);
            tickersUpdated += 1;
          } catch (e) {
            errors.push({ ticker: t || null, error: String(e) });
          }
        }

        if (includeTrades) {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          if (Array.isArray(allTrades) && allTrades.length > 0) {
            for (const trade of allTrades) {
              if (!trade || !trade.ticker) continue;
              const tradeTicker = String(trade.ticker || "").toUpperCase();
              if (tickerFilter && tradeTicker !== tickerFilter) continue;
              try {
                const latest = await kvGetJSON(
                  KV,
                  `timed:latest:${tradeTicker}`,
                );
                const base =
                  latest && typeof latest === "object" ? latest : trade;
                const source = {
                  ...base,
                  entry_ref:
                    base.entry_ref != null
                      ? base.entry_ref
                      : (trade.entryPrice ?? base.trigger_price ?? base.price),
                  trigger_price: base.trigger_price ?? trade.entryPrice,
                  price: base.price ?? trade.currentPrice ?? trade.entryPrice,
                  sl: base.sl ?? trade.sl,
                  tp: base.tp ?? trade.tp,
                };
                const derived = deriveHorizonAndMetrics(source);
                trade.horizon_bucket = derived.horizon_bucket;
                trade.eta_days_v2 = derived.eta_days_v2;
                trade.expected_return_pct = derived.expected_return_pct;
                trade.risk_pct = derived.risk_pct;
                trade.tp_target_price = derived.tp_target_price;
                trade.tp_target_pct = derived.tp_target_pct;
                trade.tp_max_price = derived.tp_max_price;
                trade.tp_max_pct = derived.tp_max_pct;
                trade.entry_ref = derived.entry_ref ?? trade.entry_ref;
                tradesUpdated += 1;
              } catch (e) {
                errors.push({ trade_id: trade?.id || null, error: String(e) });
              }
            }
            await kvPutJSON(KV, tradesKey, allTrades);
          }
        }

        return sendJSON(
          {
            ok: true,
            ticker: tickerFilter || null,
            totalTickers: Array.isArray(tickersList) ? tickersList.length : 0,
            filtered: filteredTickers.length,
            offset,
            limit: slice.length,
            tickersUpdated,
            tradesUpdated: includeTrades ? tradesUpdated : 0,
            errorsCount: errors.length,
            errors: errors.slice(0, 25),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // ═══════════════════════════════════════════════════════════════════════
      // ALPACA INTEGRATION ENDPOINTS
      // ═══════════════════════════════════════════════════════════════════════

      // POST /timed/admin/alpaca-backfill?key=...&tf=all|D|W|...&sinceDays=30
      // One-time backfill of historical bars from Alpaca. sinceDays=30 limits to previous 30 days (default: deep history).
      if (routeKey === "POST /timed/admin/alpaca-backfill") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;

        if (!env.ALPACA_API_KEY_ID || !env.ALPACA_API_SECRET_KEY) {
          return sendJSON(
            { ok: false, error: "alpaca_not_configured", hint: "Set ALPACA_API_KEY_ID and ALPACA_API_SECRET_KEY via wrangler secret put" },
            400, corsHeaders(env, req),
          );
        }

        const tfParam = url.searchParams.get("tf") || "all";
        const sinceDaysParam = url.searchParams.get("sinceDays");
        const sinceDays = sinceDaysParam != null && sinceDaysParam !== "" ? Math.max(1, Number(sinceDaysParam) || 30) : null;
        const tickerParam = normTicker(url.searchParams.get("ticker")) || null;
        const batchOffset = Math.max(0, Number(url.searchParams.get("offset")) || 0);
        const rawLimit = url.searchParams.get("limit");
        const batchLimit = rawLimit ? Math.max(1, Math.min(200, Number(rawLimit) || 0)) : 0;
        let allTickers = tickerParam ? [tickerParam] : Object.keys(SECTOR_MAP);
        if (!tickerParam && batchLimit > 0) {
          allTickers = allTickers.slice(batchOffset, batchOffset + batchLimit);
        }

        // Run backfill in background (will take a while)
        ctx.waitUntil(
          alpacaBackfill(env, allTickers, d1UpsertCandle, tfParam, sinceDays)
            .then(res => console.log(`[ALPACA BACKFILL] Done:`, JSON.stringify(res)))
            .catch(err => console.error(`[ALPACA BACKFILL] Error:`, err))
        );

        return sendJSON(
          {
            ok: true,
            message: `Alpaca backfill started in background for ${allTickers.length} ticker(s)`,
            tickers: allTickers.length,
            tickerList: allTickers.length <= 5 ? allTickers : undefined,
            tf: tfParam,
          },
          200, corsHeaders(env, req),
        );
      }

      // POST /timed/admin/alpaca-compute?key=...&ticker=AAPL (compute scores for one ticker)
      if (routeKey === "POST /timed/admin/alpaca-compute") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const tickerParam = normTicker(url.searchParams.get("ticker"));
        if (!tickerParam) {
          return sendJSON({ ok: false, error: "missing ticker param" }, 400, corsHeaders(env, req));
        }

        const existingData = await kvGetJSON(KV, `timed:latest:${tickerParam}`);
        const result = await computeServerSideScores(tickerParam, d1GetCandles, env, existingData);

        if (!result) {
          return sendJSON(
            { ok: false, error: "insufficient_candle_data", ticker: tickerParam, hint: "Run alpaca-backfill first" },
            200, corsHeaders(env, req),
          );
        }

        result.rank = computeRank(result);
        result.score = result.rank;

        // Save to KV + D1 for immediate propagation
        await kvPutJSON(KV, `timed:latest:${tickerParam}`, result);
        ctx.waitUntil(d1UpsertTickerLatest(env, tickerParam, result));

        return sendJSON(
          {
            ok: true,
            ticker: tickerParam,
            htf_score: result.htf_score,
            ltf_score: result.ltf_score,
            state: result.state,
            price: result.price,
            sl: result.sl,
            tp_trim: result.tp_trim,
            tp_exit: result.tp_exit,
            tp_runner: result.tp_runner,
            rr: result.rr,
            data_source: result.data_source,
            flags: result.flags,
            td_sequential: result.td_sequential || null,
          },
          200, corsHeaders(env, req),
        );
      }

      // POST /timed/admin/purge-ticker-candles?key=...&ticker=GOLD (delete all candles for a ticker from D1)
      if (routeKey === "POST /timed/admin/purge-ticker-candles") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const tickerParam = normTicker(url.searchParams.get("ticker"));
        if (!tickerParam) return sendJSON({ ok: false, error: "missing ticker param" }, 400, corsHeaders(env, req));
        const db = env.DB || env.D1;
        let totalDeleted = 0;
        for (;;) {
          const del = await db.prepare(`DELETE FROM ticker_candles WHERE rowid IN (SELECT rowid FROM ticker_candles WHERE ticker = ?1 LIMIT 5000)`).bind(tickerParam).run();
          const changed = del?.meta?.changes || 0;
          totalDeleted += changed;
          if (changed < 5000) break;
        }
        // Also clear ticker_latest entry
        try { await db.prepare(`DELETE FROM ticker_latest WHERE ticker = ?1`).bind(tickerParam).run(); } catch {}
        return sendJSON({ ok: true, ticker: tickerParam, deleted_candles: totalDeleted }, 200, corsHeaders(env, req));
      }

      // POST /timed/admin/refresh-prices — manually trigger price refresh (debug)
      if (routeKey === "POST /timed/admin/refresh-prices") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const allTickers = Object.keys(SECTOR_MAP);
          const snapResult = await alpacaFetchSnapshots(env, allTickers);
          const snapshots = snapResult.snapshots || {};
          const prices = {};
          for (const [sym, snap] of Object.entries(snapshots)) {
            const price = snap.price;
            const prevClose = snap.prevDailyClose;
            const dc = (price && prevClose && prevClose > 0) ? Math.round((price - prevClose) * 100) / 100 : 0;
            const dp = (price && prevClose && prevClose > 0) ? Math.round(((price - prevClose) / prevClose) * 10000) / 100 : 0;
            prices[sym] = { p: Math.round(price * 100) / 100, pc: Math.round(prevClose * 100) / 100, dc, dp, t: Date.now() };
          }
          // Fallback for tickers missing from Alpaca (e.g. single-letter "W")
          const missing = allTickers.filter(s => !prices[s] || !(Number(prices[s]?.p) > 0));
          if (missing.length > 0 && env?.DB) {
            const KV = env.KV_TIMED;
            for (const sym of missing) {
              try {
                let price = 0;
                let prevClose = 0;
                const res = await d1GetCandles(env, sym, "5", 1);
                if (res?.ok && res.candles?.length > 0 && Number.isFinite(res.candles[0].c))
                  price = Number(res.candles[0].c);
                if (!(price > 0) && KV) {
                  const latest = await kvGetJSON(KV, `timed:latest:${sym}`);
                  if (latest && Number(latest.price) > 0) {
                    price = Number(latest.price);
                    prevClose = Number(latest.prev_close || latest.previous_close || 0) || 0;
                  }
                }
                if (price > 0) {
                  const pc = prevClose > 0 ? prevClose : 0;
                  const dc = prevClose > 0 ? Math.round((price - prevClose) * 100) / 100 : null;
                  const dp = prevClose > 0 ? Math.round(((price - prevClose) / prevClose) * 10000) / 100 : null;
                  prices[sym] = { p: Math.round(price * 100) / 100, pc: Math.round(pc * 100) / 100, dc, dp, t: Date.now() };
                }
              } catch (_) { /* best-effort */ }
            }
          }
          // Store in KV
          await kvPutJSON(env.KV_TIMED, "timed:prices", { prices, updated_at: Date.now(), ticker_count: Object.keys(prices).length });
          return sendJSON({ ok: true, ticker_count: Object.keys(prices).length, snapshot_count: Object.keys(snapshots).length, input_count: allTickers.length }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e), stack: String(e?.stack || "").slice(0, 500) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/admin/alpaca-status?key=...
      if (routeKey === "GET /timed/admin/alpaca-status") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const allTickers = Object.keys(SECTOR_MAP);
        const tfs = ["M", "W", "D", "240", "60", "30", "10", "3"];
        const coverage = {};
        let totalCandles = 0;

        // Sample a few tickers for coverage stats
        const sampleTickers = allTickers.slice(0, 10);
        for (const t of sampleTickers) {
          coverage[t] = {};
          for (const tf of tfs) {
            try {
              const res = await d1GetCandles(env, t, tf, 5);
              const count = res?.candles?.length || 0;
              coverage[t][tf] = count;
              totalCandles += count;
            } catch { coverage[t][tf] = 0; }
          }
        }

        // Count alpaca-sourced tickers in KV
        let alpacaSourced = 0;
        let tvSourced = 0;
        for (const t of allTickers.slice(0, 50)) {
          const data = await kvGetJSON(KV, `timed:latest:${t}`);
          if (data?.data_source === "alpaca") alpacaSourced++;
          else if (data?.script_version && data.script_version.startsWith("score_engine")) tvSourced++;
        }

        return sendJSON(
          {
            ok: true,
            alpaca_configured: !!(env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY),
            alpaca_enabled: env.ALPACA_ENABLED === "true",
            total_tickers: allTickers.length,
            sample_coverage: coverage,
            sample_total_candles: totalCandles,
            kv_data_sources: { alpaca: alpacaSourced, tradingview: tvSourced, sampled: 50 },
          },
          200, corsHeaders(env, req),
        );
      }

      // ═══════════════════════════════════════════════════════════════════════════
      // GET /timed/admin/ingestion-status (candle coverage report)
      // Returns candle count per ticker per TF, compared to expected minimums.
      if (routeKey === "GET /timed/admin/ingestion-status") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        const db = env?.DB;
        if (!db) return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));

        const tickerFilter = normTicker(url.searchParams.get("ticker")) || null;

        // Expected minimums per TF (approximate for good chart + scoring coverage)
        // Canonical 9 TFs (3m dropped)
        const expected = { "5": 500, "10": 500, "30": 300, "60": 300, "240": 300, "D": 250, "W": 200, "M": 60 };
        const tfs = ["M", "W", "D", "240", "60", "30", "10", "5"];

        // Expected trading days in the last N calendar days (for gap detection)
        // Intraday TFs: check last 30 calendar days (~21 trading days)
        // D/W/M: check longer windows
        const GAP_WINDOW_MS = 30 * 24 * 60 * 60 * 1000; // 30 calendar days
        const gapSinceTs = Date.now() - GAP_WINDOW_MS;
        const EXPECTED_TRADING_DAYS = 21; // ~21 trading days in 30 calendar days
        // Which TFs should have daily coverage (intraday TFs)
        const INTRADAY_TFS = new Set(["1", "5", "10", "30", "60", "240"]);

        try {
          // Run two queries in parallel via db.batch():
          // 1. Count + min/max per ticker+TF (existing)
          // 2. Distinct trading-date count in last 30 days per ticker+TF (new — for gap detection)
          const stmts = [];
          if (tickerFilter) {
            stmts.push(
              db.prepare("SELECT ticker, tf, COUNT(*) as cnt, MIN(ts) as min_ts, MAX(ts) as max_ts FROM ticker_candles WHERE ticker = ?1 GROUP BY ticker, tf ORDER BY ticker, tf").bind(tickerFilter),
              db.prepare("SELECT ticker, tf, COUNT(DISTINCT date(ts/1000, 'unixepoch', '-5 hours')) as date_count FROM ticker_candles WHERE ticker = ?1 AND ts >= ?2 GROUP BY ticker, tf").bind(tickerFilter, gapSinceTs),
            );
          } else {
            stmts.push(
              db.prepare("SELECT ticker, tf, COUNT(*) as cnt, MIN(ts) as min_ts, MAX(ts) as max_ts FROM ticker_candles GROUP BY ticker, tf ORDER BY ticker, tf"),
              db.prepare("SELECT ticker, tf, COUNT(DISTINCT date(ts/1000, 'unixepoch', '-5 hours')) as date_count FROM ticker_candles WHERE ts >= ?1 GROUP BY ticker, tf").bind(gapSinceTs),
            );
          }
          const batchRes = await db.batch(stmts);
          const rows = batchRes[0]?.results || [];
          const gapRows = batchRes[1]?.results || [];

          // Build per-ticker summary
          const byTicker = {};
          for (const r of rows) {
            if (!byTicker[r.ticker]) byTicker[r.ticker] = {};
            byTicker[r.ticker][r.tf] = { count: r.cnt, min_ts: r.min_ts, max_ts: r.max_ts };
          }

          // Build gap data: { TICKER: { TF: date_count } }
          const gapData = {};
          for (const r of gapRows) {
            if (!gapData[r.ticker]) gapData[r.ticker] = {};
            gapData[r.ticker][r.tf] = r.date_count;
          }

          // Build report from canonical watchlist (KV timed:tickers) so newly added
          // tickers appear immediately even before they have candle data or sector mapping.
          const removedSet = new Set((await kvGetJSON(KV, "timed:removed")) || []);
          const kvTickers = (await kvGetJSON(KV, "timed:tickers")) || [];
          const allTickersSorted = [...new Set([
            ...kvTickers.filter(t => !removedSet.has(String(t).toUpperCase())),
            ...Object.keys(SECTOR_MAP).filter(t => !removedSet.has(t)),
          ])].map(t => String(t).toUpperCase()).filter(Boolean).sort();
          const report = [];
          let totalComplete = 0, totalExpected = 0;
          const nowMs = Date.now();

          for (const t of allTickersSorted) {
            const tfData = {};
            let tickerQualitySum = 0;
            let tickerPct = 0;
            for (const tf of tfs) {
              const d = byTicker[t]?.[tf];
              const cnt = d?.count || 0;
              const exp = expected[tf] || 200;
              const pct = Math.min(100, Math.round((cnt / exp) * 100));

              // Freshness: hours since latest candle
              const maxTs = d?.max_ts || 0;
              const freshnessHours = maxTs > 0 ? Math.round((nowMs - maxTs) / 3600000 * 10) / 10 : null;

              // Gap detection: distinct trading dates in last 30 days vs expected
              const recentDates = gapData[t]?.[tf] || 0;
              let gapDays = null;
              if (INTRADAY_TFS.has(tf)) {
                gapDays = Math.max(0, EXPECTED_TRADING_DAYS - recentDates);
              }

              // Quality: weighted score factoring count + freshness + gaps
              // count_score: 0-40 points (did we reach expected count?)
              // freshness_score: 0-30 points (is data current?)
              // gap_score: 0-30 points (is data contiguous for intraday TFs?)
              const countScore = Math.min(40, Math.round((cnt / exp) * 40));
              const freshScore = freshnessHours == null ? 30
                : freshnessHours <= 1 ? 30
                : freshnessHours <= 24 ? 20
                : freshnessHours <= 72 ? 10
                : 0;
              let gapScore = 30; // default full marks for D/W/M
              if (INTRADAY_TFS.has(tf) && recentDates > 0) {
                gapScore = Math.min(30, Math.round((recentDates / EXPECTED_TRADING_DAYS) * 30));
              } else if (INTRADAY_TFS.has(tf) && recentDates === 0) {
                gapScore = 0;
              }
              const qualityPct = Math.min(100, countScore + freshScore + gapScore);

              tfData[tf] = {
                count: cnt, expected: exp, pct,
                min_ts: d?.min_ts || null, max_ts: d?.max_ts || null,
                freshness_hours: freshnessHours,
                gap_days: gapDays,
                recent_dates: recentDates,
                quality: qualityPct,
              };
              tickerPct += pct;
              tickerQualitySum += qualityPct;
              totalComplete += cnt;
              totalExpected += exp;
            }
            const avgPct = Math.round(tickerPct / tfs.length);
            const avgQuality = Math.round(tickerQualitySum / tfs.length);
            const missingTfs = tfs.filter(tf => !tfData[tf] || tfData[tf].count === 0);
            report.push({ ticker: t, sector: SECTOR_MAP[t] || "Unknown", pct: avgPct, quality: avgQuality, missing: missingTfs, tfs: tfData });
          }

          // Sort by quality ascending (worst first)
          report.sort((a, b) => a.quality - b.quality);

          // Summary — based on canonical list
          const tickersWithData = new Set(report.filter(r => (r.tfs && Object.values(r.tfs).some(tf => tf && tf.count > 0))).map(r => r.ticker));
          const tickersNoData = allTickersSorted.filter(t => !tickersWithData.has(t));

          return sendJSON({
            ok: true,
            summary: {
              total_tickers_in_system: allTickersSorted.length,
              tickers_with_candle_data: tickersWithData.size,
              tickers_no_data: tickersNoData.length,
              tickers_no_data_list: tickersNoData.slice(0, 30),
              overall_pct: totalExpected > 0 ? Math.round((totalComplete / totalExpected) * 100) : 0,
            },
            tickers: report,
            worst_10: report.slice(0, 10).map(r => ({ ticker: r.ticker, pct: r.pct, quality: r.quality, missing: r.missing })),
          }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: String(err) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════════
      // GET /timed/admin/backfill-status
      // Returns current backfill progress from KV (written by alpacaBackfill).
      if (routeKey === "GET /timed/admin/backfill-status") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        const status = await kvGetJSON(KV, "timed:backfill:status");
        return sendJSON({ ok: true, status: status || null }, 200, corsHeaders(env, req));
      }


      // POST /timed/admin/candle-replay
      // Pure candle-based replay: generates scoring snapshots from Alpaca historical
      // candle data (no trail/webhook dependency). Pre-loads candles into memory,
      // then slides through 5-min intervals computing scores + running trade sim.
      //
      // Params:
      //   date=YYYY-MM-DD       (required) trading day to replay
      //   tickerOffset=0        batch start index into SECTOR_MAP
      //   tickerBatch=15        tickers per invocation
      //   intervalMinutes=5     interval between scoring snapshots
      //   cleanSlate=1          purge all trades first (only on first batch of first day)
      // ═══════════════════════════════════════════════════════════════════════════
      if (routeKey === "POST /timed/admin/candle-replay") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));

        const dateParam = url.searchParams.get("date");
        if (!dateParam || !/^\d{4}-\d{2}-\d{2}$/.test(dateParam)) {
          return sendJSON({ ok: false, error: "date param required (YYYY-MM-DD)" }, 400, corsHeaders(env, req));
        }

        const tickerOffset = Math.max(0, Number(url.searchParams.get("tickerOffset")) || 0);
        const tickerBatch = Math.max(1, Math.min(30, Number(url.searchParams.get("tickerBatch")) || 15));
        const intervalMinutes = Math.max(1, Math.min(30, Number(url.searchParams.get("intervalMinutes")) || 5));
        const cleanSlate = url.searchParams.get("cleanSlate") === "1";
        const trailOnly = url.searchParams.get("trailOnly") === "1";

        const allTickers = Object.keys(SECTOR_MAP);
        const batchTickers = allTickers.slice(tickerOffset, tickerOffset + tickerBatch);
        const hasMore = tickerOffset + tickerBatch < allTickers.length;

        if (batchTickers.length === 0) {
          return sendJSON({ ok: true, processed: 0, hasMore: false, message: "no_tickers_in_batch" }, 200, corsHeaders(env, req));
        }

        // Market hours: 9:30 AM to 4:00 PM ET
        const marketOpenMs = nyWallTimeToUtcMs(dateParam, 9, 30, 0);
        const marketCloseMs = nyWallTimeToUtcMs(dateParam, 16, 0, 0);
        if (!marketOpenMs || !marketCloseMs) {
          return sendJSON({ ok: false, error: "failed_to_compute_market_hours" }, 500, corsHeaders(env, req));
        }

        const intervalMs = intervalMinutes * 60 * 1000;
        const intervals = [];
        for (let ts = marketOpenMs; ts <= marketCloseMs; ts += intervalMs) {
          intervals.push(ts);
        }

        // Set replay-running lock (prevents live scoring cron from overwriting replay trades)
        await kvPutJSON(KV, "timed:replay:running", { since: Date.now(), date: dateParam, offset: tickerOffset });

        // Clean slate: purge ALL trades on first batch of a day (KV + D1)
        if (cleanSlate && tickerOffset === 0) {
          await kvPutJSON(KV, "timed:trades:all", []);
          await kvPutJSON(KV, "timed:portfolio:v1", null);
          await kvPutJSON(KV, "timed:activity:feed", null);

          // Also purge D1 trade-related tables so metrics stay in sync.
          // Run core tables first (guaranteed to exist), optional tables separately.
          if (db) {
            try {
              await db.batch([
                db.prepare("DELETE FROM trade_events"),
                db.prepare("DELETE FROM trades"),
              ]);
              console.log("[REPLAY cleanSlate] Purged D1 trade_events + trades");
            } catch (d1Err) {
              console.warn("[REPLAY cleanSlate] D1 trades purge error:", String(d1Err?.message || d1Err).slice(0, 200));
            }
            // Optional tables — may not exist; purge individually
            for (const tbl of ["positions", "execution_actions", "lots", "alerts"]) {
              try {
                await db.prepare(`DELETE FROM ${tbl}`).run();
              } catch { /* table may not exist */ }
            }
          }
        }

        // Pre-load all candles for batch tickers (all 7 TFs) in parallel
        const REPLAY_TFS = ["W", "D", "240", "60", "30", "10", "5"];
        const candleCache = {}; // { TICKER: { TF: [candles sorted asc by ts] } }

        // Use batch D1 reads (1 call per ticker instead of 7) to stay under subrequest limit
        await Promise.all(
          batchTickers.map(async (ticker) => {
            candleCache[ticker] = {};
            try {
              const tfConfigs = REPLAY_TFS.map(tf => ({ tf, limit: 1500 }));
              const batchResult = await d1GetCandlesAllTfs(env, ticker, tfConfigs);
              for (const tf of REPLAY_TFS) {
                const res = batchResult[tf];
                candleCache[ticker][tf] = (res?.ok && Array.isArray(res.candles)) ? res.candles : [];
              }
            } catch {
              for (const tf of REPLAY_TFS) candleCache[ticker][tf] = [];
            }
          })
        );

        // Load existing trades for trade simulation
        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        const replayCtx = { allTrades, execStates: new Map() };

        // State map: track evolving ticker state across intervals
        const stateMap = {};
        for (const ticker of batchTickers) {
          stateMap[ticker] = (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
        }

        let processed = 0;
        let tradesCreated = 0;
        let scored = 0;
        let skipped = 0;
        const errors = [];
        const timeline = [];
        const stageCounts = {}; // Track stage distribution
        const pendingTrail = []; // Collect trail points for batch write

        for (const intervalTs of intervals) {
          for (const ticker of batchTickers) {
            try {
              // Slice candles to only include bars at or before this interval
              const bundles = {};
              let hasData = false;
              for (const tf of REPLAY_TFS) {
                const allCandles = candleCache[ticker][tf] || [];
                const sliced = allCandles.filter(c => c.ts <= intervalTs);
                if (sliced.length >= 50) {
                  const bundle = computeTfBundle(sliced);
                  if (bundle) {
                    bundles[tf] = bundle;
                    hasData = true;
                  }
                }
              }

              if (!hasData) { skipped++; continue; }

              const bundleMap = {
                W: bundles.W || null,
                D: bundles.D || null,
                "240": bundles["240"] || null,
                "60": bundles["60"] || null,
                "30": bundles["30"] || null,
                "10": bundles["10"] || null,
                "5": bundles["5"] || null,
              };

              // Pass raw Daily/Weekly candles for Phase 2a regime detection
              const rawBars = {};
              for (const tf of ["D", "W"]) {
                const allCandles = candleCache[ticker]?.[tf] || [];
                const sliced = allCandles.filter(c => c.ts <= intervalTs);
                if (sliced.length >= 25) rawBars[tf] = sliced;
              }

              const existing = stateMap[ticker] || {};
              const result = assembleTickerData(ticker, bundleMap, existing, { rawBars });
              if (!result) { skipped++; continue; }

              // Enrich with timestamp and derived fields
              result.ts = intervalTs;
              result.ingest_ts = intervalTs;
              result.data_source = "candle_replay";
              result.data_source_ts = intervalTs;

              // Compute RR, rank, move status — always recompute from current price
              result.rr = computeRR(result);
              if (result.rr != null && Number(result.rr) > 25) result.rr = 25;
              if (result.score == null && result.rank == null) {
                result.score = computeRank(result);
              }
              if (result.rr_warning == null && Number.isFinite(result.rr)) {
                result.rr_warning = computeRRWarning(result.rr);
              }
              result.move_status = computeMoveStatus(result);
              if (result.flags) {
                result.flags.move_invalidated = result.move_status?.status === "INVALIDATED";
                result.flags.move_completed = result.move_status?.status === "COMPLETED";
              }

              // Carry forward entry state from previous interval
              if (existing?.entry_ts != null && result.entry_ts == null) result.entry_ts = existing.entry_ts;
              if (existing?.entry_price != null && result.entry_price == null) result.entry_price = existing.entry_price;
              if (existing?.kanban_cycle_enter_now_ts != null) result.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
              if (existing?.kanban_cycle_trigger_ts != null) result.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
              if (existing?.kanban_cycle_side != null) result.kanban_cycle_side = existing.kanban_cycle_side;

              // Synthesize trigger_ts for candle-based replay (MUST happen BEFORE classifyKanbanStage):
              // When state transitions to an aligned/actionable state, mark as fresh trigger.
              // Carry forward trigger_ts from previous interval if state hasn't changed.
              const prevState = existing?.state;
              const curState = result.state;
              const isActionable = curState && (
                curState.includes("BULL_BULL") || curState.includes("BEAR_BEAR") ||
                curState.includes("PULLBACK")
              );
              if (isActionable && curState !== prevState) {
                result.trigger_ts = intervalTs;
              } else if (existing?.trigger_ts) {
                result.trigger_ts = existing.trigger_ts;
              }

              // Classify kanban stage
              const openTrade = replayCtx.allTrades.find(
                t => String(t?.ticker || "").toUpperCase() === ticker && isOpenTradeStatus(t?.status)
              ) || null;
              const prevStage = existing?.kanban_stage;
              const stage = classifyKanbanStage(result, openTrade, intervalTs);
              let finalStage = stage;

              // Enter gate: set cycle tracking
              if (finalStage === "enter_now" || finalStage === "enter") {
                result.kanban_cycle_enter_now_ts = intervalTs;
                result.kanban_cycle_trigger_ts = Number.isFinite(Number(result?.trigger_ts)) ? result.trigger_ts : intervalTs;
                result.kanban_cycle_side = sideFromStateOrScores(result);
              } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
                result.kanban_cycle_enter_now_ts = existing?.kanban_cycle_enter_now_ts ?? null;
                result.kanban_cycle_trigger_ts = existing?.kanban_cycle_trigger_ts ?? null;
                result.kanban_cycle_side = existing?.kanban_cycle_side ?? null;
              } else {
                result.kanban_cycle_enter_now_ts = null;
                result.kanban_cycle_trigger_ts = null;
                result.kanban_cycle_side = null;
              }

              // Track entry price on stage transitions
              const isNewEntry = (finalStage === "enter_now" || finalStage === "enter") && prevStage !== "enter_now" && prevStage !== "enter";
              if (isNewEntry) {
                const price = Number(result?.price);
                if (Number.isFinite(price) && price > 0) {
                  result.entry_price = price;
                  result.entry_ts = intervalTs;
                }
              }
              // Carry forward entry_price from previous interval ONLY if this is NOT a fresh entry
              if (!isNewEntry && finalStage && existing?.entry_price && result.entry_price == null) {
                result.entry_price = existing.entry_price;
                result.entry_ts = existing.entry_ts;
              }

              // Set stage transitions
              if (prevStage && finalStage && String(prevStage) !== String(finalStage)) {
                result.prev_kanban_stage = String(prevStage);
                result.prev_kanban_stage_ts = intervalTs;
              }

              result.kanban_stage = finalStage;
              result.kanban_meta = deriveKanbanMeta(result, finalStage);

              // Track stage distribution
              stageCounts[finalStage || "null"] = (stageCounts[finalStage || "null"] || 0) + 1;

              // Collect trail point for batch write at end (avoids 1000+ individual D1 calls)
              pendingTrail.push({ ticker, result: { ...result } });

              if (!trailOnly) {
                // Run trade simulation (with Discord disabled and no D1 writes)
                const replayEnv = { ...env, DISCORD_ENABLE: "false", DISCORD_WEBHOOK_URL: null };
                const countBefore = replayCtx.allTrades.filter(x => String(x?.ticker).toUpperCase() === ticker).length;
                await processTradeSimulation(KV, ticker, result, existing, replayEnv, {
                  forceUseIngestTs: true,
                  replayBatchContext: replayCtx,
                  asOfTs: intervalTs,
                });
                const countAfter = replayCtx.allTrades.filter(x => String(x?.ticker).toUpperCase() === ticker).length;
                if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
              }

              stateMap[ticker] = result;
              scored++;
              processed++;
            } catch (e) {
              errors.push({ ticker, ts: intervalTs, error: String(e?.message || e) });
            }
          }
        }

        // Batch-write all trail points to D1 (reduces 1000+ individual calls to a few batches)
        let trailWritten = 0;
        if (pendingTrail.length > 0 && db) {
          try {
            const trailStmts = [];
            for (const { ticker: t, result: r } of pendingTrail) {
              const ts = Number(r?.ts);
              if (!Number.isFinite(ts)) continue;
              const flagsJson = r?.flags ? JSON.stringify(r.flags) : null;
              trailStmts.push(
                db.prepare(
                  `INSERT OR REPLACE INTO timed_trail
                    (ticker, ts, price, htf_score, ltf_score, completion, phase_pct, state, rank, flags_json, trigger_reason, trigger_dir, kanban_stage, payload_json)
                   VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14)`
                ).bind(
                  String(t).toUpperCase(), ts,
                  r?.price ?? null, r?.htf_score ?? null, r?.ltf_score ?? null,
                  r?.completion ?? null, r?.phase_pct ?? null,
                  r?.state ?? null, r?.rank ?? null, flagsJson,
                  r?.trigger_reason ?? null, r?.trigger_dir ?? null,
                  r?.kanban_stage ?? null, null
                )
              );
            }
            for (let i = 0; i < trailStmts.length; i += 500) {
              await db.batch(trailStmts.slice(i, i + 500));
              trailWritten += Math.min(500, trailStmts.length - i);
            }
          } catch (trailErr) {
            errors.push({ ticker: "TRAIL_BATCH", error: String(trailErr?.message || trailErr).slice(0, 150) });
          }
        }

        // Write final state for each ticker to KV (skip when trailOnly to preserve current state)
        if (!trailOnly) {
          for (const ticker of batchTickers) {
            if (stateMap[ticker] && Object.keys(stateMap[ticker]).length > 0) {
              try {
                await kvPutJSON(KV, `timed:latest:${ticker}`, stateMap[ticker]);
              } catch { /* non-critical */ }
            }
          }

          // Persist trades to KV
          try {
            await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
          } catch (e) {
            errors.push({ ticker: "TRADES_SAVE", error: String(e?.message || e) });
          }

          // Also persist trades to D1 (source of truth) so they survive cron overwrites
          // Only upsert trades belonging to this batch's tickers to stay under D1 subrequest limits
          if (db) {
            const batchTickerSet = new Set(batchTickers.map(t => t.toUpperCase()));
            const batchTrades = replayCtx.allTrades.filter(t =>
              batchTickerSet.has(String(t?.ticker || "").toUpperCase())
            );
            try {
              for (const trade of batchTrades) {
                await d1UpsertTrade(env, trade).catch(() => {});
              }
            } catch (e) {
              errors.push({ ticker: "TRADES_D1_SYNC", error: String(e?.message || e).slice(0, 150) });
            }

            // ═══════════════════════════════════════════════════════════════════
            // Sync OPEN trades → D1 positions table
            // The capture handler + scoring cron use getPositionContext() which
            // queries the positions table. Without this, they classify kanban in
            // discovery mode (watch/setup/enter) and overwrite the replay's
            // correct management stages (hold/defend/trim/exit).
            // ═══════════════════════════════════════════════════════════════════
            const openBatchTrades = batchTrades.filter(t =>
              String(t?.status || "").toUpperCase() === "OPEN"
            );
            let positionsSynced = 0;
            for (const trade of openBatchTrades) {
              try {
                const sym = String(trade.ticker).toUpperCase();
                const dir = String(trade.direction || "LONG").toUpperCase();
                const shares = Number(trade.shares) || 0;
                const ep = Number(trade.entryPrice) || 0;
                const costBasis = shares * ep;
                const entryTs = Number(trade.entry_ts) || Number(trade.created_at) || Date.now();
                const sl = Number(trade.sl);
                const tp = Number(trade.tp);
                const posId = trade.id || `replay-${sym}-${entryTs}`;
                await d1InsertPosition(env, {
                  position_id: posId,
                  ticker: sym,
                  direction: dir,
                  status: "OPEN",
                  total_qty: shares,
                  cost_basis: costBasis,
                  created_at: entryTs,
                  updated_at: entryTs,
                  stop_loss: Number.isFinite(sl) ? sl : null,
                  take_profit: Number.isFinite(tp) ? tp : null,
                });
                positionsSynced++;
              } catch { /* non-critical */ }
            }
            if (positionsSynced > 0) {
              console.log(`[REPLAY] Synced ${positionsSynced} open positions to D1 positions table`);
            }
          }
        }

        // Clear replay lock when this is the last batch
        if (!hasMore) {
          await kvPutJSON(KV, "timed:replay:running", null);
          console.log("[REPLAY] Last batch done, cleared replay:running lock");
        }

        return sendJSON({
          ok: true,
          date: dateParam,
          tickerOffset,
          tickerBatch,
          tickersProcessed: batchTickers.length,
          intervals: intervals.length,
          intervalMinutes,
          scored,
          skipped,
          tradesCreated,
          totalTrades: replayCtx.allTrades.length,
          hasMore,
          nextTickerOffset: hasMore ? tickerOffset + tickerBatch : null,
          errorsCount: errors.length,
          errors: errors.slice(0, 10),
          stageCounts,
        }, 200, corsHeaders(env, req));
      }

      // POST /timed/admin/run-lifecycle?key=...
      // Manually trigger data lifecycle: aggregate timed_trail → trail_5m_facts, purge old data.
      if (routeKey === "POST /timed/admin/run-lifecycle") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          // Optional: ?cutoff_hours=N to override the 48h window (e.g., cutoff_hours=0 forces all)
          const cutoffHoursRaw = url.searchParams.get("cutoff_hours");
          const opts = {};
          if (cutoffHoursRaw != null && cutoffHoursRaw !== "") {
            const h = Number(cutoffHoursRaw);
            if (Number.isFinite(h) && h >= 0) {
              opts.cutoffMs = Date.now() - h * 60 * 60 * 1000;
            }
          }
          await runDataLifecycle(env, opts);
          return sendJSON({ ok: true, message: "data_lifecycle_complete" }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // MODEL ENDPOINTS (Phase 2 — Self-Learning Model)
      // ═══════════════════════════════════════════════════════════════════════

      // POST /timed/admin/model-retro?key=...
      // Manually trigger the weekly retrospective.
      if (routeKey === "POST /timed/admin/model-retro") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const result = await runWeeklyRetrospective(DB);
          return sendJSON({ ok: true, ...result }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/model-approve?change_id=...&action=approve|reject
      // Approve or reject a model_changelog proposal. Approved changes are applied.
      if (routeKey === "POST /timed/admin/model-approve") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));

          const changeId = url.searchParams.get("change_id");
          const action = url.searchParams.get("action") || "approve"; // approve | reject

          if (!changeId) return sendJSON({ ok: false, error: "change_id required" }, 400, corsHeaders(env, req));
          if (!["approve", "reject"].includes(action)) return sendJSON({ ok: false, error: "action must be approve or reject" }, 400, corsHeaders(env, req));

          const now = Date.now();
          const { results: rows } = await DB.prepare(
            `SELECT * FROM model_changelog WHERE change_id = ? AND status = 'proposed'`
          ).bind(changeId).all();

          if (!rows || rows.length === 0) {
            return sendJSON({ ok: false, error: "proposal not found or already processed" }, 404, corsHeaders(env, req));
          }

          const change = rows[0];

          if (action === "reject") {
            await DB.prepare(
              `UPDATE model_changelog SET status = 'rejected', approved_at = ?, approved_by = 'human' WHERE change_id = ?`
            ).bind(now, changeId).run();
            return sendJSON({ ok: true, action: "rejected", change_id: changeId }, 200, corsHeaders(env, req));
          }

          // Apply the approved change
          if (change.change_type === "degrade_pattern" && change.pattern_id) {
            await DB.prepare(
              `UPDATE pattern_library SET status = 'degraded', last_updated = ? WHERE pattern_id = ?`
            ).bind(now, change.pattern_id).run();
          } else if (change.change_type === "promote_pattern" && change.pattern_id) {
            await DB.prepare(
              `UPDATE pattern_library SET status = 'active', last_updated = ? WHERE pattern_id = ?`
            ).bind(now, change.pattern_id).run();
          } else if (change.change_type === "retire_pattern" && change.pattern_id) {
            await DB.prepare(
              `UPDATE pattern_library SET status = 'retired', last_updated = ? WHERE pattern_id = ?`
            ).bind(now, change.pattern_id).run();
          }
          // add_pattern and other types would require additional data — handled by seed script

          await DB.prepare(
            `UPDATE model_changelog SET status = 'approved', approved_at = ?, approved_by = 'human' WHERE change_id = ?`
          ).bind(now, changeId).run();

          return sendJSON({ ok: true, action: "approved", change_id: changeId, change_type: change.change_type, pattern_id: change.pattern_id }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/model-resolve?key=...
      // Resolve expired predictions against actual price data.
      if (routeKey === "POST /timed/admin/model-resolve") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const result = await resolveExpiredPredictions(DB, Date.now());
          return sendJSON({ ok: true, ...result }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/health
      // Model health summary: prediction counts, hit rates, pattern status.
      if (routeKey === "GET /timed/model/health") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const health = await getModelHealth(DB);
          return sendJSON({ ok: true, ...health }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/predictions?ticker=XYZ&resolved=0&limit=50
      // Query model predictions.
      if (routeKey === "GET /timed/model/predictions") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const ticker = url.searchParams.get("ticker");
          const resolved = url.searchParams.get("resolved");
          const limit = Math.min(Number(url.searchParams.get("limit")) || 50, 200);

          let sql = "SELECT * FROM model_predictions WHERE 1=1";
          const binds = [];
          if (ticker) { sql += " AND ticker = ?"; binds.push(normTicker(ticker)); }
          if (resolved != null) { sql += " AND resolved = ?"; binds.push(Number(resolved)); }
          sql += " ORDER BY ts DESC LIMIT ?";
          binds.push(limit);

          const stmt = DB.prepare(sql);
          const { results } = await (binds.length ? stmt.bind(...binds) : stmt).all();
          return sendJSON({ ok: true, predictions: results || [] }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/signals?level=ticker|sector|market
      // Multi-level predictions: ticker, sector, and market regime signals.
      if (routeKey === "GET /timed/model/signals") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const level = url.searchParams.get("level"); // ticker, sector, market, or null (all)
          const predictions = await computeMultiLevelPredictions(DB, SECTOR_MAP);

          if (level === "ticker") return sendJSON({ ok: true, ticker: predictions.ticker }, 200, corsHeaders(env, req));
          if (level === "sector") return sendJSON({ ok: true, sector: predictions.sector }, 200, corsHeaders(env, req));
          if (level === "market") return sendJSON({ ok: true, market: predictions.market }, 200, corsHeaders(env, req));
          return sendJSON({ ok: true, ...predictions }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/changelog?status=proposed&limit=50
      // View model change proposals and history.
      if (routeKey === "GET /timed/model/changelog") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const status = url.searchParams.get("status"); // proposed, approved, rejected, auto_applied
          const limit = Math.min(Number(url.searchParams.get("limit")) || 50, 200);

          let sql = "SELECT * FROM model_changelog";
          const binds = [];
          if (status) { sql += " WHERE status = ?"; binds.push(status); }
          sql += " ORDER BY proposed_at DESC LIMIT ?";
          binds.push(limit);

          const stmt = DB.prepare(sql);
          const { results } = await (binds.length ? stmt.bind(...binds) : stmt).all();
          return sendJSON({ ok: true, changes: results || [] }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/patterns?status=active
      // Query the pattern library.
      if (routeKey === "GET /timed/model/patterns") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const status = url.searchParams.get("status") || "active";

          const { results } = await DB.prepare(
            `SELECT * FROM pattern_library WHERE status = ? ORDER BY expected_value DESC`
          ).bind(status).all();
          return sendJSON({ ok: true, patterns: results || [] }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/direction-accuracy — query direction accuracy records
      if (routeKey === "GET /timed/model/direction-accuracy") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureLearningSchema(env);
          const ticker = url.searchParams.get("ticker");
          const status = url.searchParams.get("status");
          const source = url.searchParams.get("source");
          const limit = Math.min(Number(url.searchParams.get("limit")) || 200, 1000);
          let sql = `SELECT * FROM direction_accuracy WHERE 1=1`;
          const binds = [];
          if (ticker) { sql += ` AND ticker = ?`; binds.push(ticker.toUpperCase()); }
          if (status) { sql += ` AND status = ?`; binds.push(status.toUpperCase()); }
          if (source) { sql += ` AND direction_source = ?`; binds.push(source); }
          sql += ` ORDER BY ts DESC LIMIT ?`;
          binds.push(limit);
          const stmt = DB.prepare(sql);
          const { results } = await (binds.length ? stmt.bind(...binds) : stmt).all();

          const total = results?.length || 0;
          const correct = (results || []).filter(r => r.direction_correct === 1).length;
          const incorrect = (results || []).filter(r => r.direction_correct === 0).length;
          const open = (results || []).filter(r => r.status === "OPEN").length;
          return sendJSON({
            ok: true,
            summary: { total, correct, incorrect, open, accuracy: total > open ? (correct / (total - open) * 100).toFixed(1) + "%" : "N/A" },
            records: results || [],
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/model/retrospective — aggregate accuracy by source, path, time
      if (routeKey === "GET /timed/model/retrospective") {
        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureLearningSchema(env);

          const bySource = (await DB.prepare(
            `SELECT direction_source, COUNT(*) as total,
             SUM(CASE WHEN direction_correct=1 THEN 1 ELSE 0 END) as correct,
             SUM(CASE WHEN direction_correct=0 THEN 1 ELSE 0 END) as incorrect,
             ROUND(AVG(pnl_pct),2) as avg_pnl_pct
             FROM direction_accuracy WHERE status != 'OPEN'
             GROUP BY direction_source ORDER BY total DESC`
          ).all()).results || [];

          const byPath = (await DB.prepare(
            `SELECT entry_path, COUNT(*) as total,
             SUM(CASE WHEN direction_correct=1 THEN 1 ELSE 0 END) as correct,
             SUM(CASE WHEN direction_correct=0 THEN 1 ELSE 0 END) as incorrect,
             ROUND(AVG(pnl_pct),2) as avg_pnl_pct,
             SUM(CASE WHEN status='WIN' THEN 1 ELSE 0 END) as wins,
             SUM(CASE WHEN status='LOSS' THEN 1 ELSE 0 END) as losses
             FROM direction_accuracy WHERE status != 'OPEN'
             GROUP BY entry_path ORDER BY total DESC`
          ).all()).results || [];

          const overall = (await DB.prepare(
            `SELECT COUNT(*) as total,
             SUM(CASE WHEN direction_correct=1 THEN 1 ELSE 0 END) as correct,
             SUM(CASE WHEN status='WIN' THEN 1 ELSE 0 END) as wins,
             SUM(CASE WHEN status='LOSS' THEN 1 ELSE 0 END) as losses,
             ROUND(AVG(pnl_pct),2) as avg_pnl_pct,
             ROUND(AVG(CASE WHEN status='WIN' THEN pnl_pct END),2) as avg_win_pct,
             ROUND(AVG(CASE WHEN status='LOSS' THEN pnl_pct END),2) as avg_loss_pct
             FROM direction_accuracy WHERE status != 'OPEN'`
          ).all()).results?.[0] || {};

          const pathPerf = (await DB.prepare(
            `SELECT * FROM path_performance ORDER BY total_trades DESC`
          ).all()).results || [];

          return sendJSON({
            ok: true, overall, by_source: bySource, by_path: byPath, path_performance: pathPerf,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // SCREENER / DISCOVERY ENDPOINTS
      // ═══════════════════════════════════════════════════════════════════════

      // GET /timed/screener/candidates - Get latest screener discovery results
      // Enriches candidates with company name from timed:context:{sym} when missing
      if (routeKey === "GET /timed/screener/candidates") {
        try {
          const raw = await KV.get("timed:screener:candidates");
          const data = raw ? JSON.parse(raw) : { candidates: [], scan_ts: null, count: 0 };
          const candidates = data.candidates || [];
          if (candidates.length > 0) {
            // Enrich missing names from context cache (batch KV reads)
            const needName = candidates.filter(c => !c.name || c.name === c.ticker);
            const syms = [...new Set(needName.map(c => String(c.ticker || "").toUpperCase()).filter(Boolean))];
            const symToName = {};
            for (let b = 0; b < syms.length; b += 50) {
              const batch = syms.slice(b, b + 50);
              const kvResults = await Promise.all(
                batch.map(sym => kvGetJSON(KV, `timed:context:${sym}`))
              );
              for (let i = 0; i < batch.length; i++) {
                const ctx = kvResults[i];
                if (ctx && typeof ctx === "object" && ctx.name) symToName[batch[i]] = ctx.name;
              }
            }
            for (const c of candidates) {
              const sym = String(c.ticker || "").toUpperCase();
              if ((!c.name || c.name === c.ticker) && symToName[sym]) c.name = symToName[sym];
            }
          }
          return sendJSON({ ok: true, ...data, candidates }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/screener/candidates?key=... - Receive screener discovery results
      if (routeKey === "POST /timed/screener/candidates") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const { obj: body } = await readBodyAsJSON(req);
          if (!body || !Array.isArray(body.candidates)) {
            return sendJSON({ ok: false, error: "candidates array required" }, 400, corsHeaders(env, req));
          }

          // Merge with existing: keep last 7 days of candidates, dedup by ticker
          const existing = await KV.get("timed:screener:candidates");
          const prev = existing ? JSON.parse(existing) : { candidates: [] };
          const sevenDaysAgo = new Date(Date.now() - 7 * 86400 * 1000).toISOString();

          // Combine: new candidates first, then recent existing (dedup by ticker)
          const seen = new Set();
          const merged = [];
          for (const c of [...body.candidates, ...(prev.candidates || [])]) {
            if (seen.has(c.ticker)) continue;
            if (c.discovered_at && c.discovered_at < sevenDaysAgo) continue;
            seen.add(c.ticker);
            merged.push(c);
          }

          const payload = {
            candidates: merged.slice(0, 500), // cap at 500
            scan_ts: body.scan_ts || new Date().toISOString(),
            count: merged.length,
            last_updated: new Date().toISOString(),
          };

          await KV.put("timed:screener:candidates", JSON.stringify(payload), {
            expirationTtl: 7 * 86400, // expire after 7 days
          });

          return sendJSON({
            ok: true,
            stored: merged.length,
            new: body.candidates.length,
            message: `Stored ${merged.length} candidates (${body.candidates.length} new)`,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // METADATA ENRICHMENT ENDPOINTS
      // ═══════════════════════════════════════════════════════════════════════

      // POST /timed/enrich-metadata — Receive bulk ticker metadata (name, sector, industry, market_cap)
      // Merges into existing context for each ticker in KV.
      if (routeKey === "POST /timed/enrich-metadata") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        try {
          const { obj: body } = await readBodyAsJSON(req);
          if (!body || !Array.isArray(body.tickers)) {
            return sendJSON({ ok: false, error: "tickers array required" }, 400, corsHeaders(env, req));
          }
          let updated = 0, skipped = 0;
          for (const item of body.tickers) {
            const sym = String(item.ticker || "").toUpperCase();
            if (!sym) { skipped++; continue; }
            try {
              // Build enrichment context from incoming data
              const enrichment = {};
              if (item.name) enrichment.name = String(item.name);
              if (item.sector) enrichment.sector = String(item.sector);
              if (item.industry) enrichment.industry = String(item.industry);
              if (item.description) enrichment.description = String(item.description);
              if (item.market_cap != null && Number.isFinite(Number(item.market_cap)) && Number(item.market_cap) > 0) {
                enrichment.market_cap = Number(item.market_cap);
              }
              if (item.country) enrichment.country = String(item.country);
              if (Object.keys(enrichment).length === 0) { skipped++; continue; }
              enrichment._enriched_at = Date.now();
              enrichment._source = "tvscreener";
              // Merge with existing context (preserve richer fields)
              const existing = await kvGetJSON(KV, `timed:context:${sym}`);
              const merged = { ...(existing || {}), ...enrichment };
              await kvPutJSON(KV, `timed:context:${sym}`, merged, 90 * 24 * 60 * 60); // 90-day TTL
              // Also update SECTOR_MAP in memory if sector provided and ticker is in universe with "Unknown" sector
              if (enrichment.sector && SECTOR_MAP[sym] && SECTOR_MAP[sym] === "Unknown") {
                SECTOR_MAP[sym] = enrichment.sector;
                await KV.put(`timed:sector_map:${sym}`, enrichment.sector);
              }
              // Patch D1 ticker_latest payload_json so context appears in /timed/all without extra KV reads
              try {
                if (env?.DB) {
                  const row = await env.DB.prepare(`SELECT payload_json FROM ticker_latest WHERE ticker = ?`).bind(sym).first();
                  if (row?.payload_json) {
                    const payload = JSON.parse(row.payload_json);
                    payload.context = { ...(payload.context || {}), ...enrichment };
                    await env.DB.prepare(`UPDATE ticker_latest SET payload_json = ? WHERE ticker = ?`).bind(JSON.stringify(payload), sym).run();
                  }
                }
              } catch (patchErr) {
                console.warn(`[ENRICH] D1 patch failed for ${sym}:`, String(patchErr));
              }
              updated++;
            } catch (e) {
              console.error(`[ENRICH] Failed for ${sym}:`, String(e));
              skipped++;
            }
          }
          return sendJSON({ ok: true, updated, skipped, total: body.tickers.length }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/enrich-metadata — Return current enrichment status for all tickers
      if (routeKey === "GET /timed/enrich-metadata") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        try {
          const allTickers = Object.keys(SECTOR_MAP);
          const missing = [];
          const enriched = [];
          for (const sym of allTickers.slice(0, 300)) {
            const ctx = await kvGetJSON(KV, `timed:context:${sym}`);
            if (ctx && ctx.name && (ctx.sector || ctx.industry)) {
              enriched.push(sym);
            } else {
              missing.push(sym);
            }
          }
          return sendJSON({
            ok: true,
            total: allTickers.length,
            enriched: enriched.length,
            missing: missing.length,
            missingTickers: missing,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/enrich-alpaca — Bulk-enrich all tickers missing context via Alpaca /v2/assets
      if (routeKey === "POST /timed/enrich-alpaca") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        try {
          if (!env.ALPACA_API_KEY_ID || !env.ALPACA_API_SECRET_KEY) {
            return sendJSON({ ok: false, error: "Alpaca not configured" }, 400, corsHeaders(env, req));
          }
          const allTickers = Object.keys(SECTOR_MAP);
          // Find tickers missing context in KV
          const missing = [];
          for (const sym of allTickers.slice(0, 300)) {
            const ctx = await kvGetJSON(KV, `timed:context:${sym}`);
            if (!ctx || !ctx.name) missing.push(sym);
          }
          if (missing.length === 0) {
            return sendJSON({ ok: true, message: "All tickers already have context", enriched: 0 }, 200, corsHeaders(env, req));
          }
          // Enrich in batches of 20 to avoid overwhelming Alpaca
          let totalEnriched = 0, totalSkipped = 0;
          for (let i = 0; i < missing.length; i += 20) {
            const batch = missing.slice(i, i + 20);
            const result = await alpacaEnrichMissingContext(env, KV, batch);
            totalEnriched += result.enriched;
            totalSkipped += result.skipped;
          }
          return sendJSON({
            ok: true,
            totalMissing: missing.length,
            enriched: totalEnriched,
            skipped: totalSkipped,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // USER / AUTH ENDPOINTS
      // ═══════════════════════════════════════════════════════════════════════

      // GET /timed/auth/login - CF Access login redirect
      // This endpoint exists on a Worker route, which CF Access protects.
      // When the user has no valid CF Access JWT, CF Access will intercept and
      // show the identity provider login page. After authentication, CF Access
      // redirects back here, and the Worker 302-redirects to the dashboard.
      // This solves the problem where Cloudflare Pages pretty-URL redirects
      // prevent the static /index-react.html path from triggering CF Access.
      if (routeKey === "GET /timed/auth/login") {
        const redirect = url.searchParams.get("redirect") || "/index-react.html";
        // Ensure redirect is same-origin to prevent open redirect
        const safeRedirect = redirect.startsWith("/") ? redirect : "/index-react.html";
        return Response.redirect(new URL(safeRedirect, url.origin).href, 302);
      }

      // GET /timed/me - Return current authenticated user info
      // Auto-promotes ADMIN_EMAIL to admin role/tier on every check.
      // Supports ?return=<url> for cross-origin login flow (Pages → Worker → CF Access → back to Pages).
      if (routeKey === "GET /timed/me") {
        const returnUrl = url.searchParams.get("return");
        try {
          const user = await authenticateUser(req, env);
          if (!user) {
            // If return param and not authenticated, CF Access didn't gate this path —
            // fall through with normal JSON so the client auth-gate shows login.
            return sendJSON({ ok: true, authenticated: false, user: null }, 200, corsHeaders(env, req));
          }

          // Auto-promote admin email if not already admin
          const adminEmail = (env.ADMIN_EMAIL || "").toLowerCase().trim();
          if (adminEmail && user.email?.toLowerCase() === adminEmail && (user.role !== "admin" || user.tier !== "admin")) {
            user.role = "admin";
            user.tier = "admin";
            try {
              const DB = env?.DB;
              if (DB) {
                await DB.prepare(
                  `UPDATE users SET role = 'admin', tier = 'admin', updated_at = ? WHERE email = ?`
                ).bind(Date.now(), user.email).run();
                console.log(`[AUTH] Auto-promoted ${user.email} to admin`);
              }
            } catch (e) {
              console.warn("[AUTH] Admin auto-promote failed:", String(e?.message || e));
            }
          }

          // Demote stale admins: if DB says admin but email no longer matches ADMIN_EMAIL
          if (adminEmail && user.role === "admin" && user.email?.toLowerCase() !== adminEmail) {
            const preservedTier = user.tier === "admin" ? "free" : (user.tier || "free");
            user.role = "member";
            user.tier = preservedTier;
            try {
              const DB = env?.DB;
              if (DB) {
                await DB.prepare(
                  `UPDATE users SET role = 'member', tier = ? WHERE email = ? AND role = 'admin'`
                ).bind(preservedTier, user.email).run();
                console.log(`[AUTH] Demoted stale admin ${user.email} → member (tier=${preservedTier})`);
              }
            } catch (e) {
              console.warn("[AUTH] Admin demotion failed:", String(e?.message || e));
            }
          }

          // ── Cross-origin login redirect ──────────────────────────────────
          // If ?return=<url> is present, the user arrived here from a Pages-hosted
          // dashboard that redirected to the worker domain so CF Access could set
          // its cookie. Now that login succeeded, redirect back to the Pages URL.
          if (returnUrl) {
            // Allow-list: only redirect to our own Pages / localhost origins
            const SAFE_RETURN_PREFIXES = [
              "https://timedtrading.pages.dev",
              "http://localhost",
              "http://127.0.0.1",
            ];
            const isSafe = SAFE_RETURN_PREFIXES.some((p) => returnUrl.startsWith(p));
            if (isSafe) {
              return new Response(null, {
                status: 302,
                headers: { Location: returnUrl },
              });
            }
          }

          // Load saved tickers for this user
          let savedTickers = [];
          try {
            const KV = env?.KV_TIMED;
            if (KV && user.email) {
              const raw = await KV.get(`timed:saved:${user.email.toLowerCase()}`);
              if (raw) savedTickers = JSON.parse(raw);
            }
          } catch (_) { /* ignore */ }

          return sendJSON({
            ok: true,
            authenticated: true,
            user: {
              email: user.email,
              display_name: user.display_name,
              role: user.role,
              tier: user.tier,
              subscription_status: user.subscription_status || null,
              trial_end: user.trial_end || null,
              last_login_at: user.last_login_at,
              terms_accepted_at: user.terms_accepted_at || null,
            },
            saved_tickers: savedTickers,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // TERMS ACCEPTANCE
      // ═══════════════════════════════════════════════════════════════════════

      // POST /timed/accept-terms - Record user's acceptance of Terms of Use
      if (routeKey === "POST /timed/accept-terms") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));

          const now = Date.now();
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));

          // Update the quick-lookup column on the users table
          await DB.prepare(
            `UPDATE users SET terms_accepted_at = ?, updated_at = ? WHERE email = ?`
          ).bind(now, now, user.email).run();

          // Insert audit trail row for legal proof
          const ipAddress = req.headers.get("CF-Connecting-IP") || req.headers.get("X-Forwarded-For") || "unknown";
          const userAgent = req.headers.get("User-Agent") || "unknown";
          await DB.prepare(
            `INSERT INTO terms_acceptance (email, terms_version, accepted_at, ip_address, user_agent) VALUES (?, ?, ?, ?, ?)`
          ).bind(user.email, "1.0", now, ipAddress, userAgent).run();

          console.log(`[TERMS] ${user.email} accepted Terms v1.0 at ${new Date(now).toISOString()}`);

          return sendJSON({ ok: true, terms_accepted_at: now }, 200, corsHeaders(env, req));
        } catch (e) {
          console.error("[TERMS] Error recording acceptance:", e);
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // USER-ADDED TICKERS — Phase 5
      // ═══════════════════════════════════════════════════════════════════════

      if (routeKey === "GET /timed/user-tickers/system-stats") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;
        try {
          const uniqueNew = await d1CountUniqueNewUserTickers(env);
          const allActive = await d1GetActiveUserTickers(env);
          return sendJSON({
            ok: true,
            unique_new_tickers: uniqueNew,
            total_active_links: allActive.length,
            system_cap: USER_TICKER_SYSTEM_CAP,
            capacity_remaining: Math.max(0, USER_TICKER_SYSTEM_CAP - uniqueNew),
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "GET /timed/user-tickers") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const slots = await d1GetUserSlots(env, user.email);
          const limit = getUserSlotLimit(user);
          const activeCount = slots.filter(s => s.active || s.held).length;
          return sendJSON({
            ok: true,
            tickers: slots.map(s => ({
              ticker: s.ticker,
              added_at: s.added_at,
              deleted_at: s.deleted_at,
              active: s.active,
              held: s.held,
              held_until: s.held ? s.deleted_at + USER_TICKER_HOLD_DAYS * 86400000 : null,
            })),
            slots_used: activeCount,
            slots_max: limit,
            tier: user.tier || "free",
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "POST /timed/user-tickers") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));

          const { obj: body } = await readBodyAsJSON(req);
          const rawTicker = String(body?.ticker || "").toUpperCase().trim();
          if (!rawTicker || !/^[A-Z]{1,5}(-[A-Z]{1,2})?$/.test(rawTicker)) {
            return sendJSON({ ok: false, error: "invalid_ticker", detail: "Must be 1-5 uppercase letters (e.g. PLTR, BRK-B)" }, 400, corsHeaders(env, req));
          }

          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureUserTickersSchema(env);

          const slots = await d1GetUserSlots(env, user.email);
          const limit = getUserSlotLimit(user);
          const activeOrHeld = slots.filter(s => s.active || s.held);

          // Check if already active
          const existing = slots.find(s => s.ticker === rawTicker && s.active);
          if (existing) {
            return sendJSON({ ok: false, error: "already_added", ticker: rawTicker, detail: `${rawTicker} is already in your custom tickers.` }, 409, corsHeaders(env, req));
          }

          // Check if ticker is already in the seeded universe
          if (SECTOR_MAP[rawTicker]) {
            return sendJSON({ ok: false, error: "already_in_universe", ticker: rawTicker, detail: `${rawTicker} is already tracked in the Timed Trading universe. Search for it by name.` }, 409, corsHeaders(env, req));
          }

          // Validate ticker exists in Alpaca feed and capture snapshot for immediate seeding
          let alpacaSnap = null;
          try {
            const alpacaKey = env.ALPACA_KEY_ID || env.ALPACA_API_KEY;
            const alpacaSecret = env.ALPACA_SECRET_KEY || env.ALPACA_API_SECRET;
            if (alpacaKey && alpacaSecret) {
              const snapRes = await fetch(`https://data.alpaca.markets/v2/stocks/${rawTicker}/snapshot?feed=sip`, {
                headers: { "APCA-API-KEY-ID": alpacaKey, "APCA-API-SECRET-KEY": alpacaSecret },
              });
              if (!snapRes.ok) {
                return sendJSON({ ok: false, error: "ticker_not_found", ticker: rawTicker, detail: `${rawTicker} was not found in the market data feed. Please check the symbol.` }, 400, corsHeaders(env, req));
              }
              alpacaSnap = await snapRes.json();
            }
          } catch (e) {
            console.warn(`[USER_TICKERS] Alpaca validation failed for ${rawTicker}:`, String(e?.message || e).slice(0, 100));
          }

          // Check slot limit
          if (activeOrHeld.length >= limit) {
            return sendJSON({
              ok: false, error: "slot_limit_reached",
              slots_used: activeOrHeld.length, slots_max: limit,
              tier: user.tier || "free",
              detail: `You have ${activeOrHeld.length}/${limit} slots used. Upgrade your plan for more.`,
            }, 403, corsHeaders(env, req));
          }

          // Check daily swap budget (only if this is a "re-add after delete" scenario)
          const swapsToday = await d1CountUserSwapsToday(env, user.email);
          const wasDeleted = slots.find(s => s.ticker === rawTicker && s.deleted_at != null);
          if (!wasDeleted && swapsToday >= USER_TICKER_DAILY_SWAPS) {
            // Only enforce swap limit for genuinely new tickers after a delete happened today
            const deletedToday = slots.some(s => s.deleted_at != null && s.deleted_at >= new Date().setUTCHours(0, 0, 0, 0));
            if (deletedToday) {
              return sendJSON({
                ok: false, error: "daily_swap_limit",
                detail: `Max ${USER_TICKER_DAILY_SWAPS} swap(s) per day. Try again tomorrow.`,
              }, 429, corsHeaders(env, req));
            }
          }

          // Check system-wide cap for genuinely new tickers
          const isInCore = !!SECTOR_MAP[rawTicker];
          const isAlreadyInSystem = isInCore || (await d1GetActiveUserTickers(env)).includes(rawTicker);
          if (!isAlreadyInSystem) {
            const uniqueCount = await d1CountUniqueNewUserTickers(env);
            if (uniqueCount >= USER_TICKER_SYSTEM_CAP) {
              return sendJSON({
                ok: false, error: "system_cap_reached",
                detail: "The system is at capacity for new unique tickers. Try adding a ticker that's already being tracked.",
              }, 503, corsHeaders(env, req));
            }
          }

          // Upsert: re-activate if soft-deleted, or insert new
          const now = Date.now();
          if (wasDeleted) {
            await db.prepare(
              `UPDATE user_tickers SET deleted_at = NULL, added_at = ? WHERE user_email = ? AND ticker = ?`
            ).bind(now, user.email, rawTicker).run();
          } else {
            await db.prepare(
              `INSERT INTO user_tickers (user_email, ticker, added_at) VALUES (?, ?, ?)
               ON CONFLICT(user_email, ticker) DO UPDATE SET deleted_at = NULL, added_at = excluded.added_at`
            ).bind(user.email, rawTicker, now).run();
          }

          // Invalidate the scoring cache
          _userTickersCache = null;

          // Seed timed:latest:{ticker} immediately from Alpaca snapshot so ticker appears in UI now
          let seeded = false;
          if (alpacaSnap && !isInCore) {
            try {
              const lt = alpacaSnap.latestTrade;
              const pdb = alpacaSnap.prevDailyBar;
              const db2 = alpacaSnap.dailyBar;
              const price = Number(lt?.p || db2?.c || 0);
              const prevClose = Number(pdb?.c || 0);
              if (price > 0) {
                const seedPayload = {
                  ticker: rawTicker,
                  price,
                  close: price,
                  open: Number(db2?.o || price),
                  high: Number(db2?.h || price),
                  low: Number(db2?.l || price),
                  prev_close: prevClose || undefined,
                  day_change: prevClose > 0 ? price - prevClose : undefined,
                  day_change_pct: prevClose > 0 ? ((price - prevClose) / prevClose) * 100 : undefined,
                  ts: Date.now(),
                  ingest_ts: Date.now(),
                  ingest_kind: "user_ticker_seed",
                  kanban_stage: null,
                  state: "NEUTRAL",
                  rank: 0,
                  htf_score: 0,
                  ltf_score: 0,
                };
                await kvPutJSON(KV, `timed:latest:${rawTicker}`, seedPayload);
                seeded = true;
                console.log(`[USER_TICKERS] Seeded timed:latest:${rawTicker} from Alpaca snapshot (price=$${price})`);
              }
            } catch (e) {
              console.warn(`[USER_TICKERS] Seed failed for ${rawTicker}:`, String(e?.message || e).slice(0, 100));
            }
          }

          // Deep backfill + immediate score — run via waitUntil so the response returns fast
          let backfillTriggered = false;
          if (!isInCore && !(await d1TickerHasCandles(env, rawTicker))) {
            backfillTriggered = true;
            ctx.waitUntil((async () => {
              try {
                // null sinceDays → deep-history lookup: W gets ~2100 days, D gets 450, etc.
                // This ensures 50+ candles per TF so scoring succeeds
                await alpacaBackfill(env, [rawTicker], d1UpsertCandle, "all", null);
                console.log(`[USER_TICKERS] Deep backfilled candles for ${rawTicker}`);

                // Immediately score so the ticker gets SL/TP/state/stage
                try {
                  const existing = await kvGetJSON(KV, `timed:latest:${rawTicker}`);
                  const result = await computeServerSideScores(rawTicker, d1GetCandles, env, existing);
                  if (result) {
                    const now = Date.now();
                    result.data_source = "alpaca";
                    result.data_source_ts = now;
                    result.ingest_ts = now;
                    result.ingest_time = new Date(now).toISOString();
                    result.trigger_ts = now;
                    result.rank = computeRank(result);
                    result.score = result.rank;
                    if (existing?.price) result.price = existing.price;
                    if (existing?.prev_close) result.prev_close = existing.prev_close;
                    if (existing?.day_change) result.day_change = existing.day_change;
                    if (existing?.day_change_pct) result.day_change_pct = existing.day_change_pct;
                    await kvPutJSON(KV, `timed:latest:${rawTicker}`, result);
                    console.log(`[USER_TICKERS] Scored ${rawTicker}: score=${result.score}, stage=${result.kanban_stage}, state=${result.state}`);
                  } else {
                    console.warn(`[USER_TICKERS] Scoring returned null for ${rawTicker} — insufficient candle data even after backfill`);
                  }
                } catch (scoreErr) {
                  console.warn(`[USER_TICKERS] Post-backfill scoring failed for ${rawTicker}:`, String(scoreErr?.message || scoreErr).slice(0, 200));
                }
              } catch (e) {
                console.warn(`[USER_TICKERS] Deep backfill failed for ${rawTicker}:`, String(e?.message || e).slice(0, 200));
              }
            })());
          }

          console.log(`[USER_TICKERS] ${user.email} added ${rawTicker} (core: ${isInCore}, backfill: ${backfillTriggered}, seeded: ${seeded})`);
          return sendJSON({
            ok: true,
            ticker: rawTicker,
            is_core_ticker: isInCore,
            backfill_triggered: backfillTriggered,
            seeded,
            slots_used: activeOrHeld.length + 1,
            slots_max: limit,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          console.error("[USER_TICKERS] POST error:", e);
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "DELETE /timed/user-tickers/:ticker") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));

          const tickerFromPath = url.pathname.split("/timed/user-tickers/")[1]?.toUpperCase();
          if (!tickerFromPath) return sendJSON({ ok: false, error: "missing_ticker" }, 400, corsHeaders(env, req));

          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureUserTickersSchema(env);

          const existing = await db.prepare(
            `SELECT * FROM user_tickers WHERE user_email = ? AND ticker = ? AND deleted_at IS NULL`
          ).bind(user.email, tickerFromPath).first();

          if (!existing) {
            return sendJSON({ ok: false, error: "not_found", ticker: tickerFromPath }, 404, corsHeaders(env, req));
          }

          const now = Date.now();
          await db.prepare(
            `UPDATE user_tickers SET deleted_at = ? WHERE user_email = ? AND ticker = ?`
          ).bind(now, user.email, tickerFromPath).run();

          _userTickersCache = null;

          const heldUntil = now + USER_TICKER_HOLD_DAYS * 86400000;
          console.log(`[USER_TICKERS] ${user.email} removed ${tickerFromPath} (slot held until ${new Date(heldUntil).toISOString()})`);

          return sendJSON({
            ok: true,
            ticker: tickerFromPath,
            held_until: heldUntil,
            detail: `Slot held for ${USER_TICKER_HOLD_DAYS} days. It will free on ${new Date(heldUntil).toLocaleDateString()}.`,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // SAVED TICKERS (per-user favorites)
      // ═══════════════════════════════════════════════════════════════════════

      // GET /timed/saved - Return current user's saved tickers
      if (routeKey === "GET /timed/saved") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const KV = env?.KV_TIMED;
          const raw = KV ? await KV.get(`timed:saved:${user.email.toLowerCase()}`) : null;
          const saved = raw ? JSON.parse(raw) : [];
          return sendJSON({ ok: true, saved_tickers: saved }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/saved/toggle - Toggle a ticker in/out of saved list
      if (routeKey === "POST /timed/saved/toggle") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const body = await req.json().catch(() => ({}));
          const ticker = String(body.ticker || "").toUpperCase().trim();
          if (!ticker) return sendJSON({ ok: false, error: "missing_ticker" }, 400, corsHeaders(env, req));

          const KV = env?.KV_TIMED;
          if (!KV) return sendJSON({ ok: false, error: "no_kv" }, 500, corsHeaders(env, req));

          const key = `timed:saved:${user.email.toLowerCase()}`;
          const raw = await KV.get(key);
          const saved = raw ? JSON.parse(raw) : [];
          const idx = saved.indexOf(ticker);
          let action;
          if (idx >= 0) {
            saved.splice(idx, 1);
            action = "removed";
          } else {
            saved.push(ticker);
            action = "added";
          }
          await KV.put(key, JSON.stringify(saved));
          return sendJSON({ ok: true, action, ticker, saved_tickers: saved }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/admin/users - List all users (admin only, supports JWT + API key)
      if (routeKey === "GET /timed/admin/users") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;

        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureStripeSchema(env);
          await d1EnsureAdminSchema(env);
          const { results } = await DB.prepare(
            `SELECT email, display_name, role, tier, subscription_status, stripe_customer_id,
                    created_at, last_login_at, expires_at, terms_accepted_at,
                    login_count, login_days, trial_end
             FROM users ORDER BY last_login_at DESC`
          ).all();
          return sendJSON({ ok: true, users: results || [] }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/users/:email/tier - Update user tier (admin only, supports JWT + API key)
      if (routeKey === "POST /timed/admin/users/:email/tier") {
        const authFail = await requireKeyOrAdmin(req, env);
        if (authFail) return authFail;

        try {
          const DB = env?.DB;
          if (!DB) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureStripeSchema(env);

          // Extract email from path: /timed/admin/users/{email}/tier
          const pathParts = url.pathname.split("/");
          const emailIdx = pathParts.indexOf("users") + 1;
          const email = decodeURIComponent(pathParts[emailIdx]);
          const tier = url.searchParams.get("tier");
          const expiresAt = url.searchParams.get("expires_at") || null;

          if (!tier || !["free", "pro", "vip", "admin"].includes(tier)) {
            return sendJSON({ ok: false, error: "tier must be free, pro, vip, or admin" }, 400, corsHeaders(env, req));
          }

          // Set subscription_status alongside tier so admin-granted Pro/VIP is distinguishable
          const subStatus = (tier === "pro" || tier === "vip" || tier === "admin") ? "manual" : "none";

          await DB.prepare(
            `UPDATE users SET tier = ?, subscription_status = ?, expires_at = ?, updated_at = ? WHERE email = ?`
          ).bind(tier, subStatus, expiresAt, Date.now(), email).run();

          return sendJSON({ ok: true, email, tier, subscription_status: subStatus, expires_at: expiresAt }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════
      // Notification Center Endpoints
      // ═══════════════════════════════════════════════════════════════

      // POST /timed/push/subscribe — Store push subscription for authenticated user
      if (routeKey === "POST /timed/push/subscribe") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const { obj: body } = await readBodyAsJSON(req);
          const { endpoint, keys } = body || {};
          if (!endpoint || !keys?.p256dh || !keys?.auth) {
            return sendJSON({ ok: false, error: "missing_subscription_fields" }, 400, corsHeaders(env, req));
          }
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureNotificationSchema(env);
          await db.prepare(`
            INSERT INTO push_subscriptions (email, endpoint, p256dh, auth, created_at)
            VALUES (?1, ?2, ?3, ?4, ?5)
            ON CONFLICT(email, endpoint) DO UPDATE SET p256dh = excluded.p256dh, auth = excluded.auth
          `).bind(user.email.toLowerCase(), endpoint, keys.p256dh, keys.auth, Date.now()).run();
          return sendJSON({ ok: true }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/notifications — Returns user's notifications (unread first, paginated)
      if (routeKey === "GET /timed/notifications") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureNotificationSchema(env);
          const limit = Math.min(Number(url.searchParams.get("limit")) || 50, 100);
          const offset = Number(url.searchParams.get("offset")) || 0;
          const email = user.email.toLowerCase();
          // Get user-specific + broadcast notifications, unread first
          const { results } = await db.prepare(`
            SELECT id, email, type, title, body, link, read_at, created_at
            FROM user_notifications
            WHERE email = ?1 OR email IS NULL
            ORDER BY read_at IS NOT NULL ASC, created_at DESC
            LIMIT ?2 OFFSET ?3
          `).bind(email, limit, offset).all();
          // Unread count (total)
          const countRow = await db.prepare(`
            SELECT COUNT(*) as cnt FROM user_notifications
            WHERE (email = ?1 OR email IS NULL) AND read_at IS NULL
          `).bind(email).first();
          // Unread trade-alert count only (for bell badge — trade_entry, trade_exit, trade_trim)
          const tradeAlertRow = await db.prepare(`
            SELECT COUNT(*) as cnt FROM user_notifications
            WHERE (email = ?1 OR email IS NULL) AND read_at IS NULL
            AND type IN ('trade_entry','trade_exit','trade_trim')
          `).bind(email).first();
          return sendJSON({
            ok: true,
            notifications: results || [],
            unread_count: countRow?.cnt || 0,
            unread_trade_alert_count: tradeAlertRow?.cnt ?? 0,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/notifications/read — Mark one or all as read
      if (routeKey === "POST /timed/notifications/read") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureNotificationSchema(env);
          const body = await readBodyAsJSON(req);
          const now = Date.now();
          const email = user.email.toLowerCase();
          if (body?.id) {
            // Mark single notification as read
            await db.prepare(`
              UPDATE user_notifications SET read_at = ?1 WHERE id = ?2 AND (email = ?3 OR email IS NULL)
            `).bind(now, body.id, email).run();
          } else {
            // Mark all as read
            await db.prepare(`
              UPDATE user_notifications SET read_at = ?1 WHERE (email = ?2 OR email IS NULL) AND read_at IS NULL
            `).bind(now, email).run();
          }
          return sendJSON({ ok: true }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/notifications/clear — Clear all notifications
      if (routeKey === "POST /timed/notifications/clear") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureNotificationSchema(env);
          const email = user.email.toLowerCase();
          await db.prepare(`
            DELETE FROM user_notifications WHERE email = ?1
          `).bind(email).run();
          return sendJSON({ ok: true }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════
      // Stripe / Subscription Endpoints
      // ═══════════════════════════════════════════════════════════════

      // POST /timed/stripe/create-checkout — Creates a Stripe Checkout Session (authenticated)
      // Prevents duplicate free trials: checks Stripe for existing customers with
      // prior subscriptions/trials before granting trial_period_days.
      if (routeKey === "POST /timed/stripe/create-checkout") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));

          // VIP and admin users should never see the paywall; block checkout to prevent confusion
          if (user.tier === "vip" || user.tier === "admin" || user.tier === "pro") {
            return sendJSON({ ok: false, error: "already_subscribed", details: "You already have an active subscription." }, 400, corsHeaders(env, req));
          }

          const stripeKey = env.STRIPE_SECRET_KEY;
          const priceId = env.STRIPE_PRICE_ID;
          if (!stripeKey || !priceId) {
            return sendJSON({ ok: false, error: "stripe_not_configured" }, 503, corsHeaders(env, req));
          }
          await d1EnsureStripeSchema(env);
          const body = await readBodyAsJSON(req);
          const parsed = body?.obj || {};
          const successUrl = parsed.success_url || `${url.origin}/index-react.html?stripe=success`;
          const cancelUrl = parsed.cancel_url || `${url.origin}/index-react.html?stripe=cancel`;

          // Check if user has an existing Stripe customer with prior subscriptions
          // to prevent multiple free trials (e.g. user cancels, re-signs up for another trial).
          let trialDays = 30; // default: first-month-free trial
          try {
            const custSearch = await fetch(
              `https://api.stripe.com/v1/customers?email=${encodeURIComponent(user.email)}&limit=1`,
              { headers: { "Authorization": `Bearer ${stripeKey}` } },
            );
            const custData = await custSearch.json();
            if (custData.data && custData.data.length > 0) {
              const customerId = custData.data[0].id;
              // Check for any past subscriptions (active, canceled, trialing, past_due, etc.)
              const subSearch = await fetch(
                `https://api.stripe.com/v1/subscriptions?customer=${customerId}&limit=1&status=all`,
                { headers: { "Authorization": `Bearer ${stripeKey}` } },
              );
              const subData = await subSearch.json();
              if (subData.data && subData.data.length > 0) {
                // User has had a subscription before — no free trial
                trialDays = 0;
                console.log(`[STRIPE] Returning customer ${user.email} — no trial (prior subscription found)`);
              }
            }
          } catch (e) {
            console.warn("[STRIPE] Customer lookup failed, defaulting to trial:", String(e?.message || e).slice(0, 100));
          }

          // Create Stripe Checkout Session
          const params = new URLSearchParams({
            "mode": "subscription",
            "customer_email": user.email,
            "line_items[0][price]": priceId,
            "line_items[0][quantity]": "1",
            "success_url": successUrl,
            "cancel_url": cancelUrl,
            "metadata[user_email]": user.email,
          });
          // Only include trial if user hasn't had one before
          if (trialDays > 0) {
            params.set("subscription_data[trial_period_days]", String(trialDays));
          }
          const stripeResp = await fetch("https://api.stripe.com/v1/checkout/sessions", {
            method: "POST",
            headers: {
              "Authorization": `Bearer ${stripeKey}`,
              "Content-Type": "application/x-www-form-urlencoded",
            },
            body: params.toString(),
          });
          const session = await stripeResp.json();
          if (!stripeResp.ok) {
            console.error("[STRIPE] Checkout creation failed:", JSON.stringify(session).slice(0, 300));
            return sendJSON({ ok: false, error: "stripe_checkout_failed", details: session.error?.message }, 500, corsHeaders(env, req));
          }
          return sendJSON({ ok: true, url: session.url }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/stripe/webhook — Handles Stripe webhook events (unauthenticated, signature-verified)
      if (routeKey === "POST /timed/stripe/webhook") {
        try {
          const stripeKey = env.STRIPE_SECRET_KEY;
          const webhookSecret = env.STRIPE_WEBHOOK_SECRET;
          if (!stripeKey || !webhookSecret) {
            return sendJSON({ ok: false, error: "stripe_not_configured" }, 503);
          }
          const rawBody = await req.text();
          const sigHeader = req.headers.get("stripe-signature") || "";
          // Verify webhook signature
          const parts = {};
          for (const item of sigHeader.split(",")) {
            const [k, v] = item.split("=");
            if (k && v) parts[k.trim()] = v.trim();
          }
          const timestamp = parts.t;
          const signature = parts.v1;
          if (!timestamp || !signature) {
            return sendJSON({ ok: false, error: "invalid_signature" }, 400);
          }
          // Compute expected signature
          const signedPayload = `${timestamp}.${rawBody}`;
          const key = await crypto.subtle.importKey(
            "raw",
            new TextEncoder().encode(webhookSecret),
            { name: "HMAC", hash: "SHA-256" },
            false,
            ["sign"],
          );
          const sig = await crypto.subtle.sign("HMAC", key, new TextEncoder().encode(signedPayload));
          const expectedSig = Array.from(new Uint8Array(sig)).map(b => b.toString(16).padStart(2, "0")).join("");
          if (expectedSig !== signature) {
            console.warn("[STRIPE WEBHOOK] Signature mismatch");
            return sendJSON({ ok: false, error: "signature_mismatch" }, 400);
          }
          const event = JSON.parse(rawBody);
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500);
          await d1EnsureStripeSchema(env);
          const eventType = event.type;
          console.log(`[STRIPE WEBHOOK] Event: ${eventType}`);
          if (eventType === "checkout.session.completed") {
            const session = event.data.object;
            const email = (session.customer_email || session.metadata?.user_email || "").toLowerCase();
            if (email) {
              // Fetch the real subscription status from Stripe (may be "trialing" if trial_period_days was set)
              let subStatus = "active";
              let trialEnd = null;
              if (session.subscription && env.STRIPE_SECRET_KEY) {
                try {
                  const subResp = await fetch(`https://api.stripe.com/v1/subscriptions/${session.subscription}`, {
                    headers: { "Authorization": `Bearer ${env.STRIPE_SECRET_KEY}` },
                  });
                  if (subResp.ok) {
                    const subObj = await subResp.json();
                    subStatus = subObj.status || "active"; // "trialing", "active", etc.
                    trialEnd = subObj.trial_end ? subObj.trial_end * 1000 : null; // Stripe sends epoch seconds, store as ms
                    console.log(`[STRIPE] Subscription ${session.subscription}: status=${subStatus}, trial_end=${trialEnd}`);
                  }
                } catch (e) {
                  console.warn(`[STRIPE] Failed to fetch subscription details:`, String(e));
                }
              }
              await db.prepare(`
                UPDATE users SET tier = 'pro', stripe_customer_id = ?1, stripe_subscription_id = ?2,
                subscription_status = ?3, trial_end = ?4, expires_at = NULL, updated_at = ?5 WHERE email = ?6
              `).bind(session.customer || null, session.subscription || null, subStatus, trialEnd, Date.now(), email).run();
              console.log(`[STRIPE] checkout.session.completed for ${email}, status=${subStatus}`);
              await d1InsertNotification(env, {
                email, type: "system",
                title: "Subscription Activated",
                body: subStatus === "trialing"
                  ? "Welcome to Timed Trading Pro! Your 30-day free trial has started."
                  : "Welcome to Timed Trading Pro! Your subscription is now active.",
                link: "/index-react.html",
              });
            }
          } else if (eventType === "customer.subscription.updated") {
            const sub = event.data.object;
            const custId = sub.customer;
            const status = sub.status; // active, trialing, past_due, canceled, etc.
            const trialEnd = sub.trial_end ? sub.trial_end * 1000 : null;
            if (custId) {
              await db.prepare(`
                UPDATE users SET subscription_status = ?1, trial_end = ?2, updated_at = ?3 WHERE stripe_customer_id = ?4
              `).bind(status, trialEnd, Date.now(), custId).run();
              console.log(`[STRIPE] subscription.updated: ${custId} → ${status}, trial_end=${trialEnd}`);
            }
          } else if (eventType === "customer.subscription.deleted") {
            const sub = event.data.object;
            const custId = sub.customer;
            if (custId) {
              await db.prepare(`
                UPDATE users SET tier = 'free', subscription_status = 'canceled', expires_at = ?1, updated_at = ?2 WHERE stripe_customer_id = ?3
              `).bind(Date.now(), Date.now(), custId).run();
              console.log(`[STRIPE] subscription.deleted: ${custId}`);
              // Get email for notification
              const userRow = await db.prepare(`SELECT email FROM users WHERE stripe_customer_id = ?1`).bind(custId).first();
              if (userRow?.email) {
                await d1InsertNotification(env, {
                  email: userRow.email, type: "system",
                  title: "Subscription Canceled",
                  body: "Your Timed Trading Pro subscription has been canceled.",
                  link: "/splash.html",
                });
              }
            }
          } else if (eventType === "invoice.payment_failed") {
            const invoice = event.data.object;
            const custId = invoice.customer;
            if (custId) {
              // Grace period: 3 days
              const gracePeriodMs = 3 * 24 * 60 * 60 * 1000;
              await db.prepare(`
                UPDATE users SET tier = 'free', subscription_status = 'past_due', expires_at = ?1, updated_at = ?2 WHERE stripe_customer_id = ?3
              `).bind(Date.now() + gracePeriodMs, Date.now(), custId).run();
              console.log(`[STRIPE] invoice.payment_failed: ${custId} — 3-day grace period`);
              const userRow = await db.prepare(`SELECT email FROM users WHERE stripe_customer_id = ?1`).bind(custId).first();
              if (userRow?.email) {
                await d1InsertNotification(env, {
                  email: userRow.email, type: "system",
                  title: "Payment Failed",
                  body: "Your payment failed. Please update your payment method within 3 days to keep your Pro access.",
                  link: "/index-react.html",
                });
              }
            }
          }
          return new Response(JSON.stringify({ ok: true }), { status: 200, headers: { "Content-Type": "application/json" } });
        } catch (e) {
          console.error("[STRIPE WEBHOOK] Error:", String(e).slice(0, 300));
          return new Response(JSON.stringify({ ok: false, error: String(e?.message || e) }), { status: 500, headers: { "Content-Type": "application/json" } });
        }
      }

      // POST /timed/stripe/portal — Creates a Stripe Customer Portal session (authenticated)
      if (routeKey === "POST /timed/stripe/portal") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const stripeKey = env.STRIPE_SECRET_KEY;
          if (!stripeKey) return sendJSON({ ok: false, error: "stripe_not_configured" }, 503, corsHeaders(env, req));
          await d1EnsureStripeSchema(env);
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          const userRow = await db.prepare(`SELECT stripe_customer_id FROM users WHERE email = ?1`).bind(user.email.toLowerCase()).first();
          let customerId = userRow?.stripe_customer_id;

          // Auto-create Stripe customer if missing (e.g., admin-granted Pro users)
          if (!customerId) {
            try {
              const createResp = await fetch("https://api.stripe.com/v1/customers", {
                method: "POST",
                headers: {
                  "Authorization": `Bearer ${stripeKey}`,
                  "Content-Type": "application/x-www-form-urlencoded",
                },
                body: new URLSearchParams({ email: user.email }).toString(),
              });
              const newCust = await createResp.json();
              if (createResp.ok && newCust.id) {
                customerId = newCust.id;
                await db.prepare(`UPDATE users SET stripe_customer_id = ?1, updated_at = ?2 WHERE email = ?3`)
                  .bind(customerId, Date.now(), user.email.toLowerCase()).run();
                console.log(`[STRIPE] Auto-created customer ${customerId} for ${user.email}`);
              } else {
                return sendJSON({ ok: false, error: "stripe_customer_creation_failed", details: newCust.error?.message }, 500, corsHeaders(env, req));
              }
            } catch (e) {
              return sendJSON({ ok: false, error: "stripe_customer_creation_failed", details: String(e) }, 500, corsHeaders(env, req));
            }
          }

          const body = await readBodyAsJSON(req);
          const parsed = body?.obj || {};
          const returnUrl = parsed.return_url || `${url.origin}/index-react.html`;
          const params = new URLSearchParams({
            "customer": customerId,
            "return_url": returnUrl,
          });
          const portalResp = await fetch("https://api.stripe.com/v1/billing_portal/sessions", {
            method: "POST",
            headers: {
              "Authorization": `Bearer ${stripeKey}`,
              "Content-Type": "application/x-www-form-urlencoded",
            },
            body: params.toString(),
          });
          const portalSession = await portalResp.json();
          if (!portalResp.ok) {
            return sendJSON({ ok: false, error: "portal_creation_failed", details: portalSession.error?.message }, 500, corsHeaders(env, req));
          }
          return sendJSON({ ok: true, url: portalSession.url }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/subscription — Returns current subscription status (authenticated)
      if (routeKey === "GET /timed/subscription") {
        try {
          const user = await authenticateUser(req, env);
          if (!user?.email) return sendJSON({ ok: false, error: "auth_required" }, 401, corsHeaders(env, req));
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureStripeSchema(env);
          const row = await db.prepare(`
            SELECT tier, subscription_status, stripe_customer_id, stripe_subscription_id, expires_at, trial_end
            FROM users WHERE email = ?1
          `).bind(user.email.toLowerCase()).first();
          return sendJSON({
            ok: true,
            tier: row?.tier || "free",
            subscription_status: row?.subscription_status || "none",
            has_stripe: !!row?.stripe_customer_id,
            expires_at: row?.expires_at || null,
            trial_end: row?.trial_end || null,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════
      // Calibration Pipeline Endpoints
      // ═══════════════════════════════════════════════════════════════════

      if (routeKey === "POST /timed/calibration/upload-moves") {
        try {
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureCalibrationSchema(env);
          const body = await req.json();
          const moves = body.moves;
          if (!Array.isArray(moves) || moves.length === 0) {
            return sendJSON({ ok: false, error: "moves array required" }, 400, corsHeaders(env, req));
          }
          if (body.clear) await db.prepare(`DELETE FROM calibration_moves`).run();
          const batchSize = 50;
          let inserted = 0;
          for (let i = 0; i < moves.length; i += batchSize) {
            const chunk = moves.slice(i, i + batchSize);
            const stmts = chunk.map(m => db.prepare(
              `INSERT OR REPLACE INTO calibration_moves
               (move_id,ticker,direction,start_ts,end_ts,duration_days,move_pct,move_atr,
                max_ext_atr,pullback_atr,sl_optimal_atr,tp_p50_atr,tp_p75_atr,tp_p90_atr,
                signals_json,regime_json,created_at)
               VALUES (?1,?2,?3,?4,?5,?6,?7,?8,?9,?10,?11,?12,?13,?14,?15,?16,?17)`
            ).bind(
              m.move_id, m.ticker, m.direction, m.start_ts, m.end_ts,
              m.duration_days, m.move_pct, m.move_atr, m.max_ext_atr, m.pullback_atr,
              m.sl_optimal_atr, m.tp_p50_atr, m.tp_p75_atr, m.tp_p90_atr,
              m.signals_json || null, m.regime_json || null, Date.now()
            ));
            await db.batch(stmts);
            inserted += chunk.length;
          }
          return sendJSON({ ok: true, inserted }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 500) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "POST /timed/calibration/upload-autopsy") {
        try {
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureCalibrationSchema(env);
          const body = await req.json();
          const trades = body.trades;
          if (!Array.isArray(trades) || trades.length === 0) {
            return sendJSON({ ok: false, error: "trades array required" }, 400, corsHeaders(env, req));
          }
          if (body.clear) await db.prepare(`DELETE FROM calibration_trade_autopsy`).run();
          const batchSize = 50;
          let inserted = 0;
          for (let i = 0; i < trades.length; i += batchSize) {
            const chunk = trades.slice(i, i + batchSize);
            const stmts = chunk.map(t => db.prepare(
              `INSERT OR REPLACE INTO calibration_trade_autopsy
               (trade_id,ticker,direction,entry_ts,exit_ts,entry_price,exit_price,sl_price,
                pnl_pct,r_multiple,mfe_pct,mfe_atr,mae_pct,mae_atr,exit_efficiency,
                sl_hit_before_mfe,time_to_mfe_min,optimal_hold_min,classification,
                entry_signals_json,entry_path,rank_at_entry,regime_at_entry,created_at)
               VALUES (?1,?2,?3,?4,?5,?6,?7,?8,?9,?10,?11,?12,?13,?14,?15,?16,?17,?18,?19,?20,?21,?22,?23,?24)`
            ).bind(
              t.trade_id, t.ticker, t.direction, t.entry_ts, t.exit_ts,
              t.entry_price, t.exit_price, t.sl_price, t.pnl_pct, t.r_multiple,
              t.mfe_pct, t.mfe_atr, t.mae_pct, t.mae_atr, t.exit_efficiency,
              t.sl_hit_before_mfe ? 1 : 0, t.time_to_mfe_min, t.optimal_hold_min,
              t.classification, t.entry_signals_json || null,
              t.entry_path, t.rank_at_entry, t.regime_at_entry, Date.now()
            ));
            await db.batch(stmts);
            inserted += chunk.length;
          }
          return sendJSON({ ok: true, inserted }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 500) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "POST /timed/calibration/run") {
        try {
          const db = env?.DB;
          const KV = env?.KV_TIMED;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          // Calibration can exceed Worker request timeout (~30s). Queue for cron; cron has 15min CPU for hourly.
          if (KV) {
            await KV.put("timed:calibration:requested", String(Date.now()), { expirationTtl: 86400 }); // 24h TTL
            return sendJSON(
              { ok: true, queued: true, message: "Calibration queued. It runs on the next half-hour (within ~30 min). Refresh or we'll check for the report periodically." },
              202,
              corsHeaders(env, req)
            );
          }
          // Fallback: run inline (may 503 if > 30s)
          await d1EnsureCalibrationSchema(env);
          await d1EnsureLearningSchema(env);
          const moveCount = await harvestMovesServerSide(env);
          const tradeCount = await autopsyTradesServerSide(env);
          const report = await runCalibrationAnalysis(env);
          report._harvest = { moves: moveCount, trades: tradeCount };
          return sendJSON({ ok: true, report }, 200, corsHeaders(env, req));
        } catch (e) {
          console.error("[CALIBRATION] run error:", e);
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 500) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "GET /timed/calibration/report") {
        try {
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureCalibrationSchema(env);
          const row = await db.prepare(
            `SELECT * FROM calibration_report ORDER BY run_ts DESC LIMIT 1`
          ).first();
          if (!row) return sendJSON({ ok: false, error: "no_report" }, 404, corsHeaders(env, req));
          const report = row.report_json ? JSON.parse(row.report_json) : {};
          const recommendations = row.recommendations_json ? JSON.parse(row.recommendations_json) : {};
          return sendJSON({
            ok: true,
            report_id: row.report_id,
            run_ts: row.run_ts,
            lookback_days: row.lookback_days,
            trade_count: row.trade_count,
            move_count: row.move_count,
            applied_at: row.applied_at,
            report,
            recommendations,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 500) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "POST /timed/calibration/apply") {
        try {
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));
          await d1EnsureCalibrationSchema(env);
          await d1EnsureLearningSchema(env);
          const body = await req.json();
          const reportId = body.report_id;
          if (!reportId) return sendJSON({ ok: false, error: "report_id required" }, 400, corsHeaders(env, req));
          const row = await db.prepare(`SELECT recommendations_json FROM calibration_report WHERE report_id = ?1`).bind(reportId).first();
          if (!row) return sendJSON({ ok: false, error: "report_not_found" }, 404, corsHeaders(env, req));
          const recs = JSON.parse(row.recommendations_json || "{}");
          const applied = [];
          const now = Date.now();
          if (recs.signal_weights) {
            await db.prepare(
              `INSERT OR REPLACE INTO model_config (config_key, config_value, description, updated_at, updated_by)
               VALUES ('consensus_signal_weights', ?1, 'Calibration-derived signal weights', ?2, 'calibration')`
            ).bind(JSON.stringify(recs.signal_weights), now).run();
            applied.push("consensus_signal_weights");
          }
          if (recs.tf_weights) {
            await db.prepare(
              `INSERT OR REPLACE INTO model_config (config_key, config_value, description, updated_at, updated_by)
               VALUES ('consensus_tf_weights', ?1, 'Calibration-derived TF weights', ?2, 'calibration')`
            ).bind(JSON.stringify(recs.tf_weights), now).run();
            applied.push("consensus_tf_weights");
          }
          if (recs.sl_atr != null) {
            await db.prepare(
              `INSERT OR REPLACE INTO model_config (config_key, config_value, description, updated_at, updated_by)
               VALUES ('calibrated_sl_atr', ?1, 'Calibration SL in ATR multiples', ?2, 'calibration')`
            ).bind(String(recs.sl_atr), now).run();
            applied.push("calibrated_sl_atr");
          }
          if (recs.tp_tiers) {
            await db.prepare(
              `INSERT OR REPLACE INTO model_config (config_key, config_value, description, updated_at, updated_by)
               VALUES ('calibrated_tp_tiers', ?1, 'Calibration TP tiers in ATR multiples', ?2, 'calibration')`
            ).bind(JSON.stringify(recs.tp_tiers), now).run();
            applied.push("calibrated_tp_tiers");
          }
          if (recs.rank_threshold != null) {
            await db.prepare(
              `INSERT OR REPLACE INTO model_config (config_key, config_value, description, updated_at, updated_by)
               VALUES ('calibrated_rank_min', ?1, 'Minimum rank for entry from calibration', ?2, 'calibration')`
            ).bind(String(recs.rank_threshold), now).run();
            applied.push("calibrated_rank_min");
          }
          if (recs.path_adjustments) {
            for (const [path, adj] of Object.entries(recs.path_adjustments)) {
              if (adj.action === "DISABLE") {
                await db.prepare(
                  `UPDATE path_performance SET enabled = 0, disable_reason = ?1 WHERE entry_path = ?2`
                ).bind("calibration: negative expectancy", path).run();
                applied.push(`path_disable:${path}`);
              } else if (adj.quality_gate_adj != null) {
                await db.prepare(
                  `UPDATE path_performance SET quality_gate_adj = ?1 WHERE entry_path = ?2`
                ).bind(adj.quality_gate_adj, path).run();
                applied.push(`path_qg:${path}`);
              }
            }
          }
          await db.prepare(
            `UPDATE calibration_report SET applied_at = ?1, applied_by = 'admin' WHERE report_id = ?2`
          ).bind(now, reportId).run();
          return sendJSON({ ok: true, applied }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 500) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/trades?version=2.1.0 (Get all trades, optional version filter)
      if (routeKey === "GET /timed/trades") {
        // Rate limiting - increased limits for UI polling (100 requests per minute)
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/trades",
          100, // 100 requests
          60, // per minute (instead of per hour)
        );

        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 60 },
            429,
            corsHeaders(env, req),
          );
        }
        const versionFilter = url.searchParams.get("version");
        const source = url.searchParams.get("source");
        const useD1 = source !== "kv" && env?.DB; // Default to D1; ?source=kv to force KV

        // Read from D1: positions (?source=positions) or trades+events (?source=d1 or default)
        let d1Trades = null;
        if (useD1) {
          if (source === "positions") {
            d1Trades = await d1GetAllPositionsAsTrades(env);
          } else {
            d1Trades = await d1GetAllTradesWithEvents(env);
            // Merge open positions so cards get entry_price for tickers in Hold (e.g. TT, ULTA)
            const positions = await d1GetAllPositionsAsTrades(env);
            if (Array.isArray(positions) && positions.length > 0) {
              const openByKey = new Map();
              for (const t of d1Trades) {
                const s = String(t?.ticker || "").toUpperCase();
                const status = String(t?.status || "").toUpperCase();
                if (status === "OPEN" || status === "TP_HIT_TRIM") {
                  const key = `${s}:${String(t?.direction || "").toUpperCase()}`;
                  openByKey.set(key, t);
                }
              }
              const newlyAdded = [];
              for (const p of positions) {
                const s = String(p?.ticker || "").toUpperCase();
                const status = String(p?.status || "").toUpperCase();
                if (status !== "OPEN" && status !== "TP_HIT_TRIM") continue;
                const key = `${s}:${String(p?.direction || "").toUpperCase()}`;
                if (openByKey.has(key)) continue;
                openByKey.set(key, p);
                d1Trades.push(p);
                newlyAdded.push(p);
              }
              // Apply trail correction to position-sourced trades (same as d1LoadTradesForSimulation)
              // so entry price is consistent regardless of trade source (trail-corrected, not VWAP)
              if (newlyAdded.length > 0 && env?.DB) {
                for (const t of newlyAdded) {
                  const entryTs = Number(t.entry_ts || t.created_at || 0);
                  if (!entryTs) continue;
                  try {
                    const fromTrail = await getPriceFromTrailAtTimestamp(env.DB, t.ticker, entryTs);
                    if (fromTrail != null) {
                      t.entryPrice = fromTrail;
                      t.entry_price = fromTrail;
                    }
                  } catch { /* best-effort */ }
                }
              }
            }
          }
        }
        if (d1Trades) {
          let filtered = d1Trades;
          if (versionFilter && versionFilter !== "all") {
            filtered = d1Trades.filter(
              (t) => (t.scriptVersion || t.script_version || "unknown") === versionFilter,
            );
          }
          const versions = [
            ...new Set(d1Trades.map((t) => t.scriptVersion || t.script_version || "unknown")),
          ].sort().reverse();
          return sendJSON(
            {
              ok: true,
              count: filtered.length,
              totalCount: d1Trades.length,
              version: versionFilter || "all",
              versions,
              trades: filtered,
              source: source || "d1",
            },
            200,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        let allTrades = (await kvGetJSON(KV, tradesKey)) || [];

        // Correct any trades with incorrect WIN/LOSS status based on P&L
        let corrected = false;
        for (let i = 0; i < allTrades.length; i++) {
          const trade = allTrades[i];
          if (
            (trade.status === "WIN" || trade.status === "LOSS") &&
            trade.pnl !== undefined &&
            trade.pnl !== null
          ) {
            // Check if status matches P&L
            if (trade.status === "WIN" && trade.pnl < 0) {
              console.log(
                `[TRADE CORRECTION] Correcting ${trade.ticker} ${
                  trade.direction
                }: WIN with negative P&L (${trade.pnl.toFixed(2)}) -> LOSS`,
              );
              allTrades[i] = { ...trade, status: "LOSS" };
              corrected = true;
            } else if (trade.status === "LOSS" && trade.pnl > 0) {
              console.log(
                `[TRADE CORRECTION] Correcting ${trade.ticker} ${
                  trade.direction
                }: LOSS with positive P&L (${trade.pnl.toFixed(2)}) -> WIN`,
              );
              allTrades[i] = { ...trade, status: "WIN" };
              corrected = true;
            }
          }
        }

        // Save corrected trades back to KV if any corrections were made
        if (corrected) {
          await kvPutJSON(KV, tradesKey, allTrades);
          console.log(
            `[TRADE CORRECTION] Saved ${allTrades.length} trades with corrections`,
          );
        }

        // Dedupe by (ticker, direction, entry_ts) — replay can create duplicates
        const entryTsForTrade = (t) => {
          const et = Number(t?.entry_ts ?? t?.entryTs);
          if (Number.isFinite(et)) return et;
          const iso = t?.entryTime;
          if (iso) return isoToMs(iso) || null;
          const hist = Array.isArray(t?.history) ? t.history : [];
          const ent = hist.find((e) => String(e?.type || "").toUpperCase() === "ENTRY");
          return ent ? isoToMs(ent.timestamp ?? ent.ts) || null : null;
        };
        const seen = new Set();
        const deduped = [];
        for (const t of allTrades) {
          const ticker = String(t?.ticker || "").toUpperCase();
          const dir = String(t?.direction || "").toUpperCase();
          const et = entryTsForTrade(t);
          const key = `${ticker}:${dir}:${et != null ? et : t?.id || ""}`;
          if (seen.has(key)) continue;
          seen.add(key);
          deduped.push(t);
        }
        if (deduped.length < allTrades.length) {
          await kvPutJSON(KV, tradesKey, deduped);
          allTrades = deduped;
        }

        let filteredTrades = allTrades;
        if (versionFilter && versionFilter !== "all") {
          filteredTrades = allTrades.filter(
            (t) => (t.scriptVersion || "unknown") === versionFilter,
          );
        }

        // Get unique versions for reference
        const versions = [
          ...new Set(allTrades.map((t) => t.scriptVersion || "unknown")),
        ]
          .sort()
          .reverse();

        return sendJSON(
          {
            ok: true,
            count: filteredTrades.length,
            totalCount: allTrades.length,
            version: versionFilter || "all",
            versions: versions,
            trades: filteredTrades,
            corrected: corrected, // Indicate if corrections were made
          },
          200,
          corsHeaders(env, req),
        );
      }

      // ═══════════════════════════════════════════════════════════════════════
      // GET /timed/account-summary — single source of truth for account value
      // Uses account_ledger table; backfills from execution_actions / investor_lots if empty
      // ═══════════════════════════════════════════════════════════════════════
      if (routeKey === "GET /timed/account-summary") {
        try {
          const mode = url.searchParams.get("mode") || "trader";
          const db = env?.DB;
          if (!db) return sendJSON({ ok: false, error: "no_db" }, 500, corsHeaders(env, req));

          // Force schema creation (bypass throttle if table doesn't exist)
          try {
            await db.prepare("SELECT 1 FROM account_ledger LIMIT 1").first();
          } catch {
            // Table doesn't exist — force create bypassing throttle
            await ensureAccountLedgerSchema(db, null);
          }
          await ensureAccountLedgerSchema(db, KV);

          // Check if ledger has entries for this mode; if not, backfill
          const countRow = await db.prepare(
            "SELECT COUNT(*) as cnt FROM account_ledger WHERE mode = ?1"
          ).bind(mode).first();

          if (!countRow || countRow.cnt === 0) {
            // ── BACKFILL ─────────────────────────────────────────────
            const startCash = mode === "trader" ? PORTFOLIO_START_CASH : 100000;
            let balance = startCash;

            if (mode === "trader") {
              // Backfill from execution_actions
              const actions = (await db.prepare(
                `SELECT ea.action_id, ea.position_id, ea.ts, ea.action_type, ea.qty, ea.price, ea.value, ea.pnl_realized, ea.reason,
                        p.ticker, p.direction
                 FROM execution_actions ea
                 LEFT JOIN positions p ON ea.position_id = p.position_id
                 ORDER BY ea.ts ASC`
              ).all())?.results || [];

              const stmts = [];
              for (const a of actions) {
                const aType = String(a.action_type).toUpperCase();
                let cashDelta = 0;
                let realizedPnl = 0;
                if (aType === "ENTRY" || aType === "ADD_ENTRY") {
                  cashDelta = -(Number(a.value) || (Number(a.qty) * Number(a.price)) || 0);
                } else if (aType === "TRIM" || aType === "EXIT") {
                  cashDelta = Number(a.value) || (Number(a.qty) * Number(a.price)) || 0;
                  realizedPnl = Number(a.pnl_realized) || 0;
                }
                if (cashDelta === 0 && aType !== "ENTRY") continue;
                balance += cashDelta;
                stmts.push(db.prepare(
                  `INSERT INTO account_ledger (mode, ts, event_type, position_id, ticker, direction, qty, price, cash_delta, realized_pnl, balance, note)
                   VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12)`
                ).bind(
                  "trader", Number(a.ts), aType, a.position_id || null,
                  a.ticker || null, a.direction || null,
                  Number(a.qty) || null, Number(a.price) || null,
                  cashDelta, realizedPnl, balance, `Backfill from ${a.action_id}`
                ));
              }
              // Batch insert (max 500 per batch)
              for (let i = 0; i < stmts.length; i += 500) {
                await db.batch(stmts.slice(i, i + 500));
              }
              console.log(`[LEDGER BACKFILL] trader: ${stmts.length} entries from execution_actions`);

            } else if (mode === "investor") {
              // Backfill from investor_lots
              try {
                const lots = (await db.prepare(
                  `SELECT l.id, l.position_id, l.ticker, l.action, l.shares, l.price, l.value, l.ts,
                          p.avg_entry, p.cost_basis
                   FROM investor_lots l
                   LEFT JOIN investor_positions p ON l.position_id = p.id
                   ORDER BY l.ts ASC`
                ).all())?.results || [];

                const stmts = [];
                for (const lot of lots) {
                  const act = String(lot.action).toUpperCase();
                  const val = Number(lot.value) || (Number(lot.shares) * Number(lot.price)) || 0;
                  let cashDelta = 0;
                  let realizedPnl = 0;
                  if (act === "BUY" || act === "DCA_BUY") {
                    cashDelta = -val;
                  } else if (act === "SELL") {
                    cashDelta = val;
                    // Approximate realized P&L using avg_entry at time of lot
                    const avgEntry = Number(lot.avg_entry) || 0;
                    if (avgEntry > 0) {
                      realizedPnl = (Number(lot.price) - avgEntry) * Number(lot.shares);
                    }
                  }
                  if (cashDelta === 0) continue;
                  balance += cashDelta;
                  stmts.push(db.prepare(
                    `INSERT INTO account_ledger (mode, ts, event_type, position_id, ticker, direction, qty, price, cash_delta, realized_pnl, balance, note)
                     VALUES (?1, ?2, ?3, ?4, ?5, 'LONG', ?6, ?7, ?8, ?9, ?10, ?11)`
                  ).bind(
                    "investor", Number(lot.ts),
                    act === "SELL" ? "EXIT" : (act === "DCA_BUY" ? "DCA_BUY" : "ENTRY"),
                    lot.position_id || null, lot.ticker || null,
                    Number(lot.shares) || null, Number(lot.price) || null,
                    cashDelta, realizedPnl, balance, `Backfill from lot ${lot.id}`
                  ));
                }
                for (let i = 0; i < stmts.length; i += 500) {
                  await db.batch(stmts.slice(i, i + 500));
                }
                console.log(`[LEDGER BACKFILL] investor: ${stmts.length} entries from investor_lots`);
              } catch (invErr) {
                console.error("[LEDGER BACKFILL] investor failed (table may not exist):", invErr);
              }
            }
          }

          // ── Read current state ──────────────────────────────────────
          const latestRow = await db.prepare(
            "SELECT balance FROM account_ledger WHERE mode = ?1 ORDER BY ts DESC, ledger_id DESC LIMIT 1"
          ).bind(mode).first();

          const startCash = mode === "trader" ? PORTFOLIO_START_CASH : 100000;
          const cash = latestRow ? Number(latestRow.balance) : startCash;

          const pnlRow = await db.prepare(
            "SELECT SUM(realized_pnl) as total_realized FROM account_ledger WHERE mode = ?1"
          ).bind(mode).first();
          const totalRealized = pnlRow ? Number(pnlRow.total_realized) || 0 : 0;

          // Mark-to-market open positions
          let unrealized = 0;
          let costBasis = 0;
          let markToMarket = 0;

          if (mode === "trader") {
            const openPos = (await db.prepare(
              "SELECT position_id, ticker, direction, total_qty, cost_basis FROM positions WHERE status = 'OPEN'"
            ).all())?.results || [];

            // Batch price lookup — KV stores prices as { p: 71.74, pc: 77.97, ... }
            const pricesRaw = await kvGetJSON(KV, "timed:prices");
            const priceMap = {};
            if (pricesRaw?.prices) {
              for (const [sym, pObj] of Object.entries(pricesRaw.prices)) {
                priceMap[sym] = Number(pObj.p || pObj.price || pObj.latestTrade?.p) || 0;
              }
            }

            for (const pos of openPos) {
              const px = priceMap[pos.ticker] || 0;
              const qty = Number(pos.total_qty) || 0;
              const cb = Number(pos.cost_basis) || 0;
              const mtm = px * qty;
              const dir = String(pos.direction).toUpperCase() === "SHORT" ? -1 : 1;
              unrealized += dir * (mtm - cb);
              costBasis += cb;
              markToMarket += mtm;
            }
          } else {
            // Investor positions
            try {
              const openPos = (await db.prepare(
                "SELECT id, ticker, total_shares, cost_basis, avg_entry FROM investor_positions WHERE status = 'OPEN'"
              ).all())?.results || [];

              const pricesRaw = await kvGetJSON(KV, "timed:prices");
              const priceMap = {};
              if (pricesRaw?.prices) {
                for (const [sym, pObj] of Object.entries(pricesRaw.prices)) {
                  priceMap[sym] = Number(pObj.p || pObj.price || pObj.latestTrade?.p) || 0;
                }
              }

              for (const pos of openPos) {
                const px = priceMap[pos.ticker] || 0;
                const qty = Number(pos.total_shares) || 0;
                const cb = Number(pos.cost_basis) || 0;
                const mtm = px * qty;
                unrealized += mtm - cb;
                costBasis += cb;
                markToMarket += mtm;
              }
            } catch {
              // investor_positions table may not exist yet
            }
          }

          // Account value = starting capital + total P&L (realized + unrealized)
          // This is correct for mixed LONG/SHORT portfolios where cash + markToMarket
          // would double-count SHORT positions (entry deducts cash but market value is a liability)
          const accountValue = startCash + totalRealized + unrealized;

          return sendJSON({
            ok: true,
            mode,
            startCash,
            cash: Math.round(cash * 100) / 100,
            totalRealized: Math.round(totalRealized * 100) / 100,
            unrealized: Math.round(unrealized * 100) / 100,
            costBasis: Math.round(costBasis * 100) / 100,
            markToMarket: Math.round(markToMarket * 100) / 100,
            accountValue: Math.round(accountValue * 100) / 100,
            generated_at: new Date().toISOString(),
          }, 200, corsHeaders(env, req));
        } catch (err) {
          console.error("[ACCOUNT SUMMARY] Error:", err);
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/portfolio (paper portfolio + executions, derived from D1 positions)
      // D1 is the SINGLE SOURCE OF TRUTH for positions
      if (routeKey === "GET /timed/portfolio") {
        const ip = req.headers.get("CF-Connecting-IP") || "unknown";
        const rateLimit = await checkRateLimit(
          KV,
          ip,
          "/timed/portfolio",
          2000,
          3600,
        );
        if (!rateLimit.allowed) {
          return sendJSON(
            { ok: false, error: "rate_limit_exceeded", retryAfter: 3600 },
            429,
            corsHeaders(env, req),
          );
        }

        // ═══════════════════════════════════════════════════════════════════════
        // D1 SINGLE SOURCE OF TRUTH: Get positions and executions from D1
        // ═══════════════════════════════════════════════════════════════════════
        const startCash = PORTFOLIO_START_CASH;
        let useD1 = !!env?.DB;
        let d1Positions = [];
        let d1Actions = [];
        
        if (useD1) {
          try {
            // Get all positions (open and closed)
            const posRes = await env.DB.prepare(`
              SELECT position_id, ticker, direction, status, total_qty, cost_basis, 
                     created_at, updated_at, closed_at, script_version
              FROM positions 
              ORDER BY created_at DESC
            `).all();
            d1Positions = posRes?.results || [];
            
            // Get all execution actions
            const actRes = await env.DB.prepare(`
              SELECT action_id, position_id, ts, action_type, qty, price, value, pnl_realized, reason
              FROM execution_actions
              ORDER BY ts ASC
            `).all();
            d1Actions = actRes?.results || [];
          } catch (err) {
            console.warn("[PORTFOLIO] D1 query failed, falling back to KV:", err);
            useD1 = false;
          }
        }

        // Fallback to KV trades if D1 not available
        const tradesKey = "timed:trades:all";
        const trades = useD1 ? [] : ((await kvGetJSON(KV, tradesKey)) || []);

        const tpTargetPrice = (src) => {
          const directTarget = Number(src?.tp_target_price ?? src?.tp_target);
          if (Number.isFinite(directTarget) && directTarget > 0)
            return directTarget;
          const tp = Number(src?.tp);
          if (Number.isFinite(tp) && tp > 0) return tp;
          return null;
        };

        const toMs = (tsLike) => {
          const n =
            typeof tsLike === "string" ? isoToMs(tsLike) : Number(tsLike);
          if (!Number.isFinite(n) || n <= 0) return null;
          return n < 1e12 ? n * 1000 : n;
        };
        const dayKey = (ms) => {
          try {
            const d = new Date(ms);
            const y = d.getUTCFullYear();
            const m = String(d.getUTCMonth() + 1).padStart(2, "0");
            const da = String(d.getUTCDate()).padStart(2, "0");
            return `${y}-${m}-${da}`;
          } catch {
            return "unknown";
          }
        };

        const events = [];
        
        // ═══════════════════════════════════════════════════════════════════════
        // D1 SOURCE: Build events from D1 execution_actions
        // ═══════════════════════════════════════════════════════════════════════
        if (useD1 && d1Actions.length > 0) {
          // Build position lookup for direction
          const posById = new Map();
          for (const p of d1Positions) {
            posById.set(p.position_id, p);
          }
          
          for (const a of d1Actions) {
            const pos = posById.get(a.position_id);
            const ticker = pos?.ticker || "UNKNOWN";
            const dir = pos?.direction || "LONG";
            const ts = Number(a.ts);
            if (!Number.isFinite(ts) || ts <= 0) continue;
            
            const type = String(a.action_type || "").toUpperCase();
            if (!type) continue;
            
            events.push({
              ts,
              day: dayKey(ts),
              ticker,
              direction: dir,
              type,
              price: Number(a.price) || null,
              shares: Number(a.qty) || null,
              value: Number(a.value) || null,
              reason: a.reason || null,
              notional: Number(a.value) || null,
              trade_id: a.position_id,
              pnl_realized: Number(a.pnl_realized) || 0,
            });
          }
        }

        // ═══════════════════════════════════════════════════════════════════════
        // KV FALLBACK: Build events from KV trades (legacy)
        // ═══════════════════════════════════════════════════════════════════════
        for (const tr of trades) {
          const ticker = String(tr?.ticker || "").toUpperCase();
          const dir = String(tr?.direction || "").toUpperCase();
          const notional = Number(tr?.notional);
          const hist = Array.isArray(tr?.history) ? tr.history : [];
          for (const ev of hist) {
            const ts = toMs(ev?.timestamp ?? ev?.ts);
            if (!Number.isFinite(ts) || ts <= 0 || ts < 946684800000) continue; // skip zero or pre-2000 (bogus epoch)
            const type = String(ev?.type || "").toUpperCase();
            if (!type) continue;
            const price = Number(ev?.price);
            const shares = Number(ev?.shares);
            const value = Number.isFinite(Number(ev?.value))
              ? Number(ev.value)
              : Number.isFinite(price) && Number.isFinite(shares)
                ? price * shares
                : null;
            events.push({
              ts,
              day: dayKey(ts),
              ticker,
              direction: dir,
              type,
              price: Number.isFinite(price) ? price : null,
              shares: Number.isFinite(shares) ? shares : null,
              value: Number.isFinite(value) ? value : null,
              reason: ev?.reason != null ? String(ev.reason) : null,
              notional: Number.isFinite(notional) ? notional : null,
              trade_id: tr?.id || null,
            });
          }
        }

        // Dedupe events (same ticker+direction+type+ts) — prevents duplicate tape entries
        const eventKey = (e) => `${e.ticker}:${e.direction}:${e.type}:${e.ts}`;
        const seenEvents = new Set();
        const dedupedEvents = [];
        for (const e of events) {
          const k = eventKey(e);
          if (seenEvents.has(k)) continue;
          seenEvents.add(k);
          dedupedEvents.push(e);
        }
        events.length = 0;
        events.push(...dedupedEvents);

        events.sort((a, b) => a.ts - b.ts);

        // Best-effort latest snapshots for tickers referenced by the portfolio/tape.
        const latestByTicker = {};
        try {
          const tickSet = new Set();
          for (const e of events)
            if (e?.ticker) tickSet.add(String(e.ticker).toUpperCase());
          for (const tr of trades)
            if (tr?.ticker) tickSet.add(String(tr.ticker).toUpperCase());
          const tickers = Array.from(tickSet).filter(Boolean).slice(0, 500);

          // Prefer D1 for reads (batch query), fallback to KV.
          if (env?.DB && tickers.length > 0) {
            await d1EnsureLatestSchema(env);
            const placeholders = tickers.map((_, i) => `?${i + 1}`).join(", ");
            const rows = await env.DB.prepare(
              `SELECT ticker, payload_json FROM ticker_latest WHERE ticker IN (${placeholders})`,
            )
              .bind(...tickers)
              .all();
            for (const r of rows?.results || []) {
              const sym = String(r?.ticker || "").toUpperCase();
              if (!sym) continue;
              const raw = r?.payload_json;
              if (!raw) continue;
              try {
                latestByTicker[sym] = JSON.parse(String(raw));
              } catch {
                // ignore
              }
            }
          }

          // Backfill from KV when D1 misses.
          const missing = tickers.filter((t) => !latestByTicker[t]);
          if (missing.length > 0) {
            for (const t of missing) {
              const v = await kvGetJSON(KV, `timed:latest:${t}`);
              if (v && typeof v === "object") {
                latestByTicker[t] = v;
                try {
                  ctx.waitUntil(d1UpsertTickerLatest(env, t, v));
                  ctx.waitUntil(d1UpsertTickerIndex(env, t, v?.ts));
                } catch {
                  // ignore
                }
              }
            }
          }
        } catch (e) {
          console.warn(
            `[PORTFOLIO] latest snapshot join failed:`,
            String(e?.message || e),
          );
        }

        // Replay portfolio from executions (simple cash + positions model)
        let cash = startCash;
        const positions = {}; // ticker -> {direction, shares, avgEntry, cost}

        const ensurePos = (tkr, dir) => {
          if (!positions[tkr])
            positions[tkr] = {
              ticker: tkr,
              direction: dir,
              shares: 0,
              avgEntry: null,
              cost: 0,
            };
          return positions[tkr];
        };

        for (const e of events) {
          if (!e.ticker || !e.type) continue;
          const tkr = e.ticker;
          const dir = e.direction || null;
          const shares = Number(e.shares);
          const value = Number(e.value);
          if (!Number.isFinite(shares) || shares <= 0) continue;
          if (!Number.isFinite(value) || value <= 0) continue;

          if (e.type === "ENTRY") {
            cash -= value;
            const p = ensurePos(tkr, dir);
            // simple avg entry calc
            const newShares = p.shares + shares;
            const entryPx = Number(e.price);
            const newCost = p.cost + value;
            p.shares = newShares;
            p.cost = newCost;
            p.avgEntry =
              Number.isFinite(entryPx) && newShares > 0
                ? newCost / newShares
                : p.avgEntry;
            p.direction = dir || p.direction;
          } else if (e.type === "TRIM" || e.type === "EXIT") {
            cash += value;
            const p = ensurePos(tkr, dir);
            p.shares = Math.max(0, p.shares - shares);
            if (p.shares <= 1e-9) {
              delete positions[tkr];
            }
          }
        }

        // Mark-to-market open positions using last known price (best-effort)
        let positionsValue = 0;
        const openPositions = [];
        
        // ═══════════════════════════════════════════════════════════════════════
        // D1 SOURCE: Build open positions from D1 positions table
        // ═══════════════════════════════════════════════════════════════════════
        if (useD1 && d1Positions.length > 0) {
          // Fetch SL/TP from positions table (they aren't in the basic query above)
          let positionSLTP = {};
          try {
            const slTpRes = await env.DB.prepare(
              `SELECT position_id, stop_loss, take_profit FROM positions WHERE status = 'OPEN'`
            ).all();
            for (const r of (slTpRes?.results || [])) {
              positionSLTP[r.position_id] = { stop_loss: r.stop_loss, take_profit: r.take_profit };
            }
          } catch (e) { /* ignore — SL/TP enrichment is best-effort */ }

          for (const p of d1Positions) {
            if (p.status !== "OPEN") continue;
            const tkr = String(p.ticker || "").toUpperCase();
            const latest = latestByTicker[tkr];
            const shares = Number(p.total_qty) || 0;
            const costBasis = Number(p.cost_basis) || 0;
            const avgEntry = shares > 0 ? costBasis / shares : null;
            const px = Number(
              latest?.price ??
                latest?.last ??
                latest?.close
            );
            const val = Number.isFinite(px) && shares > 0 ? px * shares : null;
            if (Number.isFinite(val)) positionsValue += val;
            
            // Calculate realized P&L from actions
            const posActions = d1Actions.filter(a => a.position_id === p.position_id);
            const realizedPnl = posActions.reduce((sum, a) => sum + (Number(a.pnl_realized) || 0), 0);

            // SL/TP from position, with fallback to latest ticker data
            const posSLTP = positionSLTP[p.position_id] || {};
            const sl = Number(posSLTP.stop_loss ?? latest?.sl ?? latest?.sl_price ?? latest?.stop_loss);
            const tp = Number(posSLTP.take_profit ?? latest?.tp ?? latest?.tp_max_price ?? latest?.tp_target_price ?? latest?.tp_target);
            
            openPositions.push({
              ticker: tkr,
              direction: p.direction,
              shares,
              avgEntry,
              mark: Number.isFinite(px) ? px : null,
              value: Number.isFinite(val) ? val : null,
              phase_pct: latest?.phase_pct != null ? Number(latest.phase_pct) : null,
              completion: latest?.completion != null ? Number(latest.completion) : null,
              tp: Number.isFinite(tp) && tp > 0 ? tp : tpTargetPrice(latest),
              sl: Number.isFinite(sl) && sl > 0 ? sl : null,
              kanban_stage: latest?.kanban_stage || null,
              position_id: p.position_id,
              entry_ts: p.created_at,
              realized_pnl: realizedPnl,
              day_change: latest?.day_change != null ? Number(latest.day_change) : null,
              day_change_pct: latest?.day_change_pct != null ? Number(latest.day_change_pct) : (latest?.change_pct != null ? Number(latest.change_pct) : null),
              prev_close: latest?.prev_close != null ? Number(latest.prev_close) : null,
              source: "d1",
            });
          }
        } else {
          // KV FALLBACK: Build from replayed positions
          for (const [tkr, p] of Object.entries(positions)) {
            const trade = trades.find(
              (x) =>
                String(x?.ticker || "").toUpperCase() === tkr &&
                isOpenTradeStatus(x?.status),
            );
            const latest = latestByTicker[String(tkr).toUpperCase()];
            const px = Number(
              latest?.price ??
                latest?.last ??
                latest?.close ??
                trade?.currentPrice ??
                trade?.price,
            );
            const val = Number.isFinite(px) ? px * Number(p.shares) : null;
            if (Number.isFinite(val)) positionsValue += val;
            openPositions.push({
              ticker: tkr,
              direction: p.direction,
              shares: p.shares,
              avgEntry: p.avgEntry,
              mark: Number.isFinite(px) ? px : null,
              value: Number.isFinite(val) ? val : null,
              phase_pct: latest?.phase_pct != null ? Number(latest.phase_pct) : null,
              completion: latest?.completion != null ? Number(latest.completion) : null,
              tp: tpTargetPrice(latest),
              source: "kv",
            });
          }
        }

        const equity = cash + positionsValue;

        // Group executions by day and ticker
        const byDay = {};
        const byTicker = {};
        for (const e of events) {
          if (!byDay[e.day]) byDay[e.day] = [];
          byDay[e.day].push(e);
          if (!byTicker[e.ticker]) byTicker[e.ticker] = [];
          byTicker[e.ticker].push(e);
        }

        // Proof snapshot (server-side join): per-day rows with trade details.
        const proofByDay = {};
        try {
          const entryByTradeId = new Map(); // trade_id -> { entryPrice, entryShares, entryTs, direction }
          for (const e of events) {
            if (
              e?.type === "ENTRY" &&
              e?.trade_id &&
              Number.isFinite(Number(e?.price))
            ) {
              entryByTradeId.set(String(e.trade_id), {
                entryPrice: Number(e.price),
                entryShares: Number.isFinite(Number(e?.shares))
                  ? Number(e.shares)
                  : null,
                entryTs: Number.isFinite(Number(e?.ts)) ? Number(e.ts) : null,
                direction: e?.direction || null,
              });
            }
          }

          // Index open positions for remaining qty and avgEntry/mark.
          const posByTickerDir = new Map(); // `${tkr}:${dir}` -> pos
          for (const p of openPositions) {
            const key = `${String(p.ticker).toUpperCase()}:${String(p.direction || "").toUpperCase()}`;
            posByTickerDir.set(key, p);
          }

          const getPos = (tkr, dir) => {
            const key = `${String(tkr).toUpperCase()}:${String(dir || "").toUpperCase()}`;
            return posByTickerDir.get(key) || null;
          };

          for (const [day, dayEvents] of Object.entries(byDay)) {
            const arr = Array.isArray(dayEvents) ? dayEvents : [];
            const tradesById = new Map();
            let entries = 0,
              trims = 0,
              exits = 0;
            let realizedPnl = 0;
            const closedById = new Map(); // trade_id -> pnl

            for (const e of arr) {
              const tradeId = e?.trade_id ? String(e.trade_id) : null;
              const tkr = String(e?.ticker || "").toUpperCase();
              const type = String(e?.type || "").toUpperCase();
              if (type === "ENTRY") entries += 1;
              if (type === "TRIM") trims += 1;
              if (type === "EXIT") exits += 1;

              if (!tradeId || !tkr) continue;
              if (!tradesById.has(tradeId)) {
                const meta = entryByTradeId.get(tradeId) || {};
                const latest = latestByTicker[tkr] || null;
                const pos = getPos(tkr, meta.direction || e?.direction || "");
                const currentPx = Number(
                  pos?.mark ??
                    latest?.price ??
                    latest?.last ??
                    latest?.close ??
                    null,
                );
                const entryPx = Number.isFinite(Number(pos?.avgEntry))
                  ? Number(pos.avgEntry)
                  : Number(meta?.entryPrice);
                tradesById.set(tradeId, {
                  trade_id: tradeId,
                  ticker: tkr,
                  direction:
                    String(
                      meta.direction || e?.direction || "",
                    ).toUpperCase() || null,
                  entry: {
                    ts: meta?.entryTs ?? null,
                    price: Number.isFinite(entryPx) ? entryPx : null,
                    shares: meta?.entryShares ?? null,
                  },
                  current: {
                    price: Number.isFinite(currentPx) ? currentPx : null,
                    phase_pct:
                      latest?.phase_pct != null
                        ? Number(latest.phase_pct)
                        : null,
                    completion:
                      latest?.completion != null
                        ? Number(latest.completion)
                        : null,
                    tp: tpTargetPrice(latest),
                    ts: latest?.ts != null ? toMs(latest.ts) : null,
                  },
                  last_action_type: null,
                  last_action_ts: null,
                  trim_ts: null,
                  exit_ts: null,
                  trim_price: null,
                  exit_price: null,
                  exit_reason: null,
                  remaining_qty:
                    pos?.shares != null ? Number(pos.shares) : null,
                  realized_pnl: 0,
                });
              }

              const t = tradesById.get(tradeId);
              const px = Number(e?.price);
              const sh = Number(e?.shares);
              const eventTs = Number.isFinite(Number(e?.ts)) ? Number(e.ts) : null;
              if (eventTs != null) t.last_action_ts = eventTs;
              t.last_action_type = type || t.last_action_type;
              if (type === "TRIM") {
                if (Number.isFinite(px)) t.trim_price = px;
                if (eventTs != null) t.trim_ts = eventTs;
              }
              if (type === "EXIT") {
                if (Number.isFinite(px)) t.exit_price = px;
                if (eventTs != null) t.exit_ts = eventTs;
                if (e?.reason) t.exit_reason = String(e.reason);
              }

              // realized pnl for trim/exit if entry is known
              const entryPx = Number(t?.entry?.price);
              const dir = String(t?.direction || "").toUpperCase();
              const sign = dir === "SHORT" ? -1 : 1;
              if (
                (type === "TRIM" || type === "EXIT") &&
                Number.isFinite(entryPx) &&
                Number.isFinite(px) &&
                Number.isFinite(sh)
              ) {
                const pnl = (px - entryPx) * sh * sign;
                t.realized_pnl += pnl;
                realizedPnl += pnl;
                if (type === "EXIT") closedById.set(tradeId, pnl);
              }
            }

            let wins = 0,
              losses = 0;
            for (const pnl of closedById.values()) {
              if (!Number.isFinite(pnl) || pnl === 0) continue;
              if (pnl > 0) wins += 1;
              if (pnl < 0) losses += 1;
            }

            proofByDay[day] = {
              day,
              stats: {
                entries,
                trims,
                exits,
                wins,
                losses,
                realizedPnl,
              },
              trades: Array.from(tradesById.values()).sort((a, b) => {
                const tickerA = String(a.ticker || "").toUpperCase();
                const tickerB = String(b.ticker || "").toUpperCase();
                if (tickerA !== tickerB) return tickerA.localeCompare(tickerB);
                const entryA = Number(a.entry?.ts ?? a.entry_ts ?? 0);
                const entryB = Number(b.entry?.ts ?? b.entry_ts ?? 0);
                return entryA - entryB;
              }),
            };
          }
        } catch (e) {
          console.warn(
            `[PORTFOLIO] proof build failed:`,
            String(e?.message || e),
          );
        }

        return sendJSON(
          {
            ok: true,
            portfolio: {
              startCash,
              cash,
              equity,
              positionsValue,
              openPositions,
              updated_at: Date.now(),
            },
            executions: {
              count: events.length,
              byDay,
              byTicker,
            },
            proof: {
              generated_at: Date.now(),
              byDay: proofByDay,
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/trades?key=... (Create or update trade)
      if (routeKey === "POST /timed/trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const { obj: body, err } = await readBodyAsJSON(req);
        if (!body || !body.id) {
          return sendJSON(
            { ok: false, error: "missing trade id" },
            400,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

        // Find existing trade or add new one
        const existingIndex = allTrades.findIndex((t) => t.id === body.id);

        if (existingIndex >= 0) {
          // Update existing trade
          allTrades[existingIndex] = { ...allTrades[existingIndex], ...body };
        } else {
          // Add new trade
          allTrades.push(body);
        }

        // Sort by entry time (newest first)
        allTrades.sort((a, b) => {
          const timeA = new Date(a.entryTime || 0).getTime();
          const timeB = new Date(b.entryTime || 0).getTime();
          return timeB - timeA;
        });

        await kvPutJSON(KV, tradesKey, allTrades);

        return sendJSON(
          {
            ok: true,
            trade: existingIndex >= 0 ? allTrades[existingIndex] : body,
            action: existingIndex >= 0 ? "updated" : "created",
          },
          200,
          corsHeaders(env, req),
        );
      }

      // DELETE /timed/trades/:id?key=... (Delete trade)
      if (routeKey === "DELETE /timed/trades/:id") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const tradeId = url.pathname.split("/timed/trades/")[1];
        if (!tradeId) {
          return sendJSON(
            { ok: false, error: "missing trade id" },
            400,
            corsHeaders(env, req),
          );
        }

        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
        const filteredTrades = allTrades.filter((t) => t.id !== tradeId);

        await kvPutJSON(KV, tradesKey, filteredTrades);

        return sendJSON(
          {
            ok: true,
            deleted: allTrades.length - filteredTrades.length === 1,
            remainingCount: filteredTrades.length,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // OPTIONS /timed/ai/chat (CORS preflight)
      if (routeKey === "OPTIONS /timed/ai/chat") {
        const origin = req?.headers?.get("Origin") || "";
        // Always allow timedtrading.pages.dev origin, otherwise use "*"
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          "Access-Control-Max-Age": "86400",
          Vary: "Origin",
        };
        return new Response(null, {
          status: 204,
          headers: aiChatCorsHeaders,
        });
      }

      // POST /timed/ai/chat (AI Chat Assistant)
      if (routeKey === "POST /timed/ai/chat") {
        // Get CORS headers early - always allow timedtrading.pages.dev for AI chat
        const origin = req?.headers?.get("Origin") || "";
        // Always allow timedtrading.pages.dev origin, otherwise use "*"
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        // Wrap entire handler in try-catch to ensure CORS headers are always returned
        try {
          // Handle JSON parsing errors with CORS headers
          let body;
          try {
            const result = await readBodyAsJSON(req);
            if (result.err) {
              return sendJSON(
                { ok: false, error: "Invalid JSON in request body" },
                400,
                aiChatCorsHeaders,
              );
            }
            body = result.obj;
          } catch (e) {
            return sendJSON(
              { ok: false, error: "Failed to parse request body" },
              400,
              aiChatCorsHeaders,
            );
          }

          if (!body || !body.message) {
            return sendJSON(
              { ok: false, error: "missing message" },
              400,
              aiChatCorsHeaders,
            );
          }

          try {
            const openaiApiKey = env.OPENAI_API_KEY;
            if (!openaiApiKey) {
              return sendJSON(
                {
                  ok: false,
                  error:
                    "AI service not configured. Please set OPENAI_API_KEY secret.",
                },
                503,
                aiChatCorsHeaders,
              );
            }

            // Extract ticker symbols mentioned in the user message so we always fetch their data
            const EXCLUDED_WORDS = new Set(["I", "AI", "HTF", "LTF", "RR", "ETF", "USA", "PM", "AM", "ET", "IT", "DO", "SO", "OR", "AD", "RS", "UP", "CEO", "IPO", "API", "URL", "OF", "TO", "BE", "AS", "IS", "ME", "MY", "WE", "US", "NO", "ON", "GO", "BY"]);
            const msg = String(body.message || "");
            const mentionedTickers = [...(msg.match(/\b[A-Za-z]{2,5}\b/g) || [])]
              .map((s) => String(s).toUpperCase())
              .filter((s) => !EXCLUDED_WORDS.has(s));
            const uniqueMentioned = [...new Set(mentionedTickers)];

            // Combine mentioned tickers first, then rest from client (so AI has data for "look at CRS")
            const tickerSymbols = [...new Set([...uniqueMentioned, ...(body.tickerData || [])])];
            const tickerContext = [];

            // Handle ticker data fetching with error handling
            try {
              const tickerDataPromises = tickerSymbols
                .slice(0, 25)
                .map(async (ticker) => {
                  try {
                    const latestData = await kvGetJSON(
                      KV,
                      `timed:latest:${ticker}`,
                    );
                    if (latestData) {
                      return {
                        ticker: ticker,
                        rank: latestData.rank || 0,
                        rr: latestData.rr || 0,
                        price: latestData.price || 0,
                        state: latestData.state || "",
                        phase_pct: latestData.phase_pct || 0,
                        completion: latestData.completion || 0,
                        flags: latestData.flags || {},
                        setup_reason: latestData.setup_reason || latestData.__setup_reason || null,
                        block_reason: latestData.__entry_block_reason || latestData.entry_block_reason || null,
                        kanban_stage: latestData.kanban_stage || null,
                      };
                    }
                    return null;
                  } catch (err) {
                    console.error(
                      `[AI CHAT] Error fetching ticker ${ticker}:`,
                      err,
                    );
                    return null;
                  }
                });

              const tickerDataResults = await Promise.all(tickerDataPromises);
              tickerDataResults
                .filter(Boolean)
                .forEach((t) => tickerContext.push(t));
            } catch (err) {
              console.error("[AI CHAT] Error fetching ticker data:", err);
              // Continue with empty ticker context - not critical
            }

            // Format activity feed context with safe handling
            const activityContext = [];
            try {
              const rawActivityData = body.activityData || [];
              if (Array.isArray(rawActivityData)) {
                rawActivityData.slice(0, 10).forEach((event) => {
                  try {
                    if (event && typeof event === "object") {
                      const ts = event.ts ? Number(event.ts) : Date.now();
                      const price = Number(event.price) || 0;
                      activityContext.push({
                        ticker: String(event.ticker || "UNKNOWN"),
                        type: String(event.type || "event"),
                        time:
                          ts > 0
                            ? new Date(ts).toLocaleTimeString()
                            : "Unknown time",
                        price: price,
                        rank: Number(event.rank) || 0,
                      });
                    }
                  } catch (e) {
                    console.error(
                      "[AI CHAT] Error formatting activity event:",
                      e,
                    );
                    // Skip this event
                  }
                });
              }
            } catch (err) {
              console.error("[AI CHAT] Error processing activity data:", err);
              // Continue with empty activity context - not critical
            }

            // Build system prompt with context
            const systemPrompt = `You are an expert trading analyst assistant and active monitor for the Timed Trading platform. 
Your role is to continuously observe market conditions, identify opportunities, warn about risks, and help traders make informed decisions.

## YOUR CAPABILITIES
- **Real-time Monitoring**: Continuously observe ticker data, activity feeds, and market conditions
- **Proactive Alerts**: Identify good trades to watch, warnings about risks, trim/exit signals
- **Pattern Recognition**: Learn from trade history and identify profitable patterns
- **Data Analysis**: Analyze ticker data (ranks, RR, phase, completion, states)
- **Signal Interpretation**: Interpret trading signals and setups
- **System Education**: Explain the quadrant-based trading system
- **Risk Management**: Provide risk assessments and actionable insights
- **Research Capabilities**: Answer questions about setups, signals, and market research (note: external research APIs can be added later)

## AVAILABLE DATA
- **${
              tickerContext.length
            } tickers** with real-time data (rank, RR, price, phase, completion, state, setup/block reasons, kanban stage)
- **${
              activityContext.length
            } recent activity events** (corridor entries, squeeze releases, alignments)
${
              uniqueMentioned.length > 0
                ? `\n**The user specifically asked about: ${uniqueMentioned.join(", ")}.** Use the ticker data below for these when answering. If data is missing for an asked ticker, say so clearly.\n`
                : ""
            }

### Sample Ticker Data (Top 10):
${
  tickerContext.length > 0
    ? tickerContext
        .slice(0, 10)
        .map((t) => {
          try {
            const rr = Number(t.rr) || 0;
            const price = Number(t.price) || 0;
            const phasePct = Number(t.phase_pct) || 0;
            const completion = Number(t.completion) || 0;
            const stage = t.kanban_stage ? ` Stage: ${String(t.kanban_stage)}.` : "";
            const setup = t.setup_reason ? ` Setup: ${String(t.setup_reason).slice(0, 80)}.` : "";
            const block = t.block_reason ? ` Block: ${String(t.block_reason).slice(0, 80)}.` : "";
            return `- **${String(t.ticker || "UNKNOWN")}**: Rank ${
              Number(t.rank) || 0
            }, RR ${rr.toFixed(2)}:1, Price $${price.toFixed(
              2,
            )}, State: ${String(t.state || "UNKNOWN")}, Phase: ${(
              phasePct * 100
            ).toFixed(0)}%, Completion: ${(completion * 100).toFixed(0)}%${stage}${setup}${block}`;
          } catch (e) {
            console.error("[AI CHAT] Error formatting ticker:", t, e);
            return `- **${String(t.ticker || "UNKNOWN")}**: Data unavailable`;
          }
        })
        .filter(Boolean)
        .join("\n")
    : "No ticker data available"
}

### Recent Activity:
${
  activityContext.length > 0
    ? activityContext
        .map((a) => {
          try {
            const price = Number(a.price) || 0;
            return `- ${String(a.time || "Unknown time")}: **${String(
              a.ticker || "UNKNOWN",
            )}** ${String(a.type || "event")} at $${price.toFixed(2)}`;
          } catch (e) {
            console.error("[AI CHAT] Error formatting activity:", a, e);
            return null;
          }
        })
        .filter(Boolean)
        .join("\n")
    : "No recent activity"
}

## TRADING SYSTEM OVERVIEW

### Quadrant System:
The platform uses a quadrant-based approach combining Higher Timeframe (HTF) and Lower Timeframe (LTF) signals:

- **Q1 (HTF_BULL_LTF_PULLBACK)**: Bull Setup - High timeframe bullish, short-term pullback. Waiting for entry confirmation.
- **Q2 (HTF_BULL_LTF_BULL)**: Bull Momentum - Both timeframes bullish. Active long trend, momentum phase.
- **Q3 (HTF_BEAR_LTF_BEAR)**: Bear Momentum - Both timeframes bearish. Active short trend, momentum phase.
- **Q4 (HTF_BEAR_LTF_PULLBACK)**: Bear Setup - High timeframe bearish, short-term pullback. Waiting for entry confirmation.

### Setup Quality Indicators:
- **Prime Setup**: High rank (≥75), excellent RR (≥1.5), low completion (<40%), favorable phase (<60%). Highest quality setups.
- **Momentum Elite**: High-quality momentum stock with strong fundamentals (volume, ADR, momentum metrics).
- **In Corridor**: Price is in the optimal entry zone for the directional setup (LTF score between -8 to +12 for LONG, -12 to +8 for SHORT).
- **Squeeze Release**: Momentum indicator suggesting a directional move is beginning (pent-up energy releasing).

### Key Metrics:
- **Rank**: Composite score (0-100) based on multiple factors. Higher = better setup quality.
- **RR (Risk/Reward)**: Ratio of potential profit to potential loss. ≥1.5 is considered good.
- **Phase %**: Position in the market cycle (0-100%). Lower (<40%) = early, higher (>60%) = late.
- **Completion %**: How far price has moved toward target (0-100%). Lower = more upside potential.

## APPLICATION GUIDE (How to Use the System)

### Pages & Navigation
- **Active Trader**: Main dashboard with Kanban board, bubble chart, activity feed, and right rail for ticker details. This is the primary page for active day/swing traders.
- **Investor**: Long-term position management with stages (Research, Accumulate, Hold, Trim, Exit). Designed for portfolio-oriented users.
- **Trades**: Simulation dashboard showing all trades, P&L, win rate, and signal analysis.
- **Daily Brief**: AI-generated morning/evening market analysis with macro outlook and predictions.
- **Screener**: Filter tickers by rank, RR, state, phase, and other criteria.
- **Model**: Pattern library and prediction accuracy tracking.

### Kanban Board (Active Trader)
Tickers flow through horizontal lanes based on their scoring signals:
- **Discovery**: Tickers being monitored but not yet in a trade setup.
- **Flip Watch**: Showing early signs of a directional change.
- **Enter Now**: Active entry signal — highest conviction setups. Look here for trade ideas.
- **Manage**: Open positions being actively managed.
- **Trim**: Partial exit signals (take profits, reduce risk).
- **Exit**: Full exit signals.

### Right Rail
Click any ticker card to open the Right Rail panel showing:
- Interactive price chart (with candlesticks and indicators)
- Scoring breakdown (HTF/LTF scores, state, phase, completion)
- Signal flags (Golden Gate, SuperTrend flip, squeeze release, etc.)
- Risk metrics (stop loss, take profit, RR ratio)
- The chart can be expanded to full-screen modal view.

### Bubble Chart
Visual representation of all tickers plotted by:
- X-axis: Phase % (0-100%)
- Y-axis: Completion % (0-100%)
- Bubble Size: Rank score
- Bubble Color: Quadrant (Bull Setup=blue, Bull Momentum=green, Bear Momentum=red, Bear Setup=orange)
- Best opportunities are in the bottom-left quadrant (early phase + low completion).

### Market Pulse Row
Top row showing key indices and futures (SPX, US500, SPY, QQQ, IWM, DIA, etc.) with daily change percentage.

### Getting Started Tips
1. Start with the Daily Brief each morning for market context.
2. Check the Kanban board "Enter Now" lane for highest conviction setups.
3. Use the Bubble Chart to see the big picture — bottom-left = best opportunities.
4. Click any ticker to see details in the Right Rail.
5. Use the Screener to filter for specific criteria (e.g., Rank > 75, RR > 1.5).
6. Check the FAQ page (/faq.html) for detailed answers about the system.

## MONITORING & PROACTIVE ALERTS

As an active monitor, you should:

1. **Identify Opportunities**:
   - Prime setups (Rank ≥75, RR ≥1.5, Completion <40%, Phase <60%)
   - Momentum Elite stocks entering good setups
   - New corridor entries with strong signals
   - Squeeze releases indicating potential moves

2. **Flag Warnings**:
   - High completion (>70%) - consider trimming or exiting
   - Late phase (>80%) - risk of reversal
   - Positions approaching stop loss
   - Setups losing quality (rank dropping, RR deteriorating)

3. **Pattern Recognition**:
   - Identify which setups/types perform best
   - Recognize when similar patterns led to wins/losses
   - Suggest improvements based on historical performance

4. **Continuous Learning**:
   - Reference trade history when relevant
   - Learn from what worked and what didn't
   - Adapt recommendations based on patterns

## RESPONSE GUIDELINES

1. **Be concise but thorough**: 
   - Simple queries: 2-4 sentences
   - Analysis questions: More detailed but organized
   - Monitoring queries: Structured with Opportunities, Warnings, Insights, Recommendations
   - Use bullet points for multiple items

2. **Always reference data**: 
   - Cite specific ranks, RR values, prices, states
   - Reference activity feed events when relevant
   - Mention trade history patterns when applicable
   - If ticker data isn't available, say so clearly

3. **Provide actionable insights**:
   - Not just data, but interpretation
   - Highlight risks and opportunities proactively
   - Suggest next steps (watch, enter, trim, exit)
   - Be specific: "Consider trimming 50% of POSITION at $PRICE"

4. **Risk awareness**:
   - Always mention risks for high-completion setups
   - Caution about late-phase positions
   - Note when setups lack confirmation
   - Warn about approaching stop losses

5. **Formatting**:
   - Use **bold** for tickers and key terms
   - Use \`code\` for technical terms
   - Use bullet points for lists
   - Use emojis for quick scanning: 🎯 Opportunities, ⚠️ Warnings, 📊 Insights, 💡 Recommendations
   - Keep paragraphs short (2-3 sentences max)

6. **Educational approach**:
   - Explain concepts if user seems unfamiliar
   - Define abbreviations on first use
   - Provide context for recommendations
   - Reference the trading system when explaining decisions

## EXAMPLE RESPONSES

**Good response for "What's the status of AAPL?"**:
"**AAPL** is currently ranked #X with an RR of X:1. It's in Q2 (Bull Momentum) with phase at X% and completion at X%. [Specific insight based on data]. [Risk assessment if relevant]."

**Good response for "Show me prime setups"**:
"Based on current data, here are the prime setups: [List with ranks and RR]. These setups have high rank (≥75), good RR (≥1.5), and are in early stages. [Overall market context]."

Remember: You're a helpful assistant. Be professional, accurate, and prioritize user safety by emphasizing risk management.`;

            // Format conversation history
            const messages = [
              { role: "system", content: systemPrompt },
              ...(body.conversationHistory || []).slice(-8).map((msg) => ({
                role: msg.role,
                content: msg.content,
              })),
              { role: "user", content: body.message },
            ];

            // Call OpenAI API with timeout
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 30000); // 30 second timeout

            let aiResponse;
            try {
              aiResponse = await fetch(
                "https://api.openai.com/v1/chat/completions",
                {
                  method: "POST",
                  headers: {
                    Authorization: `Bearer ${openaiApiKey}`,
                    "Content-Type": "application/json",
                  },
                  body: JSON.stringify({
                    model:
                      env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                        ? env.OPENAI_MODEL
                        : "gpt-3.5-turbo",
                    messages: messages,
                    temperature: 0.7,
                    max_tokens: 800,
                  }),
                  signal: controller.signal,
                },
              );
            } catch (fetchError) {
              clearTimeout(timeoutId);
              if (fetchError.name === "AbortError") {
                throw new Error(
                  "Request timeout - OpenAI API took too long to respond",
                );
              }
              throw new Error(`Network error: ${fetchError.message}`);
            }

            clearTimeout(timeoutId);

            if (!aiResponse.ok) {
              let errorData = {};
              try {
                errorData = await aiResponse.json();
              } catch (e) {
                // If response isn't JSON, use status text
                errorData = { error: { message: aiResponse.statusText } };
              }
              console.error(
                "[AI CHAT] OpenAI API error:",
                aiResponse.status,
                errorData,
              );
              // Provide user-friendly error messages for common OpenAI errors
              let errorMessage =
                errorData.error?.message ||
                `OpenAI API error: ${aiResponse.status}`;
              if (aiResponse.status === 429) {
                if (errorData.error?.code === "insufficient_quota") {
                  errorMessage =
                    "OpenAI API quota exceeded. Please check your billing and plan details.";
                } else {
                  errorMessage =
                    "OpenAI API rate limit exceeded. Please try again later.";
                }
              }
              throw new Error(errorMessage);
            }

            let aiData;
            try {
              aiData = await aiResponse.json();
            } catch (e) {
              throw new Error("Invalid JSON response from OpenAI API");
            }

            const aiMessage =
              aiData.choices?.[0]?.message?.content ||
              "Sorry, I couldn't process that request.";

            // Extract sources: tickers from user message that we had data for
            const citedTickers = [];
            const tickerRegex = /\b([A-Z]{1,5})\b/g;
            const matches = body.message.toUpperCase().match(tickerRegex);
            if (matches) {
              matches.forEach((ticker) => {
                if (tickerContext.some((t) => t.ticker === ticker)) {
                  citedTickers.push(ticker);
                }
              });
            }

            return sendJSON(
              {
                ok: true,
                response: aiMessage,
                sources:
                  citedTickers.length > 0
                    ? [`Data from: ${citedTickers.join(", ")}`]
                    : [],
                timestamp: Date.now(),
              },
              200,
              aiChatCorsHeaders,
            );
          } catch (error) {
            // Catch any errors (including errors in error handling)
            console.error("[AI CHAT ERROR]", error);
            console.error("[AI CHAT ERROR] Stack:", error.stack);
            console.error("[AI CHAT ERROR] Message:", error.message);
            console.error("[AI CHAT ERROR] Name:", error.name);
            // Always return CORS headers even on error
            try {
              return sendJSON(
                {
                  ok: false,
                  error: error.message || "AI service error",
                  details: error.stack,
                },
                500,
                aiChatCorsHeaders,
              );
            } catch (sendError) {
              // If even sendJSON fails, return a basic response with CORS headers
              console.error(
                "[AI CHAT FATAL ERROR] Failed to send error response:",
                sendError,
              );
              return new Response(
                JSON.stringify({ ok: false, error: "Internal server error" }),
                {
                  status: 500,
                  headers: {
                    "Content-Type": "application/json",
                    ...aiChatCorsHeaders,
                  },
                },
              );
            }
          } // End of inner try-catch for OpenAI API
        } catch (fatalError) {
          // Catch any unhandled errors that might crash the worker
          console.error("[AI CHAT FATAL ERROR]", fatalError);
          console.error("[AI CHAT FATAL ERROR] Stack:", fatalError?.stack);
          console.error("[AI CHAT FATAL ERROR] Message:", fatalError?.message);
          console.error("[AI CHAT FATAL ERROR] Name:", fatalError?.name);
          console.error("[AI CHAT FATAL ERROR] Type:", typeof fatalError);
          // Always return CORS headers even on fatal errors
          // Re-create CORS headers in case they're out of scope
          const origin = req?.headers?.get("Origin") || "";
          const allowedOrigin = origin.includes("timedtrading.pages.dev")
            ? origin
            : "*";
          const fatalCorsHeaders = {
            "Access-Control-Allow-Origin": allowedOrigin,
            "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type",
            Vary: "Origin",
          };
          try {
            return sendJSON(
              {
                ok: false,
                error: "Internal server error",
                details: fatalError?.message || "Unknown error",
              },
              500,
              fatalCorsHeaders,
            );
          } catch (sendError) {
            // Last resort - return basic response
            console.error("[AI CHAT] Even sendJSON failed:", sendError);
            return new Response(
              JSON.stringify({ ok: false, error: "Internal server error" }),
              {
                status: 500,
                headers: {
                  "Content-Type": "application/json",
                  ...fatalCorsHeaders,
                },
              },
            );
          }
        }
      } // End of POST /timed/ai/chat handler

      // GET /timed/ai/updates (Get periodic AI updates)
      if (routeKey === "GET /timed/ai/updates") {
        const origin = req?.headers?.get("Origin") || "";
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        try {
          const limit = parseInt(url.searchParams.get("limit") || "10", 10);

          // Get list of updates
          const updatesListKey = `timed:ai:updates:list`;
          const updatesList = (await kvGetJSON(KV, updatesListKey)) || [];

          // Fetch actual update data
          const updatesPromises = updatesList
            .slice(0, limit)
            .map(async (item) => {
              try {
                const updateData = await kvGetJSON(KV, item.key);
                return updateData;
              } catch (err) {
                return null;
              }
            });

          const updates = (await Promise.all(updatesPromises))
            .filter(Boolean)
            .sort((a, b) => {
              const timeA = a.timestamp ? new Date(a.timestamp).getTime() : 0;
              const timeB = b.timestamp ? new Date(b.timestamp).getTime() : 0;
              return timeB - timeA;
            });

          return sendJSON(
            {
              ok: true,
              updates,
              count: updates.length,
            },
            200,
            aiChatCorsHeaders,
          );
        } catch (error) {
          console.error("[AI UPDATES ERROR]", error);
          return sendJSON(
            {
              ok: false,
              error: error.message || "Failed to fetch updates",
            },
            500,
            aiChatCorsHeaders,
          );
        }
      }

      // GET /timed/ai/daily-summary (Daily Summary of Simulation Dashboard Performance)
      if (routeKey === "GET /timed/ai/daily-summary") {
        const origin = req?.headers?.get("Origin") || "";
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        try {
          const openaiApiKey = env.OPENAI_API_KEY;
          if (!openaiApiKey) {
            return sendJSON(
              {
                ok: false,
                error:
                  "AI service not configured. Please set OPENAI_API_KEY secret.",
              },
              503,
              aiChatCorsHeaders,
            );
          }

          // Get date filter (default: today)
          const dateParam = url.searchParams.get("date");
          const targetDate = dateParam ? new Date(dateParam) : new Date();
          const todayStart = new Date(targetDate);
          todayStart.setHours(0, 0, 0, 0);
          const todayEnd = new Date(targetDate);
          todayEnd.setHours(23, 59, 59, 999);

          // Fetch all trades from unified storage
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

          // Filter trades by date
          const todayTrades = allTrades.filter((trade) => {
            if (!trade.entryTime) return false;
            const entryDate = new Date(trade.entryTime);
            return entryDate >= todayStart && entryDate <= todayEnd;
          });

          // Categorize trades
          const newTrades = todayTrades.filter(
            (t) => t.status === "OPEN" || !t.status,
          );
          const closedTrades = todayTrades.filter(
            (t) => t.status === "WIN" || t.status === "LOSS",
          );
          const trimmedTrades = todayTrades.filter(
            (t) => t.status === "TP_HIT_TRIM",
          );

          // Calculate P&L
          const closedPnl = closedTrades.reduce(
            (sum, t) => sum + (Number(t.pnl) || 0),
            0,
          );
          const openPnl = newTrades.reduce(
            (sum, t) => sum + (Number(t.pnl) || 0),
            0,
          );
          const trimmedPnl = trimmedTrades.reduce(
            (sum, t) => sum + (Number(t.pnl) || 0),
            0,
          );

          // Calculate win rate
          const wins = closedTrades.filter((t) => t.status === "WIN").length;
          const losses = closedTrades.filter((t) => t.status === "LOSS").length;
          const winRate =
            closedTrades.length > 0 ? (wins / closedTrades.length) * 100 : 0;

          // Analyze patterns for learning
          const winningTrades = closedTrades.filter((t) => t.status === "WIN");
          const losingTrades = closedTrades.filter((t) => t.status === "LOSS");

          // Analyze by signal types (trigger reasons and flags)
          const signalAnalysis = {};
          const allTradesForSignals = [...todayTrades];
          allTradesForSignals.forEach((trade) => {
            const signals = [];

            // Trigger reasons
            if (trade.state) {
              const state = String(trade.state || "");
              if (state.includes("BULL")) signals.push("HTF_BULL");
              if (state.includes("BEAR")) signals.push("HTF_BEAR");
              if (state.includes("PULLBACK")) signals.push("LTF_PULLBACK");
              if (state.includes("LTF_BULL")) signals.push("LTF_BULL");
              if (state.includes("LTF_BEAR")) signals.push("LTF_BEAR");
            }

            // Flags
            const flags = trade.flags || {};
            if (flags.sq30_release) signals.push("SQUEEZE_RELEASE");
            if (flags.sq30_on) signals.push("SQUEEZE_ON");
            if (flags.phase_zone_change) signals.push("PHASE_ZONE_CHANGE");
            if (flags.momentum_elite) signals.push("MOMENTUM_ELITE");

            // Trigger reason
            if (trade.trigger_reason) {
              const triggerReason = String(trade.trigger_reason || "");
              if (triggerReason === "EMA_CROSS")
                signals.push("EMA_CROSS_DAILY");
              if (triggerReason === "SQUEEZE_RELEASE")
                signals.push("SQUEEZE_RELEASE_TRIGGER");
            }

            const signalKey =
              signals.length > 0 ? signals.sort().join("+") : "NO_SIGNALS";

            if (!signalAnalysis[signalKey]) {
              signalAnalysis[signalKey] = {
                total: 0,
                wins: 0,
                losses: 0,
                totalPnl: 0,
                trades: [],
              };
            }

            signalAnalysis[signalKey].total++;
            if (trade.status === "WIN") signalAnalysis[signalKey].wins++;
            if (trade.status === "LOSS") signalAnalysis[signalKey].losses++;
            signalAnalysis[signalKey].totalPnl += Number(trade.pnl) || 0;
            signalAnalysis[signalKey].trades.push({
              ticker: trade.ticker,
              status: trade.status,
              pnl: Number(trade.pnl) || 0,
              rank: Number(trade.rank) || 0,
              rr: Number(trade.rr) || 0,
            });
          });

          // Analyze by rank ranges
          const rankAnalysis = {};
          closedTrades.forEach((trade) => {
            const rank = Number(trade.rank) || 0;
            let range = "Unknown";
            if (rank >= 80) range = "Rank ≥ 80";
            else if (rank >= 70) range = "Rank 70-80";
            else if (rank >= 60) range = "Rank 60-70";
            else if (rank > 0) range = "Rank < 60";

            if (!rankAnalysis[range]) {
              rankAnalysis[range] = { wins: 0, losses: 0, totalPnl: 0 };
            }
            if (trade.status === "WIN") rankAnalysis[range].wins++;
            if (trade.status === "LOSS") rankAnalysis[range].losses++;
            rankAnalysis[range].totalPnl += Number(trade.pnl) || 0;
          });

          // Analyze by RR ranges
          const rrAnalysis = {};
          closedTrades.forEach((trade) => {
            const rr = Number(trade.rr) || 0;
            let range = "Unknown";
            if (rr >= 2.0) range = "RR ≥ 2.0";
            else if (rr >= 1.5) range = "RR 1.5-2.0";
            else if (rr >= 1.0) range = "RR 1.0-1.5";
            else if (rr > 0) range = "RR < 1.0";

            if (!rrAnalysis[range]) {
              rrAnalysis[range] = { wins: 0, losses: 0, totalPnl: 0 };
            }
            if (trade.status === "WIN") rrAnalysis[range].wins++;
            if (trade.status === "LOSS") rrAnalysis[range].losses++;
            rrAnalysis[range].totalPnl += Number(trade.pnl) || 0;
          });

          // Find most common signals
          const topSignals = Object.entries(signalAnalysis)
            .filter(([_, stats]) => stats.total >= 2)
            .sort((a, b) => {
              const aRate = a[1].wins / (a[1].wins + a[1].losses || 1);
              const bRate = b[1].wins / (b[1].wins + b[1].losses || 1);
              return bRate - aRate;
            })
            .slice(0, 5);

          // Build summary prompt
          const summaryPrompt = `You are a senior trading analyst providing a comprehensive daily market thesis. Write as if someone asked you: "How did the market do today? What interesting developments were there?"

Your response should be thesis-driven, narrative, and detailed - like a professional market commentary.

## TODAY'S PERFORMANCE SUMMARY

**Date:** ${targetDate.toLocaleDateString()}

### Trade Activity:
- **New Trades:** ${newTrades.length}
- **Closed Trades:** ${closedTrades.length} (${wins} wins, ${losses} losses)
- **Trimmed Trades:** ${trimmedTrades.length}

### P&L Summary:
- **Closed P&L:** $${closedPnl.toFixed(2)}
- **Open P&L:** $${openPnl.toFixed(2)}
- **Trimmed P&L:** $${trimmedPnl.toFixed(2)}
- **Total P&L:** $${(closedPnl + openPnl + trimmedPnl).toFixed(2)}
- **Win Rate:** ${winRate.toFixed(1)}%

### Signal Breakdown - What Drove Today's Trades:

**Most Common Signal Combinations:**
${
  topSignals.length > 0
    ? topSignals
        .map(
          ([signals, stats]) =>
            `- **${signals}**: ${stats.total} trades | ${stats.wins}W/${
              stats.losses
            }L (${(
              (stats.wins / (stats.wins + stats.losses || 1)) *
              100
            ).toFixed(1)}% win rate) | P&L: $${stats.totalPnl.toFixed(2)}`,
        )
        .join("\n")
    : "No significant signal patterns"
}

**Signal Details:**
- **EMA Crossovers (Daily)**: ${
            allTradesForSignals.filter((t) => t.trigger_reason === "EMA_CROSS")
              .length
          } trades
- **Squeeze Releases**: ${
            allTradesForSignals.filter((t) => t.flags?.sq30_release).length
          } trades
- **Momentum Elite**: ${
            allTradesForSignals.filter((t) => t.flags?.momentum_elite).length
          } trades
- **Phase Zone Changes**: ${
            allTradesForSignals.filter((t) => t.flags?.phase_zone_change).length
          } trades

---

### Performance by Rank:
${
  Object.entries(rankAnalysis)
    .map(
      ([range, stats]) =>
        `- **${range}**: ${stats.wins}W/${
          stats.losses
        }L | P&L: $${stats.totalPnl.toFixed(2)}`,
    )
    .join("\n") || "No data"
}

---

### Performance by RR:
${
  Object.entries(rrAnalysis)
    .map(
      ([range, stats]) =>
        `- **${range}**: ${stats.wins}W/${
          stats.losses
        }L | P&L: $${stats.totalPnl.toFixed(2)}`,
    )
    .join("\n") || "No data"
}

---

### Top Performers:
${
  winningTrades
    .sort((a, b) => (Number(b.pnl) || 0) - (Number(a.pnl) || 0))
    .slice(0, 5)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: +$${(Number(t.pnl) || 0).toFixed(2)} | Rank ${
        t.rank || 0
      } | RR ${rrFormatted}`;
    })
    .join("\n") || "None"
}

### Worst Performers:
${
  losingTrades
    .sort((a, b) => (Number(a.pnl) || 0) - (Number(b.pnl) || 0))
    .slice(0, 5)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: $${(Number(t.pnl) || 0).toFixed(2)} | Rank ${
        t.rank || 0
      } | RR ${rrFormatted}`;
    })
    .join("\n") || "None"
}

### Current Open Positions (For Actionable Recommendations):
${
  newTrades.length > 0
    ? newTrades
        .slice(0, 10)
        .map((t) => {
          const entryPrice = Number(t.entryPrice) || 0;
          const currentPrice = Number(t.currentPrice) || entryPrice;
          const sl = Number(t.sl) || 0;
          const tp = Number(t.tp) || 0;
          const rr = Number(t.rr) || 0;
          const rrFormatted =
            rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
          const direction = String(t.direction || "LONG");
          const riskPerShare =
            direction === "LONG" ? entryPrice - sl : sl - entryPrice;
          const rewardPerShare =
            direction === "LONG" ? tp - entryPrice : entryPrice - tp;
          const distanceToTP =
            direction === "LONG" ? tp - currentPrice : currentPrice - tp;
          const distanceToSL =
            direction === "LONG" ? currentPrice - sl : sl - currentPrice;
          const pctToTP =
            entryPrice > 0
              ? ((distanceToTP / rewardPerShare) * 100).toFixed(0)
              : "0";
          const trimLevel = tp; // Trim at first TP

          return `- **${t.ticker}** (${direction}): Entry $${entryPrice.toFixed(
            2,
          )} | Current $${currentPrice.toFixed(2)} | SL $${sl.toFixed(
            2,
          )} | TP $${tp.toFixed(2)} | RR ${rrFormatted} | Rank ${
            t.rank || 0
          } | ${pctToTP}% to TP`;
        })
        .join("\n")
    : "No open positions"
}

## YOUR TASK

Write a comprehensive, thesis-driven daily market summary. Structure it as follows:

### 1. **Market Thesis** (2-3 paragraphs)
Start with a clear thesis statement: "Today's market was characterized by [X]..." 
- What was the overall market character? (Bullish momentum, choppy consolidation, bearish pressure, etc.)
- What drove the day's activity? (EMA crossovers, squeeze releases, specific setups)
- Were there any notable patterns or themes?

### 2. **Signal-Driven Analysis** (Detailed breakdown)
For each major signal type, explain:
- **EMA Crossovers**: How many occurred? Were they on the daily timeframe? Did they lead to successful trades? What was the typical setup?
- **Squeeze Releases**: How many squeeze releases triggered trades? Were they bullish or bearish? How did they perform?
- **Momentum Elite**: Did Momentum Elite stocks outperform? What was their win rate?
- **Phase Zone Changes**: Did phase transitions lead to good entries? Were they early or late in the cycle?

Break down what specifically drove the scores and signals. For example:
- "The majority of winning trades today were driven by EMA crossovers on the daily timeframe, particularly when combined with squeeze releases. These setups showed an average rank of 78 and RR of 2.1:1..."
- "Squeeze releases were the dominant signal, accounting for X% of new entries. However, they showed mixed results - bullish squeezes in Q2 (HTF_BULL_LTF_BULL) performed well with a Y% win rate, while bearish squeezes struggled..."

### 3. **Interesting Developments** (What stood out)
- Were there any unusual patterns? (e.g., "Rank ≥80 trades significantly outperformed today")
- Did certain sectors or setups surprise? (e.g., "Short setups unexpectedly outperformed longs")
- Any notable failures or successes? (e.g., "High RR trades (>2.0) had perfect win rate but low volume")

### 4. **Performance Breakdown by Signals**
Reference the signal analysis data above. Explain which signal combinations worked best and why.

### 5. **Actionable Trade Recommendations** (Walk-through with actual details)
For each open position, provide specific guidance:

**Format for each recommendation:**
\`\`\`
**[TICKER]** - [DIRECTION] Setup
- **Current Price**: $X.XX
- **Entry Price**: $X.XX (if different from current)
- **Stop Loss**: $X.XX (risk: $X.XX per share, X.X% risk)
- **Take Profit**: $X.XX (reward: $X.XX per share, X.X% reward)
- **Risk/Reward**: X.X:1
- **Current Status**: X% to TP / X% above SL
- **When to Trim**: Trim 50% at $X.XX (first TP level)
- **Action Plan**: [Specific guidance - e.g., "Hold until TP at $X.XX, then trim 50%. Move SL to breakeven if price reaches $X.XX"]
- **Risk Assessment**: [Any concerns - e.g., "Approaching SL, consider tightening stop if price breaks below $X.XX"]
\`\`\`

Provide 3-5 most important open positions with full walk-through details. Be specific about price levels, percentages, and exact actions.

### 6. **Recommendations for Scoring/Capturing** (System improvements)
Based on today's data:
- Should we adjust minimum rank thresholds? (e.g., "Rank ≥80 showed 85% win rate vs 60% for Rank 70-80")
- Should we adjust RR requirements? (e.g., "RR ≥2.0 trades had perfect win rate")
- Are certain signal combinations performing better? (e.g., "EMA_CROSS+SQUEEZE_RELEASE+MOMENTUM_ELITE had 90% win rate")
- What patterns should we focus on? (e.g., "Focus on Momentum Elite stocks with squeeze releases")

### 7. **What to Watch Tomorrow**
- What setups are forming?
- What signals are developing?
- Any warnings or opportunities?

**Writing Style:**
- Write in a narrative, conversational tone (like explaining to a colleague)
- Use specific data points and examples
- Be detailed about signal mechanics (e.g., "EMA crossovers on the daily timeframe when price was above the 21 EMA")
- Reference actual tickers when relevant
- Make it insightful, not just data-dumping

**Length:** Aim for 800-1200 words. Be thorough but focused.`;

          // Call OpenAI API
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), 30000);

          let aiResponse;
          try {
            aiResponse = await fetch(
              "https://api.openai.com/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  Authorization: `Bearer ${openaiApiKey}`,
                  "Content-Type": "application/json",
                },
                body: JSON.stringify({
                  model:
                    env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                      ? env.OPENAI_MODEL
                      : "gpt-3.5-turbo",
                  messages: [{ role: "system", content: summaryPrompt }],
                  temperature: 0.7,
                  max_tokens: 2000,
                }),
                signal: controller.signal,
              },
            );
          } catch (fetchError) {
            clearTimeout(timeoutId);
            if (fetchError.name === "AbortError") {
              throw new Error("Request timeout");
            }
            throw new Error(`Network error: ${fetchError.message}`);
          }

          clearTimeout(timeoutId);

          if (!aiResponse.ok) {
            throw new Error(`OpenAI API error: ${aiResponse.status}`);
          }

          const aiData = await aiResponse.json();
          const summary =
            aiData.choices?.[0]?.message?.content ||
            "Daily summary unavailable.";

          return sendJSON(
            {
              ok: true,
              summary,
              stats: {
                date: targetDate.toISOString().split("T")[0],
                newTrades: newTrades.length,
                closedTrades: closedTrades.length,
                trimmedTrades: trimmedTrades.length,
                wins,
                losses,
                winRate: winRate.toFixed(1),
                closedPnl: closedPnl.toFixed(2),
                openPnl: openPnl.toFixed(2),
                trimmedPnl: trimmedPnl.toFixed(2),
                totalPnl: (closedPnl + openPnl + trimmedPnl).toFixed(2),
                rankAnalysis,
                rrAnalysis,
                signalAnalysis,
                topSignals: topSignals.map(([signals, stats]) => ({
                  signals,
                  ...stats,
                })),
              },
              timestamp: Date.now(),
            },
            200,
            aiChatCorsHeaders,
          );
        } catch (error) {
          console.error("[DAILY SUMMARY ERROR]", error);
          return sendJSON(
            {
              ok: false,
              error: error.message || "Daily summary service error",
            },
            500,
            aiChatCorsHeaders,
          );
        }
      }

      // GET /timed/ai/monitor (Real-time Monitoring & Proactive Alerts)
      if (routeKey === "GET /timed/ai/monitor") {
        const origin = req?.headers?.get("Origin") || "";
        const allowedOrigin = origin.includes("timedtrading.pages.dev")
          ? origin
          : "*";
        const aiChatCorsHeaders = {
          "Access-Control-Allow-Origin": allowedOrigin,
          "Access-Control-Allow-Methods": "GET,POST,OPTIONS",
          "Access-Control-Allow-Headers": "Content-Type",
          Vary: "Origin",
        };

        try {
          const openaiApiKey = env.OPENAI_API_KEY;
          if (!openaiApiKey) {
            return sendJSON(
              {
                ok: false,
                error:
                  "AI service not configured. Please set OPENAI_API_KEY secret.",
              },
              503,
              aiChatCorsHeaders,
            );
          }

          // Fetch all ticker data
          const allKeys = await KV.list({ prefix: "timed:latest:" });
          const tickerDataPromises = allKeys.keys
            .slice(0, 50)
            .map(async (key) => {
              try {
                const data = await kvGetJSON(KV, key.name);
                if (data) {
                  const ticker = key.name.replace("timed:latest:", "");
                  return {
                    ticker,
                    rank: Number(data.rank) || 0,
                    rr: Number(data.rr) || 0,
                    price: Number(data.price) || 0,
                    state: String(data.state || ""),
                    phase_pct: Number(data.phase_pct) || 0,
                    completion: Number(data.completion) || 0,
                    flags: data.flags || {},
                    htf_score: Number(data.htf_score) || 0,
                    ltf_score: Number(data.ltf_score) || 0,
                    sl: Number(data.sl) || 0,
                    tp: Number(data.tp) || 0,
                  };
                }
                return null;
              } catch (err) {
                console.error(`[AI MONITOR] Error fetching ${key.name}:`, err);
                return null;
              }
            });

          const allTickers = (await Promise.all(tickerDataPromises))
            .filter(Boolean)
            .sort((a, b) => (b.rank || 0) - (a.rank || 0));

          // Fetch recent activity feed (last 20 events)
          const activityKeys = await KV.list({ prefix: "timed:activity:" });
          const recentActivity = [];
          const activityPromises = activityKeys.keys
            .slice(-20)
            .map(async (key) => {
              try {
                const data = await kvGetJSON(KV, key.name);
                if (data) {
                  return {
                    ticker: String(data.ticker || "UNKNOWN"),
                    type: String(data.type || "event"),
                    ts: Number(data.ts) || Date.now(),
                    price: Number(data.price) || 0,
                    rank: Number(data.rank) || 0,
                  };
                }
                return null;
              } catch (err) {
                return null;
              }
            });

          const activityEvents = (await Promise.all(activityPromises))
            .filter(Boolean)
            .sort((a, b) => b.ts - a.ts)
            .slice(0, 20);

          // Fetch trade history for pattern recognition
          const tradesKey = "timed:trades:all";
          const allTradesForHistory = (await kvGetJSON(KV, tradesKey)) || [];
          const tradeHistory = allTradesForHistory
            .filter((t) => t.status === "WIN" || t.status === "LOSS")
            .slice(-50) // Increased to 50 for better pattern recognition
            .map((t) => ({
              ticker: String(t.ticker || ""),
              direction: String(t.direction || ""),
              status: String(t.status || ""),
              pnl: Number(t.pnl) || 0,
              rank: Number(t.rank) || 0,
              rr: Number(t.rr) || 0,
              entryTime: String(t.entryTime || ""),
              state: String(t.state || ""),
              flags: t.flags || {},
            }));

          // Pattern Recognition: Analyze winning patterns
          const winningPatterns = analyzeWinningPatterns(
            tradeHistory,
            allTickers,
          );

          // Proactive Alerts: Detect conditions that need attention
          const proactiveAlerts = generateProactiveAlerts(
            allTickers,
            allTradesForHistory,
          );

          // Analyze for proactive alerts
          const primeSetups = allTickers.filter(
            (t) =>
              t.rank >= 75 &&
              t.rr >= 1.5 &&
              t.completion < 0.4 &&
              t.phase_pct < 0.6,
          );

          const highRiskPositions = allTickers.filter(
            (t) => t.completion > 0.7 || t.phase_pct > 0.8,
          );

          const momentumEliteSetups = allTickers.filter(
            (t) => t.flags?.momentum_elite && t.rank >= 70,
          );

          // Build monitoring prompt
          const monitoringPrompt = `You are an AI trading monitor for the Timed Trading platform. Your role is to continuously observe market conditions, identify opportunities, warn about risks, and provide actionable insights.

## YOUR MONITORING CAPABILITIES
- **Real-time Market Analysis**: Monitor all tickers and activity feeds
- **Proactive Alerts**: Identify good trades, warnings, trim/exit signals
- **Pattern Recognition**: Learn from trade history and identify patterns
- **Risk Management**: Flag high-risk positions and suggest exits
- **Opportunity Detection**: Surface prime setups and momentum elite stocks

## CURRENT MARKET DATA
- **${allTickers.length} total tickers** being monitored
- **${
            primeSetups.length
          } prime setups** (Rank ≥75, RR ≥1.5, Completion <40%, Phase <60%)
- **${
            highRiskPositions.length
          } high-risk positions** (Completion >70% or Phase >80%)
- **${momentumEliteSetups.length} Momentum Elite setups**
- **${activityEvents.length} recent activity events**
- **${tradeHistory.length} closed trades** for pattern analysis

### Top Prime Setups (${primeSetups.slice(0, 10).length}):
${
  primeSetups
    .slice(0, 10)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: Rank ${
        t.rank
      } | RR ${rrFormatted} | Price $${t.price.toFixed(2)} | Phase ${(
        t.phase_pct * 100
      ).toFixed(0)}% | Completion ${(t.completion * 100).toFixed(0)}%`;
    })
    .join("\n") || "None"
}

### High-Risk Positions (${highRiskPositions.slice(0, 10).length}):
${
  highRiskPositions
    .slice(0, 10)
    .map(
      (t) =>
        `- **${t.ticker}**: Rank ${t.rank}, Completion ${(
          t.completion * 100
        ).toFixed(0)}%, Phase ${(t.phase_pct * 100).toFixed(
          0,
        )}%, Price $${t.price.toFixed(2)}`,
    )
    .join("\n") || "None"
}

### Recent Activity (Last ${activityEvents.slice(0, 10).length}):
${
  activityEvents
    .slice(0, 10)
    .map(
      (a) =>
        `- ${new Date(a.ts).toLocaleTimeString()}: **${a.ticker}** ${
          a.type
        } at $${a.price.toFixed(2)}`,
    )
    .join("\n") || "None"
}

### Trade History Patterns (Last ${tradeHistory.length}):
${
  tradeHistory.length > 0
    ? `Win Rate: ${(
        (tradeHistory.filter((t) => t.status === "WIN").length /
          tradeHistory.length) *
        100
      ).toFixed(1)}%\n` +
      `Avg P&L: $${(
        tradeHistory.reduce((sum, t) => sum + (t.pnl || 0), 0) /
        tradeHistory.length
      ).toFixed(2)}\n` +
      `Best Performers: ${tradeHistory
        .filter((t) => t.pnl > 0)
        .sort((a, b) => b.pnl - a.pnl)
        .slice(0, 5)
        .map((t) => `${t.ticker} (+$${t.pnl.toFixed(2)})`)
        .join(", ")}`
    : "No trade history available"
}

### Pattern Recognition Insights:
${winningPatterns.summary || "Analyzing patterns..."}

### Proactive Alerts (${proactiveAlerts.length}):
${
  proactiveAlerts.length > 0
    ? proactiveAlerts
        .slice(0, 10)
        .map((a) => `- **${a.type}**: ${a.message}`)
        .join("\n")
    : "No alerts at this time"
}

## MONITORING RESPONSE FORMAT

Provide a well-structured, easy-to-read analysis with clear spacing and formatting:

### 🎯 Opportunities

List prime setups worth watching and pattern matches. For each opportunity:
- Use bullet points with ticker symbol in **bold**
- Include: Rank, RR, Price, Phase %, Completion %
- Add a brief reason why it's worth watching
- Leave a blank line between each opportunity

Example format:
\`\`\`
- **AWI**: Rank 89 | RR 2.00:1 | Price $189.56 | Phase 34% | Completion 15%
  Prime setup with excellent risk/reward and early stage positioning.
\`\`\`

### ⚠️ Warnings

List high-risk positions and positions approaching TP/SL. Group by type:
- **High-Risk Positions**: (Completion >70% or Phase >80%)
- **Approaching TP**: (Within 5% of Take Profit - consider trimming)
- **Approaching SL**: (Within 5% of Stop Loss - monitor closely)

For each warning:
- Use bullet points with ticker symbol in **bold**
- Include relevant metrics (Completion %, Phase %, distance to TP/SL)
- Add specific action recommendation
- Leave a blank line between each warning

Example format:
\`\`\`
**High-Risk Positions:**
- **ALB**: Rank 90 | Completion 19% | Phase 83% | Price $162.05
  Late phase position - consider trimming or tightening stops.

**Approaching TP:**
- **GS**: Within 2.3% of TP at $940.68
  Consider trimming 50% at TP to lock in profits.
\`\`\`

### 📊 Market Insights

Provide overall market conditions and pattern recognition findings:
- Start with a brief summary sentence
- Reference pattern recognition insights from above
- Mention any notable trends or patterns
- Use bullet points for key insights
- Leave blank lines between major points

### 💡 Recommendations

Provide 3-5 actionable next steps:
- Number each recommendation (1., 2., 3.)
- Be specific and actionable
- Reference specific tickers when relevant
- Include price levels or percentages when applicable
- Leave blank lines between each recommendation

**FORMATTING GUIDELINES:**
- Use **bold** for ticker symbols and key terms
- Use blank lines (double newlines) to separate major sections
- Use bullet points (-) for lists within sections
- Use numbered lists (1., 2., 3.) for recommendations
- Keep paragraphs short (2-3 sentences max)
- Use code formatting for specific values like prices or percentages

**IMPORTANT**: Reference the proactive alerts above and pattern recognition insights. Prioritize alerts marked as "high" priority. Be concise but thorough. Focus on actionable insights, not just data.`;

          // Call OpenAI API
          const controller = new AbortController();
          const timeoutId = setTimeout(() => controller.abort(), 30000);

          let aiResponse;
          try {
            aiResponse = await fetch(
              "https://api.openai.com/v1/chat/completions",
              {
                method: "POST",
                headers: {
                  Authorization: `Bearer ${openaiApiKey}`,
                  "Content-Type": "application/json",
                },
                body: JSON.stringify({
                  model:
                    env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                      ? env.OPENAI_MODEL
                      : "gpt-3.5-turbo",
                  messages: [{ role: "system", content: monitoringPrompt }],
                  temperature: 0.7,
                  max_tokens: 1000,
                }),
                signal: controller.signal,
              },
            );
          } catch (fetchError) {
            clearTimeout(timeoutId);
            if (fetchError.name === "AbortError") {
              throw new Error("Request timeout");
            }
            throw new Error(`Network error: ${fetchError.message}`);
          }

          clearTimeout(timeoutId);

          if (!aiResponse.ok) {
            let errorData = {};
            try {
              errorData = await aiResponse.json();
            } catch (e) {
              errorData = { error: { message: aiResponse.statusText } };
            }
            throw new Error(
              errorData.error?.message ||
                `OpenAI API error: ${aiResponse.status}`,
            );
          }

          const aiData = await aiResponse.json();
          const aiMessage =
            aiData.choices?.[0]?.message?.content ||
            "Monitoring analysis unavailable.";

          return sendJSON(
            {
              ok: true,
              analysis: aiMessage,
              stats: {
                totalTickers: allTickers.length,
                primeSetups: primeSetups.length,
                highRiskPositions: highRiskPositions.length,
                momentumElite: momentumEliteSetups.length,
                recentActivity: activityEvents.length,
                tradeHistory: tradeHistory.length,
              },
              timestamp: Date.now(),
            },
            200,
            aiChatCorsHeaders,
          );
        } catch (error) {
          console.error("[AI MONITOR ERROR]", error);
          return sendJSON(
            {
              ok: false,
              error: error.message || "Monitoring service error",
            },
            500,
            aiChatCorsHeaders,
          );
        }
      }

      // ─────────────────────────────────────────────────────────────
      // Debug Endpoints
      // ─────────────────────────────────────────────────────────────

      // ═══════════════════════════════════════════════════════════════════════
      // INVESTOR INTELLIGENCE ENDPOINTS
      // ═══════════════════════════════════════════════════════════════════════

      // POST /timed/investor/compute — Compute all investor scores + market health
      // This runs the full investor scoring pipeline and stores results in KV
      if (routeKey === "POST /timed/investor/compute") {
        try {
          // Fetch all ticker data from KV
          const tickerListResp = await kvGetJSON(env.KV_TIMED, "timed:tickers");
          const allTickers = tickerListResp || [];
          const tickerSyms = allTickers.map(t => typeof t === "string" ? t : t.ticker).filter(Boolean);

          // Get SPY candles for relative strength
          let spyCandles = [];
          try {
            const spyResp = await env.DB.prepare(
              "SELECT ts, c FROM ticker_candles WHERE ticker = 'SPY' AND tf = 'D' ORDER BY ts ASC LIMIT 300"
            ).all();
            spyCandles = spyResp?.results || [];
          } catch {}

          const allTickerData = [];
          const allRS3m = [];
          const rsMap = {};
          const investorResults = {};

          // Phase 1: Fetch all ticker data + compute RS
          for (const ticker of tickerSyms) {
            const td = await kvGetJSON(env.KV_TIMED, `timed:latest:${ticker}`);
            if (!td || !td.price) continue;
            td._sector = SECTOR_MAP[ticker] || "Unknown";
            allTickerData.push(td);

            // Compute relative strength
            let tickerCandles = [];
            try {
              const resp = await env.DB.prepare(
                "SELECT ts, c FROM ticker_candles WHERE ticker = ? AND tf = 'D' ORDER BY ts ASC LIMIT 300"
              ).bind(ticker).all();
              tickerCandles = resp?.results || [];
            } catch {}

            const rs = computeRelativeStrength(tickerCandles, spyCandles);
            rsMap[ticker] = rs;
            if (Number.isFinite(rs.rs3m)) allRS3m.push(rs.rs3m);
          }

          // Phase 2: Compute RS ranks
          const rsRanks = {};
          for (const [ticker, rs] of Object.entries(rsMap)) {
            rsRanks[ticker] = computeRSRank(rs.rs3m, allRS3m);
          }

          // Phase 3: Compute sector RS ranks
          const sectorRS = {};
          for (const td of allTickerData) {
            const sector = td._sector;
            if (!sectorRS[sector]) sectorRS[sector] = [];
            const rs = rsMap[td.ticker];
            if (rs && Number.isFinite(rs.rs3m)) {
              sectorRS[sector].push(rs.rs3m);
            }
          }
          const sectorRsRanks = {};
          for (const [sector, values] of Object.entries(sectorRS)) {
            const avg = values.length > 0 ? values.reduce((s, v) => s + v, 0) / values.length : 0;
            sectorRsRanks[sector] = computeRSRank(avg, allRS3m);
          }

          // Phase 4: Market health
          const spyData = allTickerData.find(td => td.ticker === "SPY");
          const qqqData = allTickerData.find(td => td.ticker === "QQQ");
          const marketHealth = computeMarketHealth(allTickerData, spyData, qqqData);

          // Phase 5: Compute investor scores + stages for all tickers
          const allInvestorScores = {};
          const allAccumZones = {};
          const allStages = {};
          const allTheses = {};

          for (const td of allTickerData) {
            const ticker = td.ticker;
            const sector = td._sector;
            const rsRank = rsRanks[ticker] || 50;
            const sectorRsRank = sectorRsRanks[sector] || 50;

            const { score, components, accumZone } = computeInvestorScore(td, {
              rsRank, sectorRsRank, marketHealth: marketHealth.score,
            });

            allInvestorScores[ticker] = score;
            allAccumZones[ticker] = accumZone;

            // Investor stage (no position assumed for general compute)
            const stage = classifyInvestorStage(td, score, null, {
              rsRank, marketHealth: marketHealth.score, accumZone,
            });
            allStages[ticker] = stage;

            // Thesis
            const thesis = generateThesis(td, rsRank);
            allTheses[ticker] = thesis;

            investorResults[ticker] = {
              score, components, accumZone, sector,
              companyName: td?.context?.name || td?.name || null,
              rsRank, rs: rsMap[ticker] ? {
                rs1m: rsMap[ticker].rs1m,
                rs3m: rsMap[ticker].rs3m,
                rs6m: rsMap[ticker].rs6m,
                rsNewHigh3m: rsMap[ticker].rsNewHigh3m,
                rsNewHigh6m: rsMap[ticker].rsNewHigh6m,
              } : undefined,
              stage: stage.stage,
              stageReason: stage.reason,
              thesis: thesis.thesis,
              thesisInvalidation: thesis.invalidation,
            };
          }

          // ── Phase 5B: Threshold Alerts ──
          // Compare with previous scores to detect critical investor events
          const prevScores = await kvGetJSON(env.KV_TIMED, "timed:investor:scores") || {};
          const investorAlerts = [];

          for (const [ticker, curr] of Object.entries(investorResults)) {
            const prev = prevScores[ticker];

            // Accumulation zone entry (wasn't in zone before, now is)
            if (curr.accumZone?.inZone && (!prev?.accumZone?.inZone)) {
              investorAlerts.push({ type: "accumulation_zone", data: {
                ticker, score: curr.score, rsRank: curr.rsRank,
                confidence: curr.accumZone.confidence, signals: curr.accumZone.signals,
              }});
            }

            // RS breakout (new 3m or 6m high)
            if (curr.rs?.rsNewHigh6m && !prev?.rs?.rsNewHigh6m) {
              investorAlerts.push({ type: "rs_breakout", data: {
                ticker, period: "6-month", rsRank: curr.rsRank,
                rs3m: curr.rs.rs3m, score: curr.score,
              }});
            } else if (curr.rs?.rsNewHigh3m && !prev?.rs?.rsNewHigh3m) {
              investorAlerts.push({ type: "rs_breakout", data: {
                ticker, period: "3-month", rsRank: curr.rsRank,
                rs3m: curr.rs.rs3m, score: curr.score,
              }});
            }

            // Thesis invalidation (stage changed to "reduce" from something better)
            if (curr.stage === "reduce" && prev?.stage && prev.stage !== "reduce" && prev.stage !== "exited") {
              investorAlerts.push({ type: "thesis_invalidation", data: {
                ticker, reasons: [curr.stageReason],
              }});
            }
          }

          // Send top 5 alerts to Discord (avoid spam)
          const alertsSent = [];
          for (const alert of investorAlerts.slice(0, 5)) {
            const embed = createInvestorAlertEmbed(alert.type, alert.data);
            if (embed) {
              ctx.waitUntil(notifyDiscord(env, embed));
              alertsSent.push({ type: alert.type, ticker: alert.data.ticker });
            }
          }

          // Store in KV
          await kvPutJSON(env.KV_TIMED, "timed:investor:scores", investorResults);
          await kvPutJSON(env.KV_TIMED, "timed:investor:market-health", marketHealth);
          await kvPutJSON(env.KV_TIMED, "timed:investor:stages", allStages);
          await kvPutJSON(env.KV_TIMED, "timed:investor:rs-ranks", rsRanks);
          await kvPutJSON(env.KV_TIMED, "timed:investor:computed-at", Date.now());

          return sendJSON({
            ok: true,
            tickers: Object.keys(investorResults).length,
            marketHealth,
            alertsSent,
            topAccumulate: Object.entries(allStages)
              .filter(([, s]) => s.stage === "accumulate")
              .map(([t]) => ({ ticker: t, score: allInvestorScores[t], rsRank: rsRanks[t] }))
              .sort((a, b) => b.score - a.score)
              .slice(0, 10),
          }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // ── Daily Brief endpoints ──

      if (routeKey === "GET /timed/daily-brief") {
        try {
          const result = await handleGetBrief(env);
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "GET /timed/daily-brief/badge") {
        try {
          const result = await handleGetBadge(env);
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "GET /timed/daily-brief/archive") {
        try {
          const month = new URL(req.url).searchParams.get("month");
          const result = await handleGetArchive(env, month);
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "GET /timed/daily-brief/archive/:id") {
        try {
          const briefId = pathname.replace("/timed/daily-brief/archive/", "");
          const result = await handleGetArchiveBrief(env, briefId);
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "POST /timed/daily-brief/predict") {
        try {
          const url = new URL(req.url);
          const briefId = url.searchParams.get("id");
          const correct = url.searchParams.get("correct");
          if (!briefId || correct == null) {
            return sendJSON({ ok: false, error: "Missing id or correct param" }, 400, corsHeaders(env, req));
          }
          const result = await handleMarkPrediction(env, briefId, correct);
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/daily-brief/generate?key=...&type=morning|evening — manually trigger brief generation
      if (routeKey === "POST /timed/daily-brief/generate") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        try {
          const briefType = new URL(req.url).searchParams.get("type") || "morning";
          const dataOnly = new URL(req.url).searchParams.get("data_only") === "1";
          if (briefType !== "morning" && briefType !== "evening") {
            return sendJSON({ ok: false, error: "type must be morning or evening" }, 400, corsHeaders(env, req));
          }
          if (dataOnly) {
            // Return raw gathered data for debugging (no AI call)
            const data = await gatherDailyBriefData(env, briefType, {
              SECTOR_MAP,
              d1GetCandles,
            });
            return sendJSON({ ok: true, data }, 200, corsHeaders(env, req));
          }
          const result = await generateDailyBrief(env, briefType, {
            SECTOR_MAP,
            d1GetCandles,
            notifyDiscord,
            d1InsertNotification,
          });
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 500) }, 500, corsHeaders(env, req));
        }
      }

      // ── Admin: UPTICKS list (KV-persisted) ──
      if (routeKey === "GET /timed/admin/upticks") {
        try {
          const stored = await kvGetJSON(KV, "timed:admin:upticks");
          const list = Array.isArray(stored) ? stored : [];
          return sendJSON({ ok: true, tickers: list }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }
      if (routeKey === "PUT /timed/admin/upticks") {
        try {
          const body = await req.json();
          const tickers = Array.isArray(body?.tickers) ? body.tickers.map(t => String(t).toUpperCase().trim()).filter(Boolean) : [];
          const unique = [...new Set(tickers)];
          await kvPutJSON(KV, "timed:admin:upticks", unique);
          return sendJSON({ ok: true, count: unique.length, tickers: unique }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      // ── Admin: Sector Ratings (KV-persisted) ──
      if (routeKey === "GET /timed/admin/sector-ratings") {
        try {
          const stored = await kvGetJSON(KV, "timed:admin:sector_ratings");
          const ratings = (stored && typeof stored === "object") ? stored : {};
          const merged = { ...SECTOR_RATINGS };
          for (const [sector, val] of Object.entries(ratings)) {
            if (merged[sector]) Object.assign(merged[sector], val);
            else merged[sector] = val;
          }
          return sendJSON({ ok: true, ratings: merged }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }
      if (routeKey === "PUT /timed/admin/sector-ratings") {
        try {
          const body = await req.json();
          const ratings = (body?.ratings && typeof body.ratings === "object") ? body.ratings : {};
          await kvPutJSON(KV, "timed:admin:sector_ratings", ratings);
          // Also update in-memory SECTOR_RATINGS so scoring picks up changes immediately
          for (const [sector, val] of Object.entries(ratings)) {
            if (SECTOR_RATINGS[sector] && typeof val === "object") {
              Object.assign(SECTOR_RATINGS[sector], val);
            }
          }
          return sendJSON({ ok: true, updated: Object.keys(ratings).length }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      // ── ETF Holdings Sync ──
      if (routeKey === "GET /timed/etf/groups") {
        try {
          const result = await handleGetETFGroups(env);
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "GET /timed/etf/holdings/:symbol") {
        try {
          const symbol = pathname.replace("/timed/etf/holdings/", "").toUpperCase();
          const result = await handleGetETFHoldings(env, symbol);
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      if (routeKey === "POST /timed/etf/sync") {
        try {
          const result = await syncAllETFHoldings(env, {
            notifyDiscord,
            addToUniverse: (env2, tickers, wMap) => etfAutoAddTickers(env2, tickers, wMap, ctx),
          });
          return sendJSON(result, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e).slice(0, 200) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/investor/scores — Get all investor scores (from KV cache)
      if (routeKey === "GET /timed/investor/scores") {
        const scores = await kvGetJSON(env.KV_TIMED, "timed:investor:scores");
        const computedAt = await kvGetJSON(env.KV_TIMED, "timed:investor:computed-at");
        if (!scores) {
          return sendJSON({ ok: false, error: "No investor scores computed yet. POST /timed/investor/compute first." }, 404, corsHeaders(env, req));
        }

        // Enrich with live prices (single KV read — { prices: { ORCL: { p, dc, pc, ... } } })
        const pricesKV = await kvGetJSON(env.KV_TIMED, "timed:prices") || {};
        const priceMap = pricesKV.prices || {};

        // Optional filter
        const stage = url.searchParams.get("stage");
        const minScore = Number(url.searchParams.get("minScore") || 0);
        const sector = url.searchParams.get("sector");
        const sort = url.searchParams.get("sort") || "score";

        let entries = Object.entries(scores).map(([ticker, data]) => {
          const pf = priceMap[ticker];
          const price = pf ? Number(pf.p) : null;
          const prevClose = pf ? Number(pf.pc) : null;
          const dailyChgPct = pf ? Number(pf.dp) : null;  // dp = daily percent change, dc = dollar change
          const dailyChgDollar = pf ? Number(pf.dc) : null;
          return {
            ticker, ...data,
            sector: data.sector || SECTOR_MAP[ticker] || "Unknown",
            companyName: data.companyName || null,
            price: Number.isFinite(price) ? price : null,
            dailyChgPct: Number.isFinite(dailyChgPct) ? dailyChgPct : null,
            dailyChgDollar: Number.isFinite(dailyChgDollar) ? dailyChgDollar : null,
            prevClose: Number.isFinite(prevClose) ? prevClose : null,
          };
        });

        if (stage) entries = entries.filter(e => e.stage === stage);
        if (minScore > 0) entries = entries.filter(e => e.score >= minScore);
        if (sector) entries = entries.filter(e => (e.sector || "") === sector);

        if (sort === "rsRank") entries.sort((a, b) => (b.rsRank || 0) - (a.rsRank || 0));
        else entries.sort((a, b) => (b.score || 0) - (a.score || 0));

        return sendJSON({
          ok: true,
          count: entries.length,
          computedAt,
          tickers: entries,
        }, 200, corsHeaders(env, req));
      }

      // GET /timed/investor/market-health — Get market health (from KV cache)
      if (routeKey === "GET /timed/investor/market-health") {
        const health = await kvGetJSON(env.KV_TIMED, "timed:investor:market-health");
        const computedAt = await kvGetJSON(env.KV_TIMED, "timed:investor:computed-at");
        if (!health) {
          return sendJSON({ ok: false, error: "No market health computed yet." }, 404, corsHeaders(env, req));
        }
        return sendJSON({ ok: true, ...health, computedAt }, 200, corsHeaders(env, req));
      }

      // GET /timed/investor/ticker?ticker=AAPL — Get detailed investor data for a single ticker
      if (routeKey === "GET /timed/investor/ticker") {
        const ticker = (url.searchParams.get("ticker") || "").toUpperCase();
        if (!ticker) return sendJSON({ ok: false, error: "ticker required" }, 400, corsHeaders(env, req));

        const scores = await kvGetJSON(env.KV_TIMED, "timed:investor:scores");
        const health = await kvGetJSON(env.KV_TIMED, "timed:investor:market-health");
        const data = scores?.[ticker];
        if (!data) {
          return sendJSON({ ok: false, error: `No investor data for ${ticker}` }, 404, corsHeaders(env, req));
        }

        return sendJSON({
          ok: true,
          ticker,
          ...data,
          marketHealth: health?.score,
          marketRegime: health?.regime,
          sector: SECTOR_MAP[ticker] || "Unknown",
        }, 200, corsHeaders(env, req));
      }

      // GET /timed/investor/portfolio — Portfolio analytics for investor (uses investor_positions table)
      if (routeKey === "GET /timed/investor/portfolio") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const scores = await kvGetJSON(env.KV_TIMED, "timed:investor:scores") || {};
          const rsRanks = await kvGetJSON(env.KV_TIMED, "timed:investor:rs-ranks") || {};
          const health = await kvGetJSON(env.KV_TIMED, "timed:investor:market-health");

          // Get open investor positions from D1 (investor_positions table)
          const posResp = await env.DB.prepare(
            "SELECT id, ticker, total_shares, cost_basis, avg_entry, thesis, investor_stage, dca_enabled, dca_amount, dca_frequency, dca_next_ts, dca_total_invested, dca_num_buys, target_alloc_pct, first_entry_ts, last_entry_ts FROM investor_positions WHERE status = 'OPEN' AND total_shares > 0"
          ).all();
          const dbPositions = posResp?.results || [];

          // Enrich with current prices
          const positions = [];
          for (const p of dbPositions) {
            const td = await kvGetJSON(env.KV_TIMED, `timed:latest:${p.ticker}`);
            const mark = td?.price || 0;
            positions.push({
              ticker: p.ticker,
              direction: "LONG", // investors are always long
              shares: p.total_shares,
              avgEntry: p.avg_entry,
              mark,
              unrealizedPnl: mark > 0 ? (mark - p.avg_entry) * p.total_shares : 0,
              unrealizedPnlPct: p.avg_entry > 0 && mark > 0 ? ((mark - p.avg_entry) / p.avg_entry * 100) : 0,
              thesis: p.thesis,
              investorStage: p.investor_stage,
              targetAllocPct: p.target_alloc_pct,
              dca: p.dca_enabled ? {
                amount: p.dca_amount, frequency: p.dca_frequency,
                nextDate: p.dca_next_ts ? new Date(p.dca_next_ts).toISOString().slice(0, 10) : null,
                totalInvested: p.dca_total_invested, numBuys: p.dca_num_buys,
              } : null,
              holdingDays: p.first_entry_ts ? Math.round((Date.now() - p.first_entry_ts) / 86400000) : 0,
            });
          }

          const investorScores = {};
          const rsRankMap = {};
          for (const [t, d] of Object.entries(scores)) {
            investorScores[t] = d.score;
            rsRankMap[t] = d.rsRank || rsRanks[t] || 50;
          }

          const analytics = computePortfolioAnalytics(positions, SECTOR_MAP, {
            investorScores, rsRanks: rsRankMap,
          });

          // Accumulation zones
          const allAccumZones = {};
          for (const [t, d] of Object.entries(scores)) {
            if (d.accumZone) allAccumZones[t] = d.accumZone;
          }

          const suggestions = generateRebalancingSuggestions(
            analytics, health?.score || 50, investorScores, allAccumZones, SECTOR_MAP
          );

          return sendJSON({
            ok: true,
            ...analytics,
            marketHealth: health?.score,
            marketRegime: health?.regime,
            suggestions,
          }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/investor/weekly-digest — Generate and send weekly investor digest to Discord
      if (routeKey === "POST /timed/investor/weekly-digest") {
        try {
          const scores = await kvGetJSON(env.KV_TIMED, "timed:investor:scores") || {};
          const health = await kvGetJSON(env.KV_TIMED, "timed:investor:market-health");
          const prevHealth = await kvGetJSON(env.KV_TIMED, "timed:investor:prev-market-health");
          const prevStages = await kvGetJSON(env.KV_TIMED, "timed:investor:prev-stages") || {};
          const currentStages = await kvGetJSON(env.KV_TIMED, "timed:investor:stages") || {};

          // Detect stage changes
          const stageChanges = [];
          for (const [ticker, curr] of Object.entries(currentStages)) {
            const prev = prevStages[ticker];
            if (prev && prev.stage !== curr.stage) {
              stageChanges.push({ ticker, from: prev.stage, to: curr.stage });
            }
          }

          // Top accumulate candidates
          const topAccumulate = Object.entries(scores)
            .filter(([, d]) => d.stage === "accumulate")
            .map(([ticker, d]) => ({ ticker, score: d.score, rsRank: d.rsRank }))
            .sort((a, b) => b.score - a.score)
            .slice(0, 5);

          // Build digest embed
          const embed = createWeeklyDigestEmbed({
            marketHealth: health || {},
            prevMarketHealth: prevHealth,
            stageChanges,
            topAccumulate,
          });

          // Send to Discord
          const discordResult = await notifyDiscord(env, embed);

          // Save current state as "previous" for next week
          await kvPutJSON(env.KV_TIMED, "timed:investor:prev-market-health", health);
          await kvPutJSON(env.KV_TIMED, "timed:investor:prev-stages", currentStages);

          return sendJSON({
            ok: true,
            discord: discordResult,
            stageChanges: stageChanges.length,
            topAccumulate: topAccumulate.length,
          }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════
      // INVESTOR POSITIONS & DCA ENDPOINTS
      // ═══════════════════════════════════════════════════════════════════════

      // GET /timed/investor/positions — list all investor positions
      if (routeKey === "GET /timed/investor/positions") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const status = url.searchParams.get("status") || "OPEN";
          const ticker = url.searchParams.get("ticker");
          const compact = url.searchParams.get("compact") === "true"; // skip lots for lighter payload

          let rows;
          if (ticker) {
            rows = (await env.DB.prepare(
              "SELECT * FROM investor_positions WHERE ticker = ?1 AND status = ?2 ORDER BY updated_at DESC"
            ).bind(ticker.toUpperCase(), status).all())?.results || [];
          } else {
            rows = (await env.DB.prepare(
              "SELECT * FROM investor_positions WHERE status = ?1 ORDER BY updated_at DESC"
            ).bind(status).all())?.results || [];
          }

          // Batch price lookup from timed:prices KV
          const pricesRaw = await kvGetJSON(env.KV_TIMED, "timed:prices");
          const priceMap = {};
          if (pricesRaw?.prices) {
            for (const [sym, pObj] of Object.entries(pricesRaw.prices)) {
              priceMap[sym] = {
                price: Number(pObj.p || pObj.price || 0),
                prevClose: Number(pObj.pc || pObj.prevClose || 0),
                dailyChange: Number(pObj.dc || 0),
                dailyChangePct: Number(pObj.dp || 0),
              };
            }
          }

          // Enrich with current prices and daily change
          const enriched = [];
          for (const p of rows) {
            const pm = priceMap[p.ticker] || {};
            const mark = pm.price || 0;
            const unrealizedPnl = p.total_shares > 0 && mark > 0
              ? (mark - p.avg_entry) * p.total_shares : 0;
            const unrealizedPnlPct = p.avg_entry > 0 && mark > 0
              ? ((mark - p.avg_entry) / p.avg_entry) * 100 : 0;

            const item = {
              ...p,
              currentPrice: mark,
              prevClose: pm.prevClose || 0,
              dailyChange: pm.dailyChange || 0,
              dailyChangePct: pm.dailyChangePct || 0,
              marketValue: Math.round(mark * p.total_shares * 100) / 100,
              unrealizedPnl: Math.round(unrealizedPnl * 100) / 100,
              unrealizedPnlPct: Math.round(unrealizedPnlPct * 100) / 100,
            };

            // Get lots (skip in compact mode)
            if (!compact) {
              const lots = (await env.DB.prepare(
                "SELECT * FROM investor_lots WHERE position_id = ?1 ORDER BY ts DESC LIMIT 50"
              ).bind(p.id).all())?.results || [];
              item.lots = lots;
            }

            enriched.push(item);
          }

          return sendJSON({ ok: true, positions: enriched }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/investor/positions — open a new investor position
      if (routeKey === "POST /timed/investor/positions") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const body = await req.json();
          const { ticker, shares, price, thesis, thesisInvalidation, targetAllocPct, notes } = body;
          if (!ticker || !shares || !price) {
            return sendJSON({ ok: false, error: "ticker, shares, price required" }, 400, corsHeaders(env, req));
          }

          const sym = ticker.toUpperCase();
          const now = Date.now();
          const value = shares * price;
          const posId = `inv-${sym}-${now}`;
          const lotId = `lot-${sym}-${now}`;

          // Check for existing open position
          const existing = (await env.DB.prepare(
            "SELECT id, total_shares, cost_basis FROM investor_positions WHERE ticker = ?1 AND status = 'OPEN' LIMIT 1"
          ).bind(sym).all())?.results?.[0];

          if (existing) {
            // Add to existing position
            const newShares = existing.total_shares + shares;
            const newCost = existing.cost_basis + value;
            const newAvg = newCost / newShares;

            await env.DB.prepare(
              "UPDATE investor_positions SET total_shares = ?1, cost_basis = ?2, avg_entry = ?3, last_entry_ts = ?4, updated_at = ?4 WHERE id = ?5"
            ).bind(newShares, newCost, newAvg, now, existing.id).run();

            await env.DB.prepare(
              "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, 'BUY', ?4, ?5, ?6, ?7, ?8, ?7)"
            ).bind(lotId, existing.id, sym, shares, price, value, now, "manual_add").run();

            // Investor ledger: BUY (add to position)
            const prevBal = await d1GetLedgerBalance(env, "investor");
            d1InsertLedgerEntry(env, {
              mode: "investor", ts: now, event_type: "ENTRY",
              position_id: existing.id, ticker: sym, direction: "LONG",
              qty: shares, price, cash_delta: -value,
              realized_pnl: 0, balance: prevBal - value,
              note: `Add ${shares}sh ${sym} @$${price.toFixed(2)}`,
            }).catch(e => console.error("[LEDGER] investor BUY add failed:", e));

            return sendJSON({ ok: true, positionId: existing.id, action: "added", shares: newShares, avgEntry: newAvg }, 200, corsHeaders(env, req));
          }

          // Create new position
          await env.DB.prepare(`INSERT INTO investor_positions
            (id, ticker, status, total_shares, cost_basis, avg_entry, first_entry_ts, last_entry_ts,
             thesis, thesis_invalidation, target_alloc_pct, notes, created_at, updated_at)
            VALUES (?1, ?2, 'OPEN', ?3, ?4, ?5, ?6, ?6, ?7, ?8, ?9, ?10, ?6, ?6)
          `).bind(posId, sym, shares, value, price, now,
            thesis || null, thesisInvalidation || null,
            targetAllocPct || null, notes || null).run();

          await env.DB.prepare(
            "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, 'BUY', ?4, ?5, ?6, ?7, 'initial_entry', ?7)"
          ).bind(lotId, posId, sym, shares, price, value, now).run();

          // Investor ledger: BUY (new position)
          const prevBalNew = await d1GetLedgerBalance(env, "investor");
          d1InsertLedgerEntry(env, {
            mode: "investor", ts: now, event_type: "ENTRY",
            position_id: posId, ticker: sym, direction: "LONG",
            qty: shares, price, cash_delta: -value,
            realized_pnl: 0, balance: prevBalNew - value,
            note: `New position ${shares}sh ${sym} @$${price.toFixed(2)}`,
          }).catch(e => console.error("[LEDGER] investor BUY new failed:", e));

          return sendJSON({ ok: true, positionId: posId, action: "created", shares, avgEntry: price }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // PUT /timed/investor/positions — update position metadata (thesis, notes, target allocation)
      if (routeKey === "PUT /timed/investor/positions") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const body = await req.json();
          const { ticker, thesis, thesisInvalidation, targetAllocPct, notes, investorStage } = body;
          if (!ticker) return sendJSON({ ok: false, error: "ticker required" }, 400, corsHeaders(env, req));

          const sym = ticker.toUpperCase();
          const now = Date.now();
          const sets = [];
          const vals = [];
          let idx = 1;

          if (thesis !== undefined) { sets.push(`thesis = ?${idx++}`); vals.push(thesis); }
          if (thesisInvalidation !== undefined) { sets.push(`thesis_invalidation = ?${idx++}`); vals.push(thesisInvalidation); }
          if (targetAllocPct !== undefined) { sets.push(`target_alloc_pct = ?${idx++}`); vals.push(targetAllocPct); }
          if (notes !== undefined) { sets.push(`notes = ?${idx++}`); vals.push(notes); }
          if (investorStage !== undefined) { sets.push(`investor_stage = ?${idx++}`); vals.push(investorStage); }
          sets.push(`updated_at = ?${idx++}`); vals.push(now);

          if (sets.length < 2) return sendJSON({ ok: false, error: "no fields to update" }, 400, corsHeaders(env, req));

          vals.push(sym); // for WHERE
          await env.DB.prepare(
            `UPDATE investor_positions SET ${sets.join(", ")} WHERE ticker = ?${idx} AND status = 'OPEN'`
          ).bind(...vals).run();

          return sendJSON({ ok: true, ticker: sym }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // DELETE /timed/investor/positions — close/sell an investor position
      if (routeKey === "DELETE /timed/investor/positions") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const body = await req.json();
          const { ticker, shares, price, reason } = body;
          if (!ticker) return sendJSON({ ok: false, error: "ticker required" }, 400, corsHeaders(env, req));

          const sym = ticker.toUpperCase();
          const now = Date.now();

          const pos = (await env.DB.prepare(
            "SELECT * FROM investor_positions WHERE ticker = ?1 AND status = 'OPEN' LIMIT 1"
          ).bind(sym).all())?.results?.[0];

          if (!pos) return sendJSON({ ok: false, error: "no open position for " + sym }, 404, corsHeaders(env, req));

          const sellShares = shares || pos.total_shares;
          const sellPrice = price || 0;
          const sellValue = sellShares * sellPrice;
          const remaining = pos.total_shares - sellShares;
          const lotId = `lot-${sym}-sell-${now}`;

          // Log the sell lot
          await env.DB.prepare(
            "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, 'SELL', ?4, ?5, ?6, ?7, ?8, ?7)"
          ).bind(lotId, pos.id, sym, sellShares, sellPrice, sellValue, now, reason || "manual_sell").run();

          if (remaining <= 0.0001) {
            // Full close
            const pnl = sellValue - pos.cost_basis;
            await env.DB.prepare(
              "UPDATE investor_positions SET status = 'CLOSED', total_shares = 0, closed_at = ?1, updated_at = ?1 WHERE id = ?2"
            ).bind(now, pos.id).run();

            // Investor ledger: EXIT (full close)
            const prevBalClose = await d1GetLedgerBalance(env, "investor");
            d1InsertLedgerEntry(env, {
              mode: "investor", ts: now, event_type: "EXIT",
              position_id: pos.id, ticker: sym, direction: "LONG",
              qty: sellShares, price: sellPrice, cash_delta: sellValue,
              realized_pnl: pnl, balance: prevBalClose + sellValue,
              note: `Close ${sym} ${sellShares}sh @$${sellPrice.toFixed(2)} PnL=$${pnl.toFixed(2)}`,
            }).catch(e => console.error("[LEDGER] investor EXIT failed:", e));

            return sendJSON({ ok: true, action: "closed", pnl: Math.round(pnl * 100) / 100, pnlPct: pos.cost_basis > 0 ? Math.round(pnl / pos.cost_basis * 10000) / 100 : 0 }, 200, corsHeaders(env, req));
          } else {
            // Partial sell
            const newCost = pos.cost_basis * (remaining / pos.total_shares);
            const partialCostBasis = pos.cost_basis * (sellShares / pos.total_shares);
            const partialPnl = sellValue - partialCostBasis;
            await env.DB.prepare(
              "UPDATE investor_positions SET total_shares = ?1, cost_basis = ?2, avg_entry = ?3, updated_at = ?4 WHERE id = ?5"
            ).bind(remaining, newCost, pos.avg_entry, now, pos.id).run();

            // Investor ledger: TRIM (partial sell)
            const prevBalPartial = await d1GetLedgerBalance(env, "investor");
            d1InsertLedgerEntry(env, {
              mode: "investor", ts: now, event_type: "TRIM",
              position_id: pos.id, ticker: sym, direction: "LONG",
              qty: sellShares, price: sellPrice, cash_delta: sellValue,
              realized_pnl: partialPnl, balance: prevBalPartial + sellValue,
              note: `Partial sell ${sym} ${sellShares}sh @$${sellPrice.toFixed(2)} PnL=$${partialPnl.toFixed(2)}`,
            }).catch(e => console.error("[LEDGER] investor TRIM failed:", e));

            return sendJSON({ ok: true, action: "partial_sell", remainingShares: remaining, soldShares: sellShares }, 200, corsHeaders(env, req));
          }
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // DELETE /timed/investor/purge-ticker — admin: completely remove a ticker from investor tables
      if (routeKey === "DELETE /timed/investor/purge-ticker") {
        try {
          const body = await req.json();
          const tickerRaw = body?.ticker;
          if (!tickerRaw) return sendJSON({ ok: false, error: "ticker required" }, 400, corsHeaders(env, req));
          const sym = tickerRaw.toUpperCase();
          const db = env.DB;

          // 1. Delete investor_lots for this ticker
          const lotsResult = await db.prepare("DELETE FROM investor_lots WHERE ticker = ?1").bind(sym).run();
          const lotsDeleted = lotsResult?.meta?.changes || 0;

          // 2. Delete investor_positions for this ticker
          const posResult = await db.prepare("DELETE FROM investor_positions WHERE ticker = ?1").bind(sym).run();
          const posDeleted = posResult?.meta?.changes || 0;

          // 3. Delete account_ledger entries for this ticker with mode='investor'
          const ledgerResult = await db.prepare("DELETE FROM account_ledger WHERE mode = 'investor' AND ticker = ?1").bind(sym).run();
          const ledgerDeleted = ledgerResult?.meta?.changes || 0;

          console.log(`[PURGE] ${sym}: lots=${lotsDeleted}, positions=${posDeleted}, ledger=${ledgerDeleted}`);
          return sendJSON({
            ok: true,
            ticker: sym,
            deleted: { lots: lotsDeleted, positions: posDeleted, ledger: ledgerDeleted },
          }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/investor/positions/lot — manually add a buy/sell lot to an existing position
      if (routeKey === "POST /timed/investor/positions/lot") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const body = await req.json();
          const { ticker, action, shares, price, reason } = body;
          if (!ticker || !action || !shares || !price) {
            return sendJSON({ ok: false, error: "ticker, action (BUY/SELL), shares, price required" }, 400, corsHeaders(env, req));
          }

          const sym = ticker.toUpperCase();
          const act = action.toUpperCase();
          const now = Date.now();
          const value = shares * price;

          const pos = (await env.DB.prepare(
            "SELECT * FROM investor_positions WHERE ticker = ?1 AND status = 'OPEN' LIMIT 1"
          ).bind(sym).all())?.results?.[0];

          if (!pos) return sendJSON({ ok: false, error: "no open position for " + sym }, 404, corsHeaders(env, req));

          const lotId = `lot-${sym}-${act.toLowerCase()}-${now}`;
          await env.DB.prepare(
            "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?8)"
          ).bind(lotId, pos.id, sym, act, shares, price, value, now, reason || "manual").run();

          let newShares = pos.total_shares;
          let newCost = pos.cost_basis;
          if (act === "BUY") {
            newShares += shares;
            newCost += value;
          } else if (act === "SELL") {
            newShares = Math.max(0, newShares - shares);
            newCost = newShares > 0 ? pos.cost_basis * (newShares / pos.total_shares) : 0;
          }
          const newAvg = newShares > 0 ? newCost / newShares : 0;

          if (newShares <= 0.0001) {
            await env.DB.prepare(
              "UPDATE investor_positions SET status = 'CLOSED', total_shares = 0, cost_basis = 0, closed_at = ?1, updated_at = ?1 WHERE id = ?2"
            ).bind(now, pos.id).run();
          } else {
            await env.DB.prepare(
              "UPDATE investor_positions SET total_shares = ?1, cost_basis = ?2, avg_entry = ?3, last_entry_ts = ?4, updated_at = ?4 WHERE id = ?5"
            ).bind(newShares, newCost, newAvg, now, pos.id).run();
          }

          // Investor ledger: manual lot (BUY or SELL)
          const lotPrevBal = await d1GetLedgerBalance(env, "investor");
          const lotCashDelta = act === "BUY" ? -value : value;
          const lotPnl = act === "SELL" ? (value - pos.cost_basis * (shares / pos.total_shares)) : 0;
          d1InsertLedgerEntry(env, {
            mode: "investor", ts: now,
            event_type: act === "BUY" ? "ENTRY" : (newShares <= 0.0001 ? "EXIT" : "TRIM"),
            position_id: pos.id, ticker: sym, direction: "LONG",
            qty: shares, price, cash_delta: lotCashDelta,
            realized_pnl: lotPnl, balance: lotPrevBal + lotCashDelta,
            note: `Manual ${act} ${shares}sh ${sym} @$${price.toFixed(2)}`,
          }).catch(e => console.error("[LEDGER] investor lot failed:", e));

          return sendJSON({ ok: true, lotId, shares: newShares, avgEntry: Math.round(newAvg * 100) / 100 }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/investor/dca/plans — list all DCA plans
      if (routeKey === "GET /timed/investor/dca/plans") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const rows = (await env.DB.prepare(
            "SELECT id, ticker, status, dca_enabled, dca_amount, dca_frequency, dca_next_ts, dca_total_invested, dca_num_buys, total_shares, avg_entry, cost_basis FROM investor_positions WHERE dca_enabled = 1 ORDER BY dca_next_ts ASC"
          ).all())?.results || [];

          // Enrich with current prices
          const plans = [];
          for (const p of rows) {
            const td = await kvGetJSON(env.KV_TIMED, `timed:latest:${p.ticker}`);
            const mark = td?.price || 0;
            plans.push({
              ...p,
              currentPrice: mark,
              marketValue: Math.round(mark * p.total_shares * 100) / 100,
              nextBuyDate: p.dca_next_ts ? new Date(p.dca_next_ts).toISOString().slice(0, 10) : null,
              unrealizedPnlPct: p.avg_entry > 0 && mark > 0 ? Math.round(((mark - p.avg_entry) / p.avg_entry) * 10000) / 100 : 0,
            });
          }

          return sendJSON({ ok: true, plans }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/investor/dca/configure — set up or update a DCA plan for a position
      if (routeKey === "POST /timed/investor/dca/configure") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const body = await req.json();
          const { ticker, amount, frequency, enabled } = body;
          if (!ticker) return sendJSON({ ok: false, error: "ticker required" }, 400, corsHeaders(env, req));

          const sym = ticker.toUpperCase();
          const now = Date.now();
          const freq = ["weekly", "biweekly", "monthly"].includes(frequency) ? frequency : "monthly";
          const dcaEnabled = enabled !== false ? 1 : 0;
          const nextTs = dcaEnabled ? now + dcaFrequencyMs(freq) : null;

          // Ensure position exists (create one if not)
          let pos = (await env.DB.prepare(
            "SELECT id FROM investor_positions WHERE ticker = ?1 AND status = 'OPEN' LIMIT 1"
          ).bind(sym).all())?.results?.[0];

          if (!pos) {
            // Create a zero-position placeholder for DCA
            const posId = `inv-${sym}-dca-${now}`;
            await env.DB.prepare(`INSERT INTO investor_positions
              (id, ticker, status, total_shares, cost_basis, avg_entry,
               dca_enabled, dca_amount, dca_frequency, dca_next_ts,
               created_at, updated_at)
              VALUES (?1, ?2, 'OPEN', 0, 0, 0, ?3, ?4, ?5, ?6, ?7, ?7)
            `).bind(posId, sym, dcaEnabled, amount || 0, freq, nextTs, now).run();
            pos = { id: posId };
          } else {
            await env.DB.prepare(
              "UPDATE investor_positions SET dca_enabled = ?1, dca_amount = ?2, dca_frequency = ?3, dca_next_ts = ?4, updated_at = ?5 WHERE id = ?6"
            ).bind(dcaEnabled, amount || 0, freq, nextTs, now, pos.id).run();
          }

          return sendJSON({
            ok: true, positionId: pos.id, ticker: sym,
            dca: { enabled: !!dcaEnabled, amount: amount || 0, frequency: freq, nextBuyDate: nextTs ? new Date(nextTs).toISOString().slice(0, 10) : null },
          }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/investor/dca/execute — execute all due DCA buys (called by cron or manually)
      if (routeKey === "POST /timed/investor/dca/execute") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          const now = Date.now();

          // Find all positions with DCA enabled and next_ts <= now
          const duePositions = (await env.DB.prepare(
            "SELECT * FROM investor_positions WHERE dca_enabled = 1 AND dca_next_ts <= ?1 AND status = 'OPEN' AND dca_amount > 0"
          ).bind(now).all())?.results || [];

          const executed = [];
          const errors = [];

          for (const pos of duePositions) {
            try {
              // Get current price
              const td = await kvGetJSON(env.KV_TIMED, `timed:latest:${pos.ticker}`);
              const price = td?.price;
              if (!price || price <= 0) {
                errors.push({ ticker: pos.ticker, error: "no_current_price" });
                continue;
              }

              // Check investor score — skip DCA if score is very low (< 30) or market health is poor
              const scores = await kvGetJSON(env.KV_TIMED, "timed:investor:scores") || {};
              const health = await kvGetJSON(env.KV_TIMED, "timed:investor:market-health");
              const tickerScore = scores[pos.ticker]?.score;
              const marketHealthScore = health?.score || 50;

              let skipReason = null;
              if (tickerScore !== undefined && tickerScore < 30) {
                skipReason = `investor_score_low (${tickerScore})`;
              }
              if (marketHealthScore < 25) {
                skipReason = `market_health_critical (${marketHealthScore})`;
              }

              if (skipReason) {
                // Defer DCA by one period instead of executing
                const nextTs = now + dcaFrequencyMs(pos.dca_frequency);
                await env.DB.prepare(
                  "UPDATE investor_positions SET dca_next_ts = ?1, updated_at = ?2 WHERE id = ?3"
                ).bind(nextTs, now, pos.id).run();
                errors.push({ ticker: pos.ticker, skipped: true, reason: skipReason });
                continue;
              }

              // Calculate shares to buy
              const shares = pos.dca_amount / price;
              const value = shares * price;
              const lotId = `lot-${pos.ticker}-dca-${now}`;

              // Record the lot
              await env.DB.prepare(
                "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, 'DCA_BUY', ?4, ?5, ?6, ?7, 'dca_auto', ?7)"
              ).bind(lotId, pos.id, pos.ticker, shares, price, value, now).run();

              // Update position
              const newShares = pos.total_shares + shares;
              const newCost = pos.cost_basis + value;
              const newAvg = newCost / newShares;
              const nextTs = now + dcaFrequencyMs(pos.dca_frequency);

              await env.DB.prepare(`UPDATE investor_positions SET
                total_shares = ?1, cost_basis = ?2, avg_entry = ?3,
                last_entry_ts = ?4, dca_next_ts = ?5,
                dca_total_invested = dca_total_invested + ?6,
                dca_num_buys = dca_num_buys + 1,
                updated_at = ?4
                WHERE id = ?7
              `).bind(newShares, newCost, newAvg, now, nextTs, value, pos.id).run();

              // Investor ledger: DCA_BUY
              const dcaPrevBal = await d1GetLedgerBalance(env, "investor");
              d1InsertLedgerEntry(env, {
                mode: "investor", ts: now, event_type: "DCA_BUY",
                position_id: pos.id, ticker: pos.ticker, direction: "LONG",
                qty: shares, price, cash_delta: -value,
                realized_pnl: 0, balance: dcaPrevBal - value,
                note: `DCA ${pos.ticker} ${shares.toFixed(4)}sh @$${price.toFixed(2)}`,
              }).catch(e => console.error("[LEDGER] investor DCA_BUY failed:", e));

              executed.push({
                ticker: pos.ticker, shares: Math.round(shares * 10000) / 10000,
                price, value: Math.round(value * 100) / 100,
                newTotalShares: Math.round(newShares * 10000) / 10000,
                newAvgEntry: Math.round(newAvg * 100) / 100,
                nextBuyDate: new Date(nextTs).toISOString().slice(0, 10),
              });
            } catch (e) {
              errors.push({ ticker: pos.ticker, error: e.message });
            }
          }

          return sendJSON({
            ok: true, due: duePositions.length,
            executed: executed.length, skipped: errors.length,
            buys: executed, errors,
          }, 200, corsHeaders(env, req));
        } catch (err) {
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/investor/auto-rebalance — automatically open/add positions for tickers in actionable stages
      // Called by daily cron after scoring. Determines position sizing based on stage, score, and available capital.
      if (routeKey === "POST /timed/investor/auto-rebalance") {
        try {
          await ensureInvestorPositionsSchema(env.DB, env.KV_TIMED);
          await ensureAccountLedgerSchema(env.DB, env.KV_TIMED);
          const now = Date.now();

          // ── Configuration ──
          const INVESTOR_CAPITAL = 100000;                   // Total investable capital
          const MAX_POSITIONS = 20;                          // Max simultaneous positions
          const MAX_ALLOC_PCT = 0.08;                        // Max 8% of capital per ticker
          const ACCUMULATE_BASE_PCT = 0.05;                  // Base allocation: 5% for accumulate stage
          const ACCUMULATE_STRONG_PCT = 0.07;                // Strong score (70+): 7%
          const WATCH_ALLOC_PCT = 0.02;                      // Watch stage: 2% starter position
          const MIN_ORDER_VALUE = 50;                        // Minimum order to be worth executing

          // ── Load scores and prices ──
          const scores = await kvGetJSON(env.KV_TIMED, "timed:investor:scores") || {};
          const health = await kvGetJSON(env.KV_TIMED, "timed:investor:market-health");
          const pricesRaw = await kvGetJSON(env.KV_TIMED, "timed:prices") || {};
          const priceMap = pricesRaw.prices || {};
          const marketScore = health?.score || 50;

          // Skip entirely if market health is critical
          if (marketScore < 25) {
            return sendJSON({ ok: true, skipped: true, reason: "market_health_critical", marketScore }, 200, corsHeaders(env, req));
          }

          // ── Load existing open positions ──
          const existingPos = (await env.DB.prepare(
            "SELECT id, ticker, total_shares, cost_basis, avg_entry FROM investor_positions WHERE status = 'OPEN'"
          ).all())?.results || [];
          const existingByTicker = {};
          let totalInvested = 0;
          for (const p of existingPos) {
            existingByTicker[p.ticker] = p;
            totalInvested += Number(p.cost_basis) || 0;
          }
          const availableCapital = INVESTOR_CAPITAL - totalInvested;

          // ── Identify actionable tickers from scores ──
          const actionable = [];
          for (const [ticker, data] of Object.entries(scores)) {
            const stage = data.stage;
            if (stage !== "accumulate" && stage !== "watch") continue;

            const pf = priceMap[ticker];
            const price = pf ? Number(pf.p) : null;
            if (!price || price <= 0) continue;

            const score = data.score || 0;
            actionable.push({ ticker, stage, score, price, existing: existingByTicker[ticker] || null });
          }

          // Sort by score descending — best opportunities first
          actionable.sort((a, b) => b.score - a.score);

          const opened = [];
          const added = [];
          const skipped = [];
          let positionsCount = existingPos.length;
          let remainingCapital = availableCapital;

          for (const t of actionable) {
            // Determine target allocation
            let targetPct;
            if (t.stage === "accumulate") {
              targetPct = t.score >= 70 ? ACCUMULATE_STRONG_PCT : ACCUMULATE_BASE_PCT;
            } else {
              targetPct = WATCH_ALLOC_PCT;
            }
            targetPct = Math.min(targetPct, MAX_ALLOC_PCT);
            const targetValue = INVESTOR_CAPITAL * targetPct;

            if (t.existing) {
              // Already have position — check if we should add more
              const currentValue = t.existing.total_shares * t.price;
              const gap = targetValue - Number(t.existing.cost_basis);
              if (gap < MIN_ORDER_VALUE) {
                skipped.push({ ticker: t.ticker, reason: "already_at_target", currentCostBasis: t.existing.cost_basis, targetValue });
                continue;
              }
              // Only add up to half the gap per rebalance (gradual scaling)
              const addValue = Math.min(gap * 0.5, remainingCapital);
              if (addValue < MIN_ORDER_VALUE) {
                skipped.push({ ticker: t.ticker, reason: "insufficient_capital_for_add" });
                continue;
              }
              const addShares = Math.floor((addValue / t.price) * 10000) / 10000; // 4dp precision
              if (addShares <= 0) continue;

              const value = addShares * t.price;
              const newShares = t.existing.total_shares + addShares;
              const newCost = Number(t.existing.cost_basis) + value;
              const newAvg = newCost / newShares;
              const lotId = `lot-${t.ticker}-auto-${now}`;

              await env.DB.prepare(
                "UPDATE investor_positions SET total_shares = ?1, cost_basis = ?2, avg_entry = ?3, last_entry_ts = ?4, updated_at = ?4 WHERE id = ?5"
              ).bind(newShares, newCost, newAvg, now, t.existing.id).run();

              await env.DB.prepare(
                "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, 'BUY', ?4, ?5, ?6, ?7, ?8, ?7)"
              ).bind(lotId, t.existing.id, t.ticker, addShares, t.price, value, now, `auto_rebalance_${t.stage}`).run();

              const prevBal = await d1GetLedgerBalance(env, "investor");
              d1InsertLedgerEntry(env, {
                mode: "investor", ts: now, event_type: "ENTRY",
                position_id: t.existing.id, ticker: t.ticker, direction: "LONG",
                qty: addShares, price: t.price, cash_delta: -value,
                realized_pnl: 0, balance: prevBal - value,
                note: `Auto-add ${addShares}sh ${t.ticker} @$${t.price.toFixed(2)} (${t.stage}, score ${t.score})`,
              }).catch(e => console.error("[LEDGER] auto-add failed:", e));

              remainingCapital -= value;
              added.push({ ticker: t.ticker, shares: addShares, price: t.price, value: Math.round(value * 100) / 100, stage: t.stage, score: t.score });
            } else {
              // New position
              if (positionsCount >= MAX_POSITIONS) {
                skipped.push({ ticker: t.ticker, reason: "max_positions_reached" });
                continue;
              }
              const orderValue = Math.min(targetValue, remainingCapital);
              if (orderValue < MIN_ORDER_VALUE) {
                skipped.push({ ticker: t.ticker, reason: "insufficient_capital" });
                continue;
              }
              const shares = Math.floor((orderValue / t.price) * 10000) / 10000;
              if (shares <= 0) continue;

              const value = shares * t.price;
              const posId = `inv-${t.ticker}-auto-${now}`;
              const lotId = `lot-${t.ticker}-auto-${now}`;

              await env.DB.prepare(`INSERT INTO investor_positions
                (id, ticker, status, total_shares, cost_basis, avg_entry, first_entry_ts, last_entry_ts,
                 investor_stage, notes, created_at, updated_at)
                VALUES (?1, ?2, 'OPEN', ?3, ?4, ?5, ?6, ?6, ?7, ?8, ?6, ?6)
              `).bind(posId, t.ticker, shares, value, t.price, now,
                t.stage, `Auto-initiated: ${t.stage} (score ${t.score})`).run();

              await env.DB.prepare(
                "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, 'BUY', ?4, ?5, ?6, ?7, ?8, ?7)"
              ).bind(lotId, posId, t.ticker, shares, t.price, value, now, `auto_entry_${t.stage}`).run();

              const prevBal = await d1GetLedgerBalance(env, "investor");
              d1InsertLedgerEntry(env, {
                mode: "investor", ts: now, event_type: "ENTRY",
                position_id: posId, ticker: t.ticker, direction: "LONG",
                qty: shares, price: t.price, cash_delta: -value,
                realized_pnl: 0, balance: prevBal - value,
                note: `Auto-entry ${shares}sh ${t.ticker} @$${t.price.toFixed(2)} (${t.stage}, score ${t.score})`,
              }).catch(e => console.error("[LEDGER] auto-entry failed:", e));

              remainingCapital -= value;
              positionsCount++;
              opened.push({ ticker: t.ticker, shares, price: t.price, value: Math.round(value * 100) / 100, stage: t.stage, score: t.score });
            }
          }

          // ── Auto-reduce: trim positions where score dropped to "reduce" stage ──
          const reduced = [];
          for (const pos of existingPos) {
            const data = scores[pos.ticker];
            if (!data || data.stage !== "reduce") continue;

            const pf = priceMap[pos.ticker];
            const price = pf ? Number(pf.p) : null;
            if (!price || price <= 0) continue;

            // Trim 25% of position per rebalance cycle
            const trimShares = Math.floor(pos.total_shares * 0.25 * 10000) / 10000;
            if (trimShares <= 0) continue;

            const sellValue = trimShares * price;
            const partialCostBasis = Number(pos.cost_basis) * (trimShares / pos.total_shares);
            const pnl = sellValue - partialCostBasis;
            const remaining = pos.total_shares - trimShares;
            const newCost = Number(pos.cost_basis) - partialCostBasis;
            const lotId = `lot-${pos.ticker}-autotrim-${now}`;

            if (remaining <= 0.0001) {
              // Full close
              await env.DB.prepare(
                "UPDATE investor_positions SET status = 'CLOSED', total_shares = 0, closed_at = ?1, updated_at = ?1 WHERE id = ?2"
              ).bind(now, pos.id).run();
            } else {
              await env.DB.prepare(
                "UPDATE investor_positions SET total_shares = ?1, cost_basis = ?2, updated_at = ?3 WHERE id = ?4"
              ).bind(remaining, newCost, now, pos.id).run();
            }

            await env.DB.prepare(
              "INSERT INTO investor_lots (id, position_id, ticker, action, shares, price, value, ts, reason, created_at) VALUES (?1, ?2, ?3, 'SELL', ?4, ?5, ?6, ?7, 'auto_reduce', ?7)"
            ).bind(lotId, pos.id, pos.ticker, trimShares, price, sellValue, now).run();

            const prevBal = await d1GetLedgerBalance(env, "investor");
            d1InsertLedgerEntry(env, {
              mode: "investor", ts: now, event_type: "TRIM",
              position_id: pos.id, ticker: pos.ticker, direction: "LONG",
              qty: trimShares, price, cash_delta: sellValue,
              realized_pnl: pnl, balance: prevBal + sellValue,
              note: `Auto-trim ${trimShares}sh ${pos.ticker} @$${price.toFixed(2)} (reduce stage, P&L $${pnl.toFixed(2)})`,
            }).catch(e => console.error("[LEDGER] auto-reduce failed:", e));

            reduced.push({ ticker: pos.ticker, trimmedShares: trimShares, price, pnl: Math.round(pnl * 100) / 100, remaining: Math.round(remaining * 10000) / 10000 });
          }

          return sendJSON({
            ok: true,
            capitalAvailable: Math.round(availableCapital * 100) / 100,
            capitalRemaining: Math.round(remainingCapital * 100) / 100,
            marketHealth: marketScore,
            totalPositions: positionsCount,
            newPositions: opened.length,
            addedTo: added.length,
            reduced: reduced.length,
            skippedCount: skipped.length,
            opened, added, reduced, skipped,
          }, 200, corsHeaders(env, req));
        } catch (err) {
          console.error("[AUTO-REBALANCE] Error:", err);
          return sendJSON({ ok: false, error: err.message }, 500, corsHeaders(env, req));
        }
      }

      // ═══════════════════════════════════════════════════════════════════════

      // GET /timed/debug/trades?ticker=RIOT - Get all trades with details, optionally filtered by ticker
      if (routeKey === "GET /timed/debug/trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

          // Optional ticker filter
          const tickerFilter = url.searchParams.get("ticker");
          let filteredTrades = allTrades;
          if (tickerFilter) {
            const tickerUpper = String(tickerFilter).toUpperCase();
            filteredTrades = allTrades.filter(
              (t) => String(t.ticker || "").toUpperCase() === tickerUpper,
            );
          }

          const openTrades = filteredTrades.filter(
            (t) =>
              t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
          );
          const closedTrades = filteredTrades.filter(
            (t) => t.status === "WIN" || t.status === "LOSS",
          );

          return sendJSON(
            {
              ok: true,
              ticker: tickerFilter || null,
              total: filteredTrades.length,
              open: openTrades.length,
              closed: closedTrades.length,
              trades: filteredTrades,
              summary: {
                byVersion: filteredTrades.reduce((acc, t) => {
                  const v = t.scriptVersion || "unknown";
                  acc[v] = (acc[v] || 0) + 1;
                  return acc;
                }, {}),
                byStatus: filteredTrades.reduce((acc, t) => {
                  const s = t.status || "OPEN";
                  acc[s] = (acc[s] || 0) + 1;
                  return acc;
                }, {}),
              },
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/debug/score-analysis - Analyze score distribution
      if (routeKey === "GET /timed/debug/score-analysis") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const tickerDataPromises = tickerIndex.map(async (ticker) => {
            const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
            return data;
          });

          const allData = (await Promise.all(tickerDataPromises)).filter(
            Boolean,
          );

          // Score distribution
          const scoreRanges = {
            "90-100": 0,
            "80-89": 0,
            "70-79": 0,
            "60-69": 0,
            "50-59": 0,
            "40-49": 0,
            "30-39": 0,
            "20-29": 0,
            "10-19": 0,
            "0-9": 0,
          };

          const scoreBreakdown = [];
          const componentStats = {
            aligned: { count: 0, avgScore: 0 },
            setup: { count: 0, avgScore: 0 },
            squeezeRelease: { count: 0, avgScore: 0 },
            squeezeOn: { count: 0, avgScore: 0 },
            momentumElite: { count: 0, avgScore: 0 },
            phaseZoneChange: { count: 0, avgScore: 0 },
          };

          allData.forEach((d) => {
            const rank = Number(d.rank) || 0;
            const scoreRange =
              rank >= 90
                ? "90-100"
                : rank >= 80
                  ? "80-89"
                  : rank >= 70
                    ? "70-79"
                    : rank >= 60
                      ? "60-69"
                      : rank >= 50
                        ? "50-59"
                        : rank >= 40
                          ? "40-49"
                          : rank >= 30
                            ? "30-39"
                            : rank >= 20
                              ? "20-29"
                              : rank >= 10
                                ? "10-19"
                                : "0-9";
            scoreRanges[scoreRange]++;

            // Component analysis
            const state = String(d.state || "");
            const aligned =
              state === "HTF_BULL_LTF_BULL" || state === "HTF_BEAR_LTF_BEAR";
            const setup =
              state === "HTF_BULL_LTF_PULLBACK" ||
              state === "HTF_BEAR_LTF_PULLBACK";
            const flags = d.flags || {};
            const sqRel = !!flags.sq30_release;
            const sqOn = !!flags.sq30_on;
            const momentumElite = !!flags.momentum_elite;
            const phaseZoneChange = !!flags.phase_zone_change;

            if (aligned) {
              componentStats.aligned.count++;
              componentStats.aligned.avgScore += rank;
            }
            if (setup) {
              componentStats.setup.count++;
              componentStats.setup.avgScore += rank;
            }
            if (sqRel) {
              componentStats.squeezeRelease.count++;
              componentStats.squeezeRelease.avgScore += rank;
            }
            if (sqOn && !sqRel) {
              componentStats.squeezeOn.count++;
              componentStats.squeezeOn.avgScore += rank;
            }
            if (momentumElite) {
              componentStats.momentumElite.count++;
              componentStats.momentumElite.avgScore += rank;
            }
            if (phaseZoneChange) {
              componentStats.phaseZoneChange.count++;
              componentStats.phaseZoneChange.avgScore += rank;
            }

            // Detailed breakdown for high scores
            if (rank >= 85) {
              const htf = Number(d.htf_score) || 0;
              const ltf = Number(d.ltf_score) || 0;
              const comp = Number(d.completion) || 0;
              const phase = Number(d.phase_pct) || 0;
              const rr = Number(d.rr) || 0;

              scoreBreakdown.push({
                ticker: d.ticker,
                rank,
                state,
                aligned,
                setup,
                htf_score: htf,
                ltf_score: ltf,
                completion: comp,
                phase_pct: phase,
                rr,
                flags: {
                  sq30_release: sqRel,
                  sq30_on: sqOn,
                  momentum_elite: momentumElite,
                  phase_zone_change: phaseZoneChange,
                },
              });
            }
          });

          // Calculate averages
          Object.keys(componentStats).forEach((key) => {
            if (componentStats[key].count > 0) {
              componentStats[key].avgScore =
                componentStats[key].avgScore / componentStats[key].count;
            }
          });

          // Overall stats
          const ranks = allData
            .map((d) => Number(d.rank) || 0)
            .filter((r) => r > 0);
          const avgRank =
            ranks.length > 0
              ? ranks.reduce((a, b) => a + b, 0) / ranks.length
              : 0;
          const medianRank =
            ranks.length > 0
              ? ranks.sort((a, b) => a - b)[Math.floor(ranks.length / 2)]
              : 0;
          const maxRank = ranks.length > 0 ? Math.max(...ranks) : 0;
          const minRank = ranks.length > 0 ? Math.min(...ranks) : 0;

          return sendJSON(
            {
              ok: true,
              summary: {
                totalTickers: allData.length,
                avgRank: Math.round(avgRank * 100) / 100,
                medianRank,
                maxRank,
                minRank,
              },
              distribution: scoreRanges,
              componentStats,
              highScoreBreakdown: scoreBreakdown.slice(0, 50), // Top 50 high scores
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/debug/tickers - Get all tickers with latest data
      if (routeKey === "GET /timed/debug/tickers") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const tickerDataPromises = tickerIndex
            .slice(0, 100)
            .map(async (ticker) => {
              const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
              return {
                ticker,
                hasData: !!data,
                data: data
                  ? {
                      price: data.price,
                      state: data.state,
                      rank: data.rank,
                      rr: data.rr,
                      completion: data.completion,
                      phase_pct: data.phase_pct,
                      sl: data.sl,
                      tp: data.tp,
                      script_version: data.script_version,
                      ingest_time: data.ingest_time,
                    }
                  : null,
              };
            });

          const tickerData = await Promise.all(tickerDataPromises);

          return sendJSON(
            {
              ok: true,
              totalTickers: tickerIndex.length,
              tickersWithData: tickerData.filter((t) => t.hasData).length,
              tickers: tickerData,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // GET /timed/debug/config - Check Discord and other configuration
      if (routeKey === "GET /timed/debug/config") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        return sendJSON(
          {
            ok: true,
            config: {
              discordEnabled: (env.DISCORD_ENABLE || "false") === "true",
              discordWebhookSet: !!env.DISCORD_WEBHOOK_URL,
              discordWebhookUrl: env.DISCORD_WEBHOOK_URL
                ? "***SET***"
                : "NOT SET",
              openaiApiKeySet: !!env.OPENAI_API_KEY,
              openaiModel: env.OPENAI_MODEL || "gpt-3.5-turbo",
              alertMinRR: env.ALERT_MIN_RR || "1.5",
              alertMaxCompletion: env.ALERT_MAX_COMPLETION || "0.4",
              alertMaxPhase: env.ALERT_MAX_PHASE || "0.6",
              alertMinRank: env.ALERT_MIN_RANK || "70",
            },
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/debug/staleness - Staleness breakdown for all tickers (admin)
      if (routeKey === "GET /timed/debug/staleness") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const scoringLast = await kvGetJSON(KV, "timed:scoring:last_run");
        const samples = (Array.isArray(tickers) ? tickers : []).slice(0, 250).map(async (t) => {
          const sym = String(t || "").toUpperCase();
          const data = await kvGetJSON(KV, `timed:latest:${sym}`);
          if (!data) return { ticker: sym, ageMin: null, reason: "no_data" };
          const tsRaw = data.ingest_ts ?? data.ingest_time ?? data.ts;
          const tsMs = typeof tsRaw === "string" ? new Date(tsRaw).getTime() : (Number(tsRaw) > 0 && Number(tsRaw) < 1e12 ? Number(tsRaw) * 1000 : Number(tsRaw));
          if (!Number.isFinite(tsMs)) return { ticker: sym, ageMin: null, reason: "no_ts" };
          const ageMin = (Date.now() - tsMs) / 60000;
          const bucket = ageMin > 120 ? "very_stale" : ageMin > 30 ? "stale" : "fresh";
          return { ticker: sym, ageMin: Math.round(ageMin), bucket, ts: tsMs };
        });
        const results = await Promise.all(samples);
        const fresh = results.filter((r) => r.bucket === "fresh").length;
        const stale = results.filter((r) => r.bucket === "stale").length;
        const veryStale = results.filter((r) => r.bucket === "very_stale").length;
        const noData = results.filter((r) => r.reason).length;
        const veryStaleTickers = results.filter((r) => r.bucket === "very_stale").sort((a, b) => (b.ageMin || 0) - (a.ageMin || 0)).slice(0, 20).map((r) => `${r.ticker} (${r.ageMin}m)`);

        return sendJSON(
          {
            ok: true,
            total_sampled: results.length,
            total_tickers: tickers.length,
            fresh,
            stale,
            very_stale: veryStale,
            no_data_or_ts: noData,
            very_stale_sample: veryStaleTickers,
            scoring_last_run: scoringLast && typeof scoringLast === "object" ? scoringLast : null,
            minutes_since_scoring: scoringLast?.ts ? (Date.now() - scoringLast.ts) / 60000 : null,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // GET /timed/debug/daily?ticker=AMD
      // Debug endpoint to inspect daily change inputs/sources (latest vs capture vs worker-derived).
      if (routeKey === "GET /timed/debug/daily") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const ticker = normTicker(url.searchParams.get("ticker"));
        if (!ticker) {
          return sendJSON(
            { ok: false, error: "missing ticker" },
            400,
            corsHeaders(env, req),
          );
        }

        const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
        const capture = await kvGetJSON(KV, `timed:capture:latest:${ticker}`);

        const pick = (obj, keys) => {
          for (const k of keys) {
            if (!obj || typeof obj !== "object") continue;
            if (obj[k] != null) return obj[k];
          }
          return null;
        };
        const num = (v) => {
          const n = Number(v);
          return Number.isFinite(n) ? n : null;
        };

        const latestTs = num(pick(latest, ["ts", "ingest_ts"])) || null;
        const captureTs = num(pick(capture, ["ts", "ingest_ts"])) || null;
        const asOfTs = latestTs || captureTs || Date.now();

        let derived = null;
        try {
          if (env?.DB) {
            const rec = await computePrevCloseFromTrail(env.DB, ticker, asOfTs);
            const price =
              num(pick(latest, ["price"])) ?? num(pick(capture, ["price"]));
            if (rec && Number.isFinite(price) && price > 0) {
              derived = {
                prev_close: rec.close,
                prev_close_day: rec.dayKey,
                prev_close_ts: rec.ts,
                day_change: price - rec.close,
                day_change_pct: ((price - rec.close) / rec.close) * 100,
              };
            } else {
              derived = {
                prev_close: null,
                reason: rec ? "bad_price" : "no_prev_close_row",
              };
            }
          }
        } catch (e) {
          derived = { prev_close: null, error: String(e?.message || e) };
        }

        const fields = [
          "price",
          "prev_close",
          "day_change",
          "day_change_pct",
          "change",
          "change_pct",
          "session",
          "is_rth",
          "ts",
          "ingest_ts",
        ];
        const subset = (obj) => {
          const out = {};
          for (const k of fields)
            if (obj && typeof obj === "object" && obj[k] != null)
              out[k] = obj[k];
          return out;
        };

        return sendJSON(
          {
            ok: true,
            ticker,
            latest: subset(latest),
            capture: subset(capture),
            derived,
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/debug/cleanup-duplicates?key=...&ticker=RIOT - Remove duplicate trades for a ticker
      if (routeKey === "POST /timed/debug/cleanup-duplicates") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const tickerFilter = url.searchParams.get("ticker");

          if (!tickerFilter) {
            return sendJSON(
              { ok: false, error: "ticker parameter required" },
              400,
              corsHeaders(env, req),
            );
          }

          const tickerUpper = String(tickerFilter).toUpperCase();
          const tickerTrades = allTrades.filter(
            (t) => String(t.ticker || "").toUpperCase() === tickerUpper,
          );

          if (tickerTrades.length === 0) {
            return sendJSON(
              {
                ok: true,
                message: `No trades found for ${tickerUpper}`,
                removed: 0,
                kept: 0,
              },
              200,
              corsHeaders(env, req),
            );
          }

          // Group by direction and find duplicates
          const byDirection = {};
          tickerTrades.forEach((trade) => {
            const dir = trade.direction || "UNKNOWN";
            if (!byDirection[dir]) {
              byDirection[dir] = [];
            }
            byDirection[dir].push(trade);
          });

          const tradesToKeep = [];
          const tradesToRemove = [];

          Object.keys(byDirection).forEach((direction) => {
            const dirTrades = byDirection[direction];

            // Keep the most recent open trade, or if all closed, keep the most recent one
            const openTrades = dirTrades.filter(
              (t) =>
                t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
            );

            if (openTrades.length > 0) {
              // Keep the most recent open trade
              const sortedOpen = openTrades.sort((a, b) => {
                const timeA = new Date(a.entryTime || 0).getTime();
                const timeB = new Date(b.entryTime || 0).getTime();
                return timeB - timeA;
              });
              tradesToKeep.push(sortedOpen[0]);
              tradesToRemove.push(...sortedOpen.slice(1));
              tradesToRemove.push(
                ...dirTrades.filter((t) => !openTrades.includes(t)),
              );
            } else {
              // All closed - keep the most recent one
              const sortedClosed = dirTrades.sort((a, b) => {
                const timeA = new Date(a.entryTime || 0).getTime();
                const timeB = new Date(b.entryTime || 0).getTime();
                return timeB - timeA;
              });
              tradesToKeep.push(sortedClosed[0]);
              tradesToRemove.push(...sortedClosed.slice(1));
            }
          });

          // Remove duplicates from allTrades
          const tradeIdsToRemove = new Set(tradesToRemove.map((t) => t.id));
          const cleanedTrades = allTrades.filter(
            (t) => !tradeIdsToRemove.has(t.id),
          );

          await kvPutJSON(KV, tradesKey, cleanedTrades);

          return sendJSON(
            {
              ok: true,
              ticker: tickerUpper,
              total: tickerTrades.length,
              kept: tradesToKeep.length,
              removed: tradesToRemove.length,
              keptTrades: tradesToKeep.map((t) => ({
                id: t.id,
                entryTime: t.entryTime,
                entryPrice: t.entryPrice,
                status: t.status,
              })),
              removedTrades: tradesToRemove.map((t) => ({
                id: t.id,
                entryTime: t.entryTime,
                entryPrice: t.entryPrice,
                status: t.status,
              })),
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/purge-ticker?key=...&ticker=RIOT - Delete ALL trades for a specific ticker
      if (routeKey === "POST /timed/debug/purge-ticker") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const tickerFilter = url.searchParams.get("ticker");

          if (!tickerFilter) {
            return sendJSON(
              { ok: false, error: "ticker parameter required" },
              400,
              corsHeaders(env, req),
            );
          }

          const tickerUpper = String(tickerFilter).toUpperCase();
          const beforeCount = allTrades.length;

          // Filter out all trades for this ticker
          const filteredTrades = allTrades.filter(
            (t) => String(t.ticker || "").toUpperCase() !== tickerUpper,
          );

          const removedCount = beforeCount - filteredTrades.length;

          // Save the cleaned trades (even if 0 removed from KV, we still clear D1)
          if (removedCount > 0) {
            await kvPutJSON(KV, tradesKey, filteredTrades);
          }

          // Also clear D1 positions, lots, execution_actions, trades, trade_events for this ticker
          let d1Cleared = { positions: 0, lots: 0, actions: 0, trades: 0, events: 0 };
          if (env?.DB) {
            try {
              // Get position IDs first (for FK cleanup)
              const posRows = await env.DB.prepare(
                `SELECT position_id FROM positions WHERE ticker = ?1`
              ).bind(tickerUpper).all();
              const posIds = (posRows?.results || []).map((r) => r.position_id);
              
              // Clear execution_actions and lots for each position
              for (const pid of posIds) {
                const actRes = await env.DB.prepare(
                  `DELETE FROM execution_actions WHERE position_id = ?1`
                ).bind(pid).run();
                d1Cleared.actions += actRes?.meta?.changes || 0;
                
                const lotRes = await env.DB.prepare(
                  `DELETE FROM lots WHERE position_id = ?1`
                ).bind(pid).run();
                d1Cleared.lots += lotRes?.meta?.changes || 0;
              }
              
              // Clear positions
              const posRes = await env.DB.prepare(
                `DELETE FROM positions WHERE ticker = ?1`
              ).bind(tickerUpper).run();
              d1Cleared.positions = posRes?.meta?.changes || 0;
              
              // Clear trade_events for trades of this ticker
              const tradeRows = await env.DB.prepare(
                `SELECT trade_id FROM trades WHERE ticker = ?1`
              ).bind(tickerUpper).all();
              for (const row of tradeRows?.results || []) {
                const evtRes = await env.DB.prepare(
                  `DELETE FROM trade_events WHERE trade_id = ?1`
                ).bind(row.trade_id).run();
                d1Cleared.events += evtRes?.meta?.changes || 0;
              }
              
              // Clear trades
              const trdRes = await env.DB.prepare(
                `DELETE FROM trades WHERE ticker = ?1`
              ).bind(tickerUpper).run();
              d1Cleared.trades = trdRes?.meta?.changes || 0;
            } catch (d1Err) {
              console.warn(`[purge-ticker] D1 cleanup error for ${tickerUpper}:`, d1Err?.message || d1Err);
            }
          }

          // Also clear the ticker's latest KV record to reset kanban state
          try {
            await KV.delete(`timed:latest:${tickerUpper}`);
          } catch (_) {}

          const totalD1 = d1Cleared.positions + d1Cleared.lots + d1Cleared.actions + d1Cleared.trades + d1Cleared.events;

          return sendJSON(
            {
              ok: true,
              ticker: tickerUpper,
              kv: { removed: removedCount, remaining: filteredTrades.length, beforeCount },
              d1: d1Cleared,
              message: `Purged ${removedCount} KV trades and ${totalD1} D1 records for ${tickerUpper}`,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/cleanup-all-duplicates?key=... - Remove all duplicate trades (keeps most recent per ticker+direction)
      if (routeKey === "POST /timed/debug/cleanup-all-duplicates") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];

          const beforeCount = allTrades.length;

          // Group trades by ticker+direction, keep most recent
          const tradeMap = new Map();
          const duplicates = [];

          allTrades.forEach((trade) => {
            const key = `${String(trade.ticker || "").toUpperCase()}_${
              trade.direction || "UNKNOWN"
            }`;
            const existing = tradeMap.get(key);

            if (!existing) {
              tradeMap.set(key, trade);
            } else {
              // Compare entry times to keep the most recent
              const existingTime = existing.entryTime
                ? new Date(existing.entryTime).getTime()
                : 0;
              const currentTime = trade.entryTime
                ? new Date(trade.entryTime).getTime()
                : 0;

              if (currentTime > existingTime) {
                duplicates.push(existing);
                tradeMap.set(key, trade);
              } else {
                duplicates.push(trade);
              }
            }
          });

          const cleanedTrades = Array.from(tradeMap.values());
          const removedCount = beforeCount - cleanedTrades.length;

          if (removedCount === 0) {
            return sendJSON(
              {
                ok: true,
                message: "No duplicates found",
                beforeCount,
                afterCount: cleanedTrades.length,
                removed: 0,
              },
              200,
              corsHeaders(env, req),
            );
          }

          // Save cleaned trades
          await kvPutJSON(KV, tradesKey, cleanedTrades);

          // Group duplicates by ticker for summary
          const duplicatesByTicker = {};
          duplicates.forEach((d) => {
            const ticker = String(d.ticker || "UNKNOWN").toUpperCase();
            if (!duplicatesByTicker[ticker]) {
              duplicatesByTicker[ticker] = [];
            }
            duplicatesByTicker[ticker].push({
              id: d.id,
              entryTime: d.entryTime,
              entryPrice: d.entryPrice,
              status: d.status,
            });
          });

          return sendJSON(
            {
              ok: true,
              message: `Successfully removed ${removedCount} duplicate trades`,
              beforeCount,
              afterCount: cleanedTrades.length,
              removed: removedCount,
              duplicatesByTicker,
              summary: Object.keys(duplicatesByTicker).map((ticker) => ({
                ticker,
                count: duplicatesByTicker[ticker].length,
              })),
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/recalculate-ranks?key=... - Recalculate ranks for all tickers using new formula
      if (routeKey === "POST /timed/debug/recalculate-ranks") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const results = {
            processed: 0,
            updated: 0,
            errors: [],
          };

          // Process all tickers
          for (const ticker of tickerIndex) {
            try {
              const data = await kvGetJSON(KV, `timed:latest:${ticker}`);
              if (!data) {
                results.errors.push({ ticker, error: "No data found" });
                continue;
              }

              // Recalculate rank using new formula
              const newRank = computeRank(data);
              const oldRank = Number(data.rank) || 0;

              // Only update if rank changed
              if (newRank !== oldRank) {
                data.rank = newRank;
                await kvPutJSON(KV, `timed:latest:${ticker}`, data);
                results.updated++;
              }

              results.processed++;
            } catch (err) {
              results.errors.push({ ticker, error: err.message });
            }
          }

          return sendJSON(
            {
              ok: true,
              message: `Recalculated ranks for ${results.processed} tickers`,
              results,
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/fix-entry-prices?key=... - Fix entry prices for trades that used trigger_price instead of current price
      if (routeKey === "POST /timed/debug/fix-entry-prices") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          let fixed = 0;
          const fixedTrades = [];

          for (let i = 0; i < allTrades.length; i++) {
            const trade = allTrades[i];

            // Only fix OPEN trades (closed trades should keep their original entry price)
            if (trade.status !== "OPEN" && trade.status !== "TP_HIT_TRIM") {
              continue;
            }

            // Get latest ticker data
            const tickerData = await kvGetJSON(
              KV,
              `timed:latest:${trade.ticker}`,
            );
            if (!tickerData || !tickerData.price) {
              console.log(
                `[FIX ENTRY PRICES] Skipping ${trade.ticker} - no current price data`,
              );
              continue;
            }

            const currentPrice = Number(tickerData.price);
            const entryPrice = Number(trade.entryPrice);

            if (
              !Number.isFinite(currentPrice) ||
              !Number.isFinite(entryPrice)
            ) {
              continue;
            }

            // Check if entry price differs significantly from current price (>1%)
            const priceDiffPct =
              Math.abs(currentPrice - entryPrice) / entryPrice;
            if (priceDiffPct <= 0.01) {
              // Entry price is close to current price - likely correct
              continue;
            }

            // Check if this looks like it was created from trigger_price
            // (entry price matches trigger_price or is significantly different from current)
            const triggerPrice = tickerData.trigger_price
              ? Number(tickerData.trigger_price)
              : null;
            const entryMatchesTrigger =
              triggerPrice &&
              Math.abs(entryPrice - triggerPrice) / triggerPrice < 0.001;

            // Also check if trade is old (more than 1 hour)
            const entryTime = trade.entryTime
              ? new Date(trade.entryTime).getTime()
              : null;
            const now = Date.now();
            const isOldTrade = entryTime && now - entryTime > 60 * 60 * 1000;

            if (entryMatchesTrigger || isOldTrade || priceDiffPct > 0.05) {
              // Fix entry price to current price
              const correctedEntryPrice = currentPrice;

              // Recalculate shares based on new entry price
              const tickerUpper = String(trade.ticker || "").toUpperCase();
              const isFutures =
                FUTURES_SPECS[tickerUpper] || tickerUpper.endsWith("1!");
              const correctedShares =
                isFutures && FUTURES_SPECS[tickerUpper]
                  ? 1
                  : TRADE_SIZE / correctedEntryPrice;

              // Recalculate P&L with corrected entry price
              const tradeCalc = calculateTradePnl(
                tickerData,
                correctedEntryPrice,
                trade,
              );

              if (!tradeCalc) {
                console.log(
                  `[FIX ENTRY PRICES] Skipping ${trade.ticker} - cannot recalculate P&L`,
                );
                continue;
              }

              // Update trade
              const updatedTrade = {
                ...trade,
                entryPrice: correctedEntryPrice,
                shares: correctedShares,
                entryPriceCorrected: true,
                ...tradeCalc,
                history: [
                  ...(trade.history || []),
                  {
                    type: "ENTRY_PRICE_CORRECTION",
                    timestamp: new Date().toISOString(),
                    price: correctedEntryPrice,
                    shares: correctedShares,
                    value: correctedEntryPrice * correctedShares,
                    note: `Entry price corrected from $${entryPrice.toFixed(
                      2,
                    )} to $${correctedEntryPrice.toFixed(
                      2,
                    )} (was using trigger_price or outdated price)`,
                  },
                ],
                lastUpdate: new Date().toISOString(),
              };

              allTrades[i] = updatedTrade;
              fixed++;
              fixedTrades.push({
                ticker: trade.ticker,
                direction: trade.direction,
                oldEntryPrice: entryPrice.toFixed(2),
                newEntryPrice: correctedEntryPrice.toFixed(2),
                oldPnl: trade.pnl?.toFixed(2) || "0.00",
                newPnl: tradeCalc.pnl?.toFixed(2) || "0.00",
              });

              console.log(
                `[FIX ENTRY PRICES] Fixed ${trade.ticker} ${
                  trade.direction
                }: $${entryPrice.toFixed(2)} -> $${correctedEntryPrice.toFixed(
                  2,
                )} (P&L: $${(trade.pnl || 0).toFixed(
                  2,
                )} -> $${tradeCalc.pnl.toFixed(2)})`,
              );
            }
          }

          if (fixed > 0) {
            await kvPutJSON(KV, tradesKey, allTrades);
            console.log(
              `[FIX ENTRY PRICES] Fixed ${fixed} trades with incorrect entry prices`,
            );
          }

          return sendJSON(
            {
              ok: true,
              message: `Fixed ${fixed} trades with incorrect entry prices`,
              fixed,
              fixedTrades,
            },
            200,
            corsHeaders(env, req, true),
          );
        } catch (err) {
          console.error(`[FIX ENTRY PRICES ERROR]`, {
            error: String(err),
            message: err.message,
            stack: err.stack,
          });
          return sendJSON(
            { ok: false, error: "internal_error", message: err.message },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/debug/fix-backfill-trades?key=... - Fix entryTime for backfilled trades
      if (routeKey === "POST /timed/debug/fix-backfill-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const now = Date.now();
          let fixed = 0;
          const fixedTrades = [];

          const threeDaysAgo = now - 3 * 24 * 60 * 60 * 1000; // 3 days ago

          for (const trade of allTrades) {
            let updated = false;
            const updatedTrade = { ...trade };
            let bestMatchTimestamp = null;
            let bestMatchPrice = null;
            let matchMethod = null;

            // Method 1: Check if trade has triggerTimestamp that's significantly older than entryTime
            if (trade.triggerTimestamp && trade.entryTime) {
              const triggerTime = new Date(trade.triggerTimestamp).getTime();
              const entryTime = new Date(trade.entryTime).getTime();
              const isBackfill =
                triggerTime && now - triggerTime > 60 * 60 * 1000; // More than 1 hour old

              if (isBackfill && triggerTime < entryTime) {
                bestMatchTimestamp = trade.triggerTimestamp;
                bestMatchPrice = trade.entryPrice;
                matchMethod = "triggerTimestamp";
              }
            }

            // Method 2: Search trail data for when entry price was actually touched (last 3 days)
            if (!bestMatchTimestamp && trade.ticker && trade.entryPrice) {
              try {
                const trail =
                  (await kvGetJSON(KV, `timed:trail:${trade.ticker}`)) || [];
                const entryPrice = Number(trade.entryPrice);
                const priceTolerance = entryPrice * 0.005; // 0.5% tolerance

                // Search through trail points in reverse (most recent first)
                // Find the point where price matches entryPrice within tolerance
                for (let i = trail.length - 1; i >= 0; i--) {
                  const point = trail[i];
                  if (!point.ts || !point.price) continue;

                  const pointTime = Number(point.ts);
                  const pointPrice = Number(point.price);

                  // Only consider points from last 3 days
                  if (pointTime < threeDaysAgo) continue;

                  // Check if price matches entry price (within tolerance)
                  const priceDiff = Math.abs(pointPrice - entryPrice);
                  if (priceDiff <= priceTolerance) {
                    // Found a match - use this timestamp
                    bestMatchTimestamp = new Date(pointTime).toISOString();
                    bestMatchPrice = pointPrice;
                    matchMethod = "trail_price_match";
                    break; // Use first match (most recent)
                  }
                }

                // If no exact match, find closest price match in last 3 days
                if (!bestMatchTimestamp) {
                  let closestDiff = Infinity;
                  let closestPoint = null;
                  for (const point of trail) {
                    if (!point.ts || !point.price) continue;
                    const pointTime = Number(point.ts);
                    const pointPrice = Number(point.price);
                    if (pointTime < threeDaysAgo) continue;

                    const priceDiff = Math.abs(pointPrice - entryPrice);
                    if (priceDiff < closestDiff) {
                      closestDiff = priceDiff;
                      closestPoint = point;
                    }
                  }

                  // Use closest match if it's within 2% of entry price
                  if (closestPoint && closestDiff <= entryPrice * 0.02) {
                    bestMatchTimestamp = new Date(
                      Number(closestPoint.ts),
                    ).toISOString();
                    bestMatchPrice = Number(closestPoint.price);
                    matchMethod = "trail_closest_match";
                  }
                }
              } catch (err) {
                // Ignore errors - trail data might not exist
              }
            }

            // Method 3: Try to get triggerTimestamp from ticker's latest data
            if (!bestMatchTimestamp && trade.ticker) {
              try {
                const tickerData = await kvGetJSON(
                  KV,
                  `timed:latest:${trade.ticker}`,
                );
                if (tickerData && tickerData.trigger_ts) {
                  const triggerTime = Number(tickerData.trigger_ts);
                  // Only use if it's from last 3 days and older than current entryTime
                  if (triggerTime >= threeDaysAgo) {
                    const entryTime = trade.entryTime
                      ? new Date(trade.entryTime).getTime()
                      : now;
                    if (triggerTime < entryTime) {
                      bestMatchTimestamp = new Date(triggerTime).toISOString();
                      bestMatchPrice =
                        tickerData.trigger_price || trade.entryPrice;
                      matchMethod = "ticker_trigger_ts";
                      // Store it in the trade for future reference
                      updatedTrade.triggerTimestamp = bestMatchTimestamp;
                    }
                  }
                }
              } catch (err) {
                // Ignore errors
              }
            }

            // Update entryTime if we found a better match
            if (bestMatchTimestamp && trade.entryTime) {
              const currentEntryTime = new Date(trade.entryTime).getTime();
              const newEntryTime = new Date(bestMatchTimestamp).getTime();

              // Only update if new time is significantly different (more than 5 minutes) and older
              if (
                Math.abs(newEntryTime - currentEntryTime) > 5 * 60 * 1000 &&
                newEntryTime < currentEntryTime
              ) {
                updatedTrade.entryTime = bestMatchTimestamp;
                updated = true;

                // Also update entry price if we found a better match from trail
                if (
                  bestMatchPrice &&
                  matchMethod.includes("trail") &&
                  Math.abs(bestMatchPrice - trade.entryPrice) >
                    trade.entryPrice * 0.01
                ) {
                  updatedTrade.entryPrice = bestMatchPrice;
                }
              }
            }

            // Update history entry timestamp if it matches the old entryTime
            if (
              updated &&
              updatedTrade.history &&
              Array.isArray(updatedTrade.history)
            ) {
              updatedTrade.history = updatedTrade.history.map((event) => {
                if (
                  event.type === "ENTRY" &&
                  event.timestamp === trade.entryTime
                ) {
                  return {
                    ...event,
                    timestamp: updatedTrade.entryTime,
                    price: updatedTrade.entryPrice || event.price,
                  };
                }
                return event;
              });
            }

            if (updated) {
              fixed++;
              fixedTrades.push({
                id: trade.id,
                ticker: trade.ticker,
                oldEntryTime: trade.entryTime,
                newEntryTime: updatedTrade.entryTime,
                oldEntryPrice: trade.entryPrice,
                newEntryPrice: updatedTrade.entryPrice,
                matchMethod: matchMethod,
              });
              const index = allTrades.findIndex((t) => t.id === trade.id);
              if (index >= 0) {
                allTrades[index] = updatedTrade;
              }
            }
          }

          if (fixed > 0) {
            await kvPutJSON(KV, tradesKey, allTrades);
          }

          return sendJSON(
            {
              ok: true,
              fixed,
              totalTrades: allTrades.length,
              fixedTrades: fixedTrades.slice(0, 50), // Show first 50
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/clear-all-trades?key=... - Clear all trades and start fresh
      if (routeKey === "POST /timed/debug/clear-all-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const tradeCount = allTrades.length;

          // Clear all trades
          await KV.delete(tradesKey);

          return sendJSON(
            {
              ok: true,
              message: "All trades cleared successfully",
              clearedCount: tradeCount,
              note: "New trades will be created automatically as TradingView alerts come in",
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/debug/simulate-trades?key=... - Manually simulate trades for all tickers
      if (routeKey === "POST /timed/debug/simulate-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
          const results = {
            processed: 0,
            created: 0,
            updated: 0,
            skipped: 0,
            errors: [],
          };

          // Process first 50 tickers to avoid timeout
          for (const ticker of tickerIndex.slice(0, 50)) {
            try {
              const latestData = await kvGetJSON(KV, `timed:latest:${ticker}`);
              if (latestData) {
                const prevLatest = null; // No previous data for manual simulation
                await processTradeSimulation(
                  KV,
                  ticker,
                  latestData,
                  prevLatest,
                  env,
                );
                results.processed++;
              } else {
                results.skipped++;
              }
            } catch (err) {
              results.errors.push({ ticker, error: err.message });
            }
          }

          // Get final trade count
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const openTrades = allTrades.filter(
            (t) =>
              t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
          );

          return sendJSON(
            {
              ok: true,
              message: `Processed ${results.processed} tickers`,
              results,
              currentTrades: {
                total: allTrades.length,
                open: openTrades.length,
              },
            },
            200,
            corsHeaders(env, req),
          );
        } catch (err) {
          return sendJSON(
            { ok: false, error: err.message },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/ml/train?key=... - Trigger ML model training from labeled queue
      if (routeKey === "POST /timed/ml/train") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const limit = Number(url.searchParams.get("limit")) || 75;
          const force = url.searchParams.get("force") === "1";
          const result = await mlV1TrainFromQueue(env, KV, limit, force);
          return sendJSON(result, 200, corsHeaders(env, req, true));
        } catch (error) {
          return sendJSON(
            { ok: false, error: String(error) },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/ml/backfill-queue?key=... - Backfill ML queue from timed_trail
      if (routeKey === "POST /timed/ml/backfill-queue") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const db = env?.DB;
          if (!db) {
            return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req, true));
          }

          await d1EnsureMlV1Schema(env);
          
          const daysBack = Number(url.searchParams.get("days")) || 7;
          const cutoff = Date.now() - (daysBack * 24 * 60 * 60 * 1000);
          
          // Get recent trail data
          const rows = await db.prepare(
            `SELECT ticker, ts, payload_json FROM timed_trail 
             WHERE ts >= ?1 
             ORDER BY ts DESC 
             LIMIT 1000`
          ).bind(cutoff).all();

          let queued = 0;
          const horizons = [4 * 60 * 60 * 1000, 24 * 60 * 60 * 1000]; // 4h, 1d

          for (const row of (rows?.results || [])) {
            try {
              const payload = JSON.parse(row.payload_json);
              await d1EnqueueMlV1(env, row.ticker, payload, horizons);
              queued++;
            } catch (e) {
              // Skip invalid entries
            }
          }

          return sendJSON(
            { ok: true, queued, daysBack, processed: rows?.results?.length || 0 },
            200,
            corsHeaders(env, req, true),
          );
        } catch (error) {
          return sendJSON(
            { ok: false, error: String(error) },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/admin/reprocess-kanban?key=...&limit=...&offset=...&ticker=...&resetTrades=1&from=YYYY-MM-DD&to=YYYY-MM-DD
      // Re-run Kanban classification + trade sim for all tickers. Batched to avoid subrequest limits.
      // Default limit=15 per call; use offset to process remaining (e.g. offset=15, offset=30).
      // resetTrades=1: purge open trades for batch tickers (optionally in from/to range) and clear entry state before reprocess.
      if (routeKey === "POST /timed/admin/reprocess-kanban") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const qLimit = Number(url.searchParams.get("limit") || "15");
        const qOffset = Number(url.searchParams.get("offset") || "0");
        const tickerFilter = normTicker(url.searchParams.get("ticker"));
        const resetTrades = url.searchParams.get("resetTrades") === "1" || url.searchParams.get("resetTrades") === "true";
        const fromDay = url.searchParams.get("from") || null; // YYYY-MM-DD
        const toDay = url.searchParams.get("to") || null;
        const DEFAULT_BATCH = 15;

        const tickersList = (await kvGetJSON(KV, "timed:tickers")) || [];
        const filtered = Array.isArray(tickersList)
          ? tickersList.filter((t) => {
              if (!t) return false;
              if (tickerFilter)
                return String(t).toUpperCase() === String(tickerFilter);
              return true;
            })
          : [];
        const limit = Math.min(
          qLimit > 0 ? qLimit : DEFAULT_BATCH,
          filtered.length,
          25,
        );
        const offset = Math.max(0, Number.isFinite(qOffset) ? qOffset : 0);
        const slice = filtered.slice(offset, offset + limit);

        // resetTrades: purge ALL trades (open + closed) for batch tickers in from/to window for clean slate
        let tradesPurged = 0;
        if (resetTrades && slice.length > 0) {
          const allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
          const sliceSet = new Set(slice.map((t) => String(t || "").toUpperCase()));
          let tsMin = null;
          let tsMax = null;
          if (fromDay && /^\d{4}-\d{2}-\d{2}$/.test(fromDay)) {
            tsMin = nyWallMidnightToUtcMs(fromDay) ?? null;
          }
          if (toDay && /^\d{4}-\d{2}-\d{2}$/.test(toDay)) {
            const endOfDay = nyWallTimeToUtcMs(toDay, 23, 59, 59);
            tsMax = endOfDay != null ? endOfDay + 999 : null;
          }
          const kept = allTrades.filter((t) => {
            const ticker = String(t?.ticker || "").toUpperCase();
            if (!sliceSet.has(ticker)) return true;
            const entryTs = Number(t?.entry_ts ?? t?.entryTime);
            if (!Number.isFinite(entryTs)) return true;
            if (tsMin != null && entryTs < tsMin) return true;
            if (tsMax != null && entryTs > tsMax) return true;
            tradesPurged += 1;
            return false;
          });
          await kvPutJSON(KV, "timed:trades:all", kept);
        }

        let updated = 0;
        let tradesCreated = 0;
        const laneCounts = {};
        const errors = [];

        for (const t of slice) {
          try {
            const ticker = String(t || "").toUpperCase();
            if (!ticker) continue;
            const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
            if (!latest || typeof latest !== "object") continue;

            const existing = latest;
            const payload = { ...latest };

            // resetTrades: clear entry state so we reprocess from scratch (no phantom Enter Now -> Exit)
            if (resetTrades) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              // Merge entry_ts/entry_price from existing + D1 position
              if (existing?.entry_ts != null || existing?.entry_price != null) {
                if (payload.entry_ts == null && Number.isFinite(Number(existing?.entry_ts)))
                  payload.entry_ts = Number(existing.entry_ts);
                if (payload.entry_price == null && Number.isFinite(Number(existing?.entry_price)))
                  payload.entry_price = Number(existing.entry_price);
              }
              // D1 SINGLE SOURCE OF TRUTH
              const openPosition = env?.DB ? await getPositionContext(env, ticker) : null;
              const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
              if (hasOpenPosition) {
                if (payload.entry_ts == null && openPosition.entry_ts) {
                  payload.entry_ts = openPosition.entry_ts;
                }
                if (payload.entry_price == null && openPosition.avg_entry_price > 0) {
                  payload.entry_price = openPosition.avg_entry_price;
                }
              }
              payload.__position_context = openPosition;
            }

            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) {
              payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
              payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
            }

            // D1 position context for Kanban classification
            const openPosition = payload.__position_context || (env?.DB ? await getPositionContext(env, ticker) : null);
            const hasOpenPosition = !!(openPosition && openPosition.status === "OPEN");
            
            const prevStage = existing?.kanban_stage;
            // Pass payload.ts as asOfTs for consistent trigger freshness check
            const payloadTs = Number(payload?.ts) || Date.now();
            const stage = classifyKanbanStage(payload, openPosition, payloadTs);
            let finalStage = stage;

            // Recycle rule: position always wins
            const prevStageLegacy = prevStage === "archive" || prevStage === "closed";
            const isManagementStage = ["active", "trim", "exit", "hold", "just_entered"].includes(stage);
            if (prevStageLegacy && isManagementStage && !hasOpenPosition) {
              finalStage = "watch";
              if (!payload.flags) payload.flags = {};
              payload.flags.recycled_from_archive = true;
            }

            const tsNow = Number(payload?.ts) || Date.now();
            const dayKeyLive = nyTradingDayKey(tsNow);
            const marketOpenLive = dayKeyLive ? nyWallTimeToUtcMs(dayKeyLive, 9, 30, 0) : null;
            const existingTsLive = existing?.ts ?? existing?.ingest_ts;
            const firstBarAfterGapLive = isFirstBarOfDayAfterGap(existingTsLive, tsNow, marketOpenLive);

            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existing?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
              const cycleSide = existing?.kanban_cycle_side != null ? String(existing.kanban_cycle_side) : null;
              const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 &&
                Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
              const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig &&
                !!cycleSide && !!curSide && cycleSide === curSide;
              if (firstBarAfterGapLive) {
                if (!payload.flags) payload.flags = {};
                payload.flags.first_bar_of_day_bridge = true;
              } else {
                if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                  finalStage = "watch";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_watch_missing_trigger = true;
                } else if (!cycleOk) {
                  finalStage = "enter";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_enter_gate = true;
                }
              }
            }

            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = tsNow;
              payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              if (firstBarAfterGapLive) {
                payload.kanban_cycle_enter_now_ts = tsNow;
                payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : tsNow;
                payload.kanban_cycle_side = sideFromStateOrScores(payload) != null ? String(sideFromStateOrScores(payload)) : null;
                if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                if (payload.entry_ts == null && Number.isFinite(tsNow)) payload.entry_ts = tsNow;
              } else {
                payload.kanban_cycle_enter_now_ts = existing?.kanban_cycle_enter_now_ts || null;
                payload.kanban_cycle_trigger_ts = existing?.kanban_cycle_trigger_ts || null;
                payload.kanban_cycle_side = existing?.kanban_cycle_side || null;
              }
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }

            if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = tsNow;
            }

            if (finalStage === "enter_now" && prevStage !== "enter_now") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) {
                payload.entry_price = price;
                payload.entry_ts = payload.ts;
              }
            }
            if (finalStage && existing?.entry_price) {
              payload.entry_price = existing.entry_price;
              payload.entry_ts = existing.entry_ts;
            }

            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);

            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;

            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
            updated += 1;

            const tradesBefore = (await kvGetJSON(KV, "timed:trades:all")) || [];
            const countBefore = tradesBefore.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            await processTradeSimulation(KV, ticker, payload, existing, env, { forceUseIngestTs: true });
            const tradesAfter = (await kvGetJSON(KV, "timed:trades:all")) || [];
            const countAfter = tradesAfter.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
          } catch (e) {
            errors.push({ ticker: t || null, error: String(e?.message || e) });
          }
        }

        try {
          await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50);
        } catch (syncErr) {
          errors.push({ sync: String(syncErr?.message || syncErr) });
        }

        const nextOffset = offset + slice.length;
        const hasMore = nextOffset < filtered.length;

        return sendJSON(
          {
            ok: true,
            tickersProcessed: updated,
            tradesCreated,
            tradesPurged: resetTrades ? tradesPurged : undefined,
            laneCounts,
            offset,
            nextOffset: hasMore ? nextOffset : null,
            hasMore,
            total: filtered.length,
            errorsCount: errors.length,
            errors: errors.slice(0, 10),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/replay-ticker?key=...&ticker=BE&date=YYYY-MM-DD
      // Single-ticker replay: fetches trail via d1GetTrailRange (no payload_json), processes chronologically.
      // Use this for ticker-by-ticker replay; avoids D1 large-result limits.
      if (routeKey === "POST /timed/admin/replay-ticker") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        if (!tickerParam) {
          return sendJSON({ ok: false, error: "missing ticker" }, 400, corsHeaders(env, req));
        }
        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";

        const trailRes = await d1GetTrailRange(env, tickerParam, Math.floor(tsStart), 500);
        if (!trailRes?.ok) {
          return sendJSON(
            { ok: false, error: "trail_fetch_failed", detail: trailRes?.error || "unknown" },
            500,
            corsHeaders(env, req),
          );
        }
        const trail = (trailRes?.trail || []).filter(
          (p) => { const ts = Number(p?.ts); return Number.isFinite(ts) && ts >= tsStart && ts <= tsEnd; },
        );
        let rows;
        let replaySource = "timed_trail";

        if (trail.length > 0) {
          rows = trail.map((p) => {
            const ts = Number(p?.ts);
            const obj = { ticker: tickerParam, ts, price: p?.price, htf_score: p?.htf_score, ltf_score: p?.ltf_score, completion: p?.completion, phase_pct: p?.phase_pct, state: p?.state, rank: p?.rank, flags: p?.flags || {}, trigger_reason: p?.trigger_reason, trigger_dir: p?.trigger_dir, trigger_ts: p?.trigger_ts ?? ts, sl: p?.sl, tp: p?.tp, tp_levels: p?.tp_levels, kanban_stage: p?.kanban_stage };
            return { ticker: tickerParam, ts: obj.ts, payload_json: JSON.stringify(obj) };
          });
        } else {
          // Fallback: reconstruct from trail_5m_facts (for data older than 48h)
          replaySource = "trail_5m_facts";
          const db = env?.DB;
          let factsRows = [];
          if (db) {
            try {
              const factsRes = await db
                .prepare(
                  `SELECT bucket_ts, price_open, price_high, price_low, price_close,
                          htf_score_avg, ltf_score_avg, state, rank, completion, phase_pct,
                          kanban_stage_start, kanban_stage_end,
                          had_squeeze_release, had_ema_cross, had_st_flip, had_momentum_elite
                   FROM trail_5m_facts
                   WHERE ticker = ?1 AND bucket_ts >= ?2 AND bucket_ts <= ?3
                   ORDER BY bucket_ts ASC`,
                )
                .bind(tickerParam, tsStart, tsEnd)
                .all();
              factsRows = factsRes?.results || [];
            } catch (e) {
              console.error(`[REPLAY-TICKER] Facts fallback error:`, e);
            }
          }
          rows = factsRows.map((f) => {
            const ts = Number(f.bucket_ts);
            const obj = {
              ticker: tickerParam, ts,
              price: f.price_close ?? f.price_open,
              htf_score: f.htf_score_avg, ltf_score: f.ltf_score_avg,
              state: f.state, rank: f.rank,
              completion: f.completion, phase_pct: f.phase_pct,
              trigger_ts: ts, trigger_reason: null, trigger_dir: null,
              kanban_stage: f.kanban_stage_end || f.kanban_stage_start || null,
              flags: {
                squeeze_release: !!f.had_squeeze_release,
                ema_cross: !!f.had_ema_cross,
                st_flip: !!f.had_st_flip,
                momentum_elite: !!f.had_momentum_elite,
              },
            };
            return { ticker: tickerParam, ts, payload_json: JSON.stringify(obj) };
          });
        }

        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        let tradesPurged = 0;
        if (cleanSlate && rows.length > 0) {
          const kept = allTrades.filter((t) => {
            if (String(t?.ticker || "").toUpperCase() !== tickerParam) return true;
            const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
            if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
            if (entryTs < tsStart || entryTs > tsEnd) return true;
            tradesPurged += 1;
            return false;
          });
          allTrades = kept;
          await kvPutJSON(KV, "timed:trades:all", kept);
        }

        const existing = (await kvGetJSON(KV, `timed:latest:${tickerParam}`)) || {};
        const stateMap = { [tickerParam]: cleanSlate ? { ...existing, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null } : { ...existing } };
        const findOpenInArray = (trades, sym) => trades.find((x) => String(x?.ticker || "").toUpperCase() === sym && isOpenTradeStatus(x?.status)) || null;
        const replayCtx = { allTrades, debugEntries: [], processDebug: [] };
        let processed = 0, tradesCreated = 0;
        const laneCounts = {};
        const replayTimeline = []; // Per-snapshot timeline for time-travel

        for (const row of rows) {
          try {
            const ticker = tickerParam;
            let payload;
            try { payload = row.payload_json ? JSON.parse(row.payload_json) : null; } catch { continue; }
            if (!payload || typeof payload !== "object") continue;
            const rowTs = Number(row?.ts);
            if (!Number.isFinite(rowTs)) continue;
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            const existingState = stateMap[ticker] || {};
            const existingTs = Number(existingState?.ts ?? existingState?.ingest_ts);
            const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;
            if (isEarlierThanStored) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              if (existingState?.entry_ts != null && payload.entry_ts == null) payload.entry_ts = Number(existingState.entry_ts);
              if (existingState?.entry_price != null && payload.entry_price == null) payload.entry_price = Number(existingState.entry_price);
              if (existingState?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existingState.kanban_cycle_enter_now_ts;
              if (existingState?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existingState.kanban_cycle_trigger_ts;
              if (existingState?.kanban_cycle_side != null) payload.kanban_cycle_side = existingState.kanban_cycle_side;
            }
            const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
            if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
              const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
              const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
              if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
              if (payload.entry_price == null && Number.isFinite(ep) && ep > 0) payload.entry_price = ep;
            }
            // Compute derived fields (rr, score) - not stored in ingest_receipts/trail
            if (payload.rr == null || !Number.isFinite(Number(payload.rr))) {
              payload.rr = computeRR(payload);
              if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
            }
            if (payload.score == null && payload.rank == null) {
              payload.score = computeRank(payload);
            }
            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) { payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED"; payload.flags.move_completed = payload.move_status?.status === "COMPLETED"; }
            const prevStage = existingState?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            let finalStage = stage;
            if (prevStage === "archive" && ["hold", "just_entered", "trim", "exit"].includes(stage)) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.recycled_from_archive = true; }
            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existingState?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existingState?.kanban_cycle_trigger_ts);
              const cycleSide = existingState?.kanban_cycle_side != null ? String(existingState.kanban_cycle_side) : null;
              const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 && Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
              const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig && !!cycleSide && !!curSide && cycleSide === curSide;
              if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.forced_watch_missing_trigger = true; }
              else if (!cycleOk) { finalStage = "enter"; if (!payload.flags) payload.flags = {}; payload.flags.forced_enter_gate = true; }
            }
            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = rowTs;
              payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              payload.kanban_cycle_enter_now_ts = existingState?.kanban_cycle_enter_now_ts ?? null;
              payload.kanban_cycle_trigger_ts = existingState?.kanban_cycle_trigger_ts ?? null;
              payload.kanban_cycle_side = existingState?.kanban_cycle_side ?? null;
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }
            if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }
            if (finalStage === "enter_now" && prevStage !== "enter_now") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) { payload.entry_price = price; payload.entry_ts = rowTs; }
            }
            if (finalStage && existingState?.entry_price) { payload.entry_price = existingState.entry_price; payload.entry_ts = existingState.entry_ts; }
            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;
            // Capture per-snapshot timeline point
            replayTimeline.push({
              ts: rowTs,
              ticker,
              price: payload.price != null ? Number(payload.price) : null,
              htf_score: payload.htf_score != null ? Number(payload.htf_score) : null,
              ltf_score: payload.ltf_score != null ? Number(payload.ltf_score) : null,
              state: payload.state || null,
              kanban_stage: finalStage,
              prev_stage: prevStage || null,
            });
            stateMap[ticker] = payload;
            const countBefore = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            // Capture debug for first few "enter" rows
            const openTradeCheck = replayCtx.allTrades.find((t) => String(t?.ticker || "").toUpperCase() === ticker && (String(t?.status || "").toUpperCase() === "OPEN" || String(t?.status || "").toUpperCase() === "TP_HIT_TRIM"));
            if ((finalStage === "enter" || finalStage === "enter_now") && replayCtx.debugEntries.length < 3) {
              replayCtx.debugEntries.push({
                ts: rowTs,
                stage: finalStage,
                entryPath: payload.__entry_path,
                state: payload.state,
                htf: payload.htf_score,
                ltf: payload.ltf_score,
                price: payload.price,
                sl: payload.sl,
                tp: payload.tp,
                atr: payload.atr,
                tradeCountBefore: countBefore,
                openTradeExists: !!openTradeCheck,
                openTradeStatus: openTradeCheck?.status || null,
              });
            }
            await processTradeSimulation(KV, ticker, payload, existingState, env, { forceUseIngestTs: true, replayBatchContext: replayCtx, asOfTs: rowTs });
            const countAfter = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
            if ((finalStage === "enter" || finalStage === "enter_now") && replayCtx.debugEntries.length > 0 && replayCtx.debugEntries[replayCtx.debugEntries.length - 1].ts === rowTs) {
              replayCtx.debugEntries[replayCtx.debugEntries.length - 1].tradeCountAfter = countAfter;
              replayCtx.debugEntries[replayCtx.debugEntries.length - 1].tradeCreated = countAfter > countBefore;
            }
            processed += 1;
          } catch (e) {
            console.error(`[REPLAY-TICKER] ${tickerParam} row error:`, e);
          }
        }

        await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
        await kvPutJSON(KV, `timed:latest:${tickerParam}`, stateMap[tickerParam] || {});
        try { await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50); } catch {}
        return sendJSON({
          ok: true,
          ticker: tickerParam,
          day: dayKey,
          source: replaySource,
          rowsProcessed: processed,
          tradesCreated,
          tradesPurged,
          laneCounts,
          timeline: replayTimeline,
          debugEntries: replayCtx.debugEntries || [],
          processDebug: replayCtx.processDebug || [],
        }, 200, corsHeaders(env, req));
      }

      // POST /timed/admin/replay-ticker-d1?key=...&ticker=AAPL&date=YYYY-MM-DD&cleanSlate=1
      // Single-ticker replay from D1 timed_trail (payload_json). Processes all rows in one request, writes KV only at end (avoids 429).
      if (routeKey === "POST /timed/admin/replay-ticker-d1") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }
        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        if (!tickerParam) {
          return sendJSON({ ok: false, error: "missing ticker" }, 400, corsHeaders(env, req));
        }
        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";
        const debug = url.searchParams.get("debug") === "1" || url.searchParams.get("debug") === "true";
        const limit = Math.min(2000, Math.max(1, parseInt(url.searchParams.get("limit") || "1000", 10)));

        let rows = [];
        try {
          const res = await db.prepare(
            `SELECT ts, payload_json FROM timed_trail
             WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3 AND payload_json IS NOT NULL
             ORDER BY ts ASC LIMIT ?4`,
          ).bind(tickerParam, Math.floor(tsStart), Math.floor(tsEnd), limit).all();
          const results = res?.results || [];
          rows = results.map((r) => ({
            ticker: tickerParam,
            ts: Number(r?.ts),
            payload_json: r?.payload_json ?? null,
          })).filter((r) => r.ts != null && Number.isFinite(r.ts));
        } catch (e) {
          return sendJSON({ ok: false, error: "d1_query_failed", detail: String(e?.message || e) }, 500, corsHeaders(env, req));
        }

        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        let tradesPurged = 0;
        if (cleanSlate && rows.length > 0) {
          const kept = allTrades.filter((t) => {
            if (String(t?.ticker || "").toUpperCase() !== tickerParam) return true;
            const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
            if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
            if (entryTs < tsStart || entryTs > tsEnd) return true;
            tradesPurged += 1;
            return false;
          });
          allTrades = kept;
          await kvPutJSON(KV, "timed:trades:all", kept);
        }

        const existing = (await kvGetJSON(KV, `timed:latest:${tickerParam}`)) || {};
        let stateMap = { [tickerParam]: cleanSlate ? { ...existing, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null } : { ...existing } };

        // Bridge 4pm–9:30am: seed with last known state before tsStart so first row can detect justEnteredCorridor / enteredAligned
        const includePrevPeriod = url.searchParams.get("includePrevPeriod") !== "0" && url.searchParams.get("includePrevPeriod") !== "false";
        let prevPeriodSeeded = false;
        if (includePrevPeriod && rows.length > 0) {
          try {
            const prevRow = await db.prepare(
              `SELECT ts, payload_json FROM timed_trail
               WHERE ticker = ?1 AND ts < ?2 AND payload_json IS NOT NULL
               ORDER BY ts DESC LIMIT 1`,
            ).bind(tickerParam, Math.floor(tsStart)).first();
            if (prevRow?.payload_json) {
              let prevPayload = null;
              try { prevPayload = JSON.parse(prevRow.payload_json); } catch {}
              if (prevPayload && typeof prevPayload === "object") {
                const prevTs = Number(prevRow?.ts);
                prevPayload.ts = prevTs;
                prevPayload.ingest_ts = prevTs;
                if ((prevPayload.trigger_ts == null || !Number.isFinite(Number(prevPayload.trigger_ts))) && Number.isFinite(prevTs)) prevPayload.trigger_ts = prevTs < 1e12 ? prevTs * 1000 : prevTs;
                if ((prevPayload.sl == null || !Number.isFinite(Number(prevPayload.sl))) && prevPayload.sl_price != null) prevPayload.sl = prevPayload.sl_price;
                const tpVal = prevPayload.tp ?? prevPayload.tp_max_price ?? prevPayload.tp_target_price ?? prevPayload.tp_target;
                if ((prevPayload.tp == null || !Number.isFinite(Number(prevPayload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) prevPayload.tp = Number(tpVal);
                prevPayload.move_status = computeMoveStatus(prevPayload);
                if (prevPayload.flags) { prevPayload.flags.move_invalidated = prevPayload.move_status?.status === "INVALIDATED"; prevPayload.flags.move_completed = prevPayload.move_status?.status === "COMPLETED"; }
                prevPayload.kanban_stage = classifyKanbanStage(prevPayload);
                prevPayload.kanban_meta = deriveKanbanMeta(prevPayload, prevPayload.kanban_stage);
                stateMap = { [tickerParam]: prevPayload };
                prevPeriodSeeded = true;
              }
            }
          } catch (e) {
            console.error("[REPLAY-TICKER-D1] prev-period seed failed:", e?.message || e);
          }
        }

        const findOpenInArray = (trades, sym) => trades.find((x) => String(x?.ticker || "").toUpperCase() === sym && isOpenTradeStatus(x?.status)) || null;
        const replayCtx = { allTrades, execStates: new Map() };
        let processed = 0, tradesCreated = 0;
        const laneCounts = {};

        for (const row of rows) {
          try {
            const ticker = tickerParam;
            let payload;
            try { payload = row.payload_json ? JSON.parse(row.payload_json) : null; } catch { continue; }
            if (!payload || typeof payload !== "object") continue;
            const rowTs = Number(row?.ts);
            if (!Number.isFinite(rowTs)) continue;
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
              payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
            }
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
            const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
            if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);

            const existingState = stateMap[ticker] || {};
            const existingTs = Number(existingState?.ts ?? existingState?.ingest_ts);
            const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;
            if (isEarlierThanStored) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              if (existingState?.entry_ts != null && payload.entry_ts == null) payload.entry_ts = Number(existingState.entry_ts);
              if (existingState?.entry_price != null && payload.entry_price == null) payload.entry_price = Number(existingState.entry_price);
              if (existingState?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existingState.kanban_cycle_enter_now_ts;
              if (existingState?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existingState.kanban_cycle_trigger_ts;
              if (existingState?.kanban_cycle_side != null) payload.kanban_cycle_side = existingState.kanban_cycle_side;
            }
            const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
            if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
              const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
              const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
              if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
              if (payload.entry_price == null && Number.isFinite(ep) && ep > 0) payload.entry_price = ep;
            }
            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) { payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED"; payload.flags.move_completed = payload.move_status?.status === "COMPLETED"; }
            const prevStage = existingState?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            let finalStage = stage;
            if (prevStage === "archive" && ["hold", "just_entered", "trim", "exit"].includes(stage)) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.recycled_from_archive = true; }
            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            const firstBarAfterGap = isFirstBarOfDayAfterGap(existingTs, rowTs, tsStart);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existingState?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existingState?.kanban_cycle_trigger_ts);
              const cycleSide = existingState?.kanban_cycle_side != null ? String(existingState.kanban_cycle_side) : null;
              const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 && Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
              const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig && !!cycleSide && !!curSide && cycleSide === curSide;
              if (firstBarAfterGap) {
                if (!payload.flags) payload.flags = {};
                payload.flags.first_bar_of_day_bridge = true;
              } else {
                if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) { finalStage = "watch"; if (!payload.flags) payload.flags = {}; payload.flags.forced_watch_missing_trigger = true; }
                else if (!cycleOk) { finalStage = "enter"; if (!payload.flags) payload.flags = {}; payload.flags.forced_enter_gate = true; }
              }
            }
            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = rowTs;
              payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              if (firstBarAfterGap) {
                payload.kanban_cycle_enter_now_ts = rowTs;
                payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : rowTs;
                payload.kanban_cycle_side = sideFromStateOrScores(payload);
                if (payload.entry_price == null && Number.isFinite(Number(payload?.price))) payload.entry_price = Number(payload.price);
                if (payload.entry_ts == null && Number.isFinite(rowTs)) payload.entry_ts = rowTs;
              } else {
                payload.kanban_cycle_enter_now_ts = existingState?.kanban_cycle_enter_now_ts ?? null;
                payload.kanban_cycle_trigger_ts = existingState?.kanban_cycle_trigger_ts ?? null;
                payload.kanban_cycle_side = existingState?.kanban_cycle_side ?? null;
              }
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }
            if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }
            if (finalStage === "enter_now" && prevStage !== "enter_now") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) { payload.entry_price = price; payload.entry_ts = rowTs; }
            }
            if (finalStage && existingState?.entry_price) { payload.entry_price = existingState.entry_price; payload.entry_ts = existingState.entry_ts; }
            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;
            stateMap[ticker] = payload;

            if (debug) {
              replayCtx.analysisRows = replayCtx.analysisRows || [];
              if (replayCtx.analysisRows.length < 300) {
                const shouldTrigger = finalStage === "enter_now" ? shouldTriggerTradeSimulation(ticker, payload, existingState) : false;
                const blockers = finalStage === "enter_now" ? getEntryBlockers(ticker, payload, existingState) : [];
                const compRaw = completionForSize(payload);
                const compToMax = computeCompletionToTpMax(payload);
                const compUsed = Number.isFinite(compToMax) ? compToMax : compRaw;
                const forcedReason = payload.flags?.forced_watch_missing_trigger ? "forced_watch_missing_trigger" : payload.flags?.forced_enter_now_gate ? "forced_enter_now_gate" : payload.flags?.first_bar_of_day_bridge ? "first_bar_of_day_bridge" : null;
                replayCtx.analysisRows.push({
                  ts: rowTs,
                  time: new Date(rowTs < 1e12 ? rowTs * 1000 : rowTs).toISOString(),
                  stage,
                  finalStage,
                  shouldTrigger: finalStage === "enter_now" ? shouldTrigger : null,
                  blockers: finalStage === "enter_now" && blockers.length ? blockers : null,
                  forcedReason,
                  rank: payload.rank ?? payload.rank_position ?? payload.position,
                  rr: payload.rr != null ? Number(payload.rr) : null,
                  comp: compUsed,
                  phase: payload.phase_pct != null ? Number(payload.phase_pct) : null,
                  state: payload.state,
                  trigger_reason: payload.trigger_reason || null,
                  price: payload.price != null ? Number(payload.price) : null,
                  htf: payload.htf_score != null ? Number(payload.htf_score) : null,
                  ltf: payload.ltf_score != null ? Number(payload.ltf_score) : null,
                  prevStage: existingState?.kanban_stage || null,
                });
              }
            }

            const countBefore = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            await processTradeSimulation(KV, ticker, payload, existingState, env, { forceUseIngestTs: true, replayBatchContext: replayCtx, asOfTs: rowTs });
            const countAfter = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
            processed += 1;
          } catch (e) {
            console.error(`[REPLAY-TICKER-D1] ${tickerParam} row error:`, e);
          }
        }

        await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
        await kvPutJSON(KV, `timed:latest:${tickerParam}`, stateMap[tickerParam] || {});
        try { await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50); } catch {}
        const resp = {
          ok: true,
          ticker: tickerParam,
          day: dayKey,
          source: "timed_trail",
          rowsProcessed: processed,
          tradesCreated,
          tradesPurged,
          laneCounts,
          prevPeriodSeeded,
        };
        if (debug && replayCtx.analysisRows) {
          const enterNowRows = replayCtx.analysisRows.filter((r) => r.finalStage === "enter_now");
          const forcedWatch = replayCtx.analysisRows.filter((r) => r.forcedReason === "forced_watch_missing_trigger");
          const forcedEnterNow = replayCtx.analysisRows.filter((r) => r.forcedReason === "forced_enter_now_gate");
          resp.analysis = {
            rows: replayCtx.analysisRows,
            enterNowCount: enterNowRows.length,
            forcedWatchCount: forcedWatch.length,
            forcedEnterNowCount: forcedEnterNow.length,
            firstBarBridgeCount: replayCtx.analysisRows.filter((r) => r.forcedReason === "first_bar_of_day_bridge").length,
          };
        }
        return sendJSON(resp, 200, corsHeaders(env, req));
      }

      // GET /timed/admin/replay-data-stats?key=...&date=YYYY-MM-DD&ticker=AAPL
      // Returns row counts and payload_json presence for timed_trail vs ingest_receipts (confirm D1 as replay source).
      if (routeKey === "GET /timed/admin/replay-data-stats") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }
        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const tsStartInt = Math.floor(Number(tsStart));
        const tsEndInt = Math.floor(Number(tsEnd));
        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();

        try {
          const trailTotal = tickerParam
            ? await db.prepare(
                `SELECT count(*) AS n, sum(CASE WHEN payload_json IS NOT NULL AND length(payload_json) > 0 THEN 1 ELSE 0 END) AS with_payload
                 FROM timed_trail WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3`,
              ).bind(tickerParam, tsStartInt, tsEndInt).first()
            : await db.prepare(
                `SELECT count(*) AS n, sum(CASE WHEN payload_json IS NOT NULL AND length(payload_json) > 0 THEN 1 ELSE 0 END) AS with_payload
                 FROM timed_trail WHERE ts >= ?1 AND ts <= ?2`,
              ).bind(tsStartInt, tsEndInt).first();
          const receiptTotal = tickerParam
            ? await db.prepare(
                `SELECT count(*) AS n FROM ingest_receipts WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3`,
              ).bind(tickerParam, tsStartInt, tsEndInt).first()
            : await db.prepare(
                `SELECT count(*) AS n FROM ingest_receipts WHERE ts >= ?1 AND ts <= ?2`,
              ).bind(tsStartInt, tsEndInt).first();

          const trailN = Number(trailTotal?.n) || 0;
          const trailWithPayload = Number(trailTotal?.with_payload) || 0;
          const receiptN = Number(receiptTotal?.n) || 0;

          return sendJSON({
            ok: true,
            date: dayKey,
            ticker: tickerParam || null,
            tsStart: tsStartInt,
            tsEnd: tsEndInt,
            timed_trail: { rows: trailN, rows_with_payload_json: trailWithPayload, usable: trailWithPayload > 0 },
            ingest_receipts: { rows: receiptN },
            recommendation: trailWithPayload > 0
              ? "Use replay-ticker-d1 (timed_trail) for single-ticker replay to avoid KV 429."
              : receiptN > 0
                ? "timed_trail has no payload_json; use replay-ingest (ingest_receipts) or backfill timed_trail from ingest."
                : "No data for this date/ticker; run ingest or backfill first.",
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: "query_failed", detail: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/admin/data-range?key=... — Returns first and last date with valid replay data (ingest_receipts, 7d retention).
      if (routeKey === "GET /timed/admin/data-range") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;
        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }
        try {
          const row = await db.prepare(
            `SELECT MIN(ts) AS min_ts, MAX(ts) AS max_ts, COUNT(*) AS total FROM ingest_receipts`
          ).first();
          const minTs = Number(row?.min_ts);
          const maxTs = Number(row?.max_ts);
          const total = Number(row?.total) || 0;
          if (!Number.isFinite(minTs) || !Number.isFinite(maxTs) || total === 0) {
            return sendJSON({ ok: true, firstDate: null, lastDate: null, totalRows: 0, source: "ingest_receipts" }, 200, corsHeaders(env, req));
          }
          const firstDate = nyTradingDayKey(minTs);
          const lastDate = nyTradingDayKey(maxTs);
          return sendJSON({
            ok: true,
            firstDate: firstDate || null,
            lastDate: lastDate || null,
            minTs,
            maxTs,
            totalRows: total,
            source: "ingest_receipts",
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: "query_failed", detail: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // GET /timed/admin/history?key=...&ticker=AAPL&date=YYYY-MM-DD
      // Time-travel endpoint: returns historical score + kanban lane timeline for a ticker on a given day.
      // Reads from trail_5m_facts (30+ day retention) with fallback to timed_trail (48h raw data).
      // Returns 5-minute bucketed snapshots: {ts, price, htf_score, ltf_score, state, kanban_stage, flags}
      if (routeKey === "GET /timed/admin/history") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));

        const tickerParam = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        if (!tickerParam) return sendJSON({ ok: false, error: "missing ticker param" }, 400, corsHeaders(env, req));

        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());

        // Compute day boundaries (UTC ms)
        const dayStartMs = new Date(dayKey + "T00:00:00Z").getTime();
        const dayEndMs = new Date(dayKey + "T23:59:59Z").getTime();

        let source = "trail_5m_facts";
        let timeline = [];

        try {
          // Try trail_5m_facts first (long-term archive)
          const factsRes = await db
            .prepare(
              `SELECT bucket_ts, price_open, price_high, price_low, price_close,
                      htf_score_avg, htf_score_min, htf_score_max,
                      ltf_score_avg, ltf_score_min, ltf_score_max,
                      state, rank, completion, phase_pct,
                      kanban_stage_start, kanban_stage_end, kanban_changed,
                      had_squeeze_release, had_ema_cross, had_st_flip, had_momentum_elite,
                      sample_count
               FROM trail_5m_facts
               WHERE ticker = ?1 AND bucket_ts >= ?2 AND bucket_ts <= ?3
               ORDER BY bucket_ts ASC`,
            )
            .bind(tickerParam, dayStartMs, dayEndMs)
            .all();

          const factsRows = factsRes?.results || [];

          if (factsRows.length > 0) {
            timeline = factsRows.map((r) => ({
              ts: Number(r.bucket_ts),
              price_open: r.price_open != null ? Number(r.price_open) : null,
              price_high: r.price_high != null ? Number(r.price_high) : null,
              price_low: r.price_low != null ? Number(r.price_low) : null,
              price_close: r.price_close != null ? Number(r.price_close) : null,
              htf_score: r.htf_score_avg != null ? Number(r.htf_score_avg) : null,
              htf_score_range: r.htf_score_min != null ? [Number(r.htf_score_min), Number(r.htf_score_max)] : null,
              ltf_score: r.ltf_score_avg != null ? Number(r.ltf_score_avg) : null,
              ltf_score_range: r.ltf_score_min != null ? [Number(r.ltf_score_min), Number(r.ltf_score_max)] : null,
              state: r.state || null,
              rank: r.rank != null ? Number(r.rank) : null,
              kanban_stage: r.kanban_stage_end || r.kanban_stage_start || null,
              kanban_changed: !!r.kanban_changed,
              flags: {
                squeeze_release: !!r.had_squeeze_release,
                ema_cross: !!r.had_ema_cross,
                st_flip: !!r.had_st_flip,
                momentum_elite: !!r.had_momentum_elite,
              },
              samples: Number(r.sample_count) || 0,
            }));
          } else {
            // Fallback: read from timed_trail (raw 48h data) if facts are empty
            source = "timed_trail";
            const trailRes = await db
              .prepare(
                `SELECT ts, price, htf_score, ltf_score, state, rank, completion, phase_pct,
                        kanban_stage, flags_json
                 FROM timed_trail
                 WHERE ticker = ?1 AND ts >= ?2 AND ts <= ?3
                 ORDER BY ts ASC
                 LIMIT 5000`,
              )
              .bind(tickerParam, dayStartMs, dayEndMs)
              .all();

            const trailRows = trailRes?.results || [];

            // Bucket raw trail into 5-minute windows for consistency
            const bucketMs = 5 * 60 * 1000;
            const buckets = {};
            for (const r of trailRows) {
              const ts = Number(r.ts);
              if (!Number.isFinite(ts)) continue;
              const bucketTs = Math.floor(ts / bucketMs) * bucketMs;
              if (!buckets[bucketTs]) buckets[bucketTs] = [];
              buckets[bucketTs].push(r);
            }

            for (const [bucketTs, rows] of Object.entries(buckets).sort((a, b) => a[0] - b[0])) {
              const first = rows[0];
              const last = rows[rows.length - 1];
              let flags = {};
              try {
                if (last.flags_json) flags = JSON.parse(last.flags_json);
              } catch {}
              timeline.push({
                ts: Number(bucketTs),
                price_open: first.price != null ? Number(first.price) : null,
                price_close: last.price != null ? Number(last.price) : null,
                price_high: Math.max(...rows.map(r => Number(r.price)).filter(Number.isFinite)),
                price_low: Math.min(...rows.map(r => Number(r.price)).filter(Number.isFinite)),
                htf_score: last.htf_score != null ? Number(last.htf_score) : null,
                ltf_score: last.ltf_score != null ? Number(last.ltf_score) : null,
                state: last.state || null,
                rank: last.rank != null ? Number(last.rank) : null,
                kanban_stage: last.kanban_stage || null,
                kanban_changed: first.kanban_stage !== last.kanban_stage,
                flags: {
                  squeeze_release: !!flags.sq30_release || !!flags.squeeze_release,
                  ema_cross: !!flags.ema_cross_1h_13_48 || !!flags.ema_cross,
                  st_flip: !!flags.st_flip_30m || !!flags.st_flip,
                  momentum_elite: !!flags.momentum_elite,
                },
                samples: rows.length,
              });
            }
          }

          // Also get trade activity for this ticker on this day
          let trades = [];
          try {
            const tradesRes = await db
              .prepare(
                `SELECT trade_id, direction, entry_ts, entry_price, exit_ts, exit_price,
                        status, exit_reason, pnl_pct, trimmed_pct
                 FROM trades
                 WHERE ticker = ?1 AND entry_ts >= ?2 AND entry_ts <= ?3
                 ORDER BY entry_ts ASC`,
              )
              .bind(tickerParam, dayStartMs, dayEndMs)
              .all();
            trades = (tradesRes?.results || []).map((t) => ({
              trade_id: t.trade_id,
              direction: t.direction,
              entry_ts: Number(t.entry_ts),
              entry_price: t.entry_price != null ? Number(t.entry_price) : null,
              exit_ts: t.exit_ts != null ? Number(t.exit_ts) : null,
              exit_price: t.exit_price != null ? Number(t.exit_price) : null,
              status: t.status,
              exit_reason: t.exit_reason,
              pnl_pct: t.pnl_pct != null ? Number(t.pnl_pct) : null,
              trimmed_pct: t.trimmed_pct != null ? Number(t.trimmed_pct) : null,
            }));
          } catch {}

          // Get daily summary if available
          let dailySummary = null;
          try {
            dailySummary = await db
              .prepare(`SELECT * FROM trail_daily_summary WHERE ticker = ?1 AND date = ?2`)
              .bind(tickerParam, dayKey)
              .first();
          } catch {}

          return sendJSON({
            ok: true,
            ticker: tickerParam,
            date: dayKey,
            source,
            buckets: timeline.length,
            timeline,
            trades,
            dailySummary: dailySummary || null,
          }, 200, corsHeaders(env, req));
        } catch (e) {
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/replay-ingest?key=...&date=YYYY-MM-DD&bucket=...&ticker=...&scriptVersion=2.5.0&cleanSlate=1
      // Bucket-by-bucket replay from ingest_receipts (Script Version 2.5.0). Avoids D1 memory limits.
      // Client iterates buckets from 9:30 ET; pass bucket= to process one bucket per request.
      if (routeKey === "POST /timed/admin/replay-ingest") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON({ ok: false, error: "no_db_binding" }, 500, corsHeaders(env, req));
        }

        const dateParam = url.searchParams.get("date") || null;
        const dayKey = dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam) ? dateParam : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 16, 0, 0);
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsEnd = dayEnd != null ? dayEnd : Date.now();
        const bucketParam = url.searchParams.get("bucket");
        const bucketMs = 5 * 60 * 1000;
        const tickerFilter = (url.searchParams.get("ticker") || "").trim().toUpperCase() || null;
        const scriptVersion = url.searchParams.get("scriptVersion") || "2.5.0";
        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";
        const debug = url.searchParams.get("debug") === "1" || url.searchParams.get("debug") === "true";
        const limit = Math.min(200, Math.max(1, parseInt(url.searchParams.get("limit") || "100", 10)));
        const bucketOffset = Math.max(0, parseInt(url.searchParams.get("bucketOffset") || "0", 10));

        let currentBucket;
        if (bucketParam != null && bucketParam !== "") {
          currentBucket = parseInt(bucketParam, 10);
          if (!Number.isFinite(currentBucket)) {
            return sendJSON({ ok: false, error: "invalid_bucket" }, 400, corsHeaders(env, req));
          }
        } else {
          currentBucket = Math.floor(tsStart / bucketMs) * bucketMs;
        }

        if (currentBucket < tsStart || currentBucket > tsEnd) {
          return sendJSON({
            ok: true,
            date: dayKey,
            bucketProcessed: currentBucket,
            rowsProcessed: 0,
            tradesCreated: 0,
            tradesPurged: 0,
            nextBucket: null,
            hasMore: false,
            hasMoreInBucket: false,
          }, 200, corsHeaders(env, req));
        }

        try {
          const metaStmt = db.prepare(
            tickerFilter
              ? `SELECT receipt_id, ticker, ts FROM ingest_receipts
                 WHERE bucket_5m = ?1 AND (script_version = ?2 OR script_version IS NULL)
                 AND ticker = ?3
                 ORDER BY ts ASC LIMIT ?4 OFFSET ?5`
              : `SELECT receipt_id, ticker, ts FROM ingest_receipts
                 WHERE bucket_5m = ?1 AND (script_version = ?2 OR script_version IS NULL)
                 ORDER BY ts ASC LIMIT ?3 OFFSET ?4`,
          );
          const metaResult = tickerFilter
            ? await metaStmt.bind(currentBucket, scriptVersion, tickerFilter, limit, bucketOffset).all()
            : await metaStmt.bind(currentBucket, scriptVersion, limit, bucketOffset).all();
          const metaRows = metaResult?.results || [];

          const rows = [];
          for (const m of metaRows) {
            const receiptId = m?.receipt_id;
            if (!receiptId) continue;
            try {
              const payRow = await db.prepare(
                `SELECT payload_json FROM ingest_receipts WHERE receipt_id = ?1 LIMIT 1`,
              ).bind(String(receiptId)).first();
              const ticker = String(m?.ticker || "").toUpperCase();
              const ts = Number(m?.ts);
              if (ticker && Number.isFinite(ts)) {
                rows.push({ ticker, ts, payload_json: payRow?.payload_json ?? null });
              }
            } catch {
              // skip
            }
          }

          let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
          let tradesPurged = 0;
          const tickersInBucket = [...new Set(rows.map((r) => r.ticker))];

          if (cleanSlate && bucketOffset === 0) {
            const toRemove = allTrades.filter((t) => {
              const tkr = String(t?.ticker || "").toUpperCase();
              if (tickerFilter && tkr !== tickerFilter) return false;
              const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
              if (!Number.isFinite(entryTs) || entryTs <= 0) return false;
              if (entryTs < tsStart || entryTs > tsEnd + 86400000) return false;
              return true;
            });
            tradesPurged = toRemove.length;
            const purgedTickers = new Set(toRemove.map((t) => String(t?.ticker || "").toUpperCase()).filter(Boolean));
            tickersInBucket.forEach((t) => purgedTickers.add(t));
            allTrades = allTrades.filter((t) => !toRemove.includes(t));
            await kvPutJSON(KV, "timed:trades:all", allTrades);
            for (const tkr of purgedTickers) {
              if (!tkr) continue;
              const existing = (await kvGetJSON(KV, `timed:latest:${tkr}`)) || {};
              const reset = { ...existing, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null };
              await kvPutJSON(KV, `timed:latest:${tkr}`, reset);
            }
          }

          const stateMap = {};
          const findOpenInArray = (trades, sym) => trades.find((x) => String(x?.ticker || "").toUpperCase() === sym && isOpenTradeStatus(x?.status)) || null;
          const replayCtx = { allTrades, execStates: new Map() };
          let tradesCreated = 0;

          for (const row of rows) {
            try {
              const ticker = row.ticker;
              let payload;
              try {
                payload = row.payload_json ? JSON.parse(row.payload_json) : null;
              } catch {
                continue;
              }
              if (!payload || typeof payload !== "object") continue;
              const rowTs = row.ts;
              payload.ts = rowTs;
              payload.ingest_ts = rowTs;
              // Replay: ensure trigger_ts for lifecycle gate (use ingest ts if missing)
              if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
                payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
              }
              // Normalize SL/TP from alternate field names (ingest payload may vary)
              if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
              if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
              const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
              if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);
              const existingState = stateMap[ticker] || (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
              const existingTs = Number(existingState?.ts ?? existingState?.ingest_ts);
              const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;
              if (isEarlierThanStored) {
                payload.entry_ts = null;
                payload.entry_price = null;
                payload.kanban_cycle_enter_now_ts = null;
                payload.kanban_cycle_trigger_ts = null;
                payload.kanban_cycle_side = null;
              } else {
                if (existingState?.entry_ts != null && payload.entry_ts == null) payload.entry_ts = Number(existingState.entry_ts);
                if (existingState?.entry_price != null && payload.entry_price == null) payload.entry_price = Number(existingState.entry_price);
                if (existingState?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existingState.kanban_cycle_enter_now_ts;
                if (existingState?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existingState.kanban_cycle_trigger_ts;
                if (existingState?.kanban_cycle_side != null) payload.kanban_cycle_side = existingState.kanban_cycle_side;
              }
              const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
              if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
                const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
                const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
                if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
                if (payload.entry_price == null && Number.isFinite(ep) && ep > 0) payload.entry_price = ep;
              }
              // Compute derived fields (rr, score) - not stored in ingest_receipts
              if (payload.rr == null || !Number.isFinite(Number(payload.rr))) {
                payload.rr = computeRR(payload);
                if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
              }
              payload.move_status = computeMoveStatus(payload);
              if (payload.flags) {
                payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
                payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
              }
              if (payload.score == null && payload.rank == null && payload.rank_position == null) {
                const dyn = computeDynamicScore(payload);
                payload.score = dyn;
                if (dyn >= 70) payload.rank_position = Math.max(1, Math.min(50, Math.round(160 - dyn)));
              }
              const prevStage = existingState?.kanban_stage;
              // Pass rowTs as asOfTs for replay-aware trigger freshness check
              const stage = classifyKanbanStage(payload, null, rowTs);
              let finalStage = stage;
              if (prevStage === "archive" && ["hold", "just_entered", "trim", "exit"].includes(stage)) {
                finalStage = "watch";
                if (!payload.flags) payload.flags = {};
                payload.flags.recycled_from_archive = true;
              }
              const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
              if (mgmt) {
                const curTriggerTs = Number(payload?.trigger_ts);
                const curSide = sideFromStateOrScores(payload);
                const cycleEnterTs = Number(existingState?.kanban_cycle_enter_now_ts);
                const cycleTrig = Number(existingState?.kanban_cycle_trigger_ts);
                const cycleSide = existingState?.kanban_cycle_side != null ? String(existingState.kanban_cycle_side) : null;
                const sameTrig = Number.isFinite(curTriggerTs) && curTriggerTs > 0 && Number.isFinite(cycleTrig) && cycleTrig > 0 && cycleTrig === curTriggerTs;
                const cycleOk = Number.isFinite(cycleEnterTs) && cycleEnterTs > 0 && sameTrig && !!cycleSide && !!curSide && cycleSide === curSide;
                if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                  finalStage = "watch";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_watch_missing_trigger = true;
                } else if (!cycleOk) {
                  finalStage = "enter";
                  if (!payload.flags) payload.flags = {};
                  payload.flags.forced_enter_gate = true;
                }
              }
              if (finalStage === "enter_now" || finalStage === "enter") {
                payload.kanban_cycle_enter_now_ts = rowTs;
                payload.kanban_cycle_trigger_ts = Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0 ? payload.trigger_ts : null;
                payload.kanban_cycle_side = sideFromStateOrScores(payload);
              } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
                payload.kanban_cycle_enter_now_ts = existingState?.kanban_cycle_enter_now_ts ?? null;
                payload.kanban_cycle_trigger_ts = existingState?.kanban_cycle_trigger_ts ?? null;
                payload.kanban_cycle_side = existingState?.kanban_cycle_side ?? null;
              } else {
                payload.kanban_cycle_enter_now_ts = null;
                payload.kanban_cycle_trigger_ts = null;
                payload.kanban_cycle_side = null;
              }
              if (prevStage != null && finalStage != null && String(prevStage) !== String(finalStage)) {
                payload.prev_kanban_stage = String(prevStage);
                payload.prev_kanban_stage_ts = rowTs;
              }
              if (finalStage === "enter_now" && prevStage !== "enter_now") {
                const price = Number(payload?.price);
                if (Number.isFinite(price) && price > 0) {
                  payload.entry_price = price;
                  payload.entry_ts = rowTs;
                }
              }
              if (finalStage && existingState?.entry_price) {
                payload.entry_price = existingState.entry_price;
                payload.entry_ts = existingState.entry_ts;
              }
              payload.kanban_stage = finalStage;
              payload.kanban_meta = deriveKanbanMeta(payload, finalStage);
              stateMap[ticker] = payload;
              const countBefore = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
              const shouldTrigger = finalStage === "enter_now" ? shouldTriggerTradeSimulation(ticker, payload, existingState) : false;
              if (debug && tickerFilter) {
                replayCtx.debugRows = replayCtx.debugRows || [];
                replayCtx.debugEnterNow = (replayCtx.debugEnterNow || 0) + (finalStage === "enter_now" ? 1 : 0);
                if (finalStage === "enter_now" && replayCtx.debugRows.length < 15) {
                  const blockers = getEntryBlockers(ticker, payload, existingState);
                  const compRaw = completionForSize(payload);
                  const compToMax = computeCompletionToTpMax(payload);
                  const compUsed = Number.isFinite(compToMax) ? compToMax : compRaw;
                  replayCtx.debugRows.push({
                    ticker,
                    ts: rowTs,
                    stage: finalStage,
                    shouldTrigger,
                    blockers,
                    rank: payload.rank ?? payload.rank_position,
                    rr: payload.rr,
                    compFromPayload: payload.completion != null ? Number(payload.completion) : null,
                    compUsed,
                    compToMax: Number.isFinite(compToMax) ? compToMax : null,
                    price: payload.price != null ? Number(payload.price) : null,
                    trigger_price: payload.trigger_price != null ? Number(payload.trigger_price) : null,
                    tp: payload.tp != null ? Number(payload.tp) : null,
                    tp_max: computeTpMaxFromLevels(payload),
                    trigger_reason: payload.trigger_reason,
                  });
                } else if (finalStage === "watch" && payload.state === "HTF_BULL_LTF_BULL" && replayCtx.debugRows.length < 5) {
                  const ent = entryType(payload);
                  if (ent?.corridor) {
                    replayCtx.debugRows.push({ ticker, ts: rowTs, stage: "watch", reason: "momentum_in_corridor_but_watch", rank: payload.rank ?? payload.rank_position, score: payload.score, trigger_reason: payload.trigger_reason });
                  }
                }
              }
              await processTradeSimulation(KV, ticker, payload, existingState, env, { forceUseIngestTs: true, replayBatchContext: replayCtx, asOfTs: rowTs });
              const countAfter = replayCtx.allTrades.filter((x) => String(x?.ticker).toUpperCase() === ticker).length;
              if (countAfter > countBefore) tradesCreated += countAfter - countBefore;
            } catch (e) {
              console.error(`[REPLAY-INGEST] row error:`, e);
            }
          }

          for (const [ticker, payload] of Object.entries(stateMap)) {
            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
          }
          await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);

          const nextBucket = currentBucket + bucketMs;
          const hasMoreInBucket = rows.length >= limit;
          const nextBucketOffset = hasMoreInBucket ? bucketOffset + rows.length : null;
          const hasMore = hasMoreInBucket || nextBucket <= tsEnd;

          const resp = {
            ok: true,
            date: dayKey,
            ticker: tickerFilter || null,
            bucketProcessed: currentBucket,
            bucketOffset,
            rowsProcessed: rows.length,
            tradesCreated,
            tradesPurged,
            nextBucket: !hasMoreInBucket && nextBucket <= tsEnd ? nextBucket : null,
            nextBucketOffset: hasMoreInBucket ? nextBucketOffset : null,
            hasMore,
            hasMoreInBucket,
          };
          if (debug) {
            resp.debug = { rows: replayCtx?.debugRows || [], enterNowCount: replayCtx?.debugEnterNow || 0 };
          }
          return sendJSON(resp, 200, corsHeaders(env, req));
        } catch (e) {
          console.error("[REPLAY-INGEST] error:", e);
          return sendJSON({ ok: false, error: String(e?.message || e) }, 500, corsHeaders(env, req));
        }
      }

      // POST /timed/admin/replay-day?key=...&date=YYYY-MM-DD&limit=...&offset=...&cleanSlate=1&bucketMinutes=5
      // Replay a day's timed_trail ingests from 9:30 AM ET, chronologically. Kanban + trade simulation.
      // cleanSlate=1: purge ALL trades and reset entry state for a clean simulation of the day only.
      // bucketMinutes=5: group ingests into 5-min buckets (latest per ticker per bucket) for structured progression.
      if (routeKey === "POST /timed/admin/replay-day") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        if (!db) {
          return sendJSON(
            { ok: false, error: "no_db_binding" },
            500,
            corsHeaders(env, req),
          );
        }

        const dateParam = url.searchParams.get("date") || null;
        const dayKey =
          dateParam && /^\d{4}-\d{2}-\d{2}$/.test(dateParam)
            ? dateParam
            : nyTradingDayKey(Date.now());
        const marketOpen = nyWallTimeToUtcMs(dayKey, 9, 30, 0);
        const dayEnd = nyWallTimeToUtcMs(dayKey, 23, 59, 59);
        const tsEnd = dayEnd != null ? dayEnd + 999 : Date.now();
        const tsStart = marketOpen != null ? marketOpen : Date.now() - 24 * 60 * 60 * 1000;
        const tsStartInt = Math.floor(Number(tsStart));
        const tsEndInt = Math.floor(Number(tsEnd));

        const cleanSlate = url.searchParams.get("cleanSlate") === "1" || url.searchParams.get("cleanSlate") === "true";
        const useServerScores = url.searchParams.get("useServerScores") === "1";
        const bucketMinutes = Math.max(1, Math.min(60, Number(url.searchParams.get("bucketMinutes")) || 0));
        const tickerFilter = (url.searchParams.get("ticker") || "").trim().toUpperCase();
        const qLimit = tickerFilter ? 1000 : Math.min(Number(url.searchParams.get("limit")) || 500, 2000);
        const qOffset = Number(url.searchParams.get("offset")) || 0;

        let rows = [];
        let totalRows = null;
        try {
          if (bucketMinutes > 0) {
            // Bucket mode: fetch receipt_id,ticker,ts first (avoids huge payload_json in bulk), then fetch payload per batch
            const metaRes = await db.prepare(
              `SELECT receipt_id, ticker, ts FROM ingest_receipts
               WHERE ts >= ?1 AND ts <= ?2
               ORDER BY ts ASC`,
            ).bind(tsStart, tsEnd).all();
            const metaRows = metaRes?.results || [];
            const bucketMs = bucketMinutes * 60 * 1000;
            const byBucket = {};
            for (const r of metaRows) {
              const ts = Number(r?.ts);
              if (!Number.isFinite(ts)) continue;
              const bucketTs = Math.floor(ts / bucketMs) * bucketMs;
              if (!byBucket[bucketTs]) byBucket[bucketTs] = {};
              const tkr = String(r?.ticker || "").toUpperCase();
              if (!tkr) continue;
              byBucket[bucketTs][tkr] = { receipt_id: r?.receipt_id, ticker: tkr, ts };
            }
            const buckets = Object.keys(byBucket).map(Number).sort((a, b) => a - b);
            const bucketedMeta = [];
            for (const bt of buckets) {
              for (const r of Object.values(byBucket[bt])) bucketedMeta.push(r);
            }
            totalRows = bucketedMeta.length;
            const batch = bucketedMeta.slice(qOffset, qOffset + qLimit);
            if (batch.length > 0) {
              const receiptIds = batch.map((b) => b?.receipt_id).filter(Boolean);
              const payloadByReceipt = {};
              const fetchBatch = 25;
              for (let i = 0; i < receiptIds.length; i += fetchBatch) {
                const chunk = receiptIds.slice(i, i + fetchBatch);
                const placeholders = chunk.map((_, j) => `?${j + 1}`).join(",");
                const payRes = await db.prepare(
                  `SELECT receipt_id, payload_json FROM ingest_receipts WHERE receipt_id IN (${placeholders})`,
                ).bind(...chunk).all();
                for (const p of payRes?.results || []) {
                  if (p?.receipt_id) payloadByReceipt[p.receipt_id] = p?.payload_json ?? null;
                }
              }
              rows = batch.map((b) => ({ ...b, payload_json: payloadByReceipt[b.receipt_id] ?? null }));
            } else {
              rows = [];
            }
          } else if (tickerFilter) {
            // Single-ticker: use d1GetTrailRange (NO payload_json - avoids D1 string limits), build minimal payload
            let trailRes;
            try {
              trailRes = await d1GetTrailRange(env, tickerFilter, tsStartInt, 500);
              if (!trailRes?.ok) {
                return sendJSON(
                  { ok: false, error: "trail_range_failed", detail: trailRes?.error || "unknown" },
                  500,
                  corsHeaders(env, req),
                );
              }
            } catch (trailErr) {
              return sendJSON(
                { ok: false, error: "trail_fetch_failed", detail: String(trailErr?.message || trailErr) },
                500,
                corsHeaders(env, req),
              );
            }
            const trail = trailRes?.trail || [];
            const inRange = trail.filter((p) => {
              const ts = Number(p?.ts);
              return Number.isFinite(ts) && ts >= tsStartInt && ts <= tsEndInt;
            });
            rows = inRange.map((p) => {
              const obj = {
                ticker: tickerFilter,
                ts: Number(p?.ts),
                price: p?.price,
                htf_score: p?.htf_score,
                ltf_score: p?.ltf_score,
                completion: p?.completion,
                phase_pct: p?.phase_pct,
                state: p?.state,
                rank: p?.rank,
                flags: p?.flags || {},
                trigger_reason: p?.trigger_reason,
                trigger_dir: p?.trigger_dir,
              };
              return { ticker: tickerFilter, ts: obj.ts, payload_json: JSON.stringify(obj) };
            });
            totalRows = rows.length;
          } else {
            // Multi-ticker: lightweight meta then fetch payload per row
            // First get total count for pagination
            const countResult = await db.prepare(
              `SELECT COUNT(*) as cnt FROM timed_trail WHERE ts >= ?1 AND ts <= ?2`,
            ).bind(tsStartInt, tsEndInt).first();
            totalRows = Number(countResult?.cnt) || 0;

            const metaStmt = db.prepare(
              `SELECT ticker, ts FROM timed_trail
               WHERE ts >= ?1 AND ts <= ?2
               ORDER BY ts ASC
               LIMIT ?3 OFFSET ?4`,
            );
            const metaResult = await metaStmt.bind(
              tsStartInt,
              tsEndInt,
              Math.min(500, Math.floor(qLimit)),
              Math.floor(qOffset),
            ).all();
            const metaRows = metaResult?.results || [];
            rows = [];
            for (const m of metaRows) {
              const rawTicker = String(m?.ticker || "").trim();
              const tsVal = Number(m?.ts);
              if (!rawTicker || !Number.isFinite(tsVal)) continue;
              try {
                const payRow = await db.prepare(
                  `SELECT payload_json FROM timed_trail WHERE ticker = ?1 AND ts = ?2 LIMIT 1`,
                ).bind(rawTicker, tsVal).first();
                rows.push({ ticker: rawTicker, ts: tsVal, payload_json: payRow?.payload_json ?? null });
              } catch {
                rows.push({ ticker: rawTicker, ts: tsVal, payload_json: null });
              }
            }
          }
        } catch (e) {
          return sendJSON(
            { ok: false, error: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }

        let allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
        let tradesPurged = 0;
        if (qOffset === 0 && rows.length > 0) {
          if (cleanSlate) {
            if (tickerFilter) {
              // Single-ticker mode: purge only this ticker's trades in the day range
              const kept = allTrades.filter((t) => {
                const tkr = String(t?.ticker || "").toUpperCase();
                if (tkr !== tickerFilter) return true;
                const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
                if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
                if (entryTs < tsStart || entryTs > tsEnd) return true;
                tradesPurged += 1;
                return false;
              });
              allTrades = kept;
              await kvPutJSON(KV, "timed:trades:all", kept);
            } else {
              // Full replay: purge ALL trades
              tradesPurged = allTrades.length;
              allTrades = [];
              await kvPutJSON(KV, "timed:trades:all", []);
            }
          } else {
            // Purge trades in the day window only
            const kept = allTrades.filter((t) => {
              const entryTs = isoToMs(t?.entry_ts ?? t?.entryTime) ?? Number(t?.entry_ts ?? t?.entryTs);
              if (!Number.isFinite(entryTs) || entryTs <= 0) return true;
              if (entryTs < tsStart || entryTs > tsEnd) return true;
              tradesPurged += 1;
              return false;
            });
            allTrades = kept;
            await kvPutJSON(KV, "timed:trades:all", kept);
          }
        }

        const uniqueTickers = [...new Set(rows.map((r) => String(r?.ticker || "").toUpperCase()).filter(Boolean))];
        const existingMap = await Promise.all(
          uniqueTickers.map((t) => kvGetJSON(KV, `timed:latest:${t}`)),
        ).then((arr) => Object.fromEntries(uniqueTickers.map((t, i) => [t, arr[i] || {}])));
        const stateMap = {};
        for (const t of uniqueTickers) {
          const ex = existingMap[t] || {};
          const exEntryTs = Number(ex?.entry_ts ?? ex?.entryTs);
          const shouldReset = cleanSlate && (qOffset === 0 || (Number.isFinite(exEntryTs) && exEntryTs < tsStart));
          if (shouldReset) {
            stateMap[t] = { ...ex, entry_ts: null, entry_price: null, kanban_cycle_enter_now_ts: null, kanban_cycle_trigger_ts: null, kanban_cycle_side: null };
          } else {
            stateMap[t] = ex ? { ...ex } : {};
          }
        }

        const findOpenInArray = (trades, sym) =>
          trades.find(
            (x) =>
              String(x?.ticker || "").toUpperCase() === sym &&
              isOpenTradeStatus(x?.status),
          ) || null;

        const replayCtx = { allTrades, execStates: new Map() };

        let processed = 0;
        let tradesCreated = 0;
        const laneCounts = {};
        const errors = [];
        const replayTimeline = []; // Per-snapshot timeline for time-travel

        for (const row of rows) {
          try {
            const ticker = String(row?.ticker || "").toUpperCase();
            if (!ticker) continue;
            let payload;
            try {
              payload = row.payload_json ? JSON.parse(row.payload_json) : null;
            } catch {
              continue;
            }
            if (!payload || typeof payload !== "object") continue;

            const rowTs = Number(row?.ts);
            if (!Number.isFinite(rowTs)) continue;
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            // Replay: ensure trigger_ts for lifecycle gate (use ingest ts if missing)
            if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
              payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
            }
            // Normalize SL/TP from alternate field names
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
            const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
            if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);

            const existing = stateMap[ticker] || {};
            const existingTs = Number(existing?.ts ?? existing?.ingest_ts);
            const isEarlierThanStored = !Number.isFinite(existingTs) || rowTs < existingTs;

            if (isEarlierThanStored) {
              payload.entry_ts = null;
              payload.entry_price = null;
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            } else {
              if (existing?.entry_ts != null && payload.entry_ts == null)
                payload.entry_ts = Number(existing.entry_ts);
              if (existing?.entry_price != null && payload.entry_price == null)
                payload.entry_price = Number(existing.entry_price);
              if (existing?.kanban_cycle_enter_now_ts != null)
                payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
              if (existing?.kanban_cycle_trigger_ts != null)
                payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
              if (existing?.kanban_cycle_side != null)
                payload.kanban_cycle_side = existing.kanban_cycle_side;
            }

            const openTrade = findOpenInArray(replayCtx.allTrades, ticker);
            if ((payload.entry_ts == null || payload.entry_price == null) && openTrade) {
              const et = isoToMs(openTrade.entryTime) || Number(openTrade.entry_ts) || Number(openTrade.entryTs);
              const ep = Number(openTrade.entryPrice ?? openTrade.entry_price);
              if (payload.entry_ts == null && Number.isFinite(et)) payload.entry_ts = et;
              if (payload.entry_price == null && Number.isFinite(ep) && ep > 0)
                payload.entry_price = ep;
            }

            // ─────────────────────────────────────────────────────────────────────
            // Server-side re-scoring: when useServerScores=1, re-compute scores
            // from D1 candles using the current scoring algorithm (EMA triplet).
            // This replaces the old TradingView payload scores with fresh ones.
            // ─────────────────────────────────────────────────────────────────────
            if (useServerScores) {
              try {
                const asOfGetter = (env, tkr, tf, lim) => d1GetCandlesAsOf(env, tkr, tf, lim, rowTs);
                const serverResult = await computeServerSideScores(ticker, asOfGetter, env, existing);
                if (serverResult) {
                  // Merge server-computed fields into the replay payload
                  payload.htf_score = serverResult.htf_score;
                  payload.ltf_score = serverResult.ltf_score;
                  payload.flip_watch_score = serverResult.flip_watch_score;
                  payload.completion = serverResult.completion;
                  payload.phase_pct = serverResult.phase_pct;
                  payload.state = serverResult.state;
                  payload.flags = { ...(payload.flags || {}), ...(serverResult.flags || {}) };
                  payload.ema_map = serverResult.ema_map;
                  payload.tf_tech = serverResult.tf_tech;
                  payload.sl = serverResult.sl;
                  payload.tp = serverResult.tp;
                  payload.tp_trim = serverResult.tp_trim;
                  payload.tp_exit = serverResult.tp_exit;
                  payload.tp_runner = serverResult.tp_runner;
                  payload.price = serverResult.price || payload.price;
                  payload.rr = serverResult.rr;
                  payload.rank = serverResult.rank;
                  // Server-computed TD Sequential takes precedence over webhook data
                  if (serverResult.td_sequential) {
                    payload.td_sequential = serverResult.td_sequential;
                    payload._td_server_computed = true;
                  }
                  payload._server_scored = true;
                }
              } catch (e) {
                // Non-critical: fall back to payload-based scoring
                console.warn(`[REPLAY] Server scoring failed for ${ticker}:`, e);
              }
            }

            // ─────────────────────────────────────────────────────────────────────
            // CRITICAL: Compute derived fields that live ingestion normally provides.
            // The ingest_receipts payload_json does NOT contain rr, rank, score, etc.
            // Without these, qualifiesForEnter gates (rr < 1.5) block ALL entries.
            // ─────────────────────────────────────────────────────────────────────
            if (payload.rr == null || !Number.isFinite(Number(payload.rr))) {
              payload.rr = computeRR(payload);
              if (payload.rr != null && Number(payload.rr) > 25) payload.rr = 25;
            }
            if (payload.score == null && payload.rank == null) {
              payload.score = computeRank(payload);
            }
            if (payload.rr_warning == null && Number.isFinite(payload.rr)) {
              payload.rr_warning = computeRRWarning(payload.rr);
            }

            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) {
              payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
              payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
            }

            const prevStage = existing?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            let finalStage = stage;

            if (
              prevStage === "archive" &&
              ["hold", "just_entered", "trim", "exit"].includes(stage)
            ) {
              finalStage = "watch";
              if (!payload.flags) payload.flags = {};
              payload.flags.recycled_from_archive = true;
            }

            const mgmt = ["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage);
            if (mgmt) {
              const curTriggerTs = Number(payload?.trigger_ts);
              const curSide = sideFromStateOrScores(payload);
              const cycleEnterTs = Number(existing?.kanban_cycle_enter_now_ts);
              const cycleTrig = Number(existing?.kanban_cycle_trigger_ts);
              const cycleSide = existing?.kanban_cycle_side != null ? String(existing.kanban_cycle_side) : null;
              const sameTrig =
                Number.isFinite(curTriggerTs) &&
                curTriggerTs > 0 &&
                Number.isFinite(cycleTrig) &&
                cycleTrig > 0 &&
                cycleTrig === curTriggerTs;
              const cycleOk =
                Number.isFinite(cycleEnterTs) &&
                cycleEnterTs > 0 &&
                sameTrig &&
                !!cycleSide &&
                !!curSide &&
                cycleSide === curSide;

              if (!Number.isFinite(curTriggerTs) || curTriggerTs <= 0) {
                finalStage = "watch";
                if (!payload.flags) payload.flags = {};
                payload.flags.forced_watch_missing_trigger = true;
              } else if (!cycleOk) {
                finalStage = "enter";
                if (!payload.flags) payload.flags = {};
                payload.flags.forced_enter_gate = true;
              }
            }

            if (finalStage === "enter_now" || finalStage === "enter") {
              payload.kanban_cycle_enter_now_ts = rowTs;
              payload.kanban_cycle_trigger_ts =
                Number.isFinite(Number(payload?.trigger_ts)) && payload.trigger_ts > 0
                  ? payload.trigger_ts
                  : null;
              payload.kanban_cycle_side = sideFromStateOrScores(payload);
            } else if (["hold", "just_entered", "defend", "trim", "exit"].includes(finalStage)) {
              payload.kanban_cycle_enter_now_ts = existing?.kanban_cycle_enter_now_ts ?? null;
              payload.kanban_cycle_trigger_ts = existing?.kanban_cycle_trigger_ts ?? null;
              payload.kanban_cycle_side = existing?.kanban_cycle_side ?? null;
            } else {
              payload.kanban_cycle_enter_now_ts = null;
              payload.kanban_cycle_trigger_ts = null;
              payload.kanban_cycle_side = null;
            }

            if (
              prevStage != null &&
              finalStage != null &&
              String(prevStage) !== String(finalStage)
            ) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }

            if ((finalStage === "enter_now" || finalStage === "enter") && prevStage !== "enter_now" && prevStage !== "enter") {
              const price = Number(payload?.price);
              if (Number.isFinite(price) && price > 0) {
                payload.entry_price = price;
                payload.entry_ts = rowTs;
              }
            }
            if (finalStage && existing?.entry_price) {
              payload.entry_price = existing.entry_price;
              payload.entry_ts = existing.entry_ts;
            }

            payload.kanban_stage = finalStage;
            payload.kanban_meta = deriveKanbanMeta(payload, finalStage);

            laneCounts[finalStage || "null"] = (laneCounts[finalStage || "null"] || 0) + 1;

            // Capture per-snapshot timeline point (cap at 2000 to avoid huge responses)
            if (replayTimeline.length < 2000) {
              replayTimeline.push({
                ts: rowTs,
                ticker,
                price: payload.price != null ? Number(payload.price) : null,
                htf_score: payload.htf_score != null ? Number(payload.htf_score) : null,
                ltf_score: payload.ltf_score != null ? Number(payload.ltf_score) : null,
                state: payload.state || null,
                kanban_stage: finalStage,
                prev_stage: prevStage || null,
              });
            }

            stateMap[ticker] = payload;

            const countBefore = replayCtx.allTrades.filter(
              (x) => String(x?.ticker).toUpperCase() === ticker,
            ).length;
            await processTradeSimulation(KV, ticker, payload, existing, env, {
              forceUseIngestTs: true,
              replayBatchContext: replayCtx,
              asOfTs: rowTs,
            });
            const countAfter = replayCtx.allTrades.filter(
              (x) => String(x?.ticker).toUpperCase() === ticker,
            ).length;
            if (countAfter > countBefore) tradesCreated += countAfter - countBefore;

            processed += 1;
          } catch (e) {
            errors.push({ ticker: row?.ticker || null, error: String(e?.message || e) });
          }
        }

        await kvPutJSON(KV, "timed:trades:all", replayCtx.allTrades);
        await Promise.all(
          Object.entries(stateMap).map(([t, p]) =>
            kvPutJSON(KV, `timed:latest:${t}`, p),
          ),
        );

        const nextOffset = qOffset + rows.length;
        const hasMore = rows.length >= qLimit;

        try {
          await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 50);
        } catch (syncErr) {
          errors.push({ sync: String(syncErr?.message || syncErr) });
        }

        return sendJSON(
          {
            ok: true,
            day: dayKey,
            ticker: tickerFilter || undefined,
            cleanSlate: cleanSlate || undefined,
            bucketMinutes: bucketMinutes > 0 ? bucketMinutes : undefined,
            tsStart,
            tsEnd,
            totalRows: totalRows ?? undefined,
            rowsProcessed: processed,
            tradesCreated,
            tradesPurged: qOffset === 0 ? tradesPurged : undefined,
            laneCounts,
            timeline: replayTimeline,
            offset: qOffset,
            nextOffset: hasMore ? nextOffset : null,
            hasMore,
            errorsCount: errors.length,
            errors: errors.slice(0, 10),
          },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/dedupe-trades?key=... - Remove duplicate trades (same ticker+direction+entry_ts)
      if (routeKey === "POST /timed/admin/dedupe-trades") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const tradesKey = "timed:trades:all";
          const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const entryTsFor = (t) => {
            const et = Number(t?.entry_ts ?? t?.entryTs);
            if (Number.isFinite(et)) return et;
            const iso = t?.entryTime;
            if (iso) return isoToMs(iso) || null;
            const hist = Array.isArray(t?.history) ? t.history : [];
            const ent = hist.find((e) => String(e?.type || "").toUpperCase() === "ENTRY");
            return ent ? isoToMs(ent.timestamp ?? ent.ts) || null : null;
          };
          const seen = new Set();
          const deduped = [];
          for (const t of allTrades) {
            const ticker = String(t?.ticker || "").toUpperCase();
            const dir = String(t?.direction || "").toUpperCase();
            const et = entryTsFor(t);
            const key = `${ticker}:${dir}:${et != null ? et : t?.id || ""}`;
            if (seen.has(key)) continue;
            seen.add(key);
            deduped.push(t);
          }
          const removed = allTrades.length - deduped.length;
          if (removed > 0) await kvPutJSON(KV, tradesKey, deduped);
          return sendJSON(
            { ok: true, before: allTrades.length, after: deduped.length, removed },
            200,
            corsHeaders(env, req),
          );
        } catch (e) {
          return sendJSON(
            { ok: false, error: String(e?.message || e) },
            500,
            corsHeaders(env, req),
          );
        }
      }

      // POST /timed/admin/refresh-latest-from-ingest?key=... - Restore KV from actual latest ingest_receipts per ticker.
      // Use after replay to fix stale data (replay only keeps last-seen-per-bucket; this gets true latest).
      if (routeKey === "POST /timed/admin/refresh-latest-from-ingest") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const db = env?.DB;
        const KV = env?.KV_TIMED;
        if (!db || !KV) {
          return sendJSON({ ok: false, error: "missing_db_or_kv" }, 500, corsHeaders(env, req, true));
        }

        const scriptVersion = url.searchParams.get("scriptVersion") || "2.5.0";
        const limit = Math.min(50, Math.max(1, parseInt(url.searchParams.get("limit") || "25", 10)));
        const offset = Math.max(0, parseInt(url.searchParams.get("offset") || "0", 10));
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const toProcess = Array.isArray(tickers) ? tickers.slice(offset, offset + limit) : [];

        let refreshed = 0;
        let errors = 0;
        for (const t of toProcess) {
          const ticker = String(t || "").toUpperCase();
          if (!ticker) continue;
          try {
            const row = await db.prepare(
              `SELECT payload_json, ts FROM ingest_receipts
               WHERE ticker = ?1 AND (script_version = ?2 OR script_version IS NULL)
               ORDER BY ts DESC LIMIT 1`
            ).bind(ticker, scriptVersion).first();
            if (!row?.payload_json) continue;
            let payload;
            try {
              payload = JSON.parse(String(row.payload_json));
            } catch {
              continue;
            }
            if (!payload || typeof payload !== "object") continue;
            const rowTs = Number(row.ts);
            payload.ts = rowTs;
            payload.ingest_ts = rowTs;
            if ((payload.trigger_ts == null || !Number.isFinite(Number(payload.trigger_ts))) && Number.isFinite(rowTs)) {
              payload.trigger_ts = rowTs < 1e12 ? rowTs * 1000 : rowTs;
            }
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.sl_price != null) payload.sl = payload.sl_price;
            if ((payload.sl == null || !Number.isFinite(Number(payload.sl))) && payload.stop_loss != null) payload.sl = payload.stop_loss;
            const tpVal = payload.tp ?? payload.tp_max_price ?? payload.tp_target_price ?? payload.tp_target;
            if ((payload.tp == null || !Number.isFinite(Number(payload.tp))) && tpVal != null && Number.isFinite(Number(tpVal))) payload.tp = Number(tpVal);
            const existing = (await kvGetJSON(KV, `timed:latest:${ticker}`)) || {};
            if (existing?.entry_ts != null) payload.entry_ts = existing.entry_ts;
            if (existing?.entry_price != null) payload.entry_price = existing.entry_price;
            if (existing?.kanban_cycle_enter_now_ts != null) payload.kanban_cycle_enter_now_ts = existing.kanban_cycle_enter_now_ts;
            if (existing?.kanban_cycle_trigger_ts != null) payload.kanban_cycle_trigger_ts = existing.kanban_cycle_trigger_ts;
            if (existing?.kanban_cycle_side != null) payload.kanban_cycle_side = existing.kanban_cycle_side;
            payload.move_status = computeMoveStatus(payload);
            if (payload.flags) {
              payload.flags.move_invalidated = payload.move_status?.status === "INVALIDATED";
              payload.flags.move_completed = payload.move_status?.status === "COMPLETED";
            }
            const prevStage = existing?.kanban_stage;
            // Pass rowTs as asOfTs for replay-aware trigger freshness check
            const stage = classifyKanbanStage(payload, null, rowTs);
            payload.kanban_stage = stage;
            payload.kanban_meta = deriveKanbanMeta(payload, stage);
            if (prevStage != null && stage != null && String(prevStage) !== String(stage)) {
              payload.prev_kanban_stage = String(prevStage);
              payload.prev_kanban_stage_ts = rowTs;
            }
            await kvPutJSON(KV, `timed:latest:${ticker}`, payload);
            refreshed++;
          } catch (e) {
            errors++;
          }
        }

        const syncResult = refreshed > 0
          ? await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 200).catch(() => ({}))
          : {};
        return sendJSON({
          ok: true,
          refreshed,
          errors,
          total: toProcess.length,
          offset,
          hasMore: offset + toProcess.length < (Array.isArray(tickers) ? tickers.length : 0),
          sync: syncResult,
        }, 200, corsHeaders(env, req, true));
      }

      // POST /timed/admin/force-sync?key=... - Force D1 sync from KV (refresh all tickers)
      if (routeKey === "POST /timed/admin/force-sync") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        try {
          const result = await d1SyncLatestBatchFromKV(env, { waitUntil: () => {} }, 200);
          return sendJSON(result, 200, corsHeaders(env, req, true));
        } catch (error) {
          return sendJSON(
            { ok: false, error: String(error) },
            500,
            corsHeaders(env, req, true),
          );
        }
      }

      // POST /timed/admin/fix-zero-ts-events?key=... - Fix EXIT/TRIM events with zero, missing, or bogus old ts (removes "Dec 31, 1969" from By day)
      const MIN_SANE_TS_MS = 946684800000; // Jan 1, 2000 00:00 UTC — treat anything before as bogus
      if (routeKey === "POST /timed/admin/fix-zero-ts-events") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const toMs = (tsLike) => {
          const n = typeof tsLike === "string" ? isoToMs(tsLike) : Number(tsLike);
          if (!Number.isFinite(n) || n <= 0) return null;
          return n < 1e12 ? n * 1000 : n;
        };
        const isBadTs = (ts) => ts == null || ts <= 0 || ts < MIN_SANE_TS_MS;

        let fixedKV = 0;
        const tradesKey = "timed:trades:all";
        const trades = (await kvGetJSON(KV, tradesKey)) || [];
        for (const tr of trades) {
          const hist = Array.isArray(tr.history) ? tr.history : [];
          let entryTs = Number(tr.entry_ts);
          if (!Number.isFinite(entryTs) || entryTs <= 0) entryTs = null;
          if (entryTs != null && entryTs < 1e12) entryTs = entryTs * 1000;
          let exitTs = Number(tr.exit_ts);
          if (!Number.isFinite(exitTs) || exitTs <= 0) exitTs = null;
          if (exitTs != null && exitTs < 1e12) exitTs = exitTs * 1000;
          for (const ev of hist) {
            const type = String(ev?.type || "").toUpperCase();
            if (type !== "EXIT" && type !== "TRIM") continue;
            const ts = toMs(ev?.timestamp ?? ev?.ts);
            if (!isBadTs(ts)) continue;
            const fallback = exitTs || entryTs || Date.now();
            const ms = Number.isFinite(fallback) ? fallback : Date.now();
            ev.ts = ms;
            ev.timestamp = new Date(ms).toISOString();
            fixedKV++;
          }
        }
        if (fixedKV > 0) await kvPutJSON(KV, tradesKey, trades);

        let fixedD1 = 0;
        if (env?.DB) {
          try {
            const bad = await env.DB.prepare(
              `SELECT event_id, trade_id, ts, type FROM trade_events WHERE type IN ('EXIT','TRIM') AND (ts IS NULL OR ts <= 0 OR ts < ?1)`
            ).bind(MIN_SANE_TS_MS).all();
            const rows = bad?.results || [];
            for (const row of rows) {
              const tid = row?.trade_id;
              const r = await env.DB.prepare(
                `SELECT exit_ts, entry_ts FROM trades WHERE trade_id = ?1`
              ).bind(tid).first();
              const exitTs = r?.exit_ts != null ? Number(r.exit_ts) : null;
              const entryTs = r?.entry_ts != null ? Number(r.entry_ts) : null;
              let ts = Number.isFinite(exitTs) && exitTs > 0 ? exitTs : null;
              if (ts == null) ts = Number.isFinite(entryTs) && entryTs > 0 ? entryTs : null;
              if (ts != null && ts < 1e12) ts = ts * 1000;
              if (ts == null || ts <= 0) ts = Date.now();
              await env.DB.prepare(
                `UPDATE trade_events SET ts = ?1 WHERE event_id = ?2`
              ).bind(Math.round(ts), row.event_id).run();
              fixedD1++;
            }
          } catch (e) {
            console.error("[fix-zero-ts-events] D1 fix failed:", e);
          }
        }

        return sendJSON(
          { ok: true, fixedKV, fixedD1, message: `Fixed ${fixedKV} KV history events and ${fixedD1} D1 trade_events with zero/missing ts.` },
          200,
          corsHeaders(env, req),
        );
      }

      // POST /timed/admin/reset?key=... - Reset system state as if freshly launched (SAFE by default)
      // Default behavior (safe):
      // - Clears KV simulated trades + paper portfolio + activity feed
      // - Clears per-ticker Kanban entry stamps + lane transition memory + flip-watch stickiness
      // - Recomputes kanban_stage immediately (so UI is clean right away)
      // Optional (DANGEROUS; opt-in via query params):
      // - resetMl=1      -> clears ML model + training queue
      // - resetLedger=1  -> clears D1 ledger tables (alerts/trades/events)
      if (routeKey === "POST /timed/admin/reset") {
        const authFail = requireKeyOr401(req, env);
        if (authFail) return authFail;

        const resetLedger =
          url.searchParams.get("resetLedger") === "1" ||
          url.searchParams.get("resetLedger") === "true";

        const resetMl =
          url.searchParams.get("resetMl") === "1" ||
          url.searchParams.get("resetMl") === "true";

        const now = Date.now();
        const tickerIndex = (await kvGetJSON(KV, "timed:tickers")) || [];
        const tickers = Array.isArray(tickerIndex) ? tickerIndex : [];

        const resetPayload = (p) => {
          if (!p || typeof p !== "object") return p;

          // Clear Kanban state + entry stamps
          p.kanban_stage = null;
          p.prev_kanban_stage = null;
          p.prev_kanban_stage_ts = null;
          p.kanban_meta = null;
          p.kanban_cycle_enter_now_ts = null;
          p.kanban_cycle_trigger_ts = null;
          p.kanban_cycle_side = null;

          p.entry_price = null;
          p.entry_ts = null;
          p.entry_change_pct = null;

          // Clear flip watch stickiness
          p.flip_watch_score = null;
          p.flip_watch_reasons = null;
          p.flip_watch_until_ts = null;

          // Force recompute on next read/ingest
          p.move_status = null;

          // Clear forcing flags
          p.flags = p.flags && typeof p.flags === "object" ? p.flags : {};
          p.flags.flip_watch = false;
          for (const k of Object.keys(p.flags)) {
            if (
              k.startsWith("forced_") ||
              k === "recycled_from_archive" ||
              k === "move_invalidated" ||
              k === "move_completed"
            ) {
              try {
                delete p.flags[k];
              } catch {}
            }
          }

          // Recompute stage immediately so UI is clean after reset
          try {
            const stage = classifyKanbanStage(p);
            p.kanban_stage = stage;
            p.kanban_meta = deriveKanbanMeta(p, stage);
          } catch {
            p.kanban_stage = null;
            p.kanban_meta = null;
          }

          p.reset_at = now;
          return p;
        };

        // Clear KV simulated trades + paper portfolio + activity feed
        const kvCleared = [];
        try {
          await KV.delete("timed:trades:all");
          kvCleared.push("timed:trades:all");
        } catch {}
        try {
          await KV.delete(PORTFOLIO_KEY);
          kvCleared.push(PORTFOLIO_KEY);
        } catch {}
        try {
          await KV.delete("timed:activity:feed");
          kvCleared.push("timed:activity:feed");
        } catch {}

        // Clear ML model (optional; OFF by default)
        if (resetMl) {
          try {
            await KV.delete("timed:model:ml_v1");
            kvCleared.push("timed:model:ml_v1");
          } catch {}
          try {
            await KV.delete("timed:model:ml_v1:last_ts");
            kvCleared.push("timed:model:ml_v1:last_ts");
          } catch {}
        }

        // Archive open trades (always) + optionally clear ledger (OFF by default)
        let d1Cleared = [];
        try {
          if (env?.DB) {
            // Archive all open trades by default (non-destructive)
            try {
              const archiveSql = "UPDATE trades SET status = 'ARCHIVED' WHERE status NOT IN ('WIN', 'LOSS', 'ARCHIVED')";
              const archiveResult = await env.DB.prepare(archiveSql).run();
              d1Cleared.push({ sql: archiveSql, changes: archiveResult?.meta?.changes ?? 0 });
            } catch (archiveErr) {
              // ignore if table doesn't exist
            }
            
            if (resetLedger) {
              // Full ledger clear (DANGEROUS; opt-in only)
              // Clear new position-based tables first (due to foreign key constraints)
              // Also clear ticker_latest to ensure fresh state for /timed/all
              for (const sql of [
                "DELETE FROM execution_actions",
                "DELETE FROM lots",
                "DELETE FROM positions",
                "DELETE FROM trade_events",
                "DELETE FROM trades",
                "DELETE FROM alerts",
                "DELETE FROM ticker_latest",
              ]) {
                try {
                  const r = await env.DB.prepare(sql).run();
                  d1Cleared.push({ sql, changes: r?.meta?.changes ?? null });
                } catch {
                  // ignore missing tables
                }
              }
            }
            // ML queue
            if (resetMl) {
              try {
                const r = await env.DB.prepare("DELETE FROM ml_v1_queue").run();
                d1Cleared.push({
                  sql: "DELETE FROM ml_v1_queue",
                  changes: r?.meta?.changes ?? null,
                });
              } catch {}
            }
          }
        } catch {}

        // Reset per-ticker latest payloads (KV + D1 latest)
        const results = { processed: 0, updated: 0, skipped: 0, errors: [] };
        for (const t of tickers) {
          const ticker = normTicker(t);
          if (!ticker) continue;
          try {
            const latest = await kvGetJSON(KV, `timed:latest:${ticker}`);
            if (!latest || typeof latest !== "object") {
              results.skipped++;
              continue;
            }
            const next = resetPayload({ ...latest });
            await kvPutJSON(KV, `timed:latest:${ticker}`, next);
            try {
              ctx.waitUntil(d1UpsertTickerLatest(env, ticker, next));
              ctx.waitUntil(d1UpsertTickerIndex(env, ticker, next?.ts));
            } catch {}
            results.updated++;
            results.processed++;
          } catch (e) {
            results.errors.push({ ticker: String(t), error: String(e?.message || e) });
          }
        }

        return sendJSON(
          {
            ok: true,
            message: "System reset complete (as-of now).",
            now,
            tickers: { total: tickers.length, ...results },
            kvCleared,
            d1Cleared,
            resetMl,
            resetLedger,
            note: "Lanes recompute from fresh state; new KV simulated trades will be created as new data/alerts come in. D1 ledger is preserved unless resetLedger=1.",
          },
          200,
          corsHeaders(env, req),
        );
      }

      return sendJSON(
        { ok: false, error: "not_found" },
        404,
        corsHeaders(env, req),
      );
    } catch (topLevelErr) {
      // Catch any unhandled errors and return a proper response with CORS headers
      console.error(`[FETCH ERROR] Unhandled error in fetch handler:`, {
        error: String(topLevelErr),
        message: topLevelErr?.message,
        stack: topLevelErr?.stack,
        url: req?.url,
        method: req?.method,
        hasKV: !!env?.KV_TIMED,
        pathname: new URL(req?.url || "").pathname,
      });
      return sendJSON(
        {
          ok: false,
          error: "internal_error",
          message: "An unexpected error occurred",
          details:
            process.env.NODE_ENV === "development"
              ? String(topLevelErr)
              : undefined,
        },
        500,
        corsHeaders(env, req),
      );
    }
  },

  // Scheduled handler — consolidated to 3 crons (CF Workers limit: 5 per worker).
  // Real crons: "*/1 * * * *", "*/5 * * * *", "0 * * * *"
  // Handler maps current time → set of virtual crons that would have fired,
  // then dispatches to existing code blocks unchanged.
  async scheduled(event, env, ctx) {
    const _now = new Date();
    const _utcH = _now.getUTCHours();
    const _utcM = _now.getUTCMinutes();
    const _utcDay = _now.getUTCDay(); // 0=Sun … 6=Sat
    const _isWeekday = _utcDay >= 1 && _utcDay <= 5;

    // CF may normalize "*/1 * * * *" → "* * * * *"
    const _isEveryMin = event.cron === "*/1 * * * *" || event.cron === "* * * * *";
    const _isEvery5Min = event.cron === "*/5 * * * *";
    const _isHourly = event.cron === "0 * * * *";

    // Build the set of virtual crons that WOULD have fired at this time
    const vc = new Set();

    if (_isEveryMin) {
      // Price feed
      if (_isWeekday && _utcH >= 9 && _utcH <= 23) vc.add("*/1 9-23 * * 1-5");
      if (_utcDay >= 2 && _utcDay <= 6 && _utcH <= 1)  vc.add("*/1 0-1 * * 2-6");
      if (_utcDay === 0 && _utcH >= 22)                 vc.add("*/5 22-23 * * 7");
      // Overnight crypto: fills the UTC 2-8 gap (9 PM - 3 AM ET) for 24/7 crypto prices.
      // Runs every 5 min to avoid unnecessary API calls for just BTC/ETH.
      if (_utcH >= 2 && _utcH <= 8 && _utcM % 5 === 0) vc.add("*/5 2-8 * * *");
    }
    if (_isEvery5Min) {
      vc.add("*/5 * * * *");
      // Alpaca bars: unified 5-min cadence during operating hours (4AM-8PM ET = 9-23 UTC + 0-1 UTC next day)
      if (_isWeekday && _utcH >= 9 && _utcH <= 23)                vc.add("*/5 9-23 * * 1-5");
      if (_utcDay >= 2 && _utcDay <= 6 && _utcH <= 1)             vc.add("*/5 0-1 * * 2-6");
      if (_isWeekday && _utcM % 15 === 0)                          vc.add("*/15 * * * 1-5");
      if (_utcH % 6 === 0 && _utcM === 0)                          vc.add("0 */6 * * *");
      if (_isWeekday && _utcH === 14 && _utcM === 45)              vc.add("45 14 * * 1-5");
      if (_isWeekday && _utcH === 17 && _utcM === 0)               vc.add("0 17 * * 1-5");
      if (_isWeekday && _utcH === 20 && _utcM === 30)              vc.add("30 20 * * 1-5");
      if (_utcDay === 5 && _utcH === 21 && _utcM === 15)           vc.add("15 21 * * 5");
      if (_isWeekday && _utcH === 21 && _utcM === 30)              vc.add("30 21 * * 1-5");
    }
    if (_isHourly) {
      if (_isWeekday && _utcH >= 14 && _utcH <= 21)                vc.add("0 14-21 * * 1-5");
      if (_utcDay === 6 && _utcH === 15)                           vc.add("0 15 * * 6");
      if (_isWeekday && _utcH === 14)                               vc.add("0 14 * * 1-5");
      if (_isWeekday && _utcH === 22)                               vc.add("0 22 * * 1-5");
      if (_isWeekday && _utcH === 8)                                vc.add("0 8 * * 1-5");
      if (_isWeekday && _utcH === 12)                               vc.add("0 12 * * 1-5");
      if (_utcH === 4)                                              vc.add("0 4 * * *");
    }

    console.log(`[CRON] ${event.cron} → [${[...vc].join(", ")}] at ${_utcH}:${String(_utcM).padStart(2,"0")} day=${_utcDay}`);

    // Load dynamic market calendar (Alpaca API + KV cache, static fallback)
    try {
      _cronCalendar = await loadCalendar(env);
    } catch (e) {
      console.warn("[CRON] Calendar load failed, using static fallback:", String(e).slice(0, 100));
      _cronCalendar = null;
    }

    // Debug: log each cron type to a SEPARATE KV key to avoid race conditions
    const _KV_DBG = env?.KV_TIMED;
    if (_KV_DBG) {
      const _dbgKey = `timed:debug:cron:${event.cron.replace(/[^a-z0-9]/gi, "_")}`;
      ctx.waitUntil(_KV_DBG.put(_dbgKey, JSON.stringify({
        cron: event.cron,
        virtualCrons: [...vc],
        ts: Date.now(),
        utc: _now.toISOString(),
      }), { expirationTtl: 300 }).catch(() => {}));
    }

    // Calibration: runs when user clicked "Run Calibration" (sets timed:calibration:requested). Half-hour cron has 15min CPU.
    if (event.cron === "30 * * * *" && env?.DB && env?.KV_TIMED) {
      ctx.waitUntil(
        runCalibrationInCron(env).catch((e) => console.warn("[CALIBRATION] Cron waitUntil failed:", String(e?.message || e).slice(0, 200)))
      );
    }

    // Weekly Retrospective: Fridays at 9:15 PM UTC (4:15 PM ET, after market close)
    // Evaluates pattern performance, detects regime shifts, writes proposals.
    if (vc.has("15 21 * * 5")) {
      if (env?.DB) {
        ctx.waitUntil(
          runWeeklyRetrospective(env.DB)
            .then((r) => console.log(`[MODEL RETRO] Weekly retrospective: ${r.resolved} resolved, ${r.proposals.length} proposals, ${r.regimeShifts.length} regime shifts`))
            .catch((e) => console.warn(`[MODEL RETRO] Failed:`, String(e?.message || e).slice(0, 300)))
        );
        ctx.waitUntil(
          refreshPathPerformance(env)
            .then((r) => console.log(`[LEARNING] Path performance refresh: ${r.updated || 0} paths updated`))
            .catch((e) => console.warn(`[LEARNING] Path perf refresh failed:`, String(e?.message || e).slice(0, 200)))
        );
        ctx.waitUntil(
          updateConsensusWeights(env)
            .then((r) => console.log(`[LEARNING] Consensus weights update: ${r.ok ? JSON.stringify(r.weights || {}) : r.reason || r.error}`))
            .catch((e) => console.warn(`[LEARNING] Consensus weights failed:`, String(e?.message || e).slice(0, 200)))
        );
        ctx.waitUntil(
          updateScoringWeights(env)
            .then((r) => console.log(`[LEARNING] Scoring weights update: ${r.ok ? JSON.stringify(r.adj || {}) : r.reason || r.error}`))
            .catch((e) => console.warn(`[LEARNING] Scoring weights failed:`, String(e?.message || e).slice(0, 200)))
        );
        ctx.waitUntil(
          updateSignalWeights(env)
            .then((r) => console.log(`[LEARNING] Signal weights update: ${r.ok ? JSON.stringify(r.weights || {}) : r.reason || r.error}`))
            .catch((e) => console.warn(`[LEARNING] Signal weights failed:`, String(e?.message || e).slice(0, 200)))
        );
      }
    }

    // ── Investor Intelligence: hourly scoring refresh (top of hour, 9AM-4PM ET = 14-21 UTC, Mon-Fri) ──
    // Keeps investor scores fresh during market hours. Does NOT trigger DCA (that's daily only).
    if (vc.has("0 14-21 * * 1-5")) {
      ctx.waitUntil((async () => {
        try {
          const selfUrl = env.WORKER_URL || "https://timed-trading-ingest.shashant.workers.dev";
          console.log("[INVESTOR HOURLY] Triggering investor scoring refresh...");
          const compResp = await fetch(`${selfUrl}/timed/investor/compute`, { method: "POST" });
          const compData = await compResp.json().catch(() => ({}));
          console.log(`[INVESTOR HOURLY] Done: ${compData.tickers || 0} tickers, regime=${compData.marketHealth?.regime || "?"}`);
        } catch (e) {
          console.warn(`[INVESTOR HOURLY] Failed:`, String(e?.message || e).slice(0, 300));
        }
      })());
      // Don't return — let other cron handlers run too if they match
    }

    // ── Investor Intelligence: daily scoring + DCA execution (4:30 PM ET = 21:30 UTC, Mon-Fri) ──
    // Self-invokes the existing POST endpoints to reuse all logic.
    if (vc.has("30 21 * * 1-5")) {
      ctx.waitUntil((async () => {
        try {
          const selfUrl = env.WORKER_URL || "https://timed-trading-ingest.shashant.workers.dev";

          // 1. Run investor compute
          console.log("[INVESTOR CRON] Triggering daily investor compute...");
          const compResp = await fetch(`${selfUrl}/timed/investor/compute`, { method: "POST" });
          const compData = await compResp.json().catch(() => ({}));
          console.log(`[INVESTOR CRON] Compute done: ${compData.tickers || 0} tickers, market=${compData.marketHealth?.regime || "?"}`);

          // 2. Auto-rebalance: open/add/trim positions based on stages
          console.log("[INVESTOR CRON] Running auto-rebalance...");
          const rebalResp = await fetch(`${selfUrl}/timed/investor/auto-rebalance`, { method: "POST" });
          const rebalData = await rebalResp.json().catch(() => ({}));
          console.log(`[INVESTOR CRON] Rebalance: ${rebalData.newPositions || 0} new, ${rebalData.addedTo || 0} added, ${rebalData.reduced || 0} trimmed`);

          // 3. Execute due DCA buys
          console.log("[INVESTOR CRON] Checking DCA plans...");
          const dcaResp = await fetch(`${selfUrl}/timed/investor/dca/execute`, { method: "POST" });
          const dcaData = await dcaResp.json().catch(() => ({}));
          console.log(`[INVESTOR CRON] DCA: ${dcaData.executed || 0} executed, ${dcaData.skipped || 0} skipped`);
        } catch (e) {
          console.warn(`[INVESTOR CRON] Failed:`, String(e?.message || e).slice(0, 300));
        }
      })());
      // Don't return — let other cron handlers run too if they match
    }

    // ── Investor Intelligence: weekly digest (Saturday 10 AM ET = 15:00 UTC) ──
    if (vc.has("0 15 * * 6")) {
      ctx.waitUntil((async () => {
        try {
          console.log("[INVESTOR DIGEST] Triggering weekly digest...");
          const selfUrl = env.WORKER_URL || "https://timed-trading-ingest.shashant.workers.dev";
          const resp = await fetch(`${selfUrl}/timed/investor/weekly-digest`, { method: "POST" });
          const data = await resp.json().catch(() => ({}));
          console.log(`[INVESTOR DIGEST] Done: ${data.ok ? "sent" : "failed"}`);
        } catch (e) {
          console.warn(`[INVESTOR DIGEST] Failed:`, String(e?.message || e).slice(0, 300));
        }
      })());
      // Don't return — allow other handlers
    }

    // ── Daily Brief: Morning (9 AM ET = 14:00 UTC) ──
    if (vc.has("0 14 * * 1-5")) {
      // Check if it's actually morning in ET (handles EST vs EDT)
      const etHour = new Date().toLocaleString("en-US", { timeZone: "America/New_York", hour: "numeric", hour12: false });
      const h = parseInt(etHour, 10);
      if (h >= 8 && h <= 10) {
        ctx.waitUntil((async () => {
          try {
            console.log("[DAILY BRIEF CRON] Generating morning brief...");
            const result = await generateDailyBrief(env, "morning", {
              SECTOR_MAP,
              d1GetCandles,
              notifyDiscord,
              d1InsertNotification,
            });
            console.log(`[DAILY BRIEF CRON] Morning: ${result.ok ? "OK" : result.error} (${result.elapsed || 0}ms)`);
          } catch (e) {
            console.error("[DAILY BRIEF CRON] Morning failed:", String(e).slice(0, 300));
          }
        })());
      }
      // Don't return — allow other handlers
    }

    // ── Daily Brief: Evening (5 PM ET = 22:00 UTC) ──
    if (vc.has("0 22 * * 1-5")) {
      const etHour = new Date().toLocaleString("en-US", { timeZone: "America/New_York", hour: "numeric", hour12: false });
      const h = parseInt(etHour, 10);
      if (h >= 16 && h <= 18) {
        ctx.waitUntil((async () => {
          try {
            console.log("[DAILY BRIEF CRON] Generating evening brief...");
            const result = await generateDailyBrief(env, "evening", {
              SECTOR_MAP,
              d1GetCandles,
              notifyDiscord,
              d1InsertNotification,
            });
            console.log(`[DAILY BRIEF CRON] Evening: ${result.ok ? "OK" : result.error} (${result.elapsed || 0}ms)`);
          } catch (e) {
            console.error("[DAILY BRIEF CRON] Evening failed:", String(e).slice(0, 300));
          }
        })());
      }
    }

    // ── Daily Brief: Cleanup (3 AM ET = 08:00 UTC) ──
    if (vc.has("0 8 * * 1-5")) {
      const etHour = new Date().toLocaleString("en-US", { timeZone: "America/New_York", hour: "numeric", hour12: false });
      const h = parseInt(etHour, 10);
      if (h >= 2 && h <= 4) {
        ctx.waitUntil(cleanupDailyBrief(env));
      }
    }

    // ── ETF Holdings Sync (7 AM ET = 12:00 UTC) ──
    if (vc.has("0 12 * * 1-5")) {
      const etHour = new Date().toLocaleString("en-US", { timeZone: "America/New_York", hour: "numeric", hour12: false });
      const h = parseInt(etHour, 10);
      if (h >= 6 && h <= 8) {
        ctx.waitUntil((async () => {
          try {
            console.log("[ETF SYNC CRON] Syncing ETF holdings from grannyshots.com...");
            const result = await syncAllETFHoldings(env, {
              notifyDiscord,
              addToUniverse: (env2, tickers, wMap) => etfAutoAddTickers(env2, tickers, wMap, ctx),
            });
            console.log(`[ETF SYNC CRON] ${result.ok ? "OK" : result.error} (${result.elapsed || 0}ms)${result.autoAdded?.length ? `, auto-added: ${result.autoAdded.join(",")}` : ""}`);
          } catch (e) {
            console.error("[ETF SYNC CRON] Failed:", String(e).slice(0, 300));
          }
        })());
      }
    }

    // Data lifecycle: aggregate timed_trail → trail_5m_facts, purge old raw data (4 AM UTC daily)
    // Also resolve expired model predictions.
    if (vc.has("0 4 * * *")) {
      ctx.waitUntil(runDataLifecycle(env));
      // Resolve model predictions whose horizon has expired (non-blocking)
      if (env?.DB) {
        ctx.waitUntil(
          resolveExpiredPredictions(env.DB, Date.now())
            .then((r) => console.log(`[MODEL] Resolved ${r.resolved} predictions`))
            .catch((e) => console.warn(`[MODEL] Resolution failed:`, String(e?.message || e).slice(0, 200)))
        );
      }
      // Refresh market calendar from Alpaca Calendar API (non-blocking)
      ctx.waitUntil(
        fetchAndCacheCalendar(env)
          .then((cal) => {
            _cronCalendar = cal;
            console.log(`[MARKET-CAL] Daily refresh: source=${cal.source}, holidays=${cal.equityHolidays.size}`);
          })
          .catch((e) => console.warn(`[MARKET-CAL] Daily refresh failed:`, String(e?.message || e).slice(0, 200)))
      );
      // Don't return — allow other hourly tasks to run
    }

    // ═══════════════════════════════════════════════════════════════════════
    // ALPACA BAR FETCHING — 5-min cadence, 4 AM - 8 PM ET (Phase 3)
    //   Weekdays: */5 9-23 * * 1-5  (9:00-23:55 UTC)
    //             */5 0-1 * * 2-6   (00:00-01:55 UTC, = Mon-Fri evenings ET)
    // Fetches bars from Alpaca and stores them in D1.
    // ═══════════════════════════════════════════════════════════════════════
    const isAlpacaBarCron = vc.has("*/5 9-23 * * 1-5")
      || vc.has("*/5 0-1 * * 2-6");
    if (isAlpacaBarCron) {
      if (env.ALPACA_ENABLED === "true" && env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY) {

        // ── AlpacaStream lifecycle: start WS streaming if market is open ──
        // The DO self-manages via alarm heartbeats once started.
        if (env.ALPACA_STREAM) {
          try {
            const streamStatus = await alpacaStreamStatus(env);
            if (!streamStatus.isRunning && isWithinOperatingHours()) {
              const blocklist = new Set(["ES1!","NQ1!","YM1!","RTY1!","CL1!","GC1!","SI1!","HG1!","NG1!","BTCUSD","ETHUSD","US500","VX1!","SPX"]);
              const userAddedForStream = await d1GetActiveUserTickersCached(env);
              const symbols = [...new Set([...Object.keys(SECTOR_MAP), ...userAddedForStream])].filter(t => !blocklist.has(t) && /^[A-Z]{1,5}(-[A-Z]{1,2})?$/.test(t));
              const startRes = await alpacaStreamStart(env, symbols);
              console.log(`[ALPACA_STREAM] Started: ${symbols.length} symbols, result:`, JSON.stringify(startRes).slice(0, 200));
            } else if (streamStatus.isRunning && !isWithinOperatingHours()) {
              const stopRes = await alpacaStreamStop(env);
              console.log("[ALPACA_STREAM] Stopped (outside operating hours):", JSON.stringify(stopRes).slice(0, 200));
            }
          } catch (streamErr) {
            console.warn("[ALPACA_STREAM] Lifecycle error:", String(streamErr).slice(0, 200));
          }
        }

        // ── Bar cron: skip REST fetching when AlpacaStream is handling bars ──
        let streamActive = false;
        if (env.ALPACA_STREAM) {
          try {
            const st = await alpacaStreamStatus(env);
            streamActive = st.isRunning && st.barsReceived > 0;
          } catch (_) {}
        }

        if (streamActive) {
          console.log("[ALPACA CRON] Skipping REST bar fetch — AlpacaStream is active");
        } else {
          try {
            const ALPACA_SYMBOL_BLOCKLIST = new Set([
              "ES1!", "NQ1!", "YM1!", "RTY1!", "CL1!", "GC1!", "SI1!",
              "BTCUSD", "ETHUSD", "US500", "VX1!", "SPX",
            ]);
            const userAddedForAlpaca = await d1GetActiveUserTickersCached(env);
            const allTickers = [...new Set([
              ...Object.keys(SECTOR_MAP),
              ...userAddedForAlpaca,
            ])].filter(
              t => !ALPACA_SYMBOL_BLOCKLIST.has(t) && /^[A-Z]{1,5}(-[A-Z]{1,2})?$/.test(t)
            );
            const result = await alpacaCronFetchLatest(env, allTickers, d1UpsertCandle);
            console.log(`[ALPACA CRON] Fetched bars for ${allTickers.length} stocks (${userAddedForAlpaca.length} user-added): ${result.upserted} upserted, ${result.errors} errors`);
          } catch (err) {
            console.error("[ALPACA CRON] Error:", err);
          }
        }

        // ── Crypto bars: always fetch via REST (AlpacaStream handles crypto WS separately) ──
        // Keep REST as fallback; when AlpacaStream crypto WS is stable, this can be removed.
        if (!streamActive) {
          try {
            const cryptoResult = await alpacaCronFetchCrypto(env);
            if (cryptoResult.upserted > 0 || cryptoResult.errors > 0) {
              console.log(`[ALPACA CRYPTO CRON] Fetched crypto bars: ${cryptoResult.upserted} upserted, ${cryptoResult.errors} errors`);
            }
          } catch (err) {
            console.error("[ALPACA CRYPTO CRON] Error:", err);
          }
        }
      }
      // Don't return — price feed may also run in the same invocation
    }

    // ═══════════════════════════════════════════════════════════════════════
    // PRICE FEED — real-time price display + SL/TP checks
    // Uses Alpaca Snapshots API for efficient batch price fetching.
    // Stores prices in KV as `timed:prices` for the UI to poll.
    // Also checks open positions against SL/TP levels.
    // ═══════════════════════════════════════════════════════════════════════
    const isPriceFeedCron = vc.has("*/1 9-23 * * 1-5")
      || vc.has("*/1 0-1 * * 2-6")
      || vc.has("*/5 22-23 * * 7")
      || vc.has("*/5 2-8 * * *");
    // Lightweight mode: during 2-8 AM UTC, only overlay TV futures + crypto onto existing prices.
    // Skips expensive Alpaca stock REST fetch and D1 prev_close rebuild.
    const isLightweightPriceFeed = isPriceFeedCron
      && !vc.has("*/1 9-23 * * 1-5")
      && !vc.has("*/1 0-1 * * 2-6");
    if (isPriceFeedCron && env.ALPACA_ENABLED === "true") {
      const KV = env.KV_TIMED;
      try {
        const userAddedForPriceFeed = await d1GetActiveUserTickersCached(env);
        const allTickers = [...new Set([...Object.keys(SECTOR_MAP), ...userAddedForPriceFeed])];

        // ── Lightweight mode: overlay TV futures + crypto onto existing prices ──
        // Runs during 2-8 AM UTC when stocks aren't actively trading.
        // If stock prices are stale (all zero changes), does a one-time Alpaca
        // REST snapshot fetch to seed today's close and prev_close.
        if (isLightweightPriceFeed) {
          let existing = {};
          try {
            const raw = await kvGetJSON(KV, "timed:prices");
            existing = raw?.prices || {};
          } catch (_) {}

          // Refresh stock prices from Alpaca REST every 30 min during lightweight window,
          // or immediately when prices are stale (<10 non-zero changes).
          // This provides both proper day-change values and EXT (after-hours) data.
          const nonZeroCount = Object.values(existing).filter(p => Number(p?.dc) !== 0 || Number(p?.dp) !== 0).length;
          const hasAhData = Object.values(existing).some(p => Number.isFinite(Number(p?.ahdp)) && Number(p.ahdp) !== 0);
          const needsRefresh = nonZeroCount < 10 || !hasAhData || (_utcM % 30 === 0);
          if (needsRefresh) {
            try {
              const snapResult = await alpacaFetchSnapshots(env, allTickers);
              const snapshots = snapResult.snapshots || {};
              let restCount = 0;
              const CRYPTO_24H = new Set(["BTCUSD", "ETHUSD"]);
              for (const [sym, snap] of Object.entries(snapshots)) {
                const ahPrice = snap.price;
                const rthClose = snap.dailyClose;
                const pc = snap.prevDailyClose;
                const isCryptoSym = CRYPTO_24H.has(sym);
                // Crypto trades 24/7: use latest trade as price, no RTH/AH distinction
                const displayPrice = isCryptoSym ? (ahPrice > 0 ? ahPrice : rthClose) : (rthClose > 0 ? rthClose : ahPrice);
                if (!displayPrice || displayPrice <= 0) continue;
                const dc = (displayPrice > 0 && pc > 0) ? Math.round((displayPrice - pc) * 100) / 100 : 0;
                const dp = (displayPrice > 0 && pc > 0) ? Math.round(((displayPrice - pc) / pc) * 10000) / 100 : 0;
                let extDc = 0, extDp = 0;
                if (!isCryptoSym && ahPrice > 0 && rthClose > 0 && Math.abs(ahPrice - rthClose) > 0.001) {
                  extDc = Math.round((ahPrice - rthClose) * 100) / 100;
                  extDp = Math.round(((ahPrice - rthClose) / rthClose) * 10000) / 100;
                }
                const prev = existing[sym] || {};
                existing[sym] = {
                  ...prev,
                  p: Math.round(displayPrice * 100) / 100,
                  pc: pc > 0 ? Math.round(pc * 100) / 100 : (prev.pc || 0),
                  dc, dp,
                  dh: snap.dailyHigh > 0 ? Math.round(snap.dailyHigh * 100) / 100 : (prev.dh || 0),
                  dl: snap.dailyLow > 0 ? Math.round(snap.dailyLow * 100) / 100 : (prev.dl || 0),
                  dv: snap.dailyVolume || prev.dv || 0,
                  t: snap.trade_ts || Date.now(),
                  ahp: extDc !== 0 ? Math.round(ahPrice * 100) / 100 : undefined,
                  ahdc: extDc !== 0 ? extDc : undefined,
                  ahdp: extDp !== 0 ? extDp : undefined,
                };
                restCount++;
              }
              console.log(`[PRICE FEED LIGHT] REST fallback updated ${restCount} tickers (nonZero was ${nonZeroCount})`);
            } catch (e) {
              console.warn("[PRICE FEED LIGHT] REST fallback error:", String(e?.message || e).slice(0, 200));
            }
          }

          // D1 daily candle fallback for tickers still stale after REST snapshot
          // (covers tickers Alpaca didn't return — small caps, recent adds, etc.)
          try {
            if (env?.DB) {
              const staleSyms = allTickers.filter(sym => {
                const e = existing[sym];
                return !e || Number(e.dp) === 0 || !Number.isFinite(Number(e.dp));
              });
              if (staleSyms.length > 0) {
                const candleRows = await env.DB.prepare(
                  `WITH deduped AS (
                    SELECT ticker, ts, c,
                      ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                    FROM ticker_candles WHERE tf = 'D'
                  )
                  SELECT ticker, ts, c FROM (
                    SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                    FROM deduped WHERE day_rn = 1
                  ) WHERE rn <= 2
                  ORDER BY ticker, ts DESC`
                ).all();
                const cMap = {};
                for (const r of (candleRows?.results || [])) {
                  const s = String(r.ticker).toUpperCase();
                  if (!cMap[s]) cMap[s] = [];
                  cMap[s].push({ ts: Number(r.ts), c: Number(r.c) });
                }
                let d1Count = 0;
                for (const sym of staleSyms) {
                  const candles = cMap[sym];
                  if (!candles || candles.length < 2) continue;
                  const todayC = candles[0]?.c;
                  const prevC = candles[1]?.c;
                  if (!todayC || todayC <= 0 || !prevC || prevC <= 0) continue;
                  const dc = Math.round((todayC - prevC) * 100) / 100;
                  const dp = Math.round(((todayC - prevC) / prevC) * 10000) / 100;
                  if (dp === 0) continue;
                  const prev = existing[sym] || {};
                  existing[sym] = {
                    ...prev,
                    p: Math.round(todayC * 100) / 100,
                    pc: Math.round(prevC * 100) / 100,
                    dc, dp,
                    t: candles[0].ts || Date.now(),
                  };
                  d1Count++;
                }
                if (d1Count > 0) console.log(`[PRICE FEED LIGHT] D1 candle fallback updated ${d1Count} tickers (stale: ${staleSyms.length})`);
              }
            }
          } catch (e) {
            console.warn("[PRICE FEED LIGHT] D1 fallback error:", String(e?.message || e).slice(0, 200));
          }

          // 1. Overlay TV futures heartbeats
          const TV_FUTURES_LIGHT = ["ES1!", "NQ1!", "GC1!", "SI1!", "VX1!", "US500", "CL1!"];
          let tvUpdated = 0;
          for (const tvSym of TV_FUTURES_LIGHT) {
            try {
              const hbData = await kvGetJSON(KV, `timed:heartbeat:${tvSym}`);
              const latestData = await kvGetJSON(KV, `timed:latest:${tvSym}`);
              const tvData = (hbData && hbData.price > 0) ? hbData : latestData;
              if (tvData && tvData.price > 0) {
                const prevClose = Number(tvData.prev_close || tvData.previous_close || 0);
                const price = Number(tvData.price);
                const dc = prevClose > 0 ? Math.round((price - prevClose) * 100) / 100 : null;
                const dp = prevClose > 0 ? Math.round(((price - prevClose) / prevClose) * 10000) / 100 : null;
                const prev = existing[tvSym] || {};
                existing[tvSym] = {
                  ...prev,
                  p: Math.round(price * 100) / 100,
                  pc: prevClose > 0 ? Math.round(prevClose * 100) / 100 : (prev.pc || 0),
                  dc: dc ?? prev.dc, dp: dp ?? prev.dp,
                  dh: Math.round(Number(tvData.high || tvData.dailyHigh || 0) * 100) / 100 || prev.dh,
                  dl: Math.round(Number(tvData.low || tvData.dailyLow || 0) * 100) / 100 || prev.dl,
                  t: Number(tvData.ts || tvData.ingest_ts || 0) || Date.now(),
                };
                tvUpdated++;
              }
            } catch (_) {}
          }

          // 2. Overlay crypto from Alpaca snapshots
          let cryptoUpdated = 0;
          try {
            const CRYPTO_PAIRS = { "BTCUSD": "BTC/USD", "ETHUSD": "ETH/USD" };
            const headers = {
              "APCA-API-KEY-ID": env.ALPACA_API_KEY_ID,
              "APCA-API-SECRET-KEY": env.ALPACA_API_SECRET_KEY,
              "Accept": "application/json",
            };
            const params = new URLSearchParams();
            params.set("symbols", Object.values(CRYPTO_PAIRS).join(","));
            const url = `https://data.alpaca.markets/v1beta3/crypto/us/snapshots?${params.toString()}`;
            const resp = await fetch(url, { headers });
            if (resp.ok) {
              const data = await resp.json();
              const cryptoSnaps = data.snapshots || data;
              const reverseMap = {};
              for (const [k, v] of Object.entries(CRYPTO_PAIRS)) reverseMap[v] = k;
              for (const [alpacaSym, snap] of Object.entries(cryptoSnaps)) {
                const ourSym = reverseMap[alpacaSym] || alpacaSym.replace("/", "");
                const lt = snap.latestTrade;
                const db = snap.dailyBar;
                const pdb = snap.prevDailyBar;
                const price = Number(lt?.p) || Number(db?.c) || 0;
                if (price <= 0) continue;
                const prevClose = Number(pdb?.c) || 0;
                const prev = existing[ourSym] || {};
                existing[ourSym] = {
                  ...prev,
                  p: price,
                  pc: prevClose > 0 ? prevClose : (prev.pc || 0),
                  dc: prevClose > 0 ? Math.round((price - prevClose) * 100) / 100 : prev.dc,
                  dp: prevClose > 0 ? Math.round(((price - prevClose) / prevClose) * 10000) / 100 : prev.dp,
                  t: lt?.t ? new Date(lt.t).getTime() : Date.now(),
                };
                cryptoUpdated++;
              }
            }
          } catch (_) {}

          // 3. Write merged result + push to PriceHub
          const lightUpdateTs = Date.now();
          await kvPutJSON(KV, "timed:prices", {
            prices: existing,
            updated_at: lightUpdateTs,
            ticker_count: Object.keys(existing).length,
            _source: "lightweight_overnight",
          });
          ctx.waitUntil(notifyPriceHub(env, {
            type: "prices",
            data: existing,
            updated_at: lightUpdateTs,
          }));
          console.log(`[PRICE FEED LIGHT] TV futures: ${tvUpdated}, crypto: ${cryptoUpdated}, total: ${Object.keys(existing).length}`);
          // Skip the rest of the heavy pipeline
        } else {
        // ── Full pipeline (active hours) ──
        // Primary: AlpacaStream DO handles all Alpaca stock + crypto price computation.
        // Fallback: If DO prices are stale (>3 min old or all-zero changes), fetch
        //           snapshots from Alpaca REST API so prices stay accurate even when
        //           the stream isn't running.

        let prices = {};
        let pricesSource = "kv";
        let pricesUpdatedAt = 0;
        try {
          const raw = await kvGetJSON(KV, "timed:prices");
          prices = raw?.prices || {};
          pricesUpdatedAt = Number(raw?.updated_at) || 0;
        } catch (_) {}

        // Detect stale DO-managed prices: either >3 min old or all tickers show zero change
        const priceAgeMs = Date.now() - pricesUpdatedAt;
        const priceAgeMin = priceAgeMs / 60000;
        const nonZeroChanges = Object.values(prices).filter(p => Number(p?.dc) !== 0 || Number(p?.dp) !== 0).length;
        const doFresh = priceAgeMin < 3 && nonZeroChanges > 5;

        // ── REST snapshot fallback when DO isn't providing fresh data ──
        let restFallbackCount = 0;
        if (!doFresh) {
          try {
            const userAddedForPF = await d1GetActiveUserTickersCached(env);
            const allTickersForSnap = [...new Set([...Object.keys(SECTOR_MAP), ...userAddedForPF])];
            const snapResult = await alpacaFetchSnapshots(env, allTickersForSnap);
            const snapshots = snapResult.snapshots || {};
            const CRYPTO_24H_FULL = new Set(["BTCUSD", "ETHUSD"]);
            for (const [sym, snap] of Object.entries(snapshots)) {
              const ahPrice = snap.price;
              const rthClose = snap.dailyClose;
              const pc = snap.prevDailyClose;
              const isCryptoSym = CRYPTO_24H_FULL.has(sym);
              const displayPrice = isCryptoSym ? (ahPrice > 0 ? ahPrice : rthClose) : (rthClose > 0 ? rthClose : ahPrice);
              if (!displayPrice || displayPrice <= 0) continue;
              const dc = (displayPrice > 0 && pc > 0) ? Math.round((displayPrice - pc) * 100) / 100 : 0;
              const dp = (displayPrice > 0 && pc > 0) ? Math.round(((displayPrice - pc) / pc) * 10000) / 100 : 0;
              let extDc = 0, extDp = 0;
              if (!isCryptoSym && ahPrice > 0 && rthClose > 0 && Math.abs(ahPrice - rthClose) > 0.001) {
                extDc = Math.round((ahPrice - rthClose) * 100) / 100;
                extDp = Math.round(((ahPrice - rthClose) / rthClose) * 10000) / 100;
              }
              const prev = prices[sym] || {};
              prices[sym] = {
                ...prev,
                p: Math.round(displayPrice * 100) / 100,
                pc: pc > 0 ? Math.round(pc * 100) / 100 : (prev.pc || 0),
                dc, dp,
                dh: snap.dailyHigh > 0 ? Math.round(snap.dailyHigh * 100) / 100 : (prev.dh || 0),
                dl: snap.dailyLow > 0 ? Math.round(snap.dailyLow * 100) / 100 : (prev.dl || 0),
                dv: snap.dailyVolume || prev.dv || 0,
                t: snap.trade_ts || Date.now(),
                ahp: extDc !== 0 ? Math.round(ahPrice * 100) / 100 : undefined,
                ahdc: extDc !== 0 ? extDc : undefined,
                ahdp: extDp !== 0 ? extDp : undefined,
              };
              restFallbackCount++;
            }
            pricesSource = "alpaca_rest_fallback";
          } catch (e) {
            console.warn("[PRICE FEED] REST fallback error:", String(e?.message || e).slice(0, 200));
          }
        }

        // D1 daily candle fallback for tickers still stale after REST snapshot
        try {
          if (env?.DB) {
            const staleFullSyms = allTickers.filter(sym => {
              const e = prices[sym];
              return !e || Number(e.dp) === 0 || !Number.isFinite(Number(e.dp));
            });
            if (staleFullSyms.length > 0) {
              const d1Rows = await env.DB.prepare(
                `WITH deduped AS (
                  SELECT ticker, ts, c,
                    ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                  FROM ticker_candles WHERE tf = 'D'
                )
                SELECT ticker, ts, c FROM (
                  SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                  FROM deduped WHERE day_rn = 1
                ) WHERE rn <= 2
                ORDER BY ticker, ts DESC`
              ).all();
              const d1Map = {};
              for (const r of (d1Rows?.results || [])) {
                const s = String(r.ticker).toUpperCase();
                if (!d1Map[s]) d1Map[s] = [];
                d1Map[s].push({ ts: Number(r.ts), c: Number(r.c) });
              }
              let d1FullCount = 0;
              for (const sym of staleFullSyms) {
                const candles = d1Map[sym];
                if (!candles || candles.length < 2) continue;
                const todayC = candles[0]?.c;
                const prevC = candles[1]?.c;
                if (!todayC || todayC <= 0 || !prevC || prevC <= 0) continue;
                const dc = Math.round((todayC - prevC) * 100) / 100;
                const dp = Math.round(((todayC - prevC) / prevC) * 10000) / 100;
                if (dp === 0) continue;
                const prev = prices[sym] || {};
                prices[sym] = { ...prev, p: Math.round(todayC * 100) / 100, pc: Math.round(prevC * 100) / 100, dc, dp, t: candles[0].ts || Date.now() };
                d1FullCount++;
              }
              if (d1FullCount > 0) console.log(`[PRICE FEED] D1 candle fallback updated ${d1FullCount} stale tickers`);
            }
          }
        } catch (e) {
          console.warn("[PRICE FEED] D1 fallback error:", String(e?.message || e).slice(0, 200));
        }

        // Overlay TV heartbeat prices for futures/macro tickers not handled by the DO
        const TV_FUTURES_ACTIVE = ["ES1!", "NQ1!", "GC1!", "SI1!", "VX1!", "US500", "CL1!"];
        let tvOverlayCount = 0;
        for (const tvSym of TV_FUTURES_ACTIVE) {
          try {
            const hbData = await kvGetJSON(KV, `timed:heartbeat:${tvSym}`);
            const latestData = await kvGetJSON(KV, `timed:latest:${tvSym}`);
            const tvData = (hbData && hbData.price > 0) ? hbData : latestData;
            if (tvData && tvData.price > 0) {
              const prevClose = Number(tvData.prev_close || tvData.previous_close || 0);
              const price = Number(tvData.price);
              const dc = prevClose > 0 ? Math.round((price - prevClose) * 100) / 100 : null;
              const dp = prevClose > 0 ? Math.round(((price - prevClose) / prevClose) * 10000) / 100 : null;
              const prev = prices[tvSym] || {};
              prices[tvSym] = {
                ...prev,
                p: Math.round(price * 100) / 100,
                pc: prevClose > 0 ? Math.round(prevClose * 100) / 100 : (prev.pc || 0),
                dc: dc ?? prev.dc, dp: dp ?? prev.dp,
                dh: Math.round(Number(tvData.high || tvData.dailyHigh || 0) * 100) / 100 || prev.dh,
                dl: Math.round(Number(tvData.low || tvData.dailyLow || 0) * 100) / 100 || prev.dl,
                dv: Number(tvData.volume || 0) || prev.dv,
                t: Number(tvData.ts || tvData.ingest_ts || 0) || Date.now(),
              };
              tvOverlayCount++;
            }
          } catch (_) {}
        }

        const priceUpdateTs = Date.now();
        await kvPutJSON(KV, "timed:prices", {
          prices,
          updated_at: priceUpdateTs,
          ticker_count: Object.keys(prices).length,
          _source: pricesSource,
        });
        ctx.waitUntil(notifyPriceHub(env, { type: "prices", data: prices, updated_at: priceUpdateTs }));

        console.log(`[PRICE FEED] source=${pricesSource}, doFresh=${doFresh}, restFallback=${restFallbackCount}, tvOverlay=${tvOverlayCount}, total=${Object.keys(prices).length}`);

        // ── SL/TP Exit Checking on price loop ──
        // Check open positions against current prices for fast SL/TP reaction
        try {
          const allTrades = (await kvGetJSON(KV, "timed:trades:all")) || [];
          const openTrades = allTrades.filter(t => t.status === "OPEN" || t.status === "TP_HIT_TRIM");
          let slTriggered = 0, tpTriggered = 0;

          for (const trade of openTrades) {
            const sym = String(trade.ticker || "").toUpperCase();
            const snap = prices[sym];
            if (!snap || !snap.p) continue;

            const currentPrice = snap.p;
            const sl = Number(trade.stop_loss || trade.sl);
            const tp = Number(trade.take_profit || trade.tp);
            const direction = String(trade.direction || "").toUpperCase();
            const isLong = direction === "LONG";

            // SL check
            if (Number.isFinite(sl) && sl > 0) {
              const slHit = isLong ? currentPrice <= sl : currentPrice >= sl;
              if (slHit) {
                slTriggered++;
                // Flag for the scoring loop to process the exit
                trade._price_sl_triggered = true;
                trade._price_sl_triggered_at = Date.now();
                trade._price_sl_price = currentPrice;
              }
            }

            // TP check (first tier)
            if (Number.isFinite(tp) && tp > 0) {
              const tpHit = isLong ? currentPrice >= tp : currentPrice <= tp;
              if (tpHit) {
                tpTriggered++;
                trade._price_tp_triggered = true;
                trade._price_tp_triggered_at = Date.now();
                trade._price_tp_price = currentPrice;
              }
            }
          }

          // Write back flagged trades if any SL/TP triggered
          if (slTriggered > 0 || tpTriggered > 0) {
            await kvPutJSON(KV, "timed:trades:all", allTrades);
            console.log(`[PRICE FEED] SL/TP check: ${slTriggered} SL triggered, ${tpTriggered} TP triggered`);
          }
        } catch (e) {
          console.warn("[PRICE FEED] SL/TP check error:", e);
        }

        console.log(`[PRICE FEED] Updated ${Object.keys(prices).length} tickers`);

        // NOTE: Scoring chain removed from price feed to prevent dual-scoring race.
        // The */5 cron handler is the SOLE scoring loop. Running scoring here AND
        // in the */5 handler caused concurrent KV writes → kanban stage oscillation.
        } // end of full pipeline else block
      } catch (e) {
        console.error("[PRICE FEED] Error:", e);
      }
      // Don't return — D1 sync below may also run
    }

    // (Overnight crypto handler removed — absorbed into lightweight price feed above)

    // ── End of every-minute handler (price feed only; bars moved to */5 in Phase 3) ──
    if (_isEveryMin) {
      // COST OPTIMIZATION: D1 sync reduced from 4x per 5-min window to 1x.
      // Only sync on minutes ending in 2 (e.g., :02, :07, :12).
      // Saves ~300K D1 writes/month.
      const _min1 = _now.getUTCMinutes();
      if (_min1 % 5 === 2) {
        try {
          ctx.waitUntil(d1SyncLatestBatchFromKV(env, ctx, 25));
        } catch (e) {
          console.error("[D1 SYNC] scheduled kickoff failed:", String(e));
        }
      }
      return;
    }

    // ── Earnings calendar refresh (hourly) ──
    if (_isHourly) {
      ctx.waitUntil((async () => {
        try {
          const KV = env.KV_TIMED;
          if (!KV) return;
          const today = new Date().toLocaleDateString("en-CA", { timeZone: "America/New_York" });
          const future = new Date(Date.now() + 5 * 86400000).toLocaleDateString("en-CA", { timeZone: "America/New_York" });
          const raw = await fetchFinnhubEarnings(env, today, future);
          const universeSet = new Set(Object.keys(SECTOR_MAP));
          const filtered = raw
            .filter(e => universeSet.has(String(e.symbol).toUpperCase()))
            .map(e => ({
              symbol: String(e.symbol).toUpperCase(),
              date: e.date,
              hour: e.hour || "bmo",
              epsEstimate: e.epsEstimate ?? null,
              epsActual: e.epsActual ?? null,
              revenueEstimate: e.revenueEstimate ?? null,
              revenueActual: e.revenueActual ?? null,
            }));
          await kvPutJSON(KV, "timed:earnings:upcoming", {
            events: filtered,
            updated_at: Date.now(),
            range: { from: today, to: future },
          });
          console.log(`[EARNINGS CRON] Cached ${filtered.length} earnings events (${today} → ${future})`);
        } catch (e) {
          console.warn("[EARNINGS CRON] Failed:", String(e?.message || e).slice(0, 200));
        }
      })());
    }

    // ── End of hourly handler (briefs + lifecycle + investor) ──
    if (_isHourly) return;

    // ═══════════════════════════════════════════════════════════════════════
    // BELOW: only runs for the */5 cron handler (scoring + AI + ML)
    // ═══════════════════════════════════════════════════════════════════════

    const KV = env.KV_TIMED;
    const now = new Date();
    const hour = now.getUTCHours();
    const minute = now.getUTCMinutes();
    const processedTickers = new Set();

    // ═══════════════════════════════════════════════════════════════════════
    // SCORING CRON (*/5) — PRIMARY SCORING LOOP
    //
    // Every 5 minutes: fetch scores for all tickers using 7 TFs (W,D,4H,1H,30m,10m,5m).
    // This is the sole scoring loop (old */1 fast scoring removed — caused whiplash).
    // 5m cadence provides trend confirmation; UI uses 2-consecutive-cycle logic for
    // entry signals (10m effective confirmation window).
    //
    // Priority order: P0 open positions → P1 setup/enter → P2 rest
    // Parallel: 10 tickers concurrently, each with 7+ concurrent D1 reads
    // ═══════════════════════════════════════════════════════════════════════
    // ── Crypto bar fetching: true 24/7 coverage ──
    // Runs on EVERY */5 tick regardless of operating hours.
    // Crypto trades 24/7; only 2 tickers (BTCUSD, ETHUSD), lightweight.
    if (env.ALPACA_ENABLED === "true" && env.ALPACA_API_KEY_ID && env.ALPACA_API_SECRET_KEY) {
      ctx.waitUntil(
        alpacaCronFetchCrypto(env)
          .then(r => { if (r.upserted > 0) console.log(`[SCORING→CRYPTO] ${r.upserted} bars upserted`); })
          .catch(e => console.warn("[SCORING→CRYPTO] error:", String(e).slice(0, 150)))
      );
    }

    if (env.ALPACA_ENABLED === "true") {
      try {
        // ── COST GATE: Skip scoring entirely outside operating hours ──
        // Operating hours: 4 AM - 8 PM ET weekdays. This eliminates ~50% of all
        // D1 reads and KV writes from off-hours scoring (weekends, overnight).
        if (!isWithinOperatingHours()) {
          console.log(`[SCORING CRON] Skipping — outside operating hours (4 AM - 8 PM ET weekdays)`);
          return;
        }

        // Skip scoring if a replay is in progress (prevents overwriting replay trades)
        const replayLock = await kvGetJSON(KV, "timed:replay:running");
        if (replayLock && typeof replayLock === "object" && replayLock.since) {
          const lockAge = Date.now() - replayLock.since;
          // Auto-expire stale locks after 15 minutes (multi-batch replay can take 3-5 min)
          if (lockAge < 15 * 60 * 1000) {
            console.log(`[SCORING CRON] Skipping — replay in progress (started ${Math.round(lockAge / 1000)}s ago)`);
            return;
          } else {
            console.warn(`[SCORING CRON] Stale replay lock (${Math.round(lockAge / 1000)}s old), clearing and proceeding`);
            await kvPutJSON(KV, "timed:replay:running", null);
          }
        }

        const scoringStart = Date.now();

        // Pre-warm learning loop caches before scoring begins
        let _learnedTfWeights = null;
        let _learnedScoreAdj = null;
        let _learnedSignalWeights = null;
        if (env?.DB) {
          try {
            await d1EnsureLearningSchema(env);
            if (Date.now() - _pathPerfCacheTs >= PATH_PERF_CACHE_TTL) {
              const { results } = await env.DB.prepare(`SELECT * FROM path_performance`).all();
              _pathPerfCache = new Map();
              for (const row of (results || [])) _pathPerfCache.set(row.entry_path, row);
              _pathPerfCacheTs = Date.now();
            }
            [_learnedTfWeights, _learnedScoreAdj, _learnedSignalWeights] = await Promise.all([
              getLearnedConsensusWeights(env),
              getLearnedScoringWeights(env),
              getLearnedSignalWeights(env),
            ]);
          } catch { /* non-critical */ }
        }

        const coreTickers = Object.keys(SECTOR_MAP);
        const userAddedTickers = await d1GetActiveUserTickersCached(env);
        const allTickers = [...new Set([...coreTickers, ...userAddedTickers])];

        // Score ALL tickers every cycle (core + user-added)
        // With ~140+ tickers and 15-way parallelism, full cycle completes in ~10-15s
        let scored = 0, skipped = 0, errors = 0, trailWrites = 0;
        const pendingTrailPoints = []; // Collect trail points for batch write at end
        const scoredUpdates = {}; // Collect scored ticker deltas for WS push

        // ── Phase 7: Scoring delta instrumentation ──
        // Tracks what actually changed per ticker to inform adaptive scoring.
        let deltaScoreChanged = 0, deltaStageChanged = 0, deltaPriceChanged = 0, deltaNoChange = 0;

        // Get open positions for priority sorting and kanban context
        const openTradesCheck = ((await kvGetJSON(KV, "timed:trades:all")) || [])
          .filter(t => t.status === "OPEN" || t.status === "TP_HIT_TRIM");
        const openTickerSet = new Set(openTradesCheck.map(t => String(t.ticker || "").toUpperCase()));

        // Filter out removed tickers
        const removedForScoring = new Set((await kvGetJSON(KV, "timed:removed")) || []);
        
        // Priority: open positions first, then everything else
        const tickersToScore = [];
        for (const t of openTickerSet) {
          if (!removedForScoring.has(t)) tickersToScore.push(t);
        }
        for (const t of allTickers) {
          if (!openTickerSet.has(t) && !removedForScoring.has(t)) tickersToScore.push(t);
        }

        // Check if market is currently open — if closed, pin kanban stage for discovery tickers
        const stdCronMarketOpen = isNyRegularMarketOpen();

        const scoreTicker = async (ticker) => {
          try {
            const existing = await kvGetJSON(KV, `timed:latest:${ticker}`);

            // Pre-fetch ALL timeframes for this ticker in a single D1 batch call.
            // This reduces 9 D1 subrequests to 1, critical for staying under the
            // 1000 subrequests/invocation limit with 140+ tickers.
            // COST OPTIMIZATION: Reduced candle limits to match actual indicator needs.
            // EMA-233 meaningful on D/4H only. Sub-hourly TFs need ~100 candles max.
            // 1m candles REMOVED — only used for optional TD Sequential chart overlay,
            // not core scoring. Saves ~1.9M D1 queries/month.
            const tfConfigs = [
              { tf: "W", limit: 100 }, { tf: "D", limit: 250 },
              { tf: "240", limit: 250 }, { tf: "60", limit: 150 },
              { tf: "30", limit: 100 }, { tf: "10", limit: 100 },
              { tf: "5", limit: 100 },
              { tf: "M", limit: 24 },
            ];
            const candleCache = await d1GetCandlesAllTfs(env, ticker, tfConfigs);
            // Wrap cache in a getCandles-compatible function (no additional D1 calls)
            const getCandlesCached = async (_env, _ticker, tf, _limit) => {
              const tfKey = normalizeTfKey(tf);
              return candleCache[tfKey] || { ok: false, candles: [] };
            };

            // Inject learned weights so assembleTickerData uses them
            const hasLearnedWeights = _learnedTfWeights || _learnedScoreAdj || _learnedSignalWeights;
            const existWithWeights = hasLearnedWeights
              ? { ...(existing || {}), ...(_learnedTfWeights ? { _tfWeights: _learnedTfWeights } : {}), ...(_learnedSignalWeights ? { _signalWeights: _learnedSignalWeights } : {}), ...(_learnedScoreAdj ? { _scoreWeights: _learnedScoreAdj } : {}) }
              : existing;
            const result = await computeServerSideScores(ticker, getCandlesCached, env, existWithWeights);
            if (!result) {
              if (existing && typeof existing === "object") {
                const now = Date.now();
                existing.trigger_ts = now;
                existing.data_source_ts = now;
                existing.ingest_ts = now;
                existing.ingest_time = new Date(now).toISOString();
                existing._scoring_skip_reason = "insufficient_candle_data";
                await kvPutJSON(KV, `timed:latest:${ticker}`, existing);
              }
              skipped++;
              return;
            }

            const now = Date.now();
            result.data_source = "alpaca";
            result.data_source_ts = now;
            result.ingest_ts = now;
            result.ingest_time = new Date(now).toISOString();
            // Keep trigger_ts fresh: server-side scoring is the signal source now.
            // Without this, qualifiesForEnter blocks entries after 7 days (trigger_stale).
            result.trigger_ts = now;

            // Compute rank/score — computeServerSideScores builds technical data
            // but doesn't score; computeRank produces the 0-100 composite score.
            result.rank = computeRank(result);
            result.score = result.rank;

            // Overnight signal injection (throttled to once/day)
            try {
              const currentSession = getSessionType(Date.now());
              if (currentSession === "RTH") {
                const overnightKey = `timed:overnight:${ticker}:${new Date().toISOString().slice(0, 10)}`;
                const alreadyDone = await KV.get(overnightKey);
                if (!alreadyDone) {
                  const lastCloseTs = Date.now() - 18 * 3600 * 1000;
                  const overnight = await computeOvernightSignals(ticker, lastCloseTs, Date.now(), getCandlesCached, env);
                  if (overnight?.overnightFlags && Object.keys(overnight.overnightFlags).length > 0) {
                    result.flags = { ...(result.flags || {}), ...overnight.overnightFlags };
                    result._overnight_signals = overnight.signals;
                  }
                  await KV.put(overnightKey, "1", { expirationTtl: 24 * 3600 });
                }
              }
            } catch { /* overnight injection non-critical */ }

            // ── Consecutive Confirmation Logic ──
            // Entry signals require 2 consecutive scoring cycles confirming alignment
            // (effectively 10-minute confirmation window at 5m cadence).
            // Score-based exits also require 2 consecutive deterioration cycles.
            try {
              const prevState = existing?.state;
              const prevConfirmCount = Number(existing?._confirm_count) || 0;
              const prevExitCount = Number(existing?._exit_deterioration_count) || 0;

              // Entry confirmation: track consecutive cycles in the same entry state
              // (e.g., HTF_BULL_LTF_BULL for LONG, HTF_BEAR_LTF_BEAR for SHORT)
              const isEntryState = result.state === "HTF_BULL_LTF_BULL" || result.state === "HTF_BEAR_LTF_BEAR";
              if (isEntryState && result.state === prevState) {
                result._confirm_count = prevConfirmCount + 1;
              } else if (isEntryState) {
                result._confirm_count = 1; // First cycle in new entry state
              } else {
                result._confirm_count = 0; // Not in entry state
              }
              result._entry_confirmed = result._confirm_count >= 2; // 2 cycles = 10 min confirmation

              // Exit deterioration: track consecutive cycles where score moves against position
              const htf = result.htf_score || 0;
              const ltf = result.ltf_score || 0;
              const prevHtf = existing?.htf_score || 0;
              const prevLtf = existing?.ltf_score || 0;
              const scoreDeterioration = (
                (htf >= 0 && ltf < prevLtf - 3) || // Long: LTF dropping significantly
                (htf < 0 && ltf > prevLtf + 3)     // Short: LTF rising significantly
              );
              if (scoreDeterioration) {
                result._exit_deterioration_count = prevExitCount + 1;
              } else {
                result._exit_deterioration_count = 0;
              }
              result._score_exit_signal = result._exit_deterioration_count >= 2; // 2 consecutive cycles
            } catch { /* confirmation tracking non-critical */ }

            // Compute kanban_stage — pin discovery tickers when market is closed
            // Management stages (hold, defend, trim, exit) require an open position;
            // if no position exists, force reclassification to prevent stale replay stages.
            try {
              const openPos = openTradesCheck.find(t => String(t.ticker || "").toUpperCase() === ticker) || null;
              if (openPos) {
                result.kanban_stage = classifyKanbanStage(result, openPos);
              } else if (stdCronMarketOpen) {
                result.kanban_stage = classifyKanbanStage(result);
              } else {
                // Market closed: pin discovery stages but NOT management stages without a position
                const prev = existing?.kanban_stage;
                const mgmtStages = new Set(["active", "hold", "just_entered", "defend", "trim", "exit"]);
                if (prev && mgmtStages.has(prev)) {
                  // No open position + management stage = stale from replay. Reclassify.
                  result.kanban_stage = classifyKanbanStage(result);
                } else {
                  result.kanban_stage = prev || classifyKanbanStage(result);
                }
              }
            } catch { /* non-critical */ }

            // COST OPTIMIZATION: Always use delta checking. The operating hours gate
            // (Phase 1) prevents off-hours runs entirely, and the delta check now works
            // properly (5-min time gate removed). This skips KV writes for tickers with
            // no meaningful change, saving ~50-70% of KV writes during RTH.
            //
            // ── Delta instrumentation (Phase 7) ──
            const _htfDelta = Math.abs((Number(result?.htf_score) || 0) - (Number(existing?.htf_score) || 0));
            const _ltfDelta = Math.abs((Number(result?.ltf_score) || 0) - (Number(existing?.ltf_score) || 0));
            const _stageFlip = (result?.kanban_stage || "") !== (existing?.kanban_stage || "");
            const _oldPx = Number(existing?.price);
            const _newPx = Number(result?.price);
            const _pxDelta = (_oldPx > 0 && _newPx > 0) ? Math.abs(_newPx - _oldPx) / _oldPx : 0;
            if (_htfDelta >= 0.5 || _ltfDelta >= 0.5) deltaScoreChanged++;
            if (_stageFlip) deltaStageChanged++;
            if (_pxDelta >= 0.001) deltaPriceChanged++;
            if (_htfDelta < 0.5 && _ltfDelta < 0.5 && !_stageFlip && _pxDelta < 0.001) deltaNoChange++;

            if (hasPayloadChangedMeaningfully(existing, result)) {
              await kvPutJSON(KV, `timed:latest:${ticker}`, result);
              scored++;
              // Collect lightweight delta for WS push
              scoredUpdates[ticker] = {
                score: result.eqScore ?? result.eq_score,
                stage: result.kanban_stage,
                dir: result.bias_direction,
                price: result.price || result.close,
                ts: result.trigger_ts,
                blockReason: result.__entry_block_reason || null,
              };
            } else {
              // Payload unchanged — still refresh ingest_ts so UI doesn't show "stale"
              if (existing && typeof existing === "object") {
                existing.ingest_ts = now;
                existing.ingest_time = new Date(now).toISOString();
                await kvPutJSON(KV, `timed:latest:${ticker}`, existing);
              }
              skipped++;
            }

            // Collect trail points for batch write (don't make individual D1 calls here)
            const TRAIL_CADENCE_MS = 10 * 60 * 1000;
            const lastTrailTs = Number(existing?._last_trail_ts) || 0;
            if (Date.now() - lastTrailTs >= TRAIL_CADENCE_MS) {
              pendingTrailPoints.push({ ticker, result });
            }
          } catch (e) {
            errors++;
            console.warn(`[SCORING] ${ticker}:`, String(e));
          }
        };

        // Process in parallel batches of 15 (up from 10 — fewer tickers, can be more aggressive)
        const PARALLEL = 15;
        for (let i = 0; i < tickersToScore.length; i += PARALLEL) {
          const batch = tickersToScore.slice(i, i + PARALLEL);
          await Promise.allSettled(batch.map(scoreTicker));
        }

        // Batch-write all trail points in one D1 batch call (saves ~100 individual D1 calls)
        if (pendingTrailPoints.length > 0 && env?.DB) {
          try {
            const db = env.DB;
            const trailStmts = [];
            for (const { ticker, result } of pendingTrailPoints) {
              const ts = Number(result?.ts);
              if (!Number.isFinite(ts)) continue;
              const flagsJson = result?.flags ? JSON.stringify(result.flags) : null;
              trailStmts.push(
                db.prepare(
                  `INSERT OR REPLACE INTO timed_trail
                    (ticker, ts, price, htf_score, ltf_score, completion, phase_pct, state, rank, flags_json, trigger_reason, trigger_dir, kanban_stage, payload_json)
                   VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10, ?11, ?12, ?13, ?14)`
                ).bind(
                  String(ticker).toUpperCase(), ts,
                  result?.price ?? null, result?.htf_score ?? null, result?.ltf_score ?? null,
                  result?.completion ?? null, result?.phase_pct ?? null,
                  result?.state ?? null, result?.rank ?? null, flagsJson,
                  result?.trigger_reason ?? null, result?.trigger_dir ?? null,
                  result?.kanban_stage ?? null, null
                )
              );
            }
            // Write in chunks of 500 (D1 batch limit)
            for (let i = 0; i < trailStmts.length; i += 500) {
              await db.batch(trailStmts.slice(i, i + 500));
            }
            trailWrites = pendingTrailPoints.length;
            // Update _last_trail_ts for all trail tickers (batch KV writes via waitUntil)
            ctx.waitUntil(Promise.allSettled(
              pendingTrailPoints.map(({ ticker, result }) => {
                result._last_trail_ts = Date.now();
                return kvPutJSON(KV, `timed:latest:${ticker}`, result);
              })
            ));
          } catch (trailErr) {
            console.warn(`[SCORING] Trail batch write failed:`, String(trailErr).slice(0, 150));
          }
        }

        const elapsed = Date.now() - scoringStart;
        const userTickerCount = userAddedTickers.length;
        const coreTickerCount = coreTickers.length;
        console.log(`[SCORING] ${scored} scored, ${skipped} skipped, ${errors} errors, ${trailWrites} trail, ${elapsed}ms, ALL ${tickersToScore.length} tickers (${coreTickerCount} core + ${userTickerCount} user-added)`);
        console.log(`[SCORING DELTA] ${deltaScoreChanged}/${tickersToScore.length} score changed, ${deltaStageChanged} stage changed, ${deltaPriceChanged} price changed, ${deltaNoChange} no change`);
        if (elapsed > 25000) {
          console.warn(`[SCORING CAPACITY] Scoring took ${elapsed}ms — approaching 30s limit. Consider optimization if user-added tickers continue to grow.`);
        }

        // Store last run timestamp for health/staleness monitoring
        await kvPutJSON(KV, "timed:scoring:last_run", {
          ts: Date.now(),
          scored,
          skipped,
          errors,
          total: tickersToScore.length,
          core: coreTickerCount,
          userAdded: userTickerCount,
          elapsedMs: elapsed,
          delta: { scoreChanged: deltaScoreChanged, stageChanged: deltaStageChanged, priceChanged: deltaPriceChanged, noChange: deltaNoChange },
        });

        // ── KV Hot Cache: Pre-assemble /timed/all snapshot ──────────────
        // Writes a ready-to-serve snapshot so /timed/all can serve from KV
        // instead of querying D1 per request, reducing D1 load to near-zero
        // for the most-hit endpoint.
        ctx.waitUntil((async () => {
          try {
            const activeSyms = [...new Set([...Object.keys(SECTOR_MAP), ...userAddedTickers])];
            const snapshot = {};
            for (const sym of activeSyms) {
              const payload = await kvGetJSON(KV, `timed:latest:${sym}`);
              if (payload && typeof payload === "object") {
                snapshot[sym] = payload;
              }
            }

            // Enrich with sparkline data (last 60 daily closes per ticker)
            try {
              const sparkRows = await env.DB.prepare(
                `WITH deduped AS (
                  SELECT ticker, ts, c,
                    ROW_NUMBER() OVER (PARTITION BY ticker, CAST(ts / 86400000 AS INTEGER) ORDER BY ts DESC) as day_rn
                  FROM ticker_candles WHERE tf = 'D'
                )
                SELECT ticker, ts, c FROM (
                  SELECT ticker, ts, c, ROW_NUMBER() OVER (PARTITION BY ticker ORDER BY ts DESC) as rn
                  FROM deduped WHERE day_rn = 1
                ) WHERE rn <= 60
                ORDER BY ticker, ts ASC`
              ).all();
              const sparkMap = {};
              for (const r of (sparkRows?.results || [])) {
                const sym = String(r.ticker).toUpperCase();
                if (!sparkMap[sym]) sparkMap[sym] = [];
                sparkMap[sym].push(Number(r.c));
              }
              for (const [sym, closes] of Object.entries(sparkMap)) {
                if (snapshot[sym]) {
                  snapshot[sym]._sparkline = closes;
                }
              }
            } catch (sparkErr) {
              console.warn("[SCORING] Sparkline enrichment failed:", String(sparkErr?.message || sparkErr).slice(0, 150));
            }

            await kvPutJSON(KV, "timed:all:snapshot", {
              data: snapshot,
              count: Object.keys(snapshot).length,
              built_at: Date.now(),
            });
            console.log(`[SCORING] KV hot cache snapshot built: ${Object.keys(snapshot).length} tickers`);
          } catch (e) {
            console.warn("[SCORING] KV hot cache build failed:", String(e?.message || e));
          }
        })());

        // ── Push scoring deltas to WebSocket clients via PriceHub DO ──
        if (Object.keys(scoredUpdates).length > 0) {
          ctx.waitUntil(notifyPriceHub(env, {
            type: "scoring",
            data: scoredUpdates,
            updated_at: Date.now(),
            scored_count: Object.keys(scoredUpdates).length,
          }));
        }
      } catch (e) {
        console.error("[SCORING] Error:", e);
      }
    }

    // --- MARKET-HOURS GATE: Only run trade/execution logic during operating hours ---
    // Uses calendar-aware isWithinOperatingHours (4 AM - 8 PM ET weekdays, excl holidays).
    const executionMarketOpen = isNyRegularMarketOpen();
    const allowExecution = _cronCalendar ? _calIsWithinOH(_cronCalendar) : executionMarketOpen;

    if (!allowExecution) {
      const _gateNow = new Date();
      const _gateDayStr = _gateNow.toLocaleString("en-US", { timeZone: "America/New_York", weekday: "short" });
      const _gateHourStr = _gateNow.toLocaleString("en-US", { timeZone: "America/New_York", hour: "numeric", hour12: false });
      console.log(`[EXECUTION GATE] Market closed (ET hour=${_gateHourStr}, day=${_gateDayStr}). Skipping trade updates and Kanban executions.`);
    }

    // Drain queued actions at market open (once per day, first RTH cycle)
    if (executionMarketOpen) {
      try {
        const drainResult = await drainQueuedActions(env);
        if (drainResult && !drainResult.skipped && (drainResult.executed > 0 || drainResult.expired > 0)) {
          console.log(`[CRON] Queue drain: ${drainResult.executed} executed, ${drainResult.expired} expired`);
        }
      } catch (e) {
        console.error("[CRON] Queue drain error:", e);
      }
    }

    // Update open trades (runs every 5 minutes, ONLY during market/extended hours)
    if (allowExecution) {
      try {
        const tradesKey = "timed:trades:all";
        let allTrades = (await kvGetJSON(KV, tradesKey)) || [];

        // ── KV TRADE RECONCILIATION (runs FIRST, every cycle) ──
        // D1 positions is the source of truth.  Close phantom KV trades
        // (no D1 OPEN position) and deduplicate entries.  This prevents
        // the "Open" count and Kanban lanes from drifting from reality.
        try {
          const d1PosResult = await env.DB.prepare(
            `SELECT ticker FROM positions WHERE status = 'OPEN'`
          ).all();
          const d1Open = new Set((d1PosResult?.results || []).map(r => String(r.ticker).toUpperCase()));
          const seenOpen = new Set();
          let staleFixed = 0, dupsFixed = 0;

          for (const trade of allTrades) {
            const sym = String(trade?.ticker || "").toUpperCase();
            const isOpen = trade.status === "OPEN" || trade.status === "TP_HIT_TRIM" || !trade.status;
            if (!isOpen) continue;

            // Close phantom trades (KV OPEN but no D1 position)
            if (!d1Open.has(sym)) {
              trade.status = trade.status === "TP_HIT_TRIM" ? "WIN" : "CLOSED";
              trade.exit_reason = trade.exit_reason || "reconciled_no_d1_position";
              trade.exitTime = trade.exitTime || new Date().toISOString();
              staleFixed++;
              continue;
            }
            // Deduplicate (keep first OPEN per ticker)
            if (seenOpen.has(sym)) {
              const pnlVal = Number(trade.pnl || trade.realizedPnl || 0);
              trade.status = pnlVal > 0 ? "WIN" : pnlVal < 0 ? "LOSS" : "FLAT";
              trade.exit_reason = "dedup_reconcile";
              trade.exitTime = trade.exitTime || new Date().toISOString();
              if (!trade.exitPrice && trade.trim_price) trade.exitPrice = trade.trim_price;
              dupsFixed++;
              continue;
            }
            seenOpen.add(sym);
          }

          if (staleFixed > 0 || dupsFixed > 0) {
            await kvPutJSON(KV, tradesKey, allTrades);
            console.log(`[TRADE RECONCILE] Cleaned ${staleFixed} stale + ${dupsFixed} dups → ${seenOpen.size} open`);
          }
        } catch (reconcileErr) {
          console.warn("[TRADE RECONCILE]", String(reconcileErr).slice(0, 150));
        }

        const openTrades = allTrades.filter(
          (t) => t.status === "OPEN" || !t.status || t.status === "TP_HIT_TRIM",
        );

        if (openTrades.length > 0) {
          console.log(
            `[TRADE UPDATE CRON] Updating ${openTrades.length} open trades`,
          );

          for (const trade of openTrades) {
            try {
              processedTickers.add(String(trade.ticker || "").toUpperCase());
              const latestData = await kvGetJSON(
                KV,
                `timed:latest:${trade.ticker}`,
              );
              if (latestData) {
                const prevLatest = null;
                await processTradeSimulation(
                  KV,
                  trade.ticker,
                  latestData,
                  prevLatest,
                  env,
                );
              }
            } catch (err) {
              console.error(
                `[TRADE UPDATE CRON] Error updating trade ${trade.ticker}:`,
                err,
              );
            }
          }

          const finalTrades = (await kvGetJSON(KV, tradesKey)) || [];

          // ── FINAL RECONCILIATION: Clean phantom/duplicate trades right before write ──
          // This is the last write to timed:trades:all in the cron cycle, so cleanup
          // here can't be overwritten by processTradeSimulation calls.
          // NOTE: Re-query D1 here intentionally — processTradeSimulation may have
          // opened/closed positions since the first reconciliation query above.
          try {
            const d1PosCheck = await env.DB.prepare(
              `SELECT ticker FROM positions WHERE status = 'OPEN'`
            ).all();
            const d1OpenSet = new Set((d1PosCheck?.results || []).map(r => String(r.ticker).toUpperCase()));
            const seenOpenFinal = new Set();
            let fixedFinal = 0;

            for (const t of finalTrades) {
              const sym = String(t?.ticker || "").toUpperCase();
              const isO = t.status === "OPEN" || t.status === "TP_HIT_TRIM" || !t.status;
              if (!isO) continue;

              if (!d1OpenSet.has(sym)) {
                const pnlR = Number(t.pnl || t.realizedPnl || 0);
                t.status = pnlR > 0 ? "WIN" : pnlR < 0 ? "LOSS" : "FLAT";
                t.exit_reason = t.exit_reason || "reconciled_no_d1_position";
                t.exitTime = t.exitTime || new Date().toISOString();
                fixedFinal++;
              } else if (seenOpenFinal.has(sym)) {
                const pnlR = Number(t.pnl || t.realizedPnl || 0);
                t.status = pnlR > 0 ? "WIN" : pnlR < 0 ? "LOSS" : "FLAT";
                t.exit_reason = "dedup_reconcile";
                t.exitTime = t.exitTime || new Date().toISOString();
                if (!t.exitPrice && t.trim_price) t.exitPrice = t.trim_price;
                fixedFinal++;
              } else {
                seenOpenFinal.add(sym);
              }
            }
            if (fixedFinal > 0) {
              console.log(`[TRADE RECONCILE FINAL] Cleaned ${fixedFinal} entries → ${seenOpenFinal.size} open`);
            }
          } catch (recErr) {
            console.warn("[TRADE RECONCILE FINAL]", String(recErr).slice(0, 150));
          }

          finalTrades.sort((a, b) => {
            const timeA = new Date(a.entryTime || 0).getTime();
            const timeB = new Date(b.entryTime || 0).getTime();
            return timeB - timeA;
          });
          await kvPutJSON(KV, tradesKey, finalTrades);
          console.log(`[TRADE UPDATE CRON] Updated ${openTrades.length} trades`);
        }
      } catch (error) {
        console.error("[TRADE UPDATE CRON ERROR]", error);
      }
    }

    // Kanban-driven executions: evaluate entries/trims/exits (ONLY during market/extended hours).
    // Prevents phantom trades during off-hours when prices are stale.
    // Uses SECTOR_MAP as ticker source (same as scoring loop) to avoid gaps where
    // a ticker is scored but not evaluated for trade entry.
    if (allowExecution) {
      try {
        const execRemovedSet = new Set((await kvGetJSON(KV, "timed:removed")) || []);
        const userAddedForExec = await d1GetActiveUserTickersCached(env);
        const executionTickers = [...new Set([...Object.keys(SECTOR_MAP), ...userAddedForExec])].filter(t => !execRemovedSet.has(t));
        console.log(`[KANBAN CRON] Evaluating ${executionTickers.length} tickers`);
        for (const sym of executionTickers) {
          if (!sym) continue;
          if (processedTickers.has(sym)) continue;
          try {
            const latestData = await kvGetJSON(KV, `timed:latest:${sym}`);
            if (!latestData) continue;
            await processTradeSimulation(KV, sym, latestData, null, env);
          } catch (e) {
            console.error(`[KANBAN CRON] Error processing ${sym}:`, e);
          }
        }
      } catch (e) {
        console.error("[KANBAN CRON] top-level error:", e);
      }
    }

    // ═══════════════════════════════════════════════════════════════════════════
    // POSITION RECONCILIATION: Ensure ALL D1 open positions are monitored
    // This guarantees workflow follow-through: once a position opens, it MUST
    // flow through the workflow until EXIT. Catches orphaned positions where
    // TradingView alerts stopped firing or ticker fell out of KV index.
    // ═══════════════════════════════════════════════════════════════════════════
    try {
      const db = env?.DB;
      if (db) {
        // Fetch ALL open positions from D1 (source of truth)
        const openPositionsResult = await db.prepare(
          `SELECT ticker, position_id, stop_loss, take_profit, direction, cost_basis, total_qty, created_at 
           FROM positions WHERE status = 'OPEN'`
        ).all();
        
        const openPositions = openPositionsResult?.results || [];
        let reconciled = 0;
        let orphaned = 0;
        
        if (openPositions.length > 0) {
          console.log(`[POSITION RECONCILE] Found ${openPositions.length} open positions in D1`);
          
          for (const pos of openPositions) {
            const sym = String(pos.ticker).toUpperCase();
            
            // Skip if we already processed this ticker in KANBAN CRON
            if (processedTickers.has(sym)) continue;
            
            // Get latest data (try KV first, then D1 ticker_latest)
            let latestData = await kvGetJSON(KV, `timed:latest:${sym}`);
            
            if (!latestData) {
              // Fallback: try D1 ticker_latest
              try {
                const d1Latest = await db.prepare(
                  `SELECT payload_json FROM ticker_latest WHERE ticker = ?1`
                ).bind(sym).first();
                
                if (d1Latest?.payload_json) {
                  latestData = typeof d1Latest.payload_json === 'string' 
                    ? JSON.parse(d1Latest.payload_json) 
                    : d1Latest.payload_json;
                }
              } catch (parseErr) {
                console.warn(`[POSITION RECONCILE] ${sym} D1 payload parse failed:`, parseErr);
              }
            }
            
            if (latestData) {
              // Process with position context - ensures DEFEND/TRIM/EXIT logic runs
              try {
                await processTradeSimulation(KV, sym, latestData, null, env);
                processedTickers.add(sym);
                reconciled++;
                console.log(`[POSITION RECONCILE] Processed ${sym}`);
              } catch (procErr) {
                console.error(`[POSITION RECONCILE] ${sym} processTradeSimulation failed:`, procErr);
              }
            } else {
              // CRITICAL: Position exists but NO ticker data at all
              // This is an emergency - position is truly orphaned
              orphaned++;
              console.warn(
                `[POSITION RECONCILE] ⚠️ ORPHANED: ${sym} has open position (ID: ${pos.position_id}) ` +
                `but no ticker data! Entry: $${(pos.cost_basis / pos.total_qty || 0).toFixed(2)}, ` +
                `SL: ${pos.stop_loss || 'none'}, Created: ${new Date(pos.created_at).toISOString()}`
              );
              
              // TODO: Could implement emergency exit for orphaned positions here
              // For now, just log the warning for manual investigation
            }
          }
          
          if (reconciled > 0 || orphaned > 0) {
            console.log(`[POSITION RECONCILE] Summary: ${reconciled} reconciled, ${orphaned} orphaned`);
          }
        }

        // ── REVERSE RECONCILIATION: Clean up KV trades that have no D1 OPEN position ──
        // Catches phantom trades (KV says OPEN, D1 says CLOSED/missing).
        // D1 positions table is the source of truth for open/closed status.
        try {
          const tradesKey = "timed:trades:all";
          const kvTrades = (await kvGetJSON(KV, tradesKey)) || [];
          const d1OpenTickers = new Set(openPositions.map(p => String(p.ticker).toUpperCase()));
          let staleFixed = 0;
          let dupsRemoved = 0;
          const seenOpen = new Set(); // for deduplication
          const cleanedTrades = [];

          for (const trade of kvTrades) {
            const sym = String(trade?.ticker || "").toUpperCase();
            const isOpen = trade.status === "OPEN" || trade.status === "TP_HIT_TRIM" || !trade.status;

            if (isOpen) {
              // Check 1: Is there a matching D1 OPEN position?
              if (!d1OpenTickers.has(sym)) {
                // D1 says closed/missing → close the KV trade
                const pnlR = Number(trade.pnl || trade.realizedPnl || 0);
                trade.status = pnlR > 0 ? "WIN" : pnlR < 0 ? "LOSS" : "FLAT";
                trade.exit_reason = trade.exit_reason || "reconciled_no_d1_position";
                trade.exitTime = trade.exitTime || new Date().toISOString();
                staleFixed++;
                console.log(`[TRADE RECONCILE] Closed stale KV trade: ${sym} (no D1 OPEN position)`);
              }
              // Check 2: Deduplicate (only one OPEN trade per ticker)
              const stillOpen = trade.status === "OPEN" || trade.status === "TP_HIT_TRIM";
              if (stillOpen && seenOpen.has(sym)) {
                const pnlR = Number(trade.pnl || trade.realizedPnl || 0);
                trade.status = pnlR > 0 ? "WIN" : pnlR < 0 ? "LOSS" : "FLAT";
                trade.exit_reason = "dedup_reconcile";
                trade.exitTime = trade.exitTime || new Date().toISOString();
                if (!trade.exitPrice && trade.trim_price) trade.exitPrice = trade.trim_price;
                dupsRemoved++;
                console.log(`[TRADE RECONCILE] Removed duplicate KV trade: ${sym}`);
              }
              if (stillOpen) seenOpen.add(sym);
            }
            cleanedTrades.push(trade);
          }

          if (staleFixed > 0 || dupsRemoved > 0) {
            await kvPutJSON(KV, tradesKey, cleanedTrades);
            console.log(`[TRADE RECONCILE] Fixed ${staleFixed} stale, ${dupsRemoved} duplicates. KV trades: ${cleanedTrades.length} total, ${cleanedTrades.filter(t => t.status === "OPEN" || t.status === "TP_HIT_TRIM").length} open`);
          }
        } catch (tradeReconcileErr) {
          console.warn("[TRADE RECONCILE] Error:", String(tradeReconcileErr).slice(0, 200));
        }
      }
    } catch (reconcileErr) {
      console.error("[POSITION RECONCILE] Error:", reconcileErr);
    }

    // Ingest coverage check (every 5 min during market hours)
    try {
      await checkIngestCoverage(KV, now);
    } catch (err) {
      console.error("[INGEST COVERAGE ERROR]", err);
    }

    // Proactive Alerts & Pattern Recognition (every 15 minutes during market hours)
    // This runs more frequently to catch time-sensitive conditions
    const isProactiveAlertTime = minute % 15 === 0; // Every 15 minutes

    if (isProactiveAlertTime) {
      try {
        const tradesKey = "timed:trades:all";
        const allTrades = (await kvGetJSON(KV, tradesKey)) || [];
        const openTrades = allTrades.filter(
          (t) => t.status === "OPEN" || t.status === "TP_HIT_TRIM",
        );

        // Fetch current ticker data for alert generation (use tickers index; don't arbitrarily truncate to 50)
        const tickers = (await kvGetJSON(KV, "timed:tickers")) || [];
        const tickerDataPromises = (Array.isArray(tickers) ? tickers : [])
          .slice(0, 600) // safety cap
          .map(async (t) => {
            try {
              const sym = String(t || "").toUpperCase();
              if (!sym) return null;
              const data = await kvGetJSON(KV, `timed:latest:${sym}`);
              if (!data) return null;
              const tsRaw = data.ingest_ts ?? data.ingest_time ?? data.ts;
              const tsMs = typeof tsRaw === "string" ? new Date(tsRaw).getTime() : (Number(tsRaw) > 0 && Number(tsRaw) < 1e12 ? Number(tsRaw) * 1000 : Number(tsRaw));
              return {
                ticker: sym,
                rank: Number(data.rank) || 0,
                rr: Number(data.rr) || 0,
                price: Number(data.price) || 0,
                completion: Number(data.completion) || 0,
                phase_pct: Number(data.phase_pct) || 0,
                flags: data.flags || {},
                _ingest_ts: Number.isFinite(tsMs) ? tsMs : null,
              };
            } catch {
              return null;
            }
          });

        const allTickers = (await Promise.all(tickerDataPromises)).filter(Boolean);

        // Staleness check: alert if too many tickers have data older than 2 hours
        const nowMs = Date.now();
        let staleCount = 0;
        let veryStaleCount = 0;
        const STALE_MIN = 30;
        const VERY_STALE_MIN = 120;
        for (const t of allTickers) {
          const ts = t._ingest_ts;
          if (!ts || !Number.isFinite(ts)) { veryStaleCount++; continue; }
          const ageMin = (nowMs - ts) / 60000;
          if (ageMin > VERY_STALE_MIN) veryStaleCount++;
          else if (ageMin > STALE_MIN) staleCount++;
        }
        const totalWithData = allTickers.length;
        const stalePct = totalWithData > 0 ? (veryStaleCount / totalWithData) * 100 : 0;
        if (veryStaleCount >= 30 || stalePct >= 25) {
          try {
            await notifyDiscord(env, {
              content: null,
              embeds: [{
                title: "⚠️ Data Staleness Alert",
                color: 0xff9900,
                description: `${veryStaleCount} tickers have data older than 2 hours (${stalePct.toFixed(0)}%). ` +
                  `Stale: ${staleCount}. Check scoring cron, Alpaca bars, and D1 candle data.`,
                footer: { text: "Timed Trading • Staleness Monitor" },
                timestamp: new Date().toISOString(),
              }],
            });
            console.warn(`[STALENESS] Alert sent: ${veryStaleCount} very stale, ${staleCount} stale, ${stalePct.toFixed(0)}%`);
          } catch (e) {
            console.warn("[STALENESS] Discord notify failed:", String(e).slice(0, 100));
          }
        }

        // Generate proactive alerts
        const proactiveAlerts = generateProactiveAlerts(allTickers, allTrades);

        // Store high-priority alerts in KV for retrieval
        if (proactiveAlerts.filter((a) => a.priority === "high").length > 0) {
          const alertsKey = `timed:ai:alerts:${
            now.toISOString().split("T")[0]
          }`;
          const existingAlerts = (await kvGetJSON(KV, alertsKey)) || [];
          const newHighPriorityAlerts = proactiveAlerts
            .filter((a) => a.priority === "high")
            .map((a) => ({
              ...a,
              timestamp: now.toISOString(),
            }));

          // Merge and keep only last 50 alerts
          const updatedAlerts = [
            ...newHighPriorityAlerts,
            ...existingAlerts,
          ].slice(0, 50);
          await kvPutJSON(KV, alertsKey, updatedAlerts);

          console.log(
            `[PROACTIVE ALERTS] Generated ${proactiveAlerts.length} alerts, ${newHighPriorityAlerts.length} high-priority`,
          );
        }
      } catch (error) {
        console.error("[PROACTIVE ALERTS ERROR]", error);
      }
    }

    // AI Updates (only at specific times: 9:45 AM, noon, 3:30 PM ET)
    const isAITime =
      (hour === 14 && minute === 45) || // 9:45 AM ET
      (hour === 17 && minute === 0) || // 12:00 PM ET
      (hour === 20 && minute === 30); // 3:30 PM ET

    if (!isAITime) {
      return; // Only do AI updates at specific times
    }

    const openaiApiKey = env.OPENAI_API_KEY;
    if (!openaiApiKey) {
      console.error("[SCHEDULED] OpenAI API key not configured");
      return;
    }

    try {
      // Determine update time label
      let updateTime = "Market Update";
      if (hour === 14 && minute === 45) {
        updateTime = "Morning Market Update (9:45 AM ET)";
      } else if (hour === 17 && minute === 0) {
        updateTime = "Midday Market Update (12:00 PM ET)";
      } else if (hour === 20 && minute === 30) {
        updateTime = "Afternoon Market Update (3:30 PM ET)";
      }

      // Fetch all ticker data
      const allKeys = await KV.list({ prefix: "timed:latest:" });
      const tickerDataPromises = allKeys.keys.slice(0, 50).map(async (key) => {
        try {
          const data = await kvGetJSON(KV, key.name);
          if (data) {
            const ticker = key.name.replace("timed:latest:", "");
            return {
              ticker,
              rank: Number(data.rank) || 0,
              rr: Number(data.rr) || 0,
              price: Number(data.price) || 0,
              state: String(data.state || ""),
              phase_pct: Number(data.phase_pct) || 0,
              completion: Number(data.completion) || 0,
              flags: data.flags || {},
            };
          }
          return null;
        } catch (err) {
          return null;
        }
      });

      const allTickers = (await Promise.all(tickerDataPromises))
        .filter(Boolean)
        .sort((a, b) => (b.rank || 0) - (a.rank || 0));

      // Fetch recent activity
      const activityKeys = await KV.list({ prefix: "timed:activity:" });
      const activityPromises = activityKeys.keys.slice(-20).map(async (key) => {
        try {
          const data = await kvGetJSON(KV, key.name);
          if (data) {
            return {
              ticker: String(data.ticker || "UNKNOWN"),
              type: String(data.type || "event"),
              ts: Number(data.ts) || Date.now(),
              price: Number(data.price) || 0,
            };
          }
          return null;
        } catch (err) {
          return null;
        }
      });

      const activityEvents = (await Promise.all(activityPromises))
        .filter(Boolean)
        .sort((a, b) => b.ts - a.ts)
        .slice(0, 10);

      // Analyze for proactive alerts
      const primeSetups = allTickers.filter(
        (t) =>
          t.rank >= 75 &&
          t.rr >= 1.5 &&
          t.completion < 0.4 &&
          t.phase_pct < 0.6,
      );

      const highRiskPositions = allTickers.filter(
        (t) => t.completion > 0.7 || t.phase_pct > 0.8,
      );

      // Build monitoring prompt
      const monitoringPrompt = `You are providing a ${updateTime} for the Timed Trading platform.

## CURRENT MARKET DATA
- **${allTickers.length} total tickers** being monitored
- **${
        primeSetups.length
      } prime setups** (Rank ≥75, RR ≥1.5, Completion <40%, Phase <60%)
- **${
        highRiskPositions.length
      } high-risk positions** (Completion >70% or Phase >80%)
- **${activityEvents.length} recent activity events**

### Top Prime Setups:
${
  primeSetups
    .slice(0, 10)
    .map((t) => {
      const rr = Number(t.rr) || 0;
      const rrFormatted =
        rr >= 1 ? `${rr.toFixed(2)}:1` : `1:${(1 / rr).toFixed(2)}`;
      return `- **${t.ticker}**: Rank ${
        t.rank
      } | RR ${rrFormatted} | Price $${t.price.toFixed(2)} | Phase ${(
        t.phase_pct * 100
      ).toFixed(0)}% | Completion ${(t.completion * 100).toFixed(0)}%`;
    })
    .join("\n") || "None"
}

### Recent Activity:
${
  activityEvents
    .slice(0, 10)
    .map(
      (a) =>
        `- ${new Date(a.ts).toLocaleTimeString()}: **${a.ticker}** ${
          a.type
        } at $${a.price.toFixed(2)}`,
    )
    .join("\n") || "None"
}

Provide a concise market update with:
1. **🎯 Key Opportunities** (Top 3-5 setups to watch)
2. **⚠️ Warnings** (High-risk positions or market conditions)
3. **📊 Market Insights** (Overall conditions, trends)

Be concise (3-5 sentences per section).`;

      // Call OpenAI API
      const aiResponse = await fetch(
        "https://api.openai.com/v1/chat/completions",
        {
          method: "POST",
          headers: {
            Authorization: `Bearer ${openaiApiKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model:
              env.OPENAI_MODEL && env.OPENAI_MODEL !== "gpt-4"
                ? env.OPENAI_MODEL
                : "gpt-3.5-turbo",
            messages: [{ role: "system", content: monitoringPrompt }],
            temperature: 0.7,
            max_tokens: 800,
          }),
        },
      );

      if (!aiResponse.ok) {
        throw new Error(`OpenAI API error: ${aiResponse.status}`);
      }

      const aiData = await aiResponse.json();
      const aiMessage =
        aiData.choices?.[0]?.message?.content || "Market update unavailable.";

      // Store update in KV
      const updateKey = `timed:ai:update:${
        now.toISOString().split("T")[0]
      }:${hour}:${minute}`;
      const updateData = {
        timestamp: now.toISOString(),
        updateTime,
        analysis: aiMessage,
        stats: {
          totalTickers: allTickers.length,
          primeSetups: primeSetups.length,
          highRiskPositions: highRiskPositions.length,
          recentActivity: activityEvents.length,
        },
      };

      await KV.put(updateKey, JSON.stringify(updateData));

      // Also store in a list for easy retrieval
      const updatesListKey = `timed:ai:updates:list`;
      const existingList = (await kvGetJSON(KV, updatesListKey)) || [];
      existingList.unshift({
        key: updateKey,
        timestamp: now.toISOString(),
        updateTime,
      });
      // Keep only last 30 updates
      await KV.put(updatesListKey, JSON.stringify(existingList.slice(0, 30)));

      console.log(
        `[SCHEDULED] Generated ${updateTime} at ${now.toISOString()}`,
      );
    } catch (error) {
      console.error("[SCHEDULED ERROR]", error);
    }

    // ML Model Training (every 6 hours)
    // Train model from labeled queue entries
    try {
      const result = await mlV1TrainFromQueue(env, KV, 75);
      if (result.ok && result.trained > 0) {
        console.log(
          `[ML TRAINING] Trained on ${result.trained} examples, model n=${result.model_n}`,
        );
      } else if (result.ok) {
        console.log(`[ML TRAINING] No new labels ready for training`);
      }
    } catch (error) {
      console.error("[ML TRAINING ERROR]", error);
    }
  },
};

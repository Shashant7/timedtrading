# Lessons Learned

> Update after ANY correction from the user.
> Review at session start. Ruthlessly iterate until mistake rate drops.

## Patterns to Avoid

- **Don't block gold_short entries with direction mismatch checks**: Gold SHORT is an intentional mean-reversion play on HTF_BULL_LTF_BULL blow-off tops. 82.7% of big DOWN moves start from BULL state. The fix should only block entries WITHOUT a recognized entry path. [2026-02-06]
- **Don't use below_trigger exit on tiny price dips**: A 0.04% dip below anchor price is noise, not a signal. Require at least 0.3% adverse move before flagging trigger invalidation. Winner median gain is 1.0%, so sub-0.3% dips are normal. [2026-02-06]
- **Don't use 30-minute recent trade window**: Too aggressive for replay and prevents re-entry after quick exits. 10 minutes is sufficient to prevent churning. [2026-02-06]
- **Always check purge-ticker cleans BOTH KV and D1**: KV trades and D1 positions/lots/events must be cleaned together, otherwise dashboard shows stale cards. [2026-02-06]

## Rules to Prevent Mistakes

- When modifying trade direction logic: verify gold_short and gold_long entry paths are preserved
- When modifying exit triggers: ensure minimum adverse move thresholds prevent noise exits
- When cleaning up trades: always purge from both KV and D1 (use /timed/debug/purge-ticker)
- After any trade simulation changes: reset + replay to verify with clean data
- **Deploy worker to BOTH environments**: wrangler.toml has both top-level and `[env.production]` configs with identical cron triggers. Always deploy with BOTH commands: `cd worker && npx wrangler deploy && npx wrangler deploy --env production`. The cron may run from either environment. Deploying only one leaves the other running stale code. Verify with `_debug` marker in KV output that new code is actually executing. [2026-02-11]
- **Keep backfill script tickers in sync with SECTOR_MAP**: Use `require('../worker/sector-mapping.js')` instead of a hardcoded list to avoid drift. [2026-02-06]
- **D1 schema migrations need fallback handling**: When adding columns (e.g., `session`) via ALTER TABLE, the throttle can prevent the migration from running. SELECT and INSERT queries must not reference the new column until migration confirms. Use a fallback INSERT without the column, and SELECT only core columns. [2026-02-07]
- **New scoring fields need backward-compatible gates**: When adding new precision scoring fields (fuel gauge, ST support, etc.) to `qualifiesForEnter()` and `classifyKanbanStage()`, always check if the data exists before gating on it. Old KV data won't have the fields. Use `d?.field != null` checks. [2026-02-07]
- **Use `enrichResult()` wrapper for cross-cutting entry enrichments**: Rather than modifying every `return { qualifies: true }` individually, use a wrapper function that applies Golden Gate boosts, precision metrics, etc. to all qualifying entries consistently. [2026-02-07]
- **Use daily candles for price performance, not trail data**: For 5D/15D/30D/90D price change calculations, use `ticker_candles` (tf='D') — actual market close prices with 400+ days of history. Trail data (timed_trail/trail_5m_facts) is for scoring snapshots, not price lookbacks. Mixing them causes gaps, dedup complexity, and inaccurate prices from intraday snapshots. [2026-02-08]
- **Alpaca uses BRK.B not BRK-B**: Alpaca API rejects `BRK-B` (HTTP 400). The correct symbol format is `BRK.B` with a dot. A single bad symbol in a batch request fails the entire batch. [2026-02-08]
- **CORS wildcard needs explicit handling**: When `CORS_ALLOW_ORIGIN = "*"`, splitting by comma gives `["*"]` which is length 1, not 0. The `allowedOrigins.includes(origin)` check doesn't match `"*"` against `"http://localhost:8765"`. Must explicitly check `allowedOrigins.includes("*")` as an early exit to `allowed = "*"`. [2026-02-08]
- **Pattern matching in hot path needs in-memory cache**: D1 queries on every ingest (270+ tickers × every minute) would be too expensive. Cache the 17 active patterns in memory with a 5-minute TTL. Pattern matching itself is synchronous and fast — it's the D1 read that needs caching. [2026-02-08]
- **Pattern integration should boost, not gate**: Pattern matching enhances Kanban decisions but never overrides them. A "pattern boost" upgrades entry confidence or promotes watch→setup, but a pattern mismatch never blocks an entry that the rule-based system qualifies. This preserves system stability while the model learns. [2026-02-08]
- **Compiled JS must match source format**: If `shared-right-rail.compiled.js` is loaded via `<script>`, it must be pre-transpiled (no JSX). If the source uses JSX, change the script tag to `type="text/babel"` so Babel standalone processes it at runtime. [2026-02-08]
- **Snap intraday candle timestamps to timeframe boundaries**: Raw candle timestamps from the DB may not align cleanly to timeframe intervals (e.g., a 10m candle at 9:33 instead of 9:30). Snap with `Math.floor(ts / intervalMs) * intervalMs` and re-aggregate duplicates. [2026-02-08]
- **Compute technical overlays client-side from candle data**: EMAs, SuperTrend, ATR — all computable from OHLC candle arrays in the browser. No need for additional API calls. EMA: seed with SMA, then apply exponential smoothing. SuperTrend: ATR-based with directional flips. [2026-02-08]
- **Right rail overlay must use opaque background**: When the right rail slides over the main content, its container must use an opaque background (e.g., `bg-[#0b0e11]`) not a transparent one (e.g., `bg-white/[0.02]`). Transparent overlays let the underlying dashboard bleed through and are unreadable. [2026-02-08]
- **Bulk sed color replacements need syntax verification**: When doing bulk `sed` replacements across large JSX files (e.g., `bg-[#161922]` → `bg-white/[0.02]`), verify no broken syntax results. Tailwind arbitrary values with `/` (opacity) inside JSX strings are valid, but context matters. Also: Babel takes longer on files >500KB — the render timeout may fire before transpilation finishes. [2026-02-08]
- **Server-side TD Sequential replaces TradingView webhook dependency**: Computing DeMark Sequential (TD9/TD13) from D/W/M candles in the worker removes the dependency on TradingView Pine Script webhooks. Alpaca's `1Month` timeframe gives accurate monthly OHLCV without needing to derive from daily candles. The `normalizeTfKey` function must handle "M" without colliding with "1M" (which maps to 1-minute). [2026-02-08]
- **Model features should include all signal sources**: When adding new indicator computations (like TD Sequential), always integrate them into the self-learning model's feature vector (`flags_json`), prediction triggers (`shouldLogPrediction`), and outcome tracking. Without this, the model can't learn from the new signals. [2026-02-08]
- **Alpaca multi-symbol `limit` is TOTAL not per-symbol**: The `/v2/stocks/bars` endpoint's `limit` param caps the TOTAL bars across ALL symbols, sorted by symbol then timestamp. With `limit=5` and 141 symbols, you get 5 bars for the first alphabetical symbol and nothing else. Use `alpacaFetchAllBars` with `limit=10000` + pagination. [2026-02-09]
- **One bad symbol fails the entire Alpaca batch**: Alpaca returns HTTP 400 for invalid symbols (futures like `ES1!`, indices like `US500`, dashes like `BRK-B`). A single bad symbol in the `symbols=` param rejects the ENTIRE request. Always filter the ticker list before Alpaca API calls. [2026-02-09]
- **D1 has 1000 subrequests per Worker invocation**: Individual `d1UpsertCandle()` calls in a loop will hit "Too many API requests" with >1000 candles. Use `db.batch()` (max 500 statements per call) to write in bulk. This applies to cron handlers AND the `/timed/ingest-candles` endpoint. [2026-02-09]
- **Every price source should build candles**: TradingView ingests, Alpaca price feed snapshots, and capture heartbeats all provide price data every ~1 min. All three should upsert 1m candles to `ticker_candles` using merge semantics (`MAX(h)`, `MIN(l)`, latest `c`). This gives triple-redundant coverage. [2026-02-09]
- **D1 batch reads save 10x subrequests in scoring crons**: Scoring 140 tickers × 9 TFs = 1260 individual D1 reads, exceeding the 1000 limit. Use `db.batch()` for reads too (not just writes): fetch all 9 TFs for one ticker in a single batch call, then pass a cache-based `getCandles` function to the scoring engine. Also batch trail writes (100+ individual → 1 batch). [2026-02-09]
- **Candle-replay trades must persist to D1, not just KV**: The scoring cron (`*/5 * * * *`) overwrites `timed:trades:all` in KV. If candle-replay only writes to KV, trades vanish within 5 minutes. Always `d1UpsertTrade()` for each batch's trades so they survive cron overwrites. [2026-02-09]
- **Set `exit_ts` on ALL exit code paths**: The main EXIT handler and the `closeTradeAtPrice` function both set `exitPrice` but neither was setting `exit_ts`. Both paths need `trade.exit_ts = asOfMs || Date.now()`. Without it, closed trades show "—" for exit date. [2026-02-09]
- **RTH entry cutoff is 3:59 PM, not 4:00 PM**: `isNyRegularMarketOpen` should use `mins < 960` (exclusive), not `mins <= 960` (inclusive). At 4:00 PM the market is closed — no new entries should be allowed at the closing bell. [2026-02-09]
- **Replay with coarse candle data produces $0 P&L "WIN" trades**: When a ticker's 5-minute candles only update every 30+ minutes (e.g., CCJ), the price stays flat from entry to exit. Entering at 9:30 and exiting at 9:55 at the same price yields $0 P&L labeled "WIN" (since `0 >= 0`). UI should show "FLAT" for ~0% P&L trades. [2026-02-09]
- **`alpacaBackfill()` must use batch D1 writes, not individual upserts**: The original implementation called `d1UpsertCandle()` per bar (one D1 round-trip each). For 9 TFs × ~500 bars = ~4500 calls, this silently exceeded D1 subrequest limits, resulting in sparse/incomplete candle data (e.g., CCJ had only 606 5m candles scattered across 8 dates). After switching to `db.batch()` with 500-statement chunks, a single ticker's backfill writes ~14K bars in ~10 seconds with 0 errors. [2026-02-09]
- **Coverage metrics must check data QUALITY, not just row count**: The ingestion-status endpoint reported CCJ as "100% coverage" because it had 606 5m candles ≥ 500 expected. But those 606 candles were scattered across 8 random dates with 6-day gaps — useless for replay. Added quality scoring that factors in: freshness (hours since latest candle), gap detection (distinct trading dates in last 30 days vs expected 21), and count. CCJ's "100% pct" became "74% quality" for 5m, correctly revealing the problem. [2026-02-09]
- **Replay must enforce the same cooldowns as live mode**: `processTradeSimulation` was using `isReplay ? {} : kvGet(...)` for `execState`, making ALL cooldowns (`ENTER_COOLDOWN_MS=4h`, `recentTradeBlocked=10m`) return `true` during replay. This caused catastrophic churn: RBLX had 11 trades in one day, PATH had 11, FSLR had 9 — all with 5-minute exit-to-re-entry gaps. Fix: pass an in-memory `execStates` Map via `replayBatchContext` that persists across intervals, mirroring the KV writes live mode uses. Also fix `recentTradeBlocked` to check `exit_ts` (not just `entry_ts`) and extend window to 30 minutes. Result: 149 trades → 89, with zero rapid re-entries. [2026-02-10]
- **Replay cleanSlate must purge D1, not just KV**: The `candle-replay` endpoint's `cleanSlate=1` only cleared KV (`timed:trades:all`, portfolio, activity feed). D1 `trades`, `trade_events`, `positions` tables were untouched. After live trading ran alongside replay data, D1 accumulated 200+ trades (89 replay + 100+ live). The simulation dashboard reads from D1, so it showed inflated metrics. Fix: add `db.batch()` DELETEs for all trade-related tables when `cleanSlate && tickerOffset === 0`. [2026-02-10]
- **$0 P&L trades should be FLAT, not WIN**: When `realizedPnl >= 0` includes `== 0`, trades that enter and exit at the same candle close price get labeled "WIN" with $0. This inflates win rate. Changed to `> 0 ? "WIN" : < 0 ? "LOSS" : "FLAT"`. Also added a flat-price exit guard: if the current price hasn't moved >0.1% from entry and the exit reason isn't SL, skip the exit and keep holding. This prevents 21 out of 126 closed trades (16.7%) from being noise. [2026-02-10]
- **pnlPct needs a fallback when trade.notional is null**: During replay, portfolio cash can run out, making `tradeNotionalFromConfidence()` return null. The `closeTradeAtPrice` then computes `pnlPct = null` since it divides by `trade.notional`. Added fallback: compute from `trade.pnl / (trade.entryPrice * trade.shares)` when notional is missing. [2026-02-10]
- **GET /timed/trades must include open positions for card entry price**: When using D1, the default response comes from the `trades` table. Open positions may live only in the `positions` table (Phase 2). Merge open positions from `d1GetAllPositionsAsTrades` into the trades list so the dashboard's tradeByTicker has entry_price for tickers in the Hold lane (e.g. TT, ULTA). [2026-02-10]
- **Right rail stage and move when in Hold**: When a ticker has an open position, the card is forced into the Hold lane but the server may still have kanban_stage "watch". Pass effectiveStage (e.g. "hold") from the dashboard to the right rail so it shows "Hold" not "Watching". When move_status is NONE or missing but ledger has an open trade, show Move: ACTIVE. [2026-02-10]
- **Trail data drives the model analysis scripts**: The `analyze-historical-movers.js`, `analyze-big-movers.js`, and `analyze-gold-patterns.js` scripts read from `timed_trail` (D1), not directly from `ticker_candles`. Trail data includes computed scores, states, flags, and signals per 5-min interval. After a single-day replay, only ~150 rows exist per ticker (2 days). Meaningful model recalibration requires weeks/months of trail data, built by running multi-day replays or accumulated from live scoring. [2026-02-10]
- **Trade lifecycle: frontend AND server read-time recompute must pass open position context**: The frontend kanban categoriser and the `/timed/latest` read-time recompute both called `classifyKanbanStage(data)` without open position context. This caused tickers with open trades to regress from management lanes (hold/defend/trim) to discovery lanes (setup/enter) when scoring conditions changed. The server's `/timed/all` path was correct (loaded `openPositionsMap` first). Fix: (1) Frontend override: if `tradeByTicker.has(sym) && trade.status === OPEN`, force stage to at least "hold". (2) Server `/timed/latest`: call `getPositionContext(env, ticker)` before `classifyKanbanStage`. (3) Card background: always layer `getCardSkin().bgImage` over the base, not replace it with a static gradient. [2026-02-10]
- **Kanban lanes must separate signal quality from execution readiness**: `qualifiesForEnter()` validates signal quality (scores, confirmation, RSI, R:R). Execution gates (RTH, position limits, cooldowns, cash) are separate Stage 2 checks in `processTradeSimulation`. When only Stage 1 passes, the ticker should show in SETUP (entry qualified but blocked), not ENTER (all gates clear, system will execute). Without this separation, users see ENTER but no trade fires — destroying trust. Fix: (1) After `processTradeSimulation` blocks an entry, downgrade stored KV stage from "enter" → "setup" with block reason. (2) In `classifyKanbanStage`, check `__execution_ready` flag. (3) Read-time recompute (`/timed/latest`) pre-checks RTH + position limits. [2026-02-10]
- **57 open positions blocked ALL new entries via MAX_OPEN_POSITIONS=8**: Accumulated unclosed positions from replay runs + live trading clogged the pipeline. The position limit check queries `COUNT(*) FROM positions WHERE status='OPEN'`, so any lingering replay or manual positions count against the limit. Stale open positions must be cleaned up after replay runs or batch-closed if they exceed the position cap. [2026-02-10]
- **/timed/all short-circuits preserved stale "enter" stages**: The `/timed/all` path preserves stored `prevStage` for discovery stages to avoid lane-flipping on read. But "enter" is a discovery stage, so it was NEVER re-evaluated through `classifyKanbanStage`. Even after adding `__execution_ready=false`, tickers stayed in "enter" indefinitely because the classifier was never called. Fix: always re-classify "enter"/"enter_now" stages through `classifyKanbanStage` so the execution readiness check can downgrade them to "setup". [2026-02-10]
- **Hard position limits are a blunt instrument — use smart concentration gates**: `MAX_OPEN_POSITIONS=8` blocked ALL entries once 8 positions were open, regardless of quality or diversification. Replaced with: (1) sector concentration cap (max 3 per sector), (2) directional cap (max 5 same-direction), (3) correlation guard (sector proxy: 2+ in same sector raises quality bar to 75). This allows unlimited total positions while preventing concentration risk. The daily entry limit (10) remains as a safety net against runaway crons. [2026-02-10]
- **Live entries MUST use current market price, not stale tickerData.entry_price**: The `entryPxCandidate` fallback chain preferred `tickerData.entry_price` (set when the scoring signal first fired, potentially hours/days ago) over `pxNow` (current market). ULTA entered at $700.43 (yesterday's price) when the stock was trading at $688. Fix: for live mode, always use `pxNow` as entry price. For replay, keep the old fallback chain since `pxNow` is the replay candle close. Also log warnings when stored entry_price diverges >1% from market. [2026-02-10]
- **Indicator completion != position completion for TRIM classification**: `computeCompletionToTpMax` measures progress from trigger_price to TP (indicator-level), not from entry_price to TP (position-level). CAT entered at $738 near the indicator's 86% completion point, immediately triggering TRIM even though the position had barely moved. Fix: (1) Use position-aware completion `(currentPrice - entryPrice) / (TP - entryPrice)` for `isNearTp`. (2) Add 30-min + <3% P&L guard before allowing TRIM on new positions. [2026-02-10]
- **CF Access sign out requires redirect to logout endpoint**: `clearSession()` + `window.location.reload()` only clears localStorage. The CF Access JWT cookie persists across reloads, so the user is immediately re-authenticated. Fix: redirect to `https://<team>.cloudflareaccess.com/cdn-cgi/access/logout` which invalidates the session cookie. [2026-02-10]
- **Ingestion-status must include all watchlist tickers, not only those with candle data**: The ticker list was built from SECTOR_MAP + byTicker (D1 candle counts), so newly added tickers (e.g. W) never appeared until they had candles. Fix: build report from canonical list (KV timed:tickers minus timed:removed); include rows with 0% coverage and empty tfs so new tickers show immediately. [2026-02-10]
- **Add ticker: validate against Alpaca Assets API first**: Check equity symbols (exclude futures 1!) with GET /v2/assets/{symbol}. If not tradable or 404, return alpaca_symbol_not_found with invalid list so the user knows before adding. Use ALPACA_API_BASE (default paper-api.alpaca.markets); set to api.alpaca.markets for live. [2026-02-10]
- **Backfill default for new tickers: previous 30 days**: alpacaBackfill() accepts optional sinceDays; when set, all TFs use one start date (now - sinceDays). Watchlist add uses 30; admin backfill can pass ?sinceDays=30 or omit for deep history. [2026-02-10]
- **Guide and UI copy: match file encoding**: When replacing long JSX strings in index-react.html, the file uses curly apostrophes (U+2019). Search-replace with straight quotes fails; use Node script or exact character when editing. [2026-02-10]
- **Price feed fallback for tickers missing from Alpaca**: Single-letter or other symbols (e.g. ticker "W" / Wayfair) can be omitted or delayed in Alpaca’s snapshot response. If we only use snapshots, those tickers get no entry in `timed:prices` and the UI shows stale or wrong price. Fix: after building prices from snapshots (and TV futures merge), for any watchlist ticker missing or with invalid price, backfill from D1 latest 1m candle or KV `timed:latest:{ticker}`. Apply the same fallback in POST /timed/admin/refresh-prices. [2026-02-10]
- **Worker has its own SECTOR_MAP; keep in sync with sector-mapping.js**: The worker inline SECTOR_MAP in index.js is used for /timed/all (activeSet) and watchlist filtering. sector-mapping.js is used elsewhere (e.g. Alpaca backfill). When adding a ticker (e.g. W) to sector-mapping.js, also add it to the worker SECTOR_MAP in index.js so the ticker appears on the Dashboard and Tickers Page. [2026-02-10]
- **Re-added tickers need ticker_latest row**: When adding or re-adding a ticker via watchlist add, upsert a minimal ticker_latest row so /timed/all returns it and the Dashboard shows it. GET /timed/tickers merges D1 ticker_index with (timed:tickers minus timed:removed) so watchlist tickers always appear. [2026-02-10]
- **Tickers UI must merge GET /timed/tickers with ingestion-status**: The Tickers page uses ingestion-status for coverage; if a ticker (e.g. W) is in the watchlist but missing from ingestion-status (replication delay or different worker), it disappears after refresh or when navigating back. Fetch GET /timed/tickers as well and merge: show a placeholder row for any ticker in the watchlist that is not in the ingestion-status report so the ticker persists. [2026-02-10]
- **Single source of truth: getDailyChange must include live feed priority path**: The simulation-dashboard.html had an older getDailyChange() that didn't check `_live_*` fields from the price feed. This caused daily change values to come from stale scoring snapshots instead of live Alpaca/TradingView data. Fix: extract getDailyChange, getStaleInfo, and helper functions into shared-price-utils.js loaded by all pages. [2026-02-10]
- **Enrich /timed/all with timed:prices KV for consistent initial load**: The initial page load from /timed/all used per-ticker heartbeat overlay (N KV reads) but not the canonical timed:prices KV (single read). This meant prices on first render could differ from what usePriceFeed delivered 30s later. Fix: after the heartbeat overlay, read timed:prices KV and merge _live_* fields, making the initial load match the price feed. Works for both Alpaca stocks and TradingView futures since timed:prices already contains both. [2026-02-10]
- **Trail-correct entry price for position-sourced trades in /timed/trades merge**: When positions are merged into the /timed/trades response, they used VWAP (cost_basis/total_qty) while D1-sourced trades used trail-corrected entry prices. This caused inconsistent entry prices for the same trade. Fix: apply getPriceFromTrailAtTimestamp to newly-added position trades during the merge. [2026-02-10]
- **Alpaca latestTrade can be a stale low-volume AH trade**: `latestTrade.p` is not always the best price — e.g. ULTA showed $675 (a single 100-share AH trade) when the actual close was $679.28 and bid/ask was $679.29/$682. Fix: in `parseStockSnap`, if `latestTrade` is >5 min old and diverges >0.5% from the quote midpoint (or dailyBar.c), use the quote midpoint instead. This gives accurate prices during after-hours without losing real-time accuracy during RTH. [2026-02-10]
- **Kanban card entry_price priority**: The card read `t?.entry_price` from the scoring snapshot first, falling back to `openTrade.entryPrice` only if missing. But scoring snapshots can have stale entry prices (e.g. ULTA $700.43 vs trail-corrected $688.28). Fix: prefer `openTrade.entryPrice` (trail-corrected, from /timed/trades) when an open trade exists, fall back to ticker payload only when the trade doesn't have one. [2026-02-10]
- **timed:removed blocklist persists after re-adding tickers**: When tickers are added to SECTOR_MAP directly (not via the POST /timed/watchlist/add endpoint), they are NOT removed from the `timed:removed` KV blocklist. The `POST /timed/watchlist/add` code correctly un-removes tickers (line 20268: `blocklist.delete(tickerUpper)`), but manual additions bypass this. Fix: when adding tickers to SECTOR_MAP manually, also clean the timed:removed KV list. The /timed/all endpoint filters by `SECTOR_MAP minus timed:removed`, so stale removed entries silently block tickers. [2026-02-11]
- **69 missing tickers caused permanent "Backfilling" on Ticker Management**: Tickers in the watchlist (timed:tickers KV or D1 ticker_tickers) but NOT in SECTOR_MAP were invisible to /timed/all, the scoring cron, and the price feed cron. They showed "Backfilling" forever because ingestion-status had no candle data and they never received scores. Fix: add all watchlist tickers to SECTOR_MAP, run alpaca-backfill + alpaca-compute for each, and clean the timed:removed blocklist. The 1-minute price feed cron and 5-minute scoring cron use Object.keys(SECTOR_MAP) as their universe. [2026-02-11]
- **Worker ROUTES array must include new endpoints**: The worker uses a `ROUTES` lookup array at the top of index.js with `getRouteKey()` to match incoming requests. If a new endpoint (e.g. `POST /timed/accept-terms`) is added as an `if (routeKey ===)` handler but NOT registered in the ROUTES array, it will return `not_found`. Always add new routes to both the ROUTES array AND the handler section. [2026-02-11]
- **Read-time recompute must CLEAR stale block reasons, not just SET new ones**: The scoring cron stores `__entry_block_reason` in KV. The `/timed/all` read-time check computes a fresh `__execution_block_reason` but never cleared the stale `__entry_block_reason`. The card UI shows whichever is set first (`t?.__entry_block_reason || t?.__execution_block_reason`), so the stale cron value wins even during market hours. Fix: when the read-time check finds NO block reasons, explicitly `delete obj.__entry_block_reason` and `delete obj.__execution_block_reason` and set `__execution_ready = true`. [2026-02-11]
- **Use `isNyRegularMarketOpen()` (formatToParts) not `toLocaleString` + Date parsing for RTH**: The pattern `new Date(new Date().toLocaleString("en-US", {timeZone}))` is brittle on Cloudflare Workers because Date parsing of locale strings is implementation-dependent. The dedicated `isNyRegularMarketOpen()` function uses `Intl.DateTimeFormat.formatToParts()` which is reliable across all runtimes. [2026-02-11]
- **React onWheel is passive — use native addEventListener for chart zoom**: React registers `onWheel` as a passive event listener since React 17+. `e.preventDefault()` in an `onWheel` handler is silently ignored, causing the page to scroll instead of zooming the chart. Fix: attach a native (non-passive) wheel listener via `useEffect` on the container DOM element: `el.addEventListener("wheel", handler, { passive: false })`. Store chart computation state in a ref (`chartStateRef`) so the native handler can access it. [2026-02-11]
- **Drag-to-pan needs window-level mouse tracking**: SVG `onMouseMove`/`onMouseUp` only fire while cursor is over the SVG. Fast drags cause the cursor to leave the element, leaving `chartDragRef.current` stuck. Fix: attach `mousemove` and `mouseup` on `window` in a `useEffect`, and only set `chartDragRef.current` on `mousedown`. [2026-02-11]
- **Two deployment targets: Worker (npm run deploy) + Pages (git push)**: Static files like `shared-right-rail.compiled.js` are served by Cloudflare Pages (auto-deploys from git push to `main`). API endpoints are served by the Cloudflare Worker (deployed via `wrangler deploy`). Changing only the right rail JS requires BOTH a git push (for Pages) AND `npm run deploy` (for the embedded dashboard HTML cache buster). Always update the `?v=` cache buster on the `<script>` tags in both HTML files. [2026-02-11]
- **Worker routes go through /timed/* prefix on custom domain**: The custom domain `timed-trading.com` routes `/timed/*` to the Cloudflare Worker; all other paths serve from Cloudflare Pages (static files). New Worker endpoints (including WebSocket upgrade) must use the `/timed/` prefix (e.g. `/timed/ws` not `/ws`). [2026-02-11]
- **Durable Object WebSocket Hibernation API**: Use `state.acceptWebSocket(ws, tags)` for WebSocket connections in a Durable Object — hibernated connections cost $0 in duration charges. The DO wakes up only when a message arrives or the Worker POSTs to it. Tags persist across hibernation but in-memory properties on `ws` (like `ws._subscribedTickers`) do not. For persistent per-socket state, use `state.getWebSocketAutoResponseTimestamp()` or external storage. [2026-02-11]
- **Forwarding WebSocket upgrade to Durable Object — must pass original request**: `new Request(url, { method: req.method, headers: req.headers })` drops the internal WebSocket upgrade state, causing the connection to fail silently. Must use `new Request(newUrl, originalRequest)` which copies the full request including upgrade semantics. The second argument to `new Request()` is the `RequestInit` or another `Request` — when it's a `Request`, all internal state (body, signal, WebSocket upgrade) is preserved. [2026-02-11]